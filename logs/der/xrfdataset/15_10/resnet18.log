2025-02-18 23:13:04,265 [trainer.py] => 实验名称:resnet18对比实验
2025-02-18 23:13:04,283 [trainer.py] => config: ./exps/der.json
2025-02-18 23:13:04,283 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-18 23:13:04,283 [trainer.py] => prefix: reproduce
2025-02-18 23:13:04,283 [trainer.py] => dataset: xrfdataset
2025-02-18 23:13:04,283 [trainer.py] => memory_size: 1650
2025-02-18 23:13:04,284 [trainer.py] => memory_per_class: 30
2025-02-18 23:13:04,284 [trainer.py] => fixed_memory: True
2025-02-18 23:13:04,284 [trainer.py] => shuffle: True
2025-02-18 23:13:04,284 [trainer.py] => init_cls: 15
2025-02-18 23:13:04,284 [trainer.py] => increment: 10
2025-02-18 23:13:04,284 [trainer.py] => model_name: der
2025-02-18 23:13:04,284 [trainer.py] => compression_epochs: 1
2025-02-18 23:13:04,284 [trainer.py] => compression_lr: 0.1
2025-02-18 23:13:04,284 [trainer.py] => is_student_wa: False
2025-02-18 23:13:04,284 [trainer.py] => wa_value: 1
2025-02-18 23:13:04,284 [trainer.py] => T: 2
2025-02-18 23:13:04,284 [trainer.py] => convnet_type: resnet18
2025-02-18 23:13:04,284 [trainer.py] => device: [device(type='cuda', index=1), device(type='cuda', index=2)]
2025-02-18 23:13:04,284 [trainer.py] => seed: 1993
2025-02-18 23:13:04,373 [data.py] => 加载完毕XRF原始数据集
2025-02-18 23:13:04,394 [data.py] => 加载完毕XRF原始数据集
2025-02-18 23:13:04,394 [trainer.py] => All params: 0
2025-02-18 23:13:04,394 [trainer.py] => Trainable params: 0
2025-02-18 23:13:04,653 [der.py] => Learning on 0-15
2025-02-18 23:13:04,653 [der.py] => All params: 4122015
2025-02-18 23:13:04,653 [der.py] => Trainable params: 4122015
2025-02-18 23:17:10,720 [der.py] => Task 0, Epoch 1/1 => Loss 4.105, Train_accy 8.48, Test_accy 7.56
2025-02-18 23:17:10,721 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-18 23:17:36,057 [der.py] => Exemplar size: 450
2025-02-18 23:17:36,058 [trainer.py] => CNN: {'total': 7.56, '0': 0.0, '1': 0.0, '2': 0.0, '3': 91.11, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 18.33, '9': 0.0, '10': 0.0, '11': 3.33, '12': 0.0, '13': 0.0, 'old': 0, 'new': 7.56}
2025-02-18 23:17:36,058 [trainer.py] => NME: {'total': 11.67, '0': 62.78, '1': 0.56, '2': 6.67, '3': 0.0, '4': 0.0, '5': 0.0, '6': 16.11, '7': 21.11, '8': 0.0, '9': 1.67, '10': 63.89, '11': 2.22, '12': 0.0, '13': 0.0, 'old': 0, 'new': 11.67}
2025-02-18 23:17:36,058 [trainer.py] => CNN top1 curve: [7.56]
2025-02-18 23:17:36,058 [trainer.py] => CNN top5 curve: [36.85]
2025-02-18 23:17:36,058 [trainer.py] => NME top1 curve: [11.67]
2025-02-18 23:17:36,058 [trainer.py] => NME top5 curve: [46.67]

2025-02-18 23:17:36,058 [trainer.py] => All params: 4122015
2025-02-18 23:17:36,058 [trainer.py] => Trainable params: 4122015
2025-02-18 23:17:36,126 [der.py] => Learning on 15-25
2025-02-18 23:17:36,126 [der.py] => All params: 8243492
2025-02-18 23:17:36,127 [der.py] => Trainable params: 4137380
2025-02-18 23:17:36,191 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-18 23:17:36,192 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-18 23:20:08,621 [der.py] => Task 1, Epoch 1/1 => Loss 16.788, Loss_clf 16.788, Loss_aux 2.465, Train_accy 8.34, Test_accy 4.49
2025-02-18 23:20:33,976 [trainer.py] => 实验名称:resnet18对比实验
2025-02-18 23:20:33,977 [trainer.py] => config: ./exps/der.json
2025-02-18 23:20:33,977 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-18 23:20:33,977 [trainer.py] => prefix: reproduce
2025-02-18 23:20:33,977 [trainer.py] => dataset: xrfdataset
2025-02-18 23:20:33,977 [trainer.py] => memory_size: 1650
2025-02-18 23:20:33,977 [trainer.py] => memory_per_class: 30
2025-02-18 23:20:33,977 [trainer.py] => fixed_memory: True
2025-02-18 23:20:33,977 [trainer.py] => shuffle: True
2025-02-18 23:20:33,977 [trainer.py] => init_cls: 15
2025-02-18 23:20:33,977 [trainer.py] => increment: 10
2025-02-18 23:20:33,977 [trainer.py] => model_name: der
2025-02-18 23:20:33,977 [trainer.py] => compression_epochs: 1
2025-02-18 23:20:33,977 [trainer.py] => compression_lr: 0.1
2025-02-18 23:20:33,977 [trainer.py] => is_student_wa: False
2025-02-18 23:20:33,977 [trainer.py] => wa_value: 1
2025-02-18 23:20:33,977 [trainer.py] => T: 2
2025-02-18 23:20:33,977 [trainer.py] => convnet_type: resnet18
2025-02-18 23:20:33,977 [trainer.py] => device: [device(type='cuda', index=1), device(type='cuda', index=2)]
2025-02-18 23:20:33,977 [trainer.py] => seed: 1993
2025-02-18 23:20:33,989 [data.py] => 加载完毕XRF原始数据集
2025-02-18 23:20:33,994 [data.py] => 加载完毕XRF原始数据集
2025-02-18 23:20:33,995 [trainer.py] => All params: 0
2025-02-18 23:20:33,995 [trainer.py] => Trainable params: 0
2025-02-18 23:20:34,078 [der.py] => Learning on 0-15
2025-02-18 23:20:34,078 [der.py] => All params: 4122015
2025-02-18 23:20:34,078 [der.py] => Trainable params: 4122015
2025-02-18 23:20:50,480 [der.py] => Task 0, Epoch 1/1 => Loss 4.105, Train_accy 8.48, Test_accy 7.56
2025-02-18 23:20:50,481 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-18 23:21:16,170 [der.py] => Exemplar size: 450
2025-02-18 23:21:16,170 [trainer.py] => CNN: {'total': 7.56, '0': 0.0, '1': 0.0, '2': 0.0, '3': 91.11, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 18.33, '9': 0.0, '10': 0.0, '11': 3.33, '12': 0.0, '13': 0.0, 'old': 0, 'new': 7.56}
2025-02-18 23:21:16,170 [trainer.py] => NME: {'total': 11.67, '0': 62.78, '1': 0.56, '2': 6.67, '3': 0.0, '4': 0.0, '5': 0.0, '6': 16.11, '7': 21.11, '8': 0.0, '9': 1.67, '10': 63.89, '11': 2.22, '12': 0.0, '13': 0.0, 'old': 0, 'new': 11.67}
2025-02-18 23:21:16,170 [trainer.py] => CNN top1 curve: [7.56]
2025-02-18 23:21:16,170 [trainer.py] => CNN top5 curve: [36.85]
2025-02-18 23:21:16,170 [trainer.py] => NME top1 curve: [11.67]
2025-02-18 23:21:16,170 [trainer.py] => NME top5 curve: [46.67]

2025-02-18 23:21:16,171 [trainer.py] => All params: 4122015
2025-02-18 23:21:16,171 [trainer.py] => Trainable params: 4122015
2025-02-18 23:21:16,228 [der.py] => Learning on 15-25
2025-02-18 23:21:16,229 [der.py] => All params: 8243492
2025-02-18 23:21:16,230 [der.py] => Trainable params: 4137380
2025-02-18 23:21:16,295 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-18 23:21:16,296 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-18 23:21:25,407 [der.py] => Task 1, Epoch 1/1 => Loss 16.788, Loss_clf 16.788, Loss_aux 2.465, Train_accy 8.34, Test_accy 4.49
2025-02-18 23:21:34,980 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.769,  Train_accy 8.04, Test_accy 4.42
2025-02-18 23:21:34,981 [der.py] => do not weight align student!
2025-02-18 23:21:38,237 [der.py] => darknet eval: 
2025-02-18 23:21:38,237 [der.py] => CNN top1 curve: 4.42
2025-02-18 23:21:38,237 [der.py] => CNN top5 curve: 21.56
2025-02-18 23:21:38,238 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-18 23:22:05,476 [der.py] => Exemplar size: 750
2025-02-18 23:22:05,476 [trainer.py] => CNN: {'total': 4.31, '0': 23.33, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 76.67, '16': 0.0, '17': 0.56, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 6.67, '23': 0.56, 'old': 1.56, 'new': 8.44}
2025-02-18 23:22:05,476 [trainer.py] => NME: {'total': 7.82, '0': 55.0, '1': 0.0, '2': 4.44, '3': 0.0, '4': 0.0, '5': 0.0, '6': 11.11, '7': 24.44, '8': 0.0, '9': 9.44, '10': 63.89, '11': 4.44, '12': 2.22, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.56, '18': 0.0, '19': 19.44, '20': 0.0, '21': 0.56, '22': 0.0, '23': 0.0, 'old': 11.67, 'new': 2.06}
2025-02-18 23:22:05,476 [trainer.py] => CNN top1 curve: [7.56, 4.31]
2025-02-18 23:22:05,476 [trainer.py] => CNN top5 curve: [36.85, 21.31]
2025-02-18 23:22:05,476 [trainer.py] => NME top1 curve: [11.67, 7.82]
2025-02-18 23:22:05,477 [trainer.py] => NME top5 curve: [46.67, 31.04]

2025-02-18 23:22:05,477 [trainer.py] => All params: 8243492
2025-02-18 23:22:05,477 [trainer.py] => Trainable params: 4137380
2025-02-18 23:22:05,538 [der.py] => Learning on 25-35
2025-02-18 23:22:05,538 [der.py] => All params: 8253742
2025-02-18 23:22:05,539 [der.py] => Trainable params: 4147630
2025-02-18 23:22:05,612 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-18 23:22:05,612 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-18 23:24:37,375 [der.py] => Task 2, Epoch 1/1 => Loss 10.019, Loss_clf 10.019, Loss_aux 2.462, Train_accy 8.57, Test_accy 3.84
2025-02-18 23:24:48,217 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.261,  Train_accy 10.40, Test_accy 3.43
2025-02-18 23:24:48,218 [der.py] => do not weight align student!
2025-02-18 23:24:52,410 [der.py] => darknet eval: 
2025-02-18 23:24:52,410 [der.py] => CNN top1 curve: 3.43
2025-02-18 23:24:52,410 [der.py] => CNN top5 curve: 14.52
2025-02-18 23:24:52,412 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-18 23:25:25,680 [der.py] => Exemplar size: 1050
2025-02-18 23:25:25,680 [trainer.py] => CNN: {'total': 3.83, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 3.33, '26': 0.0, '27': 0.0, '28': 0.0, '29': 70.0, '30': 18.33, '31': 0.0, '32': 42.22, '33': 0.0, 'old': 0.0, 'new': 13.39}
2025-02-18 23:25:25,680 [trainer.py] => NME: {'total': 4.54, '0': 31.67, '1': 0.0, '2': 10.56, '3': 53.89, '4': 5.56, '5': 0.0, '6': 1.11, '7': 1.67, '8': 0.0, '9': 0.0, '10': 1.67, '11': 1.67, '12': 0.56, '13': 8.33, '14': 0.0, '15': 0.0, '16': 0.0, '17': 1.11, '18': 1.11, '19': 7.78, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 1.67, '26': 2.22, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 28.33, '33': 0.0, 'old': 5.07, 'new': 3.22}
2025-02-18 23:25:25,680 [trainer.py] => CNN top1 curve: [7.56, 4.31, 3.83]
2025-02-18 23:25:25,680 [trainer.py] => CNN top5 curve: [36.85, 21.31, 15.76]
2025-02-18 23:25:25,681 [trainer.py] => NME top1 curve: [11.67, 7.82, 4.54]
2025-02-18 23:25:25,681 [trainer.py] => NME top5 curve: [46.67, 31.04, 20.51]

2025-02-18 23:25:25,681 [trainer.py] => All params: 8253742
2025-02-18 23:25:25,681 [trainer.py] => Trainable params: 4147630
2025-02-18 23:25:25,740 [der.py] => Learning on 35-45
2025-02-18 23:25:25,741 [der.py] => All params: 8263992
2025-02-18 23:25:25,741 [der.py] => Trainable params: 4157880
2025-02-18 23:25:25,825 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-18 23:25:25,825 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-18 23:28:01,325 [der.py] => Task 3, Epoch 1/1 => Loss 7.079, Loss_clf 7.079, Loss_aux 2.462, Train_accy 7.98, Test_accy 2.52
2025-02-18 23:28:25,964 [der.py] => SNet: Task 3, Epoch 1/1 => Loss 3.454,  Train_accy 9.60, Test_accy 2.33
2025-02-18 23:28:25,965 [der.py] => do not weight align student!
2025-02-18 23:28:30,863 [der.py] => darknet eval: 
2025-02-18 23:28:30,864 [der.py] => CNN top1 curve: 2.33
2025-02-18 23:28:30,864 [der.py] => CNN top5 curve: 12.49
2025-02-18 23:28:30,865 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-18 23:29:21,431 [der.py] => Exemplar size: 1350
2025-02-18 23:29:21,431 [trainer.py] => CNN: {'total': 2.52, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 77.22, '37': 30.56, '38': 0.0, '39': 0.0, '40': 0.0, '41': 0.0, '42': 5.56, '43': 0.0, 'old': 0.0, 'new': 11.33}
2025-02-18 23:29:21,431 [trainer.py] => NME: {'total': 3.84, '0': 0.0, '1': 0.0, '2': 0.0, '3': 22.22, '4': 16.67, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 16.67, '11': 2.22, '12': 7.22, '13': 14.44, '14': 0.0, '15': 0.0, '16': 12.78, '17': 0.0, '18': 0.0, '19': 10.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 1.11, '26': 2.22, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.56, '31': 0.0, '32': 28.89, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 0.0, '38': 28.33, '39': 3.89, '40': 0.0, '41': 5.0, '42': 0.0, '43': 0.56, 'old': 3.86, 'new': 3.78}
2025-02-18 23:29:21,431 [trainer.py] => CNN top1 curve: [7.56, 4.31, 3.83, 2.52]
2025-02-18 23:29:21,431 [trainer.py] => CNN top5 curve: [36.85, 21.31, 15.76, 12.84]
2025-02-18 23:29:21,431 [trainer.py] => NME top1 curve: [11.67, 7.82, 4.54, 3.84]
2025-02-18 23:29:21,431 [trainer.py] => NME top5 curve: [46.67, 31.04, 20.51, 18.4]

2025-02-18 23:29:21,432 [trainer.py] => All params: 8263992
2025-02-18 23:29:21,432 [trainer.py] => Trainable params: 4157880
2025-02-18 23:29:21,491 [der.py] => Learning on 45-55
2025-02-18 23:29:21,492 [der.py] => All params: 8274242
2025-02-18 23:29:21,492 [der.py] => Trainable params: 4168130
2025-02-18 23:29:21,586 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-18 23:29:21,587 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-18 23:32:00,099 [der.py] => Task 4, Epoch 1/1 => Loss 4.865, Loss_clf 4.865, Loss_aux 2.395, Train_accy 6.41, Test_accy 2.05
2025-02-18 23:32:13,538 [der.py] => SNet: Task 4, Epoch 1/1 => Loss 3.815,  Train_accy 7.80, Test_accy 1.94
2025-02-18 23:32:13,539 [der.py] => do not weight align student!
2025-02-18 23:32:40,828 [trainer.py] => 实验名称:resnet18对比实验
2025-02-18 23:32:40,843 [trainer.py] => config: ./exps/der.json
2025-02-18 23:32:40,843 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-18 23:32:40,843 [trainer.py] => prefix: reproduce
2025-02-18 23:32:40,843 [trainer.py] => dataset: xrfdataset
2025-02-18 23:32:40,843 [trainer.py] => memory_size: 1650
2025-02-18 23:32:40,843 [trainer.py] => memory_per_class: 30
2025-02-18 23:32:40,843 [trainer.py] => fixed_memory: True
2025-02-18 23:32:40,843 [trainer.py] => shuffle: True
2025-02-18 23:32:40,843 [trainer.py] => init_cls: 15
2025-02-18 23:32:40,843 [trainer.py] => increment: 10
2025-02-18 23:32:40,843 [trainer.py] => model_name: der
2025-02-18 23:32:40,843 [trainer.py] => compression_epochs: 130
2025-02-18 23:32:40,844 [trainer.py] => compression_lr: 0.1
2025-02-18 23:32:40,844 [trainer.py] => is_student_wa: False
2025-02-18 23:32:40,844 [trainer.py] => wa_value: 1
2025-02-18 23:32:40,844 [trainer.py] => T: 2
2025-02-18 23:32:40,844 [trainer.py] => convnet_type: resnet18
2025-02-18 23:32:40,844 [trainer.py] => device: [device(type='cuda', index=1), device(type='cuda', index=2)]
2025-02-18 23:32:40,844 [trainer.py] => seed: 1993
2025-02-18 23:32:40,894 [data.py] => 加载完毕XRF原始数据集
2025-02-18 23:32:40,912 [data.py] => 加载完毕XRF原始数据集
2025-02-18 23:32:40,912 [trainer.py] => All params: 0
2025-02-18 23:32:40,912 [trainer.py] => Trainable params: 0
2025-02-18 23:32:41,001 [der.py] => Learning on 0-15
2025-02-18 23:32:41,001 [der.py] => All params: 4122015
2025-02-18 23:32:41,001 [der.py] => Trainable params: 4122015
2025-02-18 23:50:27,365 [der.py] => Task 0, Epoch 150/150 => Loss 0.032, Train_accy 99.76
2025-02-18 23:50:27,366 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-18 23:50:51,013 [der.py] => Exemplar size: 450
2025-02-18 23:50:51,013 [trainer.py] => CNN: {'total': 87.7, '0': 98.33, '1': 92.78, '2': 95.0, '3': 85.56, '4': 89.44, '5': 80.56, '6': 76.11, '7': 87.22, '8': 84.44, '9': 66.11, '10': 95.0, '11': 100.0, '12': 87.78, '13': 86.67, 'old': 0, 'new': 87.7}
2025-02-18 23:50:51,013 [trainer.py] => NME: {'total': 86.19, '0': 98.33, '1': 94.44, '2': 91.67, '3': 81.11, '4': 88.89, '5': 73.89, '6': 69.44, '7': 88.33, '8': 86.11, '9': 63.33, '10': 93.33, '11': 100.0, '12': 86.67, '13': 86.11, 'old': 0, 'new': 86.19}
2025-02-18 23:50:51,013 [trainer.py] => CNN top1 curve: [87.7]
2025-02-18 23:50:51,013 [trainer.py] => CNN top5 curve: [98.89]
2025-02-18 23:50:51,013 [trainer.py] => NME top1 curve: [86.19]
2025-02-18 23:50:51,013 [trainer.py] => NME top5 curve: [98.93]

2025-02-18 23:50:51,013 [trainer.py] => All params: 4122015
2025-02-18 23:50:51,014 [trainer.py] => Trainable params: 4122015
2025-02-18 23:50:51,071 [der.py] => Learning on 15-25
2025-02-18 23:50:51,072 [der.py] => All params: 8243492
2025-02-18 23:50:51,072 [der.py] => Trainable params: 4137380
2025-02-18 23:50:51,134 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-18 23:50:51,135 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-19 00:07:22,879 [der.py] => Task 1, Epoch 150/150 => Loss 0.003, Loss_clf 0.003, Loss_aux 2.443, Train_accy 100.00
2025-02-19 00:07:32,260 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.227,  Train_accy 39.70, Test_accy 58.71
2025-02-19 00:07:37,989 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.749,  Train_accy 63.03
2025-02-19 00:07:43,802 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.576,  Train_accy 72.17
2025-02-19 00:07:49,732 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.467,  Train_accy 79.16
2025-02-19 00:07:55,350 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.438,  Train_accy 80.86
2025-02-19 00:08:05,048 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.385,  Train_accy 84.00, Test_accy 67.09
2025-02-19 00:08:10,797 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.339,  Train_accy 86.75
2025-02-19 00:08:16,515 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.308,  Train_accy 88.11
2025-02-19 00:08:22,420 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.287,  Train_accy 89.57
2025-02-19 00:08:28,061 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.268,  Train_accy 90.13
2025-02-19 00:08:37,404 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.254,  Train_accy 90.60, Test_accy 73.87
2025-02-19 00:08:42,924 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.240,  Train_accy 91.98
2025-02-19 00:08:48,497 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.236,  Train_accy 91.55
2025-02-19 00:08:54,069 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.227,  Train_accy 91.85
2025-02-19 00:08:59,530 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.216,  Train_accy 92.47
2025-02-19 00:09:08,551 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.216,  Train_accy 92.75, Test_accy 76.71
2025-02-19 00:09:14,245 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.208,  Train_accy 92.60
2025-02-19 00:09:20,007 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.211,  Train_accy 92.90
2025-02-19 00:09:25,714 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.207,  Train_accy 92.26
2025-02-19 00:09:31,658 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.205,  Train_accy 92.71
2025-02-19 00:09:41,277 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.201,  Train_accy 92.80, Test_accy 77.53
2025-02-19 00:09:47,078 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.191,  Train_accy 93.51
2025-02-19 00:09:52,729 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.186,  Train_accy 93.66
2025-02-19 00:09:58,316 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.185,  Train_accy 93.57
2025-02-19 00:10:03,916 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.176,  Train_accy 93.70
2025-02-19 00:10:13,432 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.181,  Train_accy 93.68, Test_accy 78.69
2025-02-19 00:10:19,264 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.177,  Train_accy 93.55
2025-02-19 00:10:25,047 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.174,  Train_accy 93.40
2025-02-19 00:10:30,717 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.170,  Train_accy 93.59
2025-02-19 00:10:36,439 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.167,  Train_accy 94.13
2025-02-19 00:10:46,167 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.169,  Train_accy 93.68, Test_accy 79.42
2025-02-19 00:10:51,832 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.166,  Train_accy 93.53
2025-02-19 00:10:57,450 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.162,  Train_accy 94.02
2025-02-19 00:11:03,107 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.162,  Train_accy 93.68
2025-02-19 00:11:08,771 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.160,  Train_accy 93.25
2025-02-19 00:11:18,305 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.157,  Train_accy 94.11, Test_accy 78.27
2025-02-19 00:11:24,005 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.157,  Train_accy 93.96
2025-02-19 00:11:29,533 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.156,  Train_accy 93.98
2025-02-19 00:11:35,158 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.158,  Train_accy 93.87
2025-02-19 00:11:40,959 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.151,  Train_accy 94.04
2025-02-19 00:11:50,390 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.152,  Train_accy 93.81, Test_accy 79.20
2025-02-19 00:11:55,973 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.149,  Train_accy 94.77
2025-02-19 00:12:01,611 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.150,  Train_accy 93.87
2025-02-19 00:12:07,307 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.152,  Train_accy 94.22
2025-02-19 00:12:13,089 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.149,  Train_accy 94.09
2025-02-19 00:12:22,750 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.146,  Train_accy 94.11, Test_accy 79.78
2025-02-19 00:12:28,371 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.147,  Train_accy 93.87
2025-02-19 00:12:33,863 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.147,  Train_accy 93.72
2025-02-19 00:12:39,477 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.140,  Train_accy 94.45
2025-02-19 00:12:45,133 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.143,  Train_accy 94.06
2025-02-19 00:12:54,425 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.141,  Train_accy 94.34, Test_accy 79.62
2025-02-19 00:12:59,958 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.142,  Train_accy 94.37
2025-02-19 00:13:05,452 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.137,  Train_accy 93.98
2025-02-19 00:13:11,115 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.141,  Train_accy 94.09
2025-02-19 00:13:16,932 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.142,  Train_accy 94.37
2025-02-19 00:13:26,208 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.138,  Train_accy 94.02, Test_accy 80.38
2025-02-19 00:13:31,772 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.136,  Train_accy 94.02
2025-02-19 00:13:37,365 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.135,  Train_accy 94.15
2025-02-19 00:13:43,199 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.134,  Train_accy 94.24
2025-02-19 00:13:48,792 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.134,  Train_accy 94.00
2025-02-19 00:13:58,187 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.132,  Train_accy 94.39, Test_accy 80.60
2025-02-19 00:14:03,698 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.136,  Train_accy 94.28
2025-02-19 00:14:09,224 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.134,  Train_accy 94.28
2025-02-19 00:14:14,947 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.138,  Train_accy 94.45
2025-02-19 00:14:20,566 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.133,  Train_accy 93.83
2025-02-19 00:14:29,972 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.133,  Train_accy 94.17, Test_accy 80.13
2025-02-19 00:14:35,545 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.137,  Train_accy 94.15
2025-02-19 00:14:40,948 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.134,  Train_accy 94.26
2025-02-19 00:14:46,703 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.132,  Train_accy 94.24
2025-02-19 00:14:52,386 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.134,  Train_accy 94.00
2025-02-19 00:15:01,961 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.134,  Train_accy 94.15, Test_accy 80.40
2025-02-19 00:15:07,734 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.132,  Train_accy 94.17
2025-02-19 00:15:13,598 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.132,  Train_accy 94.60
2025-02-19 00:15:19,216 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.130,  Train_accy 94.09
2025-02-19 00:15:24,770 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.130,  Train_accy 94.06
2025-02-19 00:15:34,220 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.127,  Train_accy 94.58, Test_accy 80.56
2025-02-19 00:15:39,842 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.127,  Train_accy 94.32
2025-02-19 00:15:45,318 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.130,  Train_accy 94.15
2025-02-19 00:15:50,989 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.129,  Train_accy 94.13
2025-02-19 00:15:56,558 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.132,  Train_accy 94.15
2025-02-19 00:16:06,032 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.127,  Train_accy 94.39, Test_accy 80.69
2025-02-19 00:16:11,541 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.125,  Train_accy 94.00
2025-02-19 00:16:17,230 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.128,  Train_accy 94.00
2025-02-19 00:16:22,987 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.127,  Train_accy 94.34
2025-02-19 00:16:28,652 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.129,  Train_accy 94.15
2025-02-19 00:16:38,009 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.127,  Train_accy 94.34, Test_accy 80.84
2025-02-19 00:16:43,800 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.125,  Train_accy 93.98
2025-02-19 00:16:49,510 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.125,  Train_accy 94.62
2025-02-19 00:16:54,917 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.127,  Train_accy 94.43
2025-02-19 00:17:00,984 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.125,  Train_accy 94.30
2025-02-19 00:17:10,552 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.125,  Train_accy 94.32, Test_accy 80.89
2025-02-19 00:17:16,323 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.123,  Train_accy 94.17
2025-02-19 00:17:21,996 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.124,  Train_accy 94.52
2025-02-19 00:17:27,599 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.121,  Train_accy 94.52
2025-02-19 00:17:33,428 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.123,  Train_accy 94.39
2025-02-19 00:17:43,022 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.124,  Train_accy 94.09, Test_accy 80.71
2025-02-19 00:17:48,770 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.124,  Train_accy 94.37
2025-02-19 00:17:54,433 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.123,  Train_accy 94.26
2025-02-19 00:17:59,968 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.121,  Train_accy 94.43
2025-02-19 00:18:05,665 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.119,  Train_accy 94.30
2025-02-19 00:18:15,300 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.122,  Train_accy 94.47, Test_accy 81.38
2025-02-19 00:18:20,914 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.120,  Train_accy 94.62
2025-02-19 00:18:31,992 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.121,  Train_accy 94.17
2025-02-19 00:18:37,695 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.122,  Train_accy 94.26
2025-02-19 00:18:43,427 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.119,  Train_accy 94.24
2025-02-19 00:18:52,911 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.120,  Train_accy 93.96, Test_accy 80.98
2025-02-19 00:18:58,570 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.118,  Train_accy 94.54
2025-02-19 00:19:04,159 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.121,  Train_accy 94.65
2025-02-19 00:19:09,982 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.122,  Train_accy 93.96
2025-02-19 00:19:15,591 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.120,  Train_accy 94.39
2025-02-19 00:19:25,135 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.123,  Train_accy 94.32, Test_accy 81.07
2025-02-19 00:19:30,853 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.120,  Train_accy 94.65
2025-02-19 00:19:36,565 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.119,  Train_accy 94.22
2025-02-19 00:19:42,052 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.117,  Train_accy 94.47
2025-02-19 00:19:47,576 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.118,  Train_accy 94.45
2025-02-19 00:19:57,075 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.121,  Train_accy 94.82, Test_accy 81.02
2025-02-19 00:20:02,724 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.121,  Train_accy 94.39
2025-02-19 00:20:08,383 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.120,  Train_accy 94.49
2025-02-19 00:20:14,063 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.118,  Train_accy 94.34
2025-02-19 00:20:19,854 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.117,  Train_accy 94.52
2025-02-19 00:20:29,534 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.120,  Train_accy 94.34, Test_accy 81.20
2025-02-19 00:20:35,113 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.120,  Train_accy 94.47
2025-02-19 00:20:40,641 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.120,  Train_accy 94.41
2025-02-19 00:20:46,199 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.118,  Train_accy 94.22
2025-02-19 00:20:52,007 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.120,  Train_accy 94.49
2025-02-19 00:21:01,498 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.120,  Train_accy 94.47, Test_accy 80.87
2025-02-19 00:21:07,000 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.119,  Train_accy 94.41
2025-02-19 00:21:12,476 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.117,  Train_accy 94.45
2025-02-19 00:21:18,309 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.120,  Train_accy 94.34
2025-02-19 00:21:23,918 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.119,  Train_accy 94.45
2025-02-19 00:21:23,919 [der.py] => do not weight align student!
2025-02-19 00:21:27,271 [der.py] => darknet eval: 
2025-02-19 00:21:27,271 [der.py] => CNN top1 curve: 81.31
2025-02-19 00:21:27,271 [der.py] => CNN top5 curve: 97.69
2025-02-19 00:21:27,273 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 00:21:55,840 [der.py] => Exemplar size: 750
2025-02-19 00:21:55,840 [trainer.py] => CNN: {'total': 85.89, '0': 94.44, '1': 85.0, '2': 94.44, '3': 81.11, '4': 86.11, '5': 71.11, '6': 75.56, '7': 72.22, '8': 76.11, '9': 60.0, '10': 94.44, '11': 100.0, '12': 85.56, '13': 85.0, '14': 89.44, '15': 93.33, '16': 93.33, '17': 95.56, '18': 85.0, '19': 91.67, '20': 95.56, '21': 83.89, '22': 82.78, '23': 83.89, 'old': 83.37, 'new': 89.67}
2025-02-19 00:21:55,840 [trainer.py] => NME: {'total': 82.58, '0': 87.22, '1': 78.89, '2': 92.22, '3': 80.56, '4': 86.67, '5': 66.11, '6': 69.44, '7': 60.56, '8': 56.11, '9': 60.0, '10': 93.89, '11': 100.0, '12': 86.67, '13': 83.89, '14': 86.67, '15': 90.56, '16': 95.56, '17': 85.0, '18': 87.22, '19': 87.22, '20': 89.44, '21': 83.89, '22': 85.56, '23': 90.56, 'old': 79.26, 'new': 87.56}
2025-02-19 00:21:55,840 [trainer.py] => CNN top1 curve: [87.7, 85.89]
2025-02-19 00:21:55,840 [trainer.py] => CNN top5 curve: [98.89, 98.42]
2025-02-19 00:21:55,840 [trainer.py] => NME top1 curve: [86.19, 82.58]
2025-02-19 00:21:55,841 [trainer.py] => NME top5 curve: [98.93, 98.42]

2025-02-19 00:21:55,841 [trainer.py] => All params: 8243492
2025-02-19 00:21:55,841 [trainer.py] => Trainable params: 4137380
2025-02-19 00:21:55,898 [der.py] => Learning on 25-35
2025-02-19 00:21:55,899 [der.py] => All params: 8253742
2025-02-19 00:21:55,899 [der.py] => Trainable params: 4147630
2025-02-19 00:21:55,971 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-19 00:21:55,972 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-19 01:06:31,949 [der.py] => Task 2, Epoch 150/150 => Loss 0.005, Loss_clf 0.005, Loss_aux 2.403, Train_accy 100.00
2025-02-19 01:07:05,330 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.262,  Train_accy 50.53, Test_accy 57.17
2025-02-19 01:07:22,009 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.976,  Train_accy 69.88
2025-02-19 01:07:46,426 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.885,  Train_accy 76.04
2025-02-19 01:08:03,883 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.832,  Train_accy 79.92
2025-02-19 01:08:32,140 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.795,  Train_accy 82.22
2025-02-19 01:08:54,975 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.766,  Train_accy 83.62, Test_accy 66.98
2025-02-19 01:09:05,537 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.745,  Train_accy 85.54
2025-02-19 01:09:29,549 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.719,  Train_accy 87.45
2025-02-19 01:09:39,452 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.704,  Train_accy 87.70
2025-02-19 01:09:49,401 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.693,  Train_accy 88.99
2025-02-19 01:10:43,880 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.689,  Train_accy 89.84, Test_accy 69.44
2025-02-19 01:10:53,072 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.679,  Train_accy 89.09
2025-02-19 01:11:16,392 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.673,  Train_accy 90.42
2025-02-19 01:11:25,862 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.662,  Train_accy 91.37
2025-02-19 01:11:35,830 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.658,  Train_accy 90.28
2025-02-19 01:12:09,833 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.653,  Train_accy 91.49, Test_accy 71.44
2025-02-19 01:12:27,693 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.651,  Train_accy 91.90
2025-02-19 01:12:47,536 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.645,  Train_accy 91.49
2025-02-19 01:13:14,409 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.637,  Train_accy 91.88
2025-02-19 01:13:42,831 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.635,  Train_accy 92.63
2025-02-19 01:14:15,328 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.634,  Train_accy 92.44, Test_accy 72.38
2025-02-19 01:14:41,797 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.627,  Train_accy 92.91
2025-02-19 01:14:52,674 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.625,  Train_accy 92.89
2025-02-19 01:15:15,654 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.622,  Train_accy 92.57
2025-02-19 01:15:35,368 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.619,  Train_accy 92.81
2025-02-19 01:16:09,235 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.615,  Train_accy 93.01, Test_accy 72.86
2025-02-19 01:16:33,090 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.619,  Train_accy 93.21
2025-02-19 01:16:44,986 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.616,  Train_accy 92.87
2025-02-19 01:17:11,012 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.613,  Train_accy 93.49
2025-02-19 01:17:18,512 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.614,  Train_accy 93.43
2025-02-19 01:18:01,006 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.609,  Train_accy 93.52, Test_accy 73.25
2025-02-19 01:18:19,742 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.611,  Train_accy 93.76
2025-02-19 01:18:31,698 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.607,  Train_accy 92.89
2025-02-19 01:19:00,521 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.609,  Train_accy 93.03
2025-02-19 01:19:09,284 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.611,  Train_accy 92.95
2025-02-19 01:19:55,562 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.606,  Train_accy 93.52, Test_accy 72.95
2025-02-19 01:20:16,596 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.605,  Train_accy 93.76
2025-02-19 01:20:38,910 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.601,  Train_accy 93.76
2025-02-19 01:20:50,543 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.600,  Train_accy 93.94
2025-02-19 01:21:17,574 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.599,  Train_accy 93.88
2025-02-19 01:22:09,865 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.600,  Train_accy 93.66, Test_accy 74.35
2025-02-19 01:22:22,431 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.598,  Train_accy 93.13
2025-02-19 01:22:47,139 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.599,  Train_accy 93.54
2025-02-19 01:22:58,782 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.597,  Train_accy 94.20
2025-02-19 01:23:37,244 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.595,  Train_accy 93.62
2025-02-19 01:24:18,605 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.596,  Train_accy 93.84, Test_accy 74.14
2025-02-19 01:24:34,870 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.593,  Train_accy 94.20
2025-02-19 01:24:57,092 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.594,  Train_accy 94.46
2025-02-19 01:25:21,136 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.592,  Train_accy 94.34
2025-02-19 01:25:56,844 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.592,  Train_accy 93.54
2025-02-19 01:26:13,437 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.593,  Train_accy 94.04, Test_accy 73.44
2025-02-19 01:26:34,304 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.589,  Train_accy 93.88
2025-02-19 01:26:48,231 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.591,  Train_accy 94.16
2025-02-19 01:26:55,568 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.590,  Train_accy 93.98
2025-02-19 01:27:17,184 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.588,  Train_accy 94.46
2025-02-19 01:28:05,410 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.590,  Train_accy 94.46, Test_accy 73.92
2025-02-19 01:28:13,646 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.588,  Train_accy 94.26
2025-02-19 01:28:27,238 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.587,  Train_accy 94.26
2025-02-19 01:28:37,194 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.586,  Train_accy 94.53
2025-02-19 01:29:02,747 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.586,  Train_accy 94.08
2025-02-19 01:29:43,729 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.586,  Train_accy 94.26, Test_accy 74.16
2025-02-19 01:30:05,736 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.582,  Train_accy 94.28
2025-02-19 01:30:32,746 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.584,  Train_accy 94.20
2025-02-19 01:30:43,959 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.584,  Train_accy 94.61
2025-02-19 01:31:09,661 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.585,  Train_accy 93.92
2025-02-19 01:31:35,207 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.581,  Train_accy 94.36, Test_accy 74.68
2025-02-19 01:32:05,063 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.582,  Train_accy 94.42
2025-02-19 01:32:39,685 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.582,  Train_accy 94.48
2025-02-19 01:33:03,562 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.580,  Train_accy 94.65
2025-02-19 01:33:22,496 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.580,  Train_accy 94.63
2025-02-19 01:33:49,838 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.580,  Train_accy 94.99, Test_accy 74.65
2025-02-19 01:34:01,123 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.580,  Train_accy 94.34
2025-02-19 01:34:37,548 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.580,  Train_accy 94.73
2025-02-19 01:34:45,989 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.579,  Train_accy 94.67
2025-02-19 01:35:12,249 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.579,  Train_accy 94.83
2025-02-19 01:35:45,909 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.579,  Train_accy 94.63, Test_accy 74.86
2025-02-19 01:36:11,228 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.579,  Train_accy 95.01
2025-02-19 01:36:20,206 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.578,  Train_accy 94.87
2025-02-19 01:36:36,788 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.577,  Train_accy 94.93
2025-02-19 01:37:03,737 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.578,  Train_accy 94.36
2025-02-19 01:37:33,845 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.577,  Train_accy 94.67, Test_accy 74.94
2025-02-19 01:37:42,007 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.574,  Train_accy 94.89
2025-02-19 01:38:06,329 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.576,  Train_accy 94.71
2025-02-19 01:38:35,393 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.576,  Train_accy 94.61
2025-02-19 01:38:57,212 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.579,  Train_accy 94.57
2025-02-19 01:39:41,644 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.576,  Train_accy 94.57, Test_accy 74.76
2025-02-19 01:39:52,341 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.577,  Train_accy 94.55
2025-02-19 01:40:01,342 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.576,  Train_accy 94.69
2025-02-19 01:40:32,523 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.577,  Train_accy 94.83
2025-02-19 01:40:40,737 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.574,  Train_accy 94.61
2025-02-19 01:41:30,178 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.573,  Train_accy 94.55, Test_accy 75.02
2025-02-19 01:41:39,182 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.576,  Train_accy 94.73
2025-02-19 01:41:48,610 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.574,  Train_accy 94.26
2025-02-19 01:41:58,262 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.575,  Train_accy 94.85
2025-02-19 01:43:02,458 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.575,  Train_accy 94.79
2025-02-19 01:43:50,074 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.576,  Train_accy 94.63, Test_accy 75.02
2025-02-19 01:44:07,723 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.574,  Train_accy 94.89
2025-02-19 01:44:53,747 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.572,  Train_accy 94.79
2025-02-19 01:45:01,497 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.574,  Train_accy 94.71
2025-02-19 01:45:30,008 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.575,  Train_accy 94.79
2025-02-19 01:46:05,590 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.574,  Train_accy 94.71, Test_accy 75.19
2025-02-19 01:46:23,970 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.573,  Train_accy 94.73
2025-02-19 01:46:40,779 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.573,  Train_accy 94.81
2025-02-19 01:46:47,559 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.573,  Train_accy 95.07
2025-02-19 01:47:07,853 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.572,  Train_accy 94.85
2025-02-19 01:47:38,753 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.572,  Train_accy 94.79, Test_accy 75.05
2025-02-19 01:48:02,683 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.572,  Train_accy 94.99
2025-02-19 01:48:21,914 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.571,  Train_accy 94.97
2025-02-19 01:48:31,688 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.573,  Train_accy 94.77
2025-02-19 01:48:40,891 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.573,  Train_accy 94.69
2025-02-19 01:49:43,140 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.575,  Train_accy 94.75, Test_accy 75.06
2025-02-19 01:50:06,657 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.572,  Train_accy 94.87
2025-02-19 01:50:23,435 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.572,  Train_accy 94.85
2025-02-19 01:50:34,123 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.570,  Train_accy 95.11
2025-02-19 01:50:46,905 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.572,  Train_accy 94.57
2025-02-19 01:51:12,793 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.571,  Train_accy 95.07, Test_accy 74.90
2025-02-19 01:51:27,205 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.572,  Train_accy 94.77
2025-02-19 01:51:40,230 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.571,  Train_accy 94.57
2025-02-19 01:51:50,583 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.573,  Train_accy 95.09
2025-02-19 01:51:58,852 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.572,  Train_accy 94.67
2025-02-19 01:52:35,018 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.571,  Train_accy 94.87, Test_accy 75.17
2025-02-19 01:52:58,019 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.571,  Train_accy 95.07
2025-02-19 01:53:24,452 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.572,  Train_accy 94.63
2025-02-19 01:53:34,692 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.571,  Train_accy 94.65
2025-02-19 01:53:45,442 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.571,  Train_accy 95.01
2025-02-19 01:54:24,153 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.571,  Train_accy 94.79, Test_accy 74.92
2025-02-19 01:54:32,335 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.573,  Train_accy 94.81
2025-02-19 01:55:00,490 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.571,  Train_accy 94.83
2025-02-19 01:55:30,319 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.571,  Train_accy 94.91
2025-02-19 01:55:36,874 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.574,  Train_accy 94.87
2025-02-19 01:55:36,874 [der.py] => do not weight align student!
2025-02-19 01:56:00,813 [der.py] => darknet eval: 
2025-02-19 01:56:00,813 [der.py] => CNN top1 curve: 75.32
2025-02-19 01:56:00,813 [der.py] => CNN top5 curve: 95.22
2025-02-19 01:56:00,815 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 01:59:55,237 [der.py] => Exemplar size: 1050
2025-02-19 01:59:55,237 [trainer.py] => CNN: {'total': 76.51, '0': 81.11, '1': 53.89, '2': 87.78, '3': 57.78, '4': 78.33, '5': 33.89, '6': 73.33, '7': 27.78, '8': 40.0, '9': 38.89, '10': 83.89, '11': 97.78, '12': 79.44, '13': 72.78, '14': 62.22, '15': 93.89, '16': 96.11, '17': 93.89, '18': 90.56, '19': 93.89, '20': 93.33, '21': 87.78, '22': 91.11, '23': 83.33, '24': 74.44, '25': 66.67, '26': 87.22, '27': 82.22, '28': 68.33, '29': 81.11, '30': 86.11, '31': 84.44, '32': 97.22, '33': 75.56, 'old': 74.69, 'new': 81.06}
2025-02-19 01:59:55,237 [trainer.py] => NME: {'total': 72.27, '0': 81.11, '1': 54.44, '2': 81.67, '3': 55.56, '4': 82.22, '5': 36.67, '6': 61.67, '7': 29.44, '8': 48.33, '9': 52.78, '10': 83.89, '11': 88.33, '12': 78.33, '13': 68.89, '14': 59.44, '15': 90.56, '16': 93.33, '17': 89.44, '18': 86.11, '19': 86.11, '20': 91.11, '21': 81.67, '22': 77.78, '23': 57.78, '24': 42.22, '25': 55.0, '26': 90.56, '27': 88.89, '28': 65.56, '29': 71.67, '30': 76.11, '31': 76.11, '32': 95.0, '33': 69.44, 'old': 70.36, 'new': 77.06}
2025-02-19 01:59:55,238 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.51]
2025-02-19 01:59:55,238 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.63]
2025-02-19 01:59:55,238 [trainer.py] => NME top1 curve: [86.19, 82.58, 72.27]
2025-02-19 01:59:55,238 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.51]

2025-02-19 01:59:55,238 [trainer.py] => All params: 8253742
2025-02-19 01:59:55,239 [trainer.py] => Trainable params: 4147630
2025-02-19 01:59:55,295 [der.py] => Learning on 35-45
2025-02-19 01:59:55,296 [der.py] => All params: 8263992
2025-02-19 01:59:55,296 [der.py] => Trainable params: 4157880
2025-02-19 01:59:55,379 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-19 01:59:55,380 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-19 14:10:51,088 [trainer.py] => 实验名称:resnet18对比实验
2025-02-19 14:10:51,108 [trainer.py] => config: ./exps/der.json
2025-02-19 14:10:51,108 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-19 14:10:51,108 [trainer.py] => prefix: reproduce
2025-02-19 14:10:51,108 [trainer.py] => dataset: xrfdataset
2025-02-19 14:10:51,108 [trainer.py] => memory_size: 1650
2025-02-19 14:10:51,108 [trainer.py] => memory_per_class: 30
2025-02-19 14:10:51,108 [trainer.py] => fixed_memory: True
2025-02-19 14:10:51,108 [trainer.py] => shuffle: True
2025-02-19 14:10:51,108 [trainer.py] => init_cls: 15
2025-02-19 14:10:51,108 [trainer.py] => increment: 10
2025-02-19 14:10:51,108 [trainer.py] => model_name: der
2025-02-19 14:10:51,108 [trainer.py] => compression_epochs: 130
2025-02-19 14:10:51,108 [trainer.py] => compression_lr: 0.1
2025-02-19 14:10:51,108 [trainer.py] => is_student_wa: False
2025-02-19 14:10:51,108 [trainer.py] => wa_value: 1
2025-02-19 14:10:51,108 [trainer.py] => T: 2
2025-02-19 14:10:51,108 [trainer.py] => convnet_type: resnet18
2025-02-19 14:10:51,108 [trainer.py] => device: [device(type='cuda', index=1)]
2025-02-19 14:10:51,108 [trainer.py] => seed: 1993
2025-02-19 14:10:51,166 [data.py] => 加载完毕XRF原始数据集
2025-02-19 14:10:51,185 [data.py] => 加载完毕XRF原始数据集
2025-02-19 14:10:51,187 [trainer.py] => All params: 0
2025-02-19 14:10:51,187 [trainer.py] => Trainable params: 0
2025-02-19 14:10:51,278 [der.py] => Learning on 0-15
2025-02-19 14:10:51,278 [der.py] => All params: 4122015
2025-02-19 14:10:51,278 [der.py] => Trainable params: 4122015
2025-02-19 14:24:07,177 [der.py] => Task 0, Epoch 150/150 => Loss 0.024, Train_accy 99.86
2025-02-19 14:24:07,177 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 14:24:38,375 [der.py] => Exemplar size: 450
2025-02-19 14:24:38,375 [trainer.py] => CNN: {'total': 86.04, '0': 97.22, '1': 92.22, '2': 94.44, '3': 81.11, '4': 91.11, '5': 76.11, '6': 65.0, '7': 87.22, '8': 86.67, '9': 59.44, '10': 97.22, '11': 99.44, '12': 88.33, '13': 84.44, 'old': 0, 'new': 86.04}
2025-02-19 14:24:38,375 [trainer.py] => NME: {'total': 84.48, '0': 97.22, '1': 89.44, '2': 92.78, '3': 79.44, '4': 90.0, '5': 70.56, '6': 62.78, '7': 89.44, '8': 85.0, '9': 57.22, '10': 97.22, '11': 100.0, '12': 83.89, '13': 84.44, 'old': 0, 'new': 84.48}
2025-02-19 14:24:38,375 [trainer.py] => CNN top1 curve: [86.04]
2025-02-19 14:24:38,375 [trainer.py] => CNN top5 curve: [98.78]
2025-02-19 14:24:38,375 [trainer.py] => NME top1 curve: [84.48]
2025-02-19 14:24:38,375 [trainer.py] => NME top5 curve: [98.63]

2025-02-19 14:24:38,375 [trainer.py] => All params: 4122015
2025-02-19 14:24:38,376 [trainer.py] => Trainable params: 4122015
2025-02-19 14:24:38,432 [der.py] => Learning on 15-25
2025-02-19 14:24:38,433 [der.py] => All params: 8243492
2025-02-19 14:24:38,433 [der.py] => Trainable params: 4137380
2025-02-19 14:24:38,493 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-19 14:24:38,493 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-19 14:37:33,984 [der.py] => Task 1, Epoch 150/150 => Loss 0.003, Loss_clf 0.003, Loss_aux 2.440, Train_accy 100.00
2025-02-19 14:37:40,919 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.252,  Train_accy 36.49, Test_accy 54.56
2025-02-19 14:37:44,677 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.780,  Train_accy 58.97
2025-02-19 14:37:48,368 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.600,  Train_accy 68.77
2025-02-19 14:37:52,172 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.505,  Train_accy 74.49
2025-02-19 14:37:55,824 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.419,  Train_accy 79.44
2025-02-19 14:38:02,438 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.361,  Train_accy 81.89, Test_accy 60.58
2025-02-19 14:38:06,143 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.311,  Train_accy 85.35
2025-02-19 14:38:09,857 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.290,  Train_accy 86.54
2025-02-19 14:38:13,507 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.252,  Train_accy 88.58
2025-02-19 14:38:17,208 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.243,  Train_accy 89.14
2025-02-19 14:38:24,027 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.214,  Train_accy 90.37, Test_accy 72.60
2025-02-19 14:38:28,065 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.206,  Train_accy 91.08
2025-02-19 14:38:31,938 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.195,  Train_accy 90.84
2025-02-19 14:38:35,706 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.188,  Train_accy 91.89
2025-02-19 14:38:39,476 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.184,  Train_accy 91.55
2025-02-19 14:38:46,037 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.174,  Train_accy 91.91, Test_accy 72.40
2025-02-19 14:38:49,738 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.159,  Train_accy 92.49
2025-02-19 14:38:53,457 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.157,  Train_accy 92.41
2025-02-19 14:38:57,128 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.157,  Train_accy 92.69
2025-02-19 14:39:00,828 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.152,  Train_accy 92.69
2025-02-19 14:39:07,142 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.146,  Train_accy 92.75, Test_accy 74.98
2025-02-19 14:39:10,952 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.150,  Train_accy 93.08
2025-02-19 14:39:14,626 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.145,  Train_accy 92.28
2025-02-19 14:39:18,280 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.136,  Train_accy 93.18
2025-02-19 14:39:22,389 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.123,  Train_accy 93.18
2025-02-19 14:39:28,965 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.125,  Train_accy 93.31, Test_accy 76.04
2025-02-19 14:39:32,694 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.123,  Train_accy 93.83
2025-02-19 14:39:36,422 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.121,  Train_accy 93.40
2025-02-19 14:39:40,067 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.122,  Train_accy 93.40
2025-02-19 14:39:43,828 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.120,  Train_accy 93.81
2025-02-19 14:39:50,246 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.122,  Train_accy 93.29, Test_accy 77.24
2025-02-19 14:39:53,811 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.118,  Train_accy 93.40
2025-02-19 14:39:57,539 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.115,  Train_accy 93.48
2025-02-19 14:40:01,142 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.113,  Train_accy 93.27
2025-02-19 14:40:04,795 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.112,  Train_accy 93.66
2025-02-19 14:40:11,163 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.113,  Train_accy 93.40, Test_accy 76.71
2025-02-19 14:40:14,775 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.111,  Train_accy 93.59
2025-02-19 14:40:18,239 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.104,  Train_accy 93.72
2025-02-19 14:40:22,286 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.106,  Train_accy 93.89
2025-02-19 14:40:25,932 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.109,  Train_accy 93.78
2025-02-19 14:40:32,590 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.107,  Train_accy 93.76, Test_accy 77.67
2025-02-19 14:40:36,319 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.102,  Train_accy 93.87
2025-02-19 14:40:39,918 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.102,  Train_accy 93.46
2025-02-19 14:40:43,487 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.100,  Train_accy 93.85
2025-02-19 14:40:47,092 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.098,  Train_accy 93.94
2025-02-19 14:40:53,442 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.097,  Train_accy 93.87, Test_accy 77.44
2025-02-19 14:40:56,950 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.100,  Train_accy 93.83
2025-02-19 14:41:00,521 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.099,  Train_accy 93.83
2025-02-19 14:41:04,101 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.095,  Train_accy 93.85
2025-02-19 14:41:07,720 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.097,  Train_accy 93.70
2025-02-19 14:41:14,080 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.093,  Train_accy 93.78, Test_accy 77.84
2025-02-19 14:41:17,788 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.097,  Train_accy 93.66
2025-02-19 14:41:21,293 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.091,  Train_accy 93.74
2025-02-19 14:41:24,900 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.095,  Train_accy 94.26
2025-02-19 14:41:28,611 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.090,  Train_accy 94.11
2025-02-19 14:41:34,950 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.094,  Train_accy 93.85, Test_accy 78.11
2025-02-19 14:41:38,542 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.093,  Train_accy 93.78
2025-02-19 14:41:42,196 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.093,  Train_accy 94.15
2025-02-19 14:41:45,782 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.089,  Train_accy 93.87
2025-02-19 14:41:49,405 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.089,  Train_accy 93.98
2025-02-19 14:41:55,946 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.085,  Train_accy 93.87, Test_accy 78.82
2025-02-19 14:41:59,680 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.085,  Train_accy 93.83
2025-02-19 14:42:03,599 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.087,  Train_accy 93.78
2025-02-19 14:42:07,629 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.090,  Train_accy 93.94
2025-02-19 14:42:11,502 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.090,  Train_accy 93.83
2025-02-19 14:42:17,873 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.089,  Train_accy 93.72, Test_accy 78.84
2025-02-19 14:42:21,514 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.088,  Train_accy 94.06
2025-02-19 14:42:25,160 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.084,  Train_accy 93.98
2025-02-19 14:42:28,733 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.086,  Train_accy 93.72
2025-02-19 14:42:32,334 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.086,  Train_accy 94.30
2025-02-19 14:42:38,685 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.087,  Train_accy 94.17, Test_accy 78.76
2025-02-19 14:42:42,230 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.087,  Train_accy 94.19
2025-02-19 14:42:45,723 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.087,  Train_accy 94.09
2025-02-19 14:42:49,321 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.089,  Train_accy 93.76
2025-02-19 14:42:52,834 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.085,  Train_accy 94.09
2025-02-19 14:42:59,182 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.080,  Train_accy 94.02, Test_accy 78.78
2025-02-19 14:43:02,641 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.082,  Train_accy 94.24
2025-02-19 14:43:06,238 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.082,  Train_accy 93.74
2025-02-19 14:43:09,948 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.082,  Train_accy 93.96
2025-02-19 14:43:13,528 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.084,  Train_accy 94.17
2025-02-19 14:43:19,811 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.081,  Train_accy 94.15, Test_accy 79.04
2025-02-19 14:43:23,328 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.079,  Train_accy 93.89
2025-02-19 14:43:26,980 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.081,  Train_accy 93.94
2025-02-19 14:43:30,533 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.079,  Train_accy 93.87
2025-02-19 14:43:34,157 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.080,  Train_accy 94.04
2025-02-19 14:43:40,444 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.079,  Train_accy 94.06, Test_accy 79.24
2025-02-19 14:43:43,877 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.078,  Train_accy 93.76
2025-02-19 14:43:47,407 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.083,  Train_accy 94.13
2025-02-19 14:43:50,723 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.083,  Train_accy 94.28
2025-02-19 14:43:54,090 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.080,  Train_accy 94.06
2025-02-19 14:43:59,958 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.080,  Train_accy 94.00, Test_accy 78.53
2025-02-19 14:44:03,835 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.078,  Train_accy 94.30
2025-02-19 14:44:07,239 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.078,  Train_accy 94.04
2025-02-19 14:44:10,756 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.076,  Train_accy 93.83
2025-02-19 14:44:14,158 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.081,  Train_accy 94.09
2025-02-19 14:44:20,149 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.077,  Train_accy 94.11, Test_accy 78.80
2025-02-19 14:44:23,482 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.078,  Train_accy 93.81
2025-02-19 14:44:26,763 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.078,  Train_accy 93.63
2025-02-19 14:44:30,189 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.076,  Train_accy 94.45
2025-02-19 14:44:33,633 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.075,  Train_accy 94.00
2025-02-19 14:44:40,035 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.077,  Train_accy 94.28, Test_accy 78.91
2025-02-19 14:44:43,818 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.075,  Train_accy 94.37
2025-02-19 14:44:47,260 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.077,  Train_accy 94.00
2025-02-19 14:44:50,838 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.078,  Train_accy 93.78
2025-02-19 14:44:54,712 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.076,  Train_accy 94.39
2025-02-19 14:45:00,753 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.074,  Train_accy 93.76, Test_accy 78.87
2025-02-19 14:45:04,220 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.075,  Train_accy 93.98
2025-02-19 14:45:08,032 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.075,  Train_accy 94.04
2025-02-19 14:45:11,574 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.076,  Train_accy 94.49
2025-02-19 14:45:15,112 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.075,  Train_accy 93.78
2025-02-19 14:45:21,006 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.077,  Train_accy 94.49, Test_accy 78.96
2025-02-19 14:45:24,411 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.076,  Train_accy 94.15
2025-02-19 14:45:27,863 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.075,  Train_accy 94.00
2025-02-19 14:45:31,391 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.075,  Train_accy 94.26
2025-02-19 14:45:35,174 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.076,  Train_accy 93.68
2025-02-19 14:45:41,573 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.077,  Train_accy 94.17, Test_accy 79.02
2025-02-19 14:45:45,081 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.074,  Train_accy 94.02
2025-02-19 14:45:48,706 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.074,  Train_accy 94.11
2025-02-19 14:45:52,534 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.076,  Train_accy 93.98
2025-02-19 14:45:56,290 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.074,  Train_accy 93.94
2025-02-19 14:46:02,649 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.073,  Train_accy 94.28, Test_accy 79.02
2025-02-19 14:46:06,135 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.075,  Train_accy 94.02
2025-02-19 14:46:09,651 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.079,  Train_accy 94.00
2025-02-19 14:46:13,345 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.074,  Train_accy 94.22
2025-02-19 14:46:16,931 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.075,  Train_accy 94.04
2025-02-19 14:46:23,067 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.074,  Train_accy 94.09, Test_accy 78.89
2025-02-19 14:46:26,622 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.076,  Train_accy 94.32
2025-02-19 14:46:30,600 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.071,  Train_accy 94.26
2025-02-19 14:46:34,155 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.075,  Train_accy 94.37
2025-02-19 14:46:37,764 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.075,  Train_accy 93.74
2025-02-19 14:46:37,765 [der.py] => do not weight align student!
2025-02-19 14:46:40,444 [der.py] => darknet eval: 
2025-02-19 14:46:40,445 [der.py] => CNN top1 curve: 79.07
2025-02-19 14:46:40,445 [der.py] => CNN top5 curve: 97.71
2025-02-19 14:46:40,446 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 14:47:07,586 [der.py] => Exemplar size: 750
2025-02-19 14:47:07,586 [trainer.py] => CNN: {'total': 83.76, '0': 86.67, '1': 85.0, '2': 93.33, '3': 80.56, '4': 90.0, '5': 58.89, '6': 60.56, '7': 62.78, '8': 71.67, '9': 60.0, '10': 96.67, '11': 99.44, '12': 88.89, '13': 84.44, '14': 85.56, '15': 92.78, '16': 94.44, '17': 93.33, '18': 91.67, '19': 90.56, '20': 97.78, '21': 83.89, '22': 84.44, '23': 78.89, 'old': 80.3, 'new': 88.94}
2025-02-19 14:47:07,586 [trainer.py] => NME: {'total': 80.18, '0': 82.22, '1': 76.67, '2': 92.22, '3': 77.22, '4': 90.0, '5': 52.78, '6': 61.67, '7': 56.67, '8': 55.56, '9': 56.67, '10': 96.11, '11': 100.0, '12': 80.0, '13': 81.67, '14': 83.33, '15': 85.0, '16': 96.67, '17': 92.22, '18': 93.89, '19': 84.44, '20': 90.0, '21': 85.0, '22': 73.33, '23': 82.22, 'old': 76.19, 'new': 86.17}
2025-02-19 14:47:07,586 [trainer.py] => CNN top1 curve: [86.04, 83.76]
2025-02-19 14:47:07,586 [trainer.py] => CNN top5 curve: [98.78, 98.31]
2025-02-19 14:47:07,586 [trainer.py] => NME top1 curve: [84.48, 80.18]
2025-02-19 14:47:07,586 [trainer.py] => NME top5 curve: [98.63, 98.2]

2025-02-19 14:47:07,587 [trainer.py] => All params: 8243492
2025-02-19 14:47:07,587 [trainer.py] => Trainable params: 4137380
2025-02-19 14:47:07,651 [der.py] => Learning on 25-35
2025-02-19 14:47:07,651 [der.py] => All params: 8253742
2025-02-19 14:47:07,652 [der.py] => Trainable params: 4147630
2025-02-19 14:47:07,745 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-19 14:47:07,746 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-19 15:00:02,912 [der.py] => Task 2, Epoch 150/150 => Loss 0.005, Loss_clf 0.005, Loss_aux 2.513, Train_accy 100.00
2025-02-19 15:00:10,791 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.323,  Train_accy 45.80, Test_accy 51.97
2025-02-19 15:00:14,771 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.007,  Train_accy 67.09
2025-02-19 15:00:18,712 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.893,  Train_accy 75.52
2025-02-19 15:00:22,644 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.836,  Train_accy 79.52
2025-02-19 15:00:26,484 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.806,  Train_accy 81.29
2025-02-19 15:00:34,144 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.768,  Train_accy 84.06, Test_accy 64.70
2025-02-19 15:00:38,065 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.749,  Train_accy 85.64
2025-02-19 15:00:42,168 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.725,  Train_accy 86.77
2025-02-19 15:00:46,014 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.711,  Train_accy 87.52
2025-02-19 15:00:49,840 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.700,  Train_accy 88.32
2025-02-19 15:00:57,196 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.688,  Train_accy 89.01, Test_accy 67.17
2025-02-19 15:01:00,679 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.671,  Train_accy 90.77
2025-02-19 15:01:04,393 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.669,  Train_accy 91.03
2025-02-19 15:01:07,847 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.664,  Train_accy 90.61
2025-02-19 15:01:11,484 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.651,  Train_accy 91.49
2025-02-19 15:01:18,235 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.648,  Train_accy 91.21, Test_accy 69.13
2025-02-19 15:01:21,875 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.647,  Train_accy 91.58
2025-02-19 15:01:25,466 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.641,  Train_accy 92.06
2025-02-19 15:01:28,961 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.635,  Train_accy 92.10
2025-02-19 15:01:32,766 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.634,  Train_accy 92.48
2025-02-19 15:01:40,309 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.629,  Train_accy 92.79, Test_accy 69.92
2025-02-19 15:01:43,870 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.627,  Train_accy 92.44
2025-02-19 15:01:47,665 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.622,  Train_accy 92.97
2025-02-19 15:01:51,181 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.620,  Train_accy 93.31
2025-02-19 15:01:54,715 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.615,  Train_accy 92.77
2025-02-19 15:02:01,740 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.615,  Train_accy 93.39, Test_accy 69.27
2025-02-19 15:02:05,496 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.613,  Train_accy 93.49
2025-02-19 15:02:09,181 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.613,  Train_accy 93.54
2025-02-19 15:02:12,975 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.611,  Train_accy 93.01
2025-02-19 15:02:16,666 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.611,  Train_accy 93.23
2025-02-19 15:02:23,511 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.608,  Train_accy 93.45, Test_accy 70.08
2025-02-19 15:02:27,278 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.608,  Train_accy 93.29
2025-02-19 15:02:31,045 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.607,  Train_accy 93.76
2025-02-19 15:02:34,869 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.602,  Train_accy 93.78
2025-02-19 15:02:38,408 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.603,  Train_accy 93.52
2025-02-19 15:02:45,328 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.604,  Train_accy 93.47, Test_accy 70.59
2025-02-19 15:02:49,044 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.601,  Train_accy 94.06
2025-02-19 15:02:52,944 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.597,  Train_accy 93.90
2025-02-19 15:02:56,670 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.602,  Train_accy 93.80
2025-02-19 15:03:00,672 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.597,  Train_accy 94.06
2025-02-19 15:03:07,529 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.598,  Train_accy 94.04, Test_accy 70.40
2025-02-19 15:03:10,975 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.597,  Train_accy 93.80
2025-02-19 15:03:14,410 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.596,  Train_accy 93.76
2025-02-19 15:03:17,925 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.594,  Train_accy 93.96
2025-02-19 15:03:21,424 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.594,  Train_accy 94.20
2025-02-19 15:03:28,677 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.594,  Train_accy 93.72, Test_accy 71.22
2025-02-19 15:03:32,128 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.592,  Train_accy 93.90
2025-02-19 15:03:35,624 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.591,  Train_accy 93.92
2025-02-19 15:03:39,141 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.591,  Train_accy 94.46
2025-02-19 15:03:42,907 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.590,  Train_accy 94.16
2025-02-19 15:03:49,705 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.592,  Train_accy 94.51, Test_accy 70.94
2025-02-19 15:03:53,529 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.588,  Train_accy 94.51
2025-02-19 15:03:57,486 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.589,  Train_accy 94.02
2025-02-19 15:04:01,052 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.590,  Train_accy 94.22
2025-02-19 15:04:04,575 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.590,  Train_accy 94.16
2025-02-19 15:04:11,355 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.588,  Train_accy 94.02, Test_accy 71.11
2025-02-19 15:04:14,893 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.587,  Train_accy 94.42
2025-02-19 15:04:18,788 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.585,  Train_accy 94.51
2025-02-19 15:04:22,248 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.586,  Train_accy 94.16
2025-02-19 15:04:26,060 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.586,  Train_accy 93.94
2025-02-19 15:04:32,877 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.586,  Train_accy 94.10, Test_accy 71.33
2025-02-19 15:04:36,432 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.583,  Train_accy 94.65
2025-02-19 15:04:39,954 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.582,  Train_accy 94.73
2025-02-19 15:04:43,467 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.583,  Train_accy 94.12
2025-02-19 15:04:47,061 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.583,  Train_accy 94.53
2025-02-19 15:04:54,030 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.583,  Train_accy 94.16, Test_accy 70.78
2025-02-19 15:04:57,823 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.582,  Train_accy 94.63
2025-02-19 15:05:01,400 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.583,  Train_accy 94.10
2025-02-19 15:05:04,937 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.580,  Train_accy 94.59
2025-02-19 15:05:08,465 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.581,  Train_accy 94.53
2025-02-19 15:05:15,504 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.580,  Train_accy 94.75, Test_accy 71.38
2025-02-19 15:05:19,042 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.580,  Train_accy 94.53
2025-02-19 15:05:22,676 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.579,  Train_accy 94.75
2025-02-19 15:05:26,489 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.580,  Train_accy 94.28
2025-02-19 15:05:30,383 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.579,  Train_accy 94.67
2025-02-19 15:05:38,047 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.580,  Train_accy 94.44, Test_accy 71.40
2025-02-19 15:05:41,665 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.580,  Train_accy 94.42
2025-02-19 15:05:45,178 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.578,  Train_accy 94.61
2025-02-19 15:05:48,699 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.579,  Train_accy 94.85
2025-02-19 15:05:52,250 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.579,  Train_accy 94.48
2025-02-19 15:05:59,028 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.578,  Train_accy 94.73, Test_accy 71.06
2025-02-19 15:06:02,655 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.577,  Train_accy 94.55
2025-02-19 15:06:06,314 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.577,  Train_accy 94.65
2025-02-19 15:06:10,296 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.577,  Train_accy 94.57
2025-02-19 15:06:15,089 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.580,  Train_accy 94.85
2025-02-19 15:06:21,938 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.577,  Train_accy 94.75, Test_accy 71.52
2025-02-19 15:06:25,490 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.576,  Train_accy 94.61
2025-02-19 15:06:29,093 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.577,  Train_accy 94.59
2025-02-19 15:06:32,662 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.576,  Train_accy 95.21
2025-02-19 15:06:36,192 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.576,  Train_accy 94.89
2025-02-19 15:06:43,266 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.575,  Train_accy 95.05, Test_accy 71.79
2025-02-19 15:06:46,825 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.576,  Train_accy 94.51
2025-02-19 15:06:50,757 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.577,  Train_accy 94.85
2025-02-19 15:06:54,240 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.576,  Train_accy 94.85
2025-02-19 15:06:57,798 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.577,  Train_accy 95.17
2025-02-19 15:07:04,880 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.575,  Train_accy 94.91, Test_accy 71.51
2025-02-19 15:07:08,422 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.575,  Train_accy 94.71
2025-02-19 15:07:12,322 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.575,  Train_accy 94.91
2025-02-19 15:07:15,966 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.574,  Train_accy 94.99
2025-02-19 15:07:19,481 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.575,  Train_accy 94.83
2025-02-19 15:07:26,410 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.575,  Train_accy 94.69, Test_accy 71.51
2025-02-19 15:07:29,885 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.574,  Train_accy 94.85
2025-02-19 15:07:33,399 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.574,  Train_accy 94.85
2025-02-19 15:07:36,920 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.573,  Train_accy 95.23
2025-02-19 15:07:40,558 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.573,  Train_accy 94.85
2025-02-19 15:07:47,314 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.574,  Train_accy 94.71, Test_accy 71.70
2025-02-19 15:07:50,804 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.573,  Train_accy 95.45
2025-02-19 15:07:54,366 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.574,  Train_accy 94.69
2025-02-19 15:07:57,953 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.575,  Train_accy 95.05
2025-02-19 15:08:01,603 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.573,  Train_accy 94.95
2025-02-19 15:08:08,630 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.576,  Train_accy 95.03, Test_accy 71.92
2025-02-19 15:08:12,192 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.574,  Train_accy 95.03
2025-02-19 15:08:15,625 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.575,  Train_accy 94.83
2025-02-19 15:08:19,239 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.573,  Train_accy 95.05
2025-02-19 15:08:22,829 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.573,  Train_accy 94.65
2025-02-19 15:08:29,718 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.572,  Train_accy 95.27, Test_accy 71.67
2025-02-19 15:08:33,265 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.574,  Train_accy 94.69
2025-02-19 15:08:36,814 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.573,  Train_accy 95.15
2025-02-19 15:08:40,476 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.574,  Train_accy 94.53
2025-02-19 15:08:43,967 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.574,  Train_accy 94.63
2025-02-19 15:08:51,040 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.574,  Train_accy 95.07, Test_accy 71.90
2025-02-19 15:08:54,530 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.572,  Train_accy 94.95
2025-02-19 15:08:58,089 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.573,  Train_accy 95.03
2025-02-19 15:09:01,575 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.573,  Train_accy 94.53
2025-02-19 15:09:05,079 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.573,  Train_accy 94.65
2025-02-19 15:09:12,099 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.574,  Train_accy 94.46, Test_accy 71.60
2025-02-19 15:09:15,696 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.573,  Train_accy 95.07
2025-02-19 15:09:19,162 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.571,  Train_accy 95.07
2025-02-19 15:09:22,615 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.572,  Train_accy 94.89
2025-02-19 15:09:26,114 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.573,  Train_accy 94.69
2025-02-19 15:09:26,114 [der.py] => do not weight align student!
2025-02-19 15:09:29,387 [der.py] => darknet eval: 
2025-02-19 15:09:29,387 [der.py] => CNN top1 curve: 71.75
2025-02-19 15:09:29,388 [der.py] => CNN top5 curve: 94.92
2025-02-19 15:09:29,389 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 15:10:00,133 [der.py] => Exemplar size: 1050
2025-02-19 15:10:00,133 [trainer.py] => CNN: {'total': 73.6, '0': 75.56, '1': 48.89, '2': 83.89, '3': 46.11, '4': 80.0, '5': 30.0, '6': 62.78, '7': 38.89, '8': 47.78, '9': 41.11, '10': 85.56, '11': 96.67, '12': 72.78, '13': 57.22, '14': 55.0, '15': 90.0, '16': 96.67, '17': 92.22, '18': 96.11, '19': 92.22, '20': 93.89, '21': 76.11, '22': 88.33, '23': 77.78, '24': 72.22, '25': 63.89, '26': 86.11, '27': 79.44, '28': 60.56, '29': 71.11, '30': 83.89, '31': 84.44, '32': 95.56, '33': 78.89, 'old': 71.91, 'new': 77.83}
2025-02-19 15:10:00,133 [trainer.py] => NME: {'total': 70.08, '0': 83.33, '1': 48.33, '2': 81.67, '3': 48.33, '4': 77.22, '5': 36.11, '6': 60.0, '7': 38.89, '8': 55.0, '9': 43.89, '10': 91.11, '11': 86.11, '12': 71.11, '13': 56.67, '14': 56.67, '15': 88.33, '16': 90.56, '17': 88.33, '18': 90.56, '19': 87.78, '20': 87.78, '21': 78.89, '22': 67.78, '23': 56.11, '24': 46.11, '25': 61.67, '26': 87.22, '27': 80.56, '28': 53.89, '29': 63.33, '30': 77.78, '31': 76.67, '32': 91.11, '33': 73.89, 'old': 68.67, 'new': 73.61}
2025-02-19 15:10:00,133 [trainer.py] => CNN top1 curve: [86.04, 83.76, 73.6]
2025-02-19 15:10:00,133 [trainer.py] => CNN top5 curve: [98.78, 98.31, 94.95]
2025-02-19 15:10:00,133 [trainer.py] => NME top1 curve: [84.48, 80.18, 70.08]
2025-02-19 15:10:00,133 [trainer.py] => NME top5 curve: [98.63, 98.2, 95.63]

2025-02-19 15:10:00,133 [trainer.py] => All params: 8253742
2025-02-19 15:10:00,134 [trainer.py] => Trainable params: 4147630
2025-02-19 15:10:00,195 [der.py] => Learning on 35-45
2025-02-19 15:10:00,195 [der.py] => All params: 8263992
2025-02-19 15:10:00,196 [der.py] => Trainable params: 4157880
2025-02-19 15:10:00,277 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-19 15:10:00,278 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-19 15:23:39,946 [der.py] => Task 3, Epoch 150/150 => Loss 0.038, Loss_clf 0.038, Loss_aux 2.370, Train_accy 99.90
2025-02-19 15:23:47,923 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.384,  Train_accy 23.05, Test_accy 46.77
2025-02-19 15:23:51,617 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.289,  Train_accy 24.80
2025-02-19 15:23:55,294 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 2.411,  Train_accy 23.47
2025-02-19 15:23:59,024 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 2.355,  Train_accy 24.50
2025-02-19 15:24:02,874 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 2.404,  Train_accy 23.37
2025-02-19 15:24:11,163 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.383,  Train_accy 24.40, Test_accy 40.35
2025-02-19 15:24:15,003 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 2.439,  Train_accy 23.03
2025-02-19 15:24:18,846 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 2.326,  Train_accy 26.63
2025-02-19 15:24:22,560 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 2.301,  Train_accy 27.35
2025-02-19 15:24:26,429 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 2.370,  Train_accy 25.68
2025-02-19 15:24:34,094 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.263,  Train_accy 28.32, Test_accy 44.65
2025-02-19 15:24:37,890 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.260,  Train_accy 29.10
2025-02-19 15:24:41,614 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.270,  Train_accy 28.17
2025-02-19 15:24:45,474 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.230,  Train_accy 29.58
2025-02-19 15:24:49,315 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.237,  Train_accy 30.30
2025-02-19 15:24:57,636 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.189,  Train_accy 30.86, Test_accy 48.93
2025-02-19 15:25:01,806 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.203,  Train_accy 30.84
2025-02-19 15:25:05,582 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.243,  Train_accy 29.47
2025-02-19 15:25:09,405 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.227,  Train_accy 30.90
2025-02-19 15:25:13,199 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.231,  Train_accy 30.21
2025-02-19 15:25:21,132 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.224,  Train_accy 31.03, Test_accy 44.49
2025-02-19 15:25:24,922 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.268,  Train_accy 29.37
2025-02-19 15:25:28,764 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.196,  Train_accy 31.85
2025-02-19 15:25:32,712 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.277,  Train_accy 28.86
2025-02-19 15:25:36,631 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 2.227,  Train_accy 31.41
2025-02-19 15:25:44,650 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 2.238,  Train_accy 30.72, Test_accy 47.49
2025-02-19 15:25:48,524 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 2.231,  Train_accy 30.30
2025-02-19 15:25:52,298 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 2.192,  Train_accy 32.13
2025-02-19 15:25:56,124 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 2.218,  Train_accy 31.68
2025-02-19 15:25:59,819 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 2.158,  Train_accy 32.19
2025-02-19 15:26:07,784 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 2.190,  Train_accy 32.04, Test_accy 49.02
2025-02-19 15:26:11,461 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 2.190,  Train_accy 31.92
2025-02-19 15:26:15,347 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 2.206,  Train_accy 31.50
2025-02-19 15:26:19,063 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 2.165,  Train_accy 32.67
2025-02-19 15:26:22,741 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 2.145,  Train_accy 32.84
2025-02-19 15:26:31,114 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 2.163,  Train_accy 32.17, Test_accy 49.11
2025-02-19 15:26:34,876 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 2.152,  Train_accy 32.84
2025-02-19 15:26:38,889 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 2.131,  Train_accy 33.05
2025-02-19 15:26:42,606 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 2.199,  Train_accy 31.22
2025-02-19 15:26:46,224 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 2.157,  Train_accy 32.99
2025-02-19 15:26:54,177 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 2.157,  Train_accy 32.57, Test_accy 50.42
2025-02-19 15:26:58,010 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 2.141,  Train_accy 32.88
2025-02-19 15:27:01,857 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 2.147,  Train_accy 31.94
2025-02-19 15:27:05,613 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 2.150,  Train_accy 32.82
2025-02-19 15:27:09,342 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 2.149,  Train_accy 33.49
2025-02-19 15:27:16,860 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 2.142,  Train_accy 32.17, Test_accy 48.68
2025-02-19 15:27:20,538 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 2.184,  Train_accy 32.08
2025-02-19 15:27:24,214 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 2.187,  Train_accy 32.23
2025-02-19 15:27:27,851 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 2.205,  Train_accy 31.49
2025-02-19 15:27:31,474 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 2.179,  Train_accy 32.78
2025-02-19 15:27:39,026 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 2.170,  Train_accy 33.14, Test_accy 49.93
2025-02-19 15:27:42,676 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 2.154,  Train_accy 33.35
2025-02-19 15:27:46,270 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 2.147,  Train_accy 32.53
2025-02-19 15:27:49,807 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 2.150,  Train_accy 32.51
2025-02-19 15:27:53,631 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 2.151,  Train_accy 32.67
2025-02-19 15:28:01,508 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 2.148,  Train_accy 32.32, Test_accy 48.84
2025-02-19 15:28:05,169 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 2.195,  Train_accy 31.37
2025-02-19 15:28:08,911 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 2.165,  Train_accy 32.88
2025-02-19 15:28:12,538 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 2.139,  Train_accy 33.37
2025-02-19 15:28:16,255 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 2.141,  Train_accy 34.11
2025-02-19 15:28:23,983 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 2.151,  Train_accy 33.24, Test_accy 49.41
2025-02-19 15:28:27,689 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 2.138,  Train_accy 33.89
2025-02-19 15:28:31,397 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 2.136,  Train_accy 33.68
2025-02-19 15:28:35,151 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 2.145,  Train_accy 33.33
2025-02-19 15:28:38,787 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 2.169,  Train_accy 32.74
2025-02-19 15:28:46,323 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 2.141,  Train_accy 33.62, Test_accy 48.23
2025-02-19 15:28:50,041 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 2.127,  Train_accy 33.62
2025-02-19 15:28:53,763 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 2.137,  Train_accy 32.27
2025-02-19 15:28:57,499 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 2.137,  Train_accy 33.33
2025-02-19 15:29:01,203 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 2.126,  Train_accy 34.04
2025-02-19 15:29:09,294 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 2.129,  Train_accy 33.18, Test_accy 49.19
2025-02-19 15:29:13,293 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 2.128,  Train_accy 32.48
2025-02-19 15:29:16,969 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 2.131,  Train_accy 34.15
2025-02-19 15:29:20,622 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 2.139,  Train_accy 32.97
2025-02-19 15:29:24,238 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 2.122,  Train_accy 34.02
2025-02-19 15:29:32,339 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 2.114,  Train_accy 33.62, Test_accy 50.65
2025-02-19 15:29:36,038 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 2.114,  Train_accy 33.62
2025-02-19 15:29:39,847 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 2.122,  Train_accy 33.62
2025-02-19 15:29:43,492 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 2.124,  Train_accy 34.15
2025-02-19 15:29:47,192 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 2.118,  Train_accy 33.85
2025-02-19 15:29:55,122 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 2.112,  Train_accy 33.60, Test_accy 51.37
2025-02-19 15:29:59,162 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 2.123,  Train_accy 33.50
2025-02-19 15:30:02,855 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 2.125,  Train_accy 33.14
2025-02-19 15:30:06,928 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 2.123,  Train_accy 33.70
2025-02-19 15:30:10,690 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 2.109,  Train_accy 34.08
2025-02-19 15:30:18,498 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 2.104,  Train_accy 34.30, Test_accy 52.51
2025-02-19 15:30:22,176 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 2.105,  Train_accy 33.37
2025-02-19 15:30:25,912 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 2.128,  Train_accy 34.30
2025-02-19 15:30:29,803 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 2.114,  Train_accy 33.45
2025-02-19 15:30:33,491 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 2.113,  Train_accy 33.41
2025-02-19 15:30:41,407 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 2.113,  Train_accy 33.68, Test_accy 52.15
2025-02-19 15:30:45,132 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 2.115,  Train_accy 33.92
2025-02-19 15:30:48,820 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 2.115,  Train_accy 33.89
2025-02-19 15:30:52,502 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 2.110,  Train_accy 33.81
2025-02-19 15:30:56,188 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 2.101,  Train_accy 33.94
2025-02-19 15:31:03,884 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 2.110,  Train_accy 34.13, Test_accy 51.35
2025-02-19 15:31:07,596 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 2.102,  Train_accy 33.81
2025-02-19 15:31:11,218 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 2.106,  Train_accy 34.34
2025-02-19 15:31:14,978 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 2.103,  Train_accy 33.94
2025-02-19 15:31:18,701 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 2.103,  Train_accy 33.41
2025-02-19 15:31:26,308 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 2.111,  Train_accy 34.32, Test_accy 50.86
2025-02-19 15:31:29,918 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 2.106,  Train_accy 33.96
2025-02-19 15:31:33,658 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 2.118,  Train_accy 34.29
2025-02-19 15:31:37,387 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 2.091,  Train_accy 34.51
2025-02-19 15:31:40,987 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 2.088,  Train_accy 33.58
2025-02-19 15:31:48,893 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 2.101,  Train_accy 34.08, Test_accy 49.86
2025-02-19 15:31:52,849 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 2.105,  Train_accy 33.92
2025-02-19 15:31:56,580 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 2.096,  Train_accy 33.96
2025-02-19 15:32:00,534 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 2.075,  Train_accy 33.52
2025-02-19 15:32:04,431 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 2.106,  Train_accy 34.06
2025-02-19 15:32:12,837 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 2.094,  Train_accy 33.68, Test_accy 50.22
2025-02-19 15:32:16,558 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 2.102,  Train_accy 33.87
2025-02-19 15:32:20,202 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 2.105,  Train_accy 33.43
2025-02-19 15:32:23,879 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 2.101,  Train_accy 33.66
2025-02-19 15:32:27,513 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 2.116,  Train_accy 34.25
2025-02-19 15:32:35,227 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 2.099,  Train_accy 34.42, Test_accy 51.67
2025-02-19 15:32:38,811 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 2.103,  Train_accy 34.13
2025-02-19 15:32:42,563 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 2.103,  Train_accy 34.06
2025-02-19 15:32:46,235 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 2.101,  Train_accy 33.68
2025-02-19 15:32:49,883 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 2.102,  Train_accy 33.70
2025-02-19 15:32:57,548 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 2.107,  Train_accy 33.81, Test_accy 50.47
2025-02-19 15:33:01,109 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 2.100,  Train_accy 34.21
2025-02-19 15:33:04,728 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 2.094,  Train_accy 34.10
2025-02-19 15:33:08,349 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 2.089,  Train_accy 34.06
2025-02-19 15:33:12,004 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 2.099,  Train_accy 34.30
2025-02-19 15:33:19,475 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 2.092,  Train_accy 34.00, Test_accy 51.52
2025-02-19 15:33:23,111 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 2.103,  Train_accy 34.06
2025-02-19 15:33:26,704 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 2.102,  Train_accy 33.92
2025-02-19 15:33:30,330 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 2.095,  Train_accy 33.87
2025-02-19 15:33:34,008 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 2.102,  Train_accy 34.57
2025-02-19 15:33:34,009 [der.py] => do not weight align student!
2025-02-19 15:33:37,939 [der.py] => darknet eval: 
2025-02-19 15:33:37,940 [der.py] => CNN top1 curve: 51.14
2025-02-19 15:33:37,940 [der.py] => CNN top5 curve: 87.95
2025-02-19 15:33:37,940 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 15:34:19,860 [der.py] => Exemplar size: 1350
2025-02-19 15:34:19,860 [trainer.py] => CNN: {'total': 60.85, '0': 65.56, '1': 47.22, '2': 81.11, '3': 40.0, '4': 65.0, '5': 22.78, '6': 53.33, '7': 36.67, '8': 52.78, '9': 31.11, '10': 86.11, '11': 91.11, '12': 68.89, '13': 58.89, '14': 31.67, '15': 89.44, '16': 82.78, '17': 87.22, '18': 82.78, '19': 65.56, '20': 84.44, '21': 67.78, '22': 75.56, '23': 56.67, '24': 48.89, '25': 87.22, '26': 93.33, '27': 91.67, '28': 69.44, '29': 77.78, '30': 86.67, '31': 84.44, '32': 97.22, '33': 82.78, '34': 74.44, '35': 52.22, '36': 68.33, '37': 17.78, '38': 7.78, '39': 23.33, '40': 27.78, '41': 38.33, '42': 36.11, '43': 30.0, 'old': 69.1, 'new': 32.0}
2025-02-19 15:34:19,860 [trainer.py] => NME: {'total': 63.38, '0': 57.78, '1': 41.11, '2': 76.67, '3': 28.33, '4': 72.78, '5': 29.44, '6': 54.44, '7': 35.56, '8': 56.67, '9': 41.67, '10': 88.89, '11': 83.89, '12': 65.0, '13': 55.56, '14': 45.0, '15': 87.22, '16': 85.56, '17': 83.89, '18': 78.89, '19': 72.78, '20': 84.44, '21': 50.56, '22': 62.78, '23': 45.56, '24': 43.33, '25': 61.67, '26': 85.0, '27': 82.78, '28': 62.22, '29': 67.22, '30': 78.89, '31': 76.11, '32': 86.11, '33': 51.11, '34': 70.56, '35': 86.67, '36': 79.44, '37': 43.33, '38': 81.67, '39': 60.0, '40': 44.44, '41': 56.67, '42': 64.44, '43': 47.22, 'old': 64.27, 'new': 60.28}
2025-02-19 15:34:19,860 [trainer.py] => CNN top1 curve: [86.04, 83.76, 73.6, 60.85]
2025-02-19 15:34:19,860 [trainer.py] => CNN top5 curve: [98.78, 98.31, 94.95, 92.72]
2025-02-19 15:34:19,860 [trainer.py] => NME top1 curve: [84.48, 80.18, 70.08, 63.38]
2025-02-19 15:34:19,860 [trainer.py] => NME top5 curve: [98.63, 98.2, 95.63, 91.93]

2025-02-19 15:34:19,861 [trainer.py] => All params: 8263992
2025-02-19 15:34:19,861 [trainer.py] => Trainable params: 4157880
2025-02-19 15:34:19,921 [der.py] => Learning on 45-55
2025-02-19 15:34:19,922 [der.py] => All params: 8274242
2025-02-19 15:34:19,922 [der.py] => Trainable params: 4168130
2025-02-19 15:34:20,013 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-19 15:34:20,014 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-19 16:05:22,920 [der.py] => Task 4, Epoch 150/150 => Loss 0.009, Loss_clf 0.009, Loss_aux 2.448, Train_accy 100.00
2025-02-19 16:05:41,328 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.969,  Train_accy 36.92, Test_accy 52.46
2025-02-19 16:05:44,968 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.716,  Train_accy 58.14
2025-02-19 16:05:55,844 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.608,  Train_accy 70.41
2025-02-19 16:06:01,340 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.556,  Train_accy 75.98
2025-02-19 16:06:05,238 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.514,  Train_accy 80.45
2025-02-19 16:06:20,639 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.486,  Train_accy 83.60, Test_accy 59.24
2025-02-19 16:06:26,498 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.464,  Train_accy 86.13
2025-02-19 16:06:30,159 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.455,  Train_accy 86.09
2025-02-19 16:06:35,922 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.442,  Train_accy 88.23
2025-02-19 16:06:39,587 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.428,  Train_accy 89.06
2025-02-19 16:06:47,748 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.423,  Train_accy 89.66, Test_accy 59.91
2025-02-19 16:06:55,597 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.428,  Train_accy 89.44
2025-02-19 16:07:02,157 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.412,  Train_accy 90.36
2025-02-19 16:07:05,830 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.409,  Train_accy 91.23
2025-02-19 16:07:09,445 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.398,  Train_accy 92.05
2025-02-19 16:07:17,691 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.394,  Train_accy 92.34, Test_accy 60.96
2025-02-19 16:07:21,333 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.390,  Train_accy 92.38
2025-02-19 16:07:25,017 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.391,  Train_accy 92.76
2025-02-19 16:07:29,013 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.385,  Train_accy 92.90
2025-02-19 16:07:32,796 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.382,  Train_accy 92.97
2025-02-19 16:07:41,176 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.377,  Train_accy 93.41, Test_accy 61.34
2025-02-19 16:07:51,652 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.374,  Train_accy 93.82
2025-02-19 16:07:59,110 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.382,  Train_accy 92.54
2025-02-19 16:08:02,730 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.379,  Train_accy 93.78
2025-02-19 16:08:06,388 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.373,  Train_accy 93.77
2025-02-19 16:08:17,892 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.370,  Train_accy 94.11, Test_accy 61.68
2025-02-19 16:08:21,530 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.368,  Train_accy 94.04
2025-02-19 16:08:25,188 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.365,  Train_accy 94.54
2025-02-19 16:08:28,818 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.365,  Train_accy 94.40
2025-02-19 16:08:32,551 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.361,  Train_accy 94.86
2025-02-19 16:08:56,944 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.361,  Train_accy 94.34, Test_accy 61.90
2025-02-19 16:09:00,727 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.361,  Train_accy 94.59
2025-02-19 16:09:04,347 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.361,  Train_accy 94.99
2025-02-19 16:09:08,221 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.359,  Train_accy 94.83
2025-02-19 16:09:11,873 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.360,  Train_accy 94.50
2025-02-19 16:09:19,782 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.356,  Train_accy 94.74, Test_accy 62.49
2025-02-19 16:09:23,549 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.356,  Train_accy 95.30
2025-02-19 16:09:27,334 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.352,  Train_accy 95.33
2025-02-19 16:09:31,029 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.354,  Train_accy 94.83
2025-02-19 16:09:34,826 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.352,  Train_accy 94.67
2025-02-19 16:09:42,866 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.352,  Train_accy 94.99, Test_accy 61.95
2025-02-19 16:09:46,683 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.354,  Train_accy 94.99
2025-02-19 16:09:50,477 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.352,  Train_accy 95.28
2025-02-19 16:09:54,392 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.347,  Train_accy 95.42
2025-02-19 16:09:58,274 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.346,  Train_accy 95.42
2025-02-19 16:10:06,162 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.348,  Train_accy 94.99, Test_accy 62.58
2025-02-19 16:10:10,021 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.347,  Train_accy 95.50
2025-02-19 16:10:13,657 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.350,  Train_accy 95.30
2025-02-19 16:10:17,304 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.347,  Train_accy 95.24
2025-02-19 16:10:21,404 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.347,  Train_accy 95.28
2025-02-19 16:10:29,508 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.345,  Train_accy 95.91, Test_accy 62.19
2025-02-19 16:10:33,142 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.344,  Train_accy 95.44
2025-02-19 16:10:37,026 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.344,  Train_accy 95.95
2025-02-19 16:10:40,720 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.344,  Train_accy 95.91
2025-02-19 16:10:44,444 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.342,  Train_accy 95.55
2025-02-19 16:10:52,275 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.347,  Train_accy 95.44, Test_accy 62.33
2025-02-19 16:10:55,848 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.342,  Train_accy 95.62
2025-02-19 16:10:59,481 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.340,  Train_accy 95.87
2025-02-19 16:11:03,128 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.344,  Train_accy 95.53
2025-02-19 16:11:06,754 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.338,  Train_accy 96.36
2025-02-19 16:11:14,671 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.340,  Train_accy 95.39, Test_accy 62.23
2025-02-19 16:11:18,325 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.340,  Train_accy 96.16
2025-02-19 16:11:22,056 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.338,  Train_accy 95.87
2025-02-19 16:11:25,893 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.337,  Train_accy 95.80
2025-02-19 16:11:29,522 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.342,  Train_accy 95.93
2025-02-19 16:11:37,381 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.340,  Train_accy 95.96, Test_accy 62.62
2025-02-19 16:11:40,993 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.336,  Train_accy 95.77
2025-02-19 16:11:44,674 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.339,  Train_accy 95.87
2025-02-19 16:11:48,427 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.338,  Train_accy 95.71
2025-02-19 16:11:52,098 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.337,  Train_accy 96.13
2025-02-19 16:11:59,938 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.335,  Train_accy 96.13, Test_accy 62.90
2025-02-19 16:12:03,995 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.339,  Train_accy 95.73
2025-02-19 16:12:07,586 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.338,  Train_accy 96.02
2025-02-19 16:12:11,212 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.336,  Train_accy 96.11
2025-02-19 16:12:14,804 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.337,  Train_accy 96.11
2025-02-19 16:12:23,072 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.335,  Train_accy 96.00, Test_accy 62.89
2025-02-19 16:12:26,933 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.336,  Train_accy 96.07
2025-02-19 16:12:30,789 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.338,  Train_accy 95.96
2025-02-19 16:12:34,440 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.337,  Train_accy 96.25
2025-02-19 16:12:38,167 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.334,  Train_accy 96.07
2025-02-19 16:12:46,045 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.335,  Train_accy 96.07, Test_accy 62.59
2025-02-19 16:12:49,853 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.335,  Train_accy 96.05
2025-02-19 16:12:53,703 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.337,  Train_accy 96.00
2025-02-19 16:12:57,398 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.335,  Train_accy 96.07
2025-02-19 16:13:00,967 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.333,  Train_accy 95.91
2025-02-19 16:13:09,255 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.336,  Train_accy 95.78, Test_accy 62.98
2025-02-19 16:13:12,908 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.334,  Train_accy 95.89
2025-02-19 16:13:16,721 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.331,  Train_accy 96.04
2025-02-19 16:13:20,422 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.335,  Train_accy 96.09
2025-02-19 16:13:24,039 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.333,  Train_accy 95.75
2025-02-19 16:13:31,876 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.335,  Train_accy 96.11, Test_accy 62.77
2025-02-19 16:13:35,494 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.332,  Train_accy 95.98
2025-02-19 16:13:39,239 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.331,  Train_accy 96.09
2025-02-19 16:13:42,841 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.334,  Train_accy 96.20
2025-02-19 16:13:46,547 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.334,  Train_accy 96.16
2025-02-19 16:13:54,421 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.332,  Train_accy 96.00, Test_accy 62.99
2025-02-19 16:13:58,054 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.330,  Train_accy 96.13
2025-02-19 16:14:01,753 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.331,  Train_accy 96.23
2025-02-19 16:14:05,518 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.332,  Train_accy 96.13
2025-02-19 16:14:09,303 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.330,  Train_accy 96.16
2025-02-19 16:14:17,502 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.333,  Train_accy 96.41, Test_accy 63.16
2025-02-19 16:14:21,196 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.332,  Train_accy 96.09
2025-02-19 16:14:24,958 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.332,  Train_accy 96.41
2025-02-19 16:14:28,813 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.330,  Train_accy 95.86
2025-02-19 16:14:32,438 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.332,  Train_accy 96.11
2025-02-19 16:14:40,647 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.330,  Train_accy 96.16, Test_accy 62.82
2025-02-19 16:14:44,322 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.335,  Train_accy 96.23
2025-02-19 16:14:47,916 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.330,  Train_accy 96.13
2025-02-19 16:14:51,562 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.328,  Train_accy 96.11
2025-02-19 16:14:55,214 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.331,  Train_accy 96.02
2025-02-19 16:15:03,451 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.329,  Train_accy 96.05, Test_accy 63.31
2025-02-19 16:15:07,090 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.332,  Train_accy 96.11
2025-02-19 16:15:10,935 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.333,  Train_accy 96.22
2025-02-19 16:15:14,571 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.334,  Train_accy 96.16
2025-02-19 16:15:18,174 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.331,  Train_accy 96.47
2025-02-19 16:15:26,069 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.330,  Train_accy 96.38, Test_accy 62.96
2025-02-19 16:15:29,730 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.331,  Train_accy 96.27
2025-02-19 16:15:33,451 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.333,  Train_accy 96.32
2025-02-19 16:15:37,067 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.333,  Train_accy 96.20
2025-02-19 16:15:41,048 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.332,  Train_accy 96.29
2025-02-19 16:15:49,649 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.331,  Train_accy 96.31, Test_accy 63.02
2025-02-19 16:15:53,571 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.328,  Train_accy 96.31
2025-02-19 16:15:57,189 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.333,  Train_accy 95.98
2025-02-19 16:16:00,871 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.329,  Train_accy 96.11
2025-02-19 16:16:04,686 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.334,  Train_accy 96.29
2025-02-19 16:16:12,763 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.331,  Train_accy 96.18, Test_accy 63.25
2025-02-19 16:16:16,543 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.329,  Train_accy 96.20
2025-02-19 16:16:20,718 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.331,  Train_accy 96.22
2025-02-19 16:16:24,581 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.330,  Train_accy 96.43
2025-02-19 16:16:28,268 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.330,  Train_accy 96.11
2025-02-19 16:16:28,269 [der.py] => do not weight align student!
2025-02-19 16:16:32,518 [der.py] => darknet eval: 
2025-02-19 16:16:32,519 [der.py] => CNN top1 curve: 63.47
2025-02-19 16:16:32,519 [der.py] => CNN top5 curve: 88.48
2025-02-19 16:16:32,520 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-19 16:17:06,868 [der.py] => Exemplar size: 1650
2025-02-19 16:17:06,868 [trainer.py] => CNN: {'total': 62.97, '0': 44.44, '1': 44.44, '2': 65.56, '3': 19.44, '4': 58.89, '5': 25.0, '6': 37.22, '7': 27.78, '8': 49.44, '9': 37.22, '10': 68.33, '11': 62.22, '12': 58.33, '13': 46.67, '14': 43.33, '15': 79.44, '16': 80.56, '17': 70.56, '18': 66.67, '19': 61.67, '20': 71.67, '21': 52.78, '22': 62.22, '23': 47.78, '24': 61.11, '25': 53.33, '26': 70.0, '27': 70.56, '28': 38.33, '29': 43.89, '30': 60.56, '31': 67.78, '32': 82.22, '33': 47.78, '34': 53.33, '35': 93.89, '36': 96.11, '37': 40.56, '38': 76.11, '39': 92.22, '40': 62.78, '41': 85.0, '42': 88.33, '43': 95.0, '44': 35.0, '45': 88.33, '46': 81.11, '47': 76.67, '48': 72.22, '49': 72.78, '50': 70.56, '51': 75.0, '52': 71.67, '53': 73.33, 'old': 59.9, 'new': 76.78}
2025-02-19 16:17:06,868 [trainer.py] => NME: {'total': 55.43, '0': 57.22, '1': 42.78, '2': 58.33, '3': 14.44, '4': 57.78, '5': 22.78, '6': 45.0, '7': 32.22, '8': 53.89, '9': 39.44, '10': 67.78, '11': 75.0, '12': 57.22, '13': 45.0, '14': 49.44, '15': 73.89, '16': 81.11, '17': 70.56, '18': 69.44, '19': 56.11, '20': 64.44, '21': 55.0, '22': 51.67, '23': 41.67, '24': 48.89, '25': 40.56, '26': 60.0, '27': 54.44, '28': 31.67, '29': 31.11, '30': 56.67, '31': 61.67, '32': 76.67, '33': 43.89, '34': 47.78, '35': 65.56, '36': 70.56, '37': 15.56, '38': 56.11, '39': 60.56, '40': 33.33, '41': 57.78, '42': 61.11, '43': 69.44, '44': 15.56, '45': 85.56, '46': 72.22, '47': 77.22, '48': 65.0, '49': 72.22, '50': 60.56, '51': 65.0, '52': 62.78, '53': 71.11, 'old': 52.02, 'new': 70.78}
2025-02-19 16:17:06,868 [trainer.py] => CNN top1 curve: [86.04, 83.76, 73.6, 60.85, 62.97]
2025-02-19 16:17:06,868 [trainer.py] => CNN top5 curve: [98.78, 98.31, 94.95, 92.72, 88.31]
2025-02-19 16:17:06,868 [trainer.py] => NME top1 curve: [84.48, 80.18, 70.08, 63.38, 55.43]
2025-02-19 16:17:06,868 [trainer.py] => NME top5 curve: [98.63, 98.2, 95.63, 91.93, 85.65]

2025-02-19 23:47:20,408 [trainer.py] => 实验名称:resnet18对比实验
2025-02-19 23:47:20,476 [trainer.py] => config: ./exps/der.json
2025-02-19 23:47:20,477 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-19 23:47:20,477 [trainer.py] => prefix: reproduce
2025-02-19 23:47:20,477 [trainer.py] => dataset: xrfdataset
2025-02-19 23:47:20,477 [trainer.py] => memory_size: 1650
2025-02-19 23:47:20,477 [trainer.py] => memory_per_class: 30
2025-02-19 23:47:20,477 [trainer.py] => fixed_memory: True
2025-02-19 23:47:20,478 [trainer.py] => shuffle: True
2025-02-19 23:47:20,478 [trainer.py] => init_cls: 15
2025-02-19 23:47:20,478 [trainer.py] => increment: 10
2025-02-19 23:47:20,478 [trainer.py] => model_name: der
2025-02-19 23:47:20,478 [trainer.py] => compression_epochs: 130
2025-02-19 23:47:20,478 [trainer.py] => compression_lr: 0.1
2025-02-19 23:47:20,478 [trainer.py] => is_student_wa: False
2025-02-19 23:47:20,478 [trainer.py] => wa_value: 1
2025-02-19 23:47:20,478 [trainer.py] => T: 2
2025-02-19 23:47:20,478 [trainer.py] => convnet_type: resnet18
2025-02-19 23:47:20,478 [trainer.py] => device: [device(type='cuda', index=1)]
2025-02-19 23:47:20,478 [trainer.py] => seed: 1993
2025-02-19 23:47:20,624 [data.py] => 加载完毕XRF原始数据集
2025-02-19 23:47:20,643 [data.py] => 加载完毕XRF原始数据集
2025-02-19 23:47:20,643 [trainer.py] => All params: 0
2025-02-19 23:47:20,643 [trainer.py] => Trainable params: 0
2025-02-19 23:47:20,906 [der.py] => Learning on 0-15
2025-02-19 23:47:20,906 [der.py] => All params: 4122015
2025-02-19 23:47:20,906 [der.py] => Trainable params: 4122015
2025-02-19 23:49:00,839 [trainer.py] => 实验名称:resnet18对比实验
2025-02-19 23:49:00,850 [trainer.py] => config: ./exps/der.json
2025-02-19 23:49:00,850 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-19 23:49:00,850 [trainer.py] => prefix: reproduce
2025-02-19 23:49:00,850 [trainer.py] => dataset: xrfdataset
2025-02-19 23:49:00,850 [trainer.py] => memory_size: 1650
2025-02-19 23:49:00,850 [trainer.py] => memory_per_class: 30
2025-02-19 23:49:00,850 [trainer.py] => fixed_memory: True
2025-02-19 23:49:00,850 [trainer.py] => shuffle: True
2025-02-19 23:49:00,850 [trainer.py] => init_cls: 15
2025-02-19 23:49:00,850 [trainer.py] => increment: 10
2025-02-19 23:49:00,850 [trainer.py] => model_name: der
2025-02-19 23:49:00,850 [trainer.py] => compression_epochs: 130
2025-02-19 23:49:00,850 [trainer.py] => compression_lr: 0.1
2025-02-19 23:49:00,850 [trainer.py] => is_student_wa: False
2025-02-19 23:49:00,850 [trainer.py] => wa_value: 1
2025-02-19 23:49:00,850 [trainer.py] => T: 2
2025-02-19 23:49:00,850 [trainer.py] => convnet_type: resnet18
2025-02-19 23:49:00,850 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-19 23:49:00,850 [trainer.py] => seed: 1993
2025-02-19 23:49:00,879 [data.py] => 加载完毕XRF原始数据集
2025-02-19 23:49:00,897 [data.py] => 加载完毕XRF原始数据集
2025-02-19 23:49:00,898 [trainer.py] => All params: 0
2025-02-19 23:49:00,898 [trainer.py] => Trainable params: 0
2025-02-19 23:49:00,988 [der.py] => Learning on 0-15
2025-02-19 23:49:00,988 [der.py] => All params: 4122015
2025-02-19 23:49:00,988 [der.py] => Trainable params: 4122015
2025-02-20 00:09:53,043 [der.py] => Task 0, Epoch 150/150 => Loss 0.032, Train_accy 99.76
2025-02-20 00:09:53,071 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 00:10:15,973 [der.py] => Exemplar size: 450
2025-02-20 00:10:15,974 [trainer.py] => CNN: {'total': 87.7, '0': 98.33, '1': 92.78, '2': 95.0, '3': 85.56, '4': 89.44, '5': 80.56, '6': 76.11, '7': 87.22, '8': 84.44, '9': 66.11, '10': 95.0, '11': 100.0, '12': 87.78, '13': 86.67, 'old': 0, 'new': 87.7}
2025-02-20 00:10:15,974 [trainer.py] => NME: {'total': 86.19, '0': 98.33, '1': 94.44, '2': 91.67, '3': 81.11, '4': 88.89, '5': 73.89, '6': 69.44, '7': 88.33, '8': 86.11, '9': 63.33, '10': 93.33, '11': 100.0, '12': 86.67, '13': 86.11, 'old': 0, 'new': 86.19}
2025-02-20 00:10:15,974 [trainer.py] => CNN top1 curve: [87.7]
2025-02-20 00:10:15,974 [trainer.py] => CNN top5 curve: [98.89]
2025-02-20 00:10:15,974 [trainer.py] => NME top1 curve: [86.19]
2025-02-20 00:10:15,974 [trainer.py] => NME top5 curve: [98.93]

2025-02-20 00:10:15,974 [trainer.py] => All params: 4122015
2025-02-20 00:10:15,975 [trainer.py] => Trainable params: 4122015
2025-02-20 00:10:16,176 [der.py] => Learning on 15-25
2025-02-20 00:10:16,177 [der.py] => All params: 8243492
2025-02-20 00:10:16,178 [der.py] => Trainable params: 4137380
2025-02-20 00:10:16,282 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 00:10:16,284 [der.py] => per cls weights : [1.30537725 1.30537725 1.30537725 1.30537725 1.30537725 1.30537725
 1.30537725 1.30537725 1.30537725 1.30537725 1.30537725 1.30537725
 1.30537725 1.30537725 1.30537725 0.54193413 0.54193413 0.54193413
 0.54193413 0.54193413 0.54193413 0.54193413 0.54193413 0.54193413
 0.54193413]
2025-02-20 00:27:10,443 [der.py] => Task 1, Epoch 150/150 => Loss 0.003, Loss_clf 0.003, Loss_aux 2.443, Train_accy 100.00
2025-02-20 00:27:20,814 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.249,  Train_accy 37.76, Test_accy 60.22
2025-02-20 00:27:26,473 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.797,  Train_accy 60.39
2025-02-20 00:27:31,856 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.629,  Train_accy 69.25
2025-02-20 00:27:37,153 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.521,  Train_accy 77.05
2025-02-20 00:27:42,304 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.492,  Train_accy 79.25
2025-02-20 00:27:51,258 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.440,  Train_accy 81.63, Test_accy 67.98
2025-02-20 00:27:56,519 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.395,  Train_accy 84.45
2025-02-20 00:28:01,730 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.364,  Train_accy 86.24
2025-02-20 00:28:07,077 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.344,  Train_accy 87.18
2025-02-20 00:28:12,370 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.326,  Train_accy 87.76
2025-02-20 00:28:21,131 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.312,  Train_accy 87.98, Test_accy 74.13
2025-02-20 00:28:26,370 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.298,  Train_accy 89.42
2025-02-20 00:28:31,710 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.293,  Train_accy 89.05
2025-02-20 00:28:37,140 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.285,  Train_accy 89.59
2025-02-20 00:28:42,669 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.275,  Train_accy 90.02
2025-02-20 00:28:51,679 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.273,  Train_accy 90.19, Test_accy 76.53
2025-02-20 00:28:56,931 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.265,  Train_accy 90.37
2025-02-20 00:29:02,540 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.268,  Train_accy 90.75
2025-02-20 00:29:07,724 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.261,  Train_accy 90.02
2025-02-20 00:29:13,134 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.260,  Train_accy 90.41
2025-02-20 00:29:22,032 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.254,  Train_accy 90.88, Test_accy 77.31
2025-02-20 00:29:27,399 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.248,  Train_accy 91.05
2025-02-20 00:29:32,585 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.244,  Train_accy 90.95
2025-02-20 00:29:37,832 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.243,  Train_accy 90.95
2025-02-20 00:29:43,134 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.231,  Train_accy 91.23
2025-02-20 00:29:52,114 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.235,  Train_accy 91.61, Test_accy 78.64
2025-02-20 00:29:57,539 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.233,  Train_accy 91.38
2025-02-20 00:30:02,865 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.231,  Train_accy 90.77
2025-02-20 00:30:08,125 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.227,  Train_accy 91.42
2025-02-20 00:30:13,354 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.225,  Train_accy 91.81
2025-02-20 00:30:22,365 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.227,  Train_accy 90.95, Test_accy 78.27
2025-02-20 00:30:27,613 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.223,  Train_accy 91.16
2025-02-20 00:30:32,983 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.220,  Train_accy 91.85
2025-02-20 00:30:38,431 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.218,  Train_accy 91.38
2025-02-20 00:30:43,748 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.217,  Train_accy 91.29
2025-02-20 00:30:52,679 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.213,  Train_accy 91.76, Test_accy 78.04
2025-02-20 00:30:58,095 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.212,  Train_accy 91.42
2025-02-20 00:31:03,384 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.211,  Train_accy 91.83
2025-02-20 00:31:08,966 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.214,  Train_accy 91.33
2025-02-20 00:31:14,849 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.208,  Train_accy 91.85
2025-02-20 00:31:24,020 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.209,  Train_accy 91.61, Test_accy 78.62
2025-02-20 00:31:29,323 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.205,  Train_accy 92.17
2025-02-20 00:31:34,778 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.206,  Train_accy 91.44
2025-02-20 00:31:40,137 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.208,  Train_accy 91.70
2025-02-20 00:31:45,486 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.204,  Train_accy 91.70
2025-02-20 00:31:54,809 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.202,  Train_accy 91.78, Test_accy 79.02
2025-02-20 00:32:00,247 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.201,  Train_accy 91.78
2025-02-20 00:32:05,624 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.202,  Train_accy 91.44
2025-02-20 00:32:10,900 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.196,  Train_accy 92.13
2025-02-20 00:32:16,370 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.200,  Train_accy 91.81
2025-02-20 00:32:25,610 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.198,  Train_accy 91.91, Test_accy 79.56
2025-02-20 00:32:30,805 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.198,  Train_accy 92.02
2025-02-20 00:32:36,296 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.193,  Train_accy 91.51
2025-02-20 00:32:41,587 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.197,  Train_accy 92.06
2025-02-20 00:32:46,803 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.198,  Train_accy 91.98
2025-02-20 00:32:55,775 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.194,  Train_accy 91.94, Test_accy 79.60
2025-02-20 00:33:01,061 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.191,  Train_accy 91.83
2025-02-20 00:33:06,507 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.191,  Train_accy 91.74
2025-02-20 00:33:11,741 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.190,  Train_accy 91.87
2025-02-20 00:33:16,991 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.190,  Train_accy 92.15
2025-02-20 00:33:25,858 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.187,  Train_accy 91.98, Test_accy 79.93
2025-02-20 00:33:31,125 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.192,  Train_accy 92.19
2025-02-20 00:33:36,614 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.190,  Train_accy 92.00
2025-02-20 00:33:41,945 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.194,  Train_accy 92.13
2025-02-20 00:33:47,194 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.189,  Train_accy 91.59
2025-02-20 00:33:56,177 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.189,  Train_accy 91.96, Test_accy 79.98
2025-02-20 00:34:01,433 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.192,  Train_accy 91.59
2025-02-20 00:34:06,788 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.189,  Train_accy 91.74
2025-02-20 00:34:12,206 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.187,  Train_accy 92.17
2025-02-20 00:34:17,422 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.190,  Train_accy 92.04
2025-02-20 00:34:26,268 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.190,  Train_accy 91.70, Test_accy 79.84
2025-02-20 00:34:31,522 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.187,  Train_accy 91.74
2025-02-20 00:34:36,860 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.187,  Train_accy 92.15
2025-02-20 00:34:42,166 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.186,  Train_accy 92.00
2025-02-20 00:34:47,562 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.186,  Train_accy 91.89
2025-02-20 00:34:56,454 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.183,  Train_accy 92.22, Test_accy 80.29
2025-02-20 00:35:01,732 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.182,  Train_accy 92.67
2025-02-20 00:35:07,270 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.184,  Train_accy 92.13
2025-02-20 00:35:12,492 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.184,  Train_accy 91.81
2025-02-20 00:35:17,796 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.187,  Train_accy 92.22
2025-02-20 00:35:26,716 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.182,  Train_accy 91.87, Test_accy 80.29
2025-02-20 00:35:32,019 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.180,  Train_accy 91.91
2025-02-20 00:35:37,272 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.183,  Train_accy 92.09
2025-02-20 00:35:42,614 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.182,  Train_accy 92.22
2025-02-20 00:35:47,874 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.184,  Train_accy 92.11
2025-02-20 00:35:57,069 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.182,  Train_accy 92.41, Test_accy 80.27
2025-02-20 00:36:02,477 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.180,  Train_accy 91.53
2025-02-20 00:36:07,940 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.180,  Train_accy 92.09
2025-02-20 00:36:13,275 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.183,  Train_accy 92.09
2025-02-20 00:36:18,589 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.180,  Train_accy 92.09
2025-02-20 00:36:27,926 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.180,  Train_accy 92.41, Test_accy 80.36
2025-02-20 00:36:33,412 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.178,  Train_accy 92.11
2025-02-20 00:36:38,743 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.179,  Train_accy 92.41
2025-02-20 00:36:43,859 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.176,  Train_accy 92.22
2025-02-20 00:36:49,153 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.178,  Train_accy 92.22
2025-02-20 00:36:58,028 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.179,  Train_accy 92.37, Test_accy 80.27
2025-02-20 00:37:03,451 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.180,  Train_accy 92.06
2025-02-20 00:37:08,829 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.179,  Train_accy 92.09
2025-02-20 00:37:14,139 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.176,  Train_accy 92.24
2025-02-20 00:37:19,278 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.175,  Train_accy 92.30
2025-02-20 00:37:28,132 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.177,  Train_accy 92.09, Test_accy 80.67
2025-02-20 00:37:33,486 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.175,  Train_accy 92.45
2025-02-20 00:37:38,756 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.176,  Train_accy 91.96
2025-02-20 00:37:44,059 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.177,  Train_accy 92.17
2025-02-20 00:37:49,497 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.175,  Train_accy 92.28
2025-02-20 00:37:58,420 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.176,  Train_accy 92.15, Test_accy 80.62
2025-02-20 00:38:03,770 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.173,  Train_accy 92.04
2025-02-20 00:38:09,039 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.176,  Train_accy 92.28
2025-02-20 00:38:14,417 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.178,  Train_accy 92.13
2025-02-20 00:38:19,661 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.175,  Train_accy 92.06
2025-02-20 00:38:29,092 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.178,  Train_accy 92.17, Test_accy 80.76
2025-02-20 00:38:34,623 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.176,  Train_accy 92.24
2025-02-20 00:38:40,164 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.175,  Train_accy 92.37
2025-02-20 00:38:45,427 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.172,  Train_accy 92.37
2025-02-20 00:38:50,515 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.173,  Train_accy 92.11
2025-02-20 00:38:59,430 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.176,  Train_accy 92.26, Test_accy 80.56
2025-02-20 00:39:04,626 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.176,  Train_accy 91.94
2025-02-20 00:39:09,914 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.175,  Train_accy 92.09
2025-02-20 00:39:15,117 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.173,  Train_accy 92.22
2025-02-20 00:39:20,506 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.172,  Train_accy 92.49
2025-02-20 00:39:29,738 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.175,  Train_accy 92.02, Test_accy 80.42
2025-02-20 00:39:35,079 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.175,  Train_accy 92.02
2025-02-20 00:39:40,515 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.175,  Train_accy 91.89
2025-02-20 00:39:45,863 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.173,  Train_accy 91.70
2025-02-20 00:39:51,144 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.175,  Train_accy 92.43
2025-02-20 00:39:59,988 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.175,  Train_accy 92.26, Test_accy 80.71
2025-02-20 00:40:05,279 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.174,  Train_accy 92.04
2025-02-20 00:40:10,545 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.172,  Train_accy 92.26
2025-02-20 00:40:15,882 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.175,  Train_accy 92.41
2025-02-20 00:40:21,288 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.174,  Train_accy 92.47
2025-02-20 00:40:21,289 [der.py] => do not weight align student!
2025-02-20 00:40:24,953 [der.py] => darknet eval: 
2025-02-20 00:40:24,953 [der.py] => CNN top1 curve: 80.64
2025-02-20 00:40:24,953 [der.py] => CNN top5 curve: 97.96
2025-02-20 00:40:24,955 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 00:40:50,743 [der.py] => Exemplar size: 750
2025-02-20 00:40:50,743 [trainer.py] => CNN: {'total': 85.89, '0': 94.44, '1': 85.0, '2': 94.44, '3': 81.11, '4': 86.11, '5': 71.11, '6': 75.56, '7': 72.22, '8': 76.11, '9': 60.0, '10': 94.44, '11': 100.0, '12': 85.56, '13': 85.0, '14': 89.44, '15': 93.33, '16': 93.33, '17': 95.56, '18': 85.0, '19': 91.67, '20': 95.56, '21': 83.89, '22': 82.78, '23': 83.89, 'old': 83.37, 'new': 89.67}
2025-02-20 00:40:50,743 [trainer.py] => NME: {'total': 82.58, '0': 87.22, '1': 78.89, '2': 92.22, '3': 80.56, '4': 86.67, '5': 66.11, '6': 69.44, '7': 60.56, '8': 56.11, '9': 60.0, '10': 93.89, '11': 100.0, '12': 86.67, '13': 83.89, '14': 86.67, '15': 90.56, '16': 95.56, '17': 85.0, '18': 87.22, '19': 87.22, '20': 89.44, '21': 83.89, '22': 85.56, '23': 90.56, 'old': 79.26, 'new': 87.56}
2025-02-20 00:40:50,743 [trainer.py] => CNN top1 curve: [87.7, 85.89]
2025-02-20 00:40:50,743 [trainer.py] => CNN top5 curve: [98.89, 98.42]
2025-02-20 00:40:50,743 [trainer.py] => NME top1 curve: [86.19, 82.58]
2025-02-20 00:40:50,743 [trainer.py] => NME top5 curve: [98.93, 98.42]

2025-02-20 00:40:50,744 [trainer.py] => All params: 8243492
2025-02-20 00:40:50,744 [trainer.py] => Trainable params: 4137380
2025-02-20 00:40:50,799 [der.py] => Learning on 25-35
2025-02-20 00:40:50,800 [der.py] => All params: 8253742
2025-02-20 00:40:50,800 [der.py] => Trainable params: 4147630
2025-02-20 00:40:50,870 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 00:40:50,870 [der.py] => per cls weights : [1.20062219 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219
 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219
 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219
 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219 1.20062219
 1.20062219 0.49844453 0.49844453 0.49844453 0.49844453 0.49844453
 0.49844453 0.49844453 0.49844453 0.49844453 0.49844453]
2025-02-20 00:46:27,510 [trainer.py] => 实验名称:resnet18对比实验
2025-02-20 00:46:27,547 [trainer.py] => config: ./exps/der.json
2025-02-20 00:46:27,547 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-20 00:46:27,547 [trainer.py] => prefix: reproduce
2025-02-20 00:46:27,547 [trainer.py] => dataset: xrfdataset
2025-02-20 00:46:27,547 [trainer.py] => memory_size: 1650
2025-02-20 00:46:27,547 [trainer.py] => memory_per_class: 30
2025-02-20 00:46:27,547 [trainer.py] => fixed_memory: True
2025-02-20 00:46:27,547 [trainer.py] => shuffle: True
2025-02-20 00:46:27,547 [trainer.py] => init_cls: 15
2025-02-20 00:46:27,548 [trainer.py] => increment: 10
2025-02-20 00:46:27,548 [trainer.py] => model_name: der
2025-02-20 00:46:27,548 [trainer.py] => compression_epochs: 130
2025-02-20 00:46:27,548 [trainer.py] => compression_lr: 0.1
2025-02-20 00:46:27,548 [trainer.py] => is_student_wa: False
2025-02-20 00:46:27,548 [trainer.py] => wa_value: 1
2025-02-20 00:46:27,548 [trainer.py] => T: 2
2025-02-20 00:46:27,548 [trainer.py] => convnet_type: resnet18
2025-02-20 00:46:27,548 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-20 00:46:27,548 [trainer.py] => seed: 1993
2025-02-20 00:46:27,591 [data.py] => 加载完毕XRF原始数据集
2025-02-20 00:46:27,616 [data.py] => 加载完毕XRF原始数据集
2025-02-20 00:46:27,616 [trainer.py] => All params: 0
2025-02-20 00:46:27,616 [trainer.py] => Trainable params: 0
2025-02-20 00:46:27,725 [der.py] => Learning on 0-15
2025-02-20 00:46:27,725 [der.py] => All params: 4122015
2025-02-20 00:46:27,725 [der.py] => Trainable params: 4122015
2025-02-20 01:01:40,472 [der.py] => Task 2, Epoch 150/150 => Loss 0.004, Loss_clf 0.004, Loss_aux 2.403, Train_accy 100.00
2025-02-20 01:01:55,023 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.294,  Train_accy 48.89, Test_accy 56.56
2025-02-20 01:02:01,610 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.024,  Train_accy 67.47
2025-02-20 01:02:09,667 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.933,  Train_accy 74.32
2025-02-20 01:02:16,554 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.888,  Train_accy 78.34
2025-02-20 01:02:23,308 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.844,  Train_accy 81.70
2025-02-20 01:02:37,535 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.810,  Train_accy 83.29, Test_accy 67.79
2025-02-20 01:02:44,659 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.794,  Train_accy 84.16
2025-02-20 01:02:51,969 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.770,  Train_accy 85.98
2025-02-20 01:02:59,546 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.756,  Train_accy 87.07
2025-02-20 01:03:05,834 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.745,  Train_accy 88.10
2025-02-20 01:03:19,642 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.738,  Train_accy 88.26, Test_accy 69.37
2025-02-20 01:03:26,511 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.732,  Train_accy 88.51
2025-02-20 01:03:33,491 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.727,  Train_accy 88.83
2025-02-20 01:03:40,020 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.714,  Train_accy 89.66
2025-02-20 01:03:46,419 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.708,  Train_accy 89.49
2025-02-20 01:03:59,553 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.706,  Train_accy 90.08, Test_accy 70.79
2025-02-20 01:04:07,860 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.706,  Train_accy 90.22
2025-02-20 01:04:14,191 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.696,  Train_accy 91.09
2025-02-20 01:04:21,111 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.691,  Train_accy 90.67
2025-02-20 01:04:28,939 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.689,  Train_accy 91.37
2025-02-20 01:04:41,981 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.688,  Train_accy 91.33, Test_accy 72.71
2025-02-20 01:04:48,709 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.680,  Train_accy 91.43
2025-02-20 01:04:56,143 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.676,  Train_accy 91.70
2025-02-20 01:05:02,912 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.674,  Train_accy 91.68
2025-02-20 01:05:10,045 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.670,  Train_accy 91.88
2025-02-20 01:05:24,420 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.667,  Train_accy 91.72, Test_accy 72.70
2025-02-20 01:05:31,792 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.670,  Train_accy 91.88
2025-02-20 01:05:38,312 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.668,  Train_accy 92.12
2025-02-20 01:05:45,162 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.666,  Train_accy 92.12
2025-02-20 01:05:51,729 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.666,  Train_accy 92.28
2025-02-20 01:06:05,136 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.662,  Train_accy 92.00, Test_accy 73.19
2025-02-20 01:06:12,067 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.664,  Train_accy 92.38
2025-02-20 01:06:18,953 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.660,  Train_accy 92.55
2025-02-20 01:06:25,531 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.660,  Train_accy 92.28
2025-02-20 01:06:33,524 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.664,  Train_accy 92.22
2025-02-20 01:06:46,672 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.657,  Train_accy 92.67, Test_accy 72.94
2025-02-20 01:06:50,000 [der.py] => Task 0, Epoch 150/150 => Loss 0.032, Train_accy 99.76
2025-02-20 01:06:50,001 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 01:06:53,074 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.656,  Train_accy 92.28
2025-02-20 01:06:59,120 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.653,  Train_accy 92.61
2025-02-20 01:07:04,950 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.652,  Train_accy 92.63
2025-02-20 01:07:10,797 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.650,  Train_accy 93.07
2025-02-20 01:07:17,776 [der.py] => Exemplar size: 450
2025-02-20 01:07:17,776 [trainer.py] => CNN: {'total': 87.7, '0': 98.33, '1': 92.78, '2': 95.0, '3': 85.56, '4': 89.44, '5': 80.56, '6': 76.11, '7': 87.22, '8': 84.44, '9': 66.11, '10': 95.0, '11': 100.0, '12': 87.78, '13': 86.67, 'old': 0, 'new': 87.7}
2025-02-20 01:07:17,776 [trainer.py] => NME: {'total': 86.19, '0': 98.33, '1': 94.44, '2': 91.67, '3': 81.11, '4': 88.89, '5': 73.89, '6': 69.44, '7': 88.33, '8': 86.11, '9': 63.33, '10': 93.33, '11': 100.0, '12': 86.67, '13': 86.11, 'old': 0, 'new': 86.19}
2025-02-20 01:07:17,776 [trainer.py] => CNN top1 curve: [87.7]
2025-02-20 01:07:17,776 [trainer.py] => CNN top5 curve: [98.89]
2025-02-20 01:07:17,776 [trainer.py] => NME top1 curve: [86.19]
2025-02-20 01:07:17,776 [trainer.py] => NME top5 curve: [98.93]

2025-02-20 01:07:17,777 [trainer.py] => All params: 4122015
2025-02-20 01:07:17,777 [trainer.py] => Trainable params: 4122015
2025-02-20 01:07:17,836 [der.py] => Learning on 15-25
2025-02-20 01:07:17,837 [der.py] => All params: 8243492
2025-02-20 01:07:17,837 [der.py] => Trainable params: 4137380
2025-02-20 01:07:17,898 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 01:07:17,912 [der.py] => per cls weights : [1.44535979 1.44535979 1.44535979 1.44535979 1.44535979 1.44535979
 1.44535979 1.44535979 1.44535979 1.44535979 1.44535979 1.44535979
 1.44535979 1.44535979 1.44535979 0.33196032 0.33196032 0.33196032
 0.33196032 0.33196032 0.33196032 0.33196032 0.33196032 0.33196032
 0.33196032]
2025-02-20 01:07:23,579 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.651,  Train_accy 92.53, Test_accy 73.79
2025-02-20 01:07:29,845 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.650,  Train_accy 92.59
2025-02-20 01:07:35,820 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.650,  Train_accy 92.93
2025-02-20 01:07:41,521 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.650,  Train_accy 92.67
2025-02-20 01:07:47,302 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.648,  Train_accy 92.93
2025-02-20 01:08:01,642 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.647,  Train_accy 92.99, Test_accy 73.35
2025-02-20 01:08:07,972 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.645,  Train_accy 92.71
2025-02-20 01:08:14,147 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.646,  Train_accy 92.75
2025-02-20 01:08:20,609 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.645,  Train_accy 93.41
2025-02-20 01:08:26,678 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.643,  Train_accy 92.59
2025-02-20 01:08:38,076 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.645,  Train_accy 92.83, Test_accy 73.24
2025-02-20 01:08:43,736 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.641,  Train_accy 92.61
2025-02-20 01:08:50,531 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.643,  Train_accy 93.21
2025-02-20 01:08:56,919 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.642,  Train_accy 92.85
2025-02-20 01:09:03,575 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.639,  Train_accy 93.31
2025-02-20 01:09:14,881 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.641,  Train_accy 93.29, Test_accy 73.92
2025-02-20 01:09:21,441 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.641,  Train_accy 93.13
2025-02-20 01:09:27,009 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.639,  Train_accy 92.77
2025-02-20 01:09:33,816 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.639,  Train_accy 93.62
2025-02-20 01:09:40,303 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.638,  Train_accy 93.01
2025-02-20 01:09:54,571 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.638,  Train_accy 93.19, Test_accy 74.10
2025-02-20 01:10:02,308 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.634,  Train_accy 92.93
2025-02-20 01:10:09,167 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.636,  Train_accy 93.19
2025-02-20 01:10:16,467 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.635,  Train_accy 93.70
2025-02-20 01:10:23,183 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.636,  Train_accy 93.43
2025-02-20 01:10:36,811 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.634,  Train_accy 93.07, Test_accy 73.78
2025-02-20 01:10:44,177 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.634,  Train_accy 93.33
2025-02-20 01:10:51,663 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.634,  Train_accy 93.35
2025-02-20 01:10:59,070 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.632,  Train_accy 93.49
2025-02-20 01:11:05,978 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.632,  Train_accy 93.27
2025-02-20 01:11:19,617 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.632,  Train_accy 93.43, Test_accy 73.78
2025-02-20 01:11:27,016 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.632,  Train_accy 93.21
2025-02-20 01:11:33,824 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.632,  Train_accy 93.23
2025-02-20 01:11:40,296 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.631,  Train_accy 93.27
2025-02-20 01:11:47,144 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.630,  Train_accy 93.33
2025-02-20 01:11:59,686 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.631,  Train_accy 93.62, Test_accy 73.94
2025-02-20 01:12:06,241 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.631,  Train_accy 93.39
2025-02-20 01:12:12,984 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.629,  Train_accy 93.49
2025-02-20 01:12:19,363 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.629,  Train_accy 93.27
2025-02-20 01:12:26,403 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.630,  Train_accy 93.52
2025-02-20 01:12:38,267 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.628,  Train_accy 93.76, Test_accy 74.17
2025-02-20 01:12:45,328 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.626,  Train_accy 93.39
2025-02-20 01:12:52,373 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.628,  Train_accy 93.62
2025-02-20 01:12:58,797 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.628,  Train_accy 93.35
2025-02-20 01:13:05,697 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.630,  Train_accy 93.39
2025-02-20 01:13:19,715 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.628,  Train_accy 93.56, Test_accy 74.29
2025-02-20 01:13:26,578 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.629,  Train_accy 93.68
2025-02-20 01:13:32,927 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.627,  Train_accy 93.43
2025-02-20 01:13:40,148 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.628,  Train_accy 93.66
2025-02-20 01:13:46,544 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.626,  Train_accy 93.64
2025-02-20 01:14:00,870 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.625,  Train_accy 93.45, Test_accy 74.22
2025-02-20 01:14:08,082 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.627,  Train_accy 93.72
2025-02-20 01:14:15,203 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.626,  Train_accy 93.23
2025-02-20 01:14:21,513 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.627,  Train_accy 93.70
2025-02-20 01:14:29,786 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.626,  Train_accy 93.39
2025-02-20 01:14:44,836 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.627,  Train_accy 93.64, Test_accy 74.13
2025-02-20 01:14:52,033 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.626,  Train_accy 93.78
2025-02-20 01:14:59,957 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.624,  Train_accy 93.88
2025-02-20 01:15:06,562 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.626,  Train_accy 93.64
2025-02-20 01:15:13,620 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.626,  Train_accy 93.27
2025-02-20 01:15:27,050 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.625,  Train_accy 93.74, Test_accy 74.11
2025-02-20 01:15:34,391 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.625,  Train_accy 93.72
2025-02-20 01:15:40,871 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.625,  Train_accy 93.58
2025-02-20 01:15:48,472 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.626,  Train_accy 93.39
2025-02-20 01:15:55,858 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.624,  Train_accy 93.84
2025-02-20 01:16:10,404 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.624,  Train_accy 93.92, Test_accy 74.03
2025-02-20 01:16:17,645 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.624,  Train_accy 93.80
2025-02-20 01:16:24,789 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.623,  Train_accy 93.45
2025-02-20 01:16:31,713 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.625,  Train_accy 93.80
2025-02-20 01:16:38,421 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.625,  Train_accy 93.25
2025-02-20 01:16:52,180 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.626,  Train_accy 93.74, Test_accy 74.11
2025-02-20 01:16:59,548 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.624,  Train_accy 93.37
2025-02-20 01:17:06,681 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.625,  Train_accy 93.54
2025-02-20 01:17:13,470 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.623,  Train_accy 93.96
2025-02-20 01:17:21,370 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.624,  Train_accy 93.56
2025-02-20 01:17:35,020 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.624,  Train_accy 93.66, Test_accy 74.03
2025-02-20 01:17:43,019 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.625,  Train_accy 93.15
2025-02-20 01:17:50,091 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.623,  Train_accy 93.45
2025-02-20 01:17:58,435 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.625,  Train_accy 93.39
2025-02-20 01:18:05,809 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.624,  Train_accy 93.72
2025-02-20 01:18:18,986 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.623,  Train_accy 93.33, Test_accy 74.06
2025-02-20 01:18:26,534 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.623,  Train_accy 93.64
2025-02-20 01:18:35,231 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.624,  Train_accy 93.68
2025-02-20 01:18:42,772 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.624,  Train_accy 93.64
2025-02-20 01:18:50,532 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.623,  Train_accy 93.76
2025-02-20 01:19:05,416 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.623,  Train_accy 93.33, Test_accy 74.51
2025-02-20 01:19:11,855 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.624,  Train_accy 93.43
2025-02-20 01:19:19,042 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.623,  Train_accy 93.94
2025-02-20 01:19:26,786 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.623,  Train_accy 93.56
2025-02-20 01:19:33,671 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.625,  Train_accy 93.94
2025-02-20 01:19:33,672 [der.py] => do not weight align student!
2025-02-20 01:19:39,353 [der.py] => darknet eval: 
2025-02-20 01:19:39,354 [der.py] => CNN top1 curve: 73.98
2025-02-20 01:19:39,354 [der.py] => CNN top5 curve: 95.35
2025-02-20 01:19:39,355 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 01:20:19,253 [der.py] => Exemplar size: 1050
2025-02-20 01:20:19,253 [trainer.py] => CNN: {'total': 76.68, '0': 81.67, '1': 57.22, '2': 86.67, '3': 56.67, '4': 77.78, '5': 33.89, '6': 71.67, '7': 25.56, '8': 43.33, '9': 37.22, '10': 82.22, '11': 97.78, '12': 78.89, '13': 70.56, '14': 65.56, '15': 94.44, '16': 95.56, '17': 94.44, '18': 93.89, '19': 91.67, '20': 93.33, '21': 87.22, '22': 90.0, '23': 82.78, '24': 67.78, '25': 64.44, '26': 86.67, '27': 81.67, '28': 69.44, '29': 85.0, '30': 85.56, '31': 87.78, '32': 98.89, '33': 80.0, 'old': 74.31, 'new': 82.61}
2025-02-20 01:20:19,253 [trainer.py] => NME: {'total': 73.21, '0': 83.33, '1': 62.22, '2': 79.44, '3': 53.33, '4': 81.11, '5': 36.67, '6': 64.44, '7': 25.0, '8': 51.67, '9': 50.56, '10': 84.44, '11': 95.0, '12': 79.44, '13': 67.78, '14': 58.89, '15': 93.33, '16': 93.33, '17': 88.33, '18': 81.11, '19': 87.78, '20': 87.22, '21': 80.56, '22': 79.44, '23': 61.11, '24': 45.0, '25': 57.22, '26': 91.67, '27': 82.78, '28': 63.33, '29': 78.89, '30': 83.89, '31': 82.78, '32': 97.22, '33': 70.56, 'old': 70.82, 'new': 79.17}
2025-02-20 01:20:19,253 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.68]
2025-02-20 01:20:19,253 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.62]
2025-02-20 01:20:19,253 [trainer.py] => NME top1 curve: [86.19, 82.58, 73.21]
2025-02-20 01:20:19,253 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.57]

2025-02-20 01:20:19,254 [trainer.py] => All params: 8253742
2025-02-20 01:20:19,254 [trainer.py] => Trainable params: 4147630
2025-02-20 01:20:19,353 [der.py] => Learning on 35-45
2025-02-20 01:20:19,354 [der.py] => All params: 8263992
2025-02-20 01:20:19,354 [der.py] => Trainable params: 4157880
2025-02-20 01:20:19,438 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 01:20:19,438 [der.py] => per cls weights : [1.14937973 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973
 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973
 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973
 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973
 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973
 1.14937973 1.14937973 1.14937973 1.14937973 1.14937973 0.47717095
 0.47717095 0.47717095 0.47717095 0.47717095 0.47717095 0.47717095
 0.47717095 0.47717095 0.47717095]
2025-02-20 01:24:33,442 [der.py] => Task 1, Epoch 150/150 => Loss 0.003, Loss_clf 0.003, Loss_aux 2.443, Train_accy 100.00
2025-02-20 01:24:44,269 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.288,  Train_accy 31.10, Test_accy 60.71
2025-02-20 01:24:50,684 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.912,  Train_accy 50.82
2025-02-20 01:24:56,904 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.754,  Train_accy 59.87
2025-02-20 01:25:03,288 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.658,  Train_accy 67.44
2025-02-20 01:25:09,390 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.626,  Train_accy 69.35
2025-02-20 01:25:20,121 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.581,  Train_accy 72.54, Test_accy 67.31
2025-02-20 01:25:26,307 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.537,  Train_accy 75.48
2025-02-20 01:25:32,500 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.512,  Train_accy 76.73
2025-02-20 01:25:38,812 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.490,  Train_accy 77.74
2025-02-20 01:25:44,998 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.471,  Train_accy 78.86
2025-02-20 01:25:55,788 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.456,  Train_accy 80.28, Test_accy 72.00
2025-02-20 01:26:01,809 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.443,  Train_accy 80.56
2025-02-20 01:26:08,364 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.437,  Train_accy 80.11
2025-02-20 01:26:14,587 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.428,  Train_accy 81.29
2025-02-20 01:26:20,874 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.421,  Train_accy 81.25
2025-02-20 01:26:31,584 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.416,  Train_accy 81.40, Test_accy 74.71
2025-02-20 01:26:37,917 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.410,  Train_accy 82.04
2025-02-20 01:26:44,253 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.413,  Train_accy 81.31
2025-02-20 01:26:50,882 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.402,  Train_accy 82.11
2025-02-20 01:26:56,961 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.402,  Train_accy 82.02
2025-02-20 01:27:07,615 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.397,  Train_accy 82.28, Test_accy 75.13
2025-02-20 01:27:14,062 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.391,  Train_accy 82.37
2025-02-20 01:27:20,193 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.386,  Train_accy 82.37
2025-02-20 01:27:26,478 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.384,  Train_accy 83.25
2025-02-20 01:27:32,853 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.374,  Train_accy 82.88
2025-02-20 01:27:43,461 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.377,  Train_accy 83.27, Test_accy 76.40
2025-02-20 01:27:49,840 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.373,  Train_accy 82.97
2025-02-20 01:27:56,247 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.370,  Train_accy 82.77
2025-02-20 01:28:02,545 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.368,  Train_accy 82.90
2025-02-20 01:28:09,066 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.368,  Train_accy 83.20
2025-02-20 01:28:20,689 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.368,  Train_accy 82.67, Test_accy 75.64
2025-02-20 01:28:27,222 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.363,  Train_accy 82.99
2025-02-20 01:28:33,420 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.360,  Train_accy 83.38
2025-02-20 01:28:39,495 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.359,  Train_accy 83.25
2025-02-20 01:28:45,592 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.358,  Train_accy 83.42
2025-02-20 01:28:56,733 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.355,  Train_accy 83.20, Test_accy 75.40
2025-02-20 01:29:03,353 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.353,  Train_accy 83.38
2025-02-20 01:29:09,519 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.351,  Train_accy 83.44
2025-02-20 01:29:15,980 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.353,  Train_accy 83.78
2025-02-20 01:29:22,408 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.348,  Train_accy 83.29
2025-02-20 01:29:33,361 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.348,  Train_accy 83.89, Test_accy 76.73
2025-02-20 01:29:39,808 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.344,  Train_accy 83.94
2025-02-20 01:29:46,411 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.345,  Train_accy 83.61
2025-02-20 01:29:52,761 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.350,  Train_accy 82.95
2025-02-20 01:29:59,102 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.345,  Train_accy 83.12
2025-02-20 01:30:09,810 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.342,  Train_accy 83.25, Test_accy 76.27
2025-02-20 01:30:16,406 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.341,  Train_accy 84.19
2025-02-20 01:30:22,869 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.341,  Train_accy 84.19
2025-02-20 01:30:29,073 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.335,  Train_accy 83.91
2025-02-20 01:30:35,369 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.341,  Train_accy 83.38
2025-02-20 01:30:45,884 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.337,  Train_accy 83.68, Test_accy 77.04
2025-02-20 01:30:52,036 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.338,  Train_accy 84.13
2025-02-20 01:30:58,266 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.331,  Train_accy 83.33
2025-02-20 01:31:04,324 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.336,  Train_accy 83.25
2025-02-20 01:31:10,509 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.337,  Train_accy 83.63
2025-02-20 01:31:20,997 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.332,  Train_accy 83.66, Test_accy 77.53
2025-02-20 01:31:27,007 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.330,  Train_accy 83.87
2025-02-20 01:31:33,197 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.330,  Train_accy 83.72
2025-02-20 01:31:39,679 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.328,  Train_accy 83.70
2025-02-20 01:31:45,925 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.328,  Train_accy 84.15
2025-02-20 01:31:56,781 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.325,  Train_accy 83.63, Test_accy 77.84
2025-02-20 01:32:02,934 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.331,  Train_accy 84.39
2025-02-20 01:32:09,323 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.328,  Train_accy 83.85
2025-02-20 01:32:15,607 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.333,  Train_accy 83.87
2025-02-20 01:32:22,051 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.326,  Train_accy 83.85
2025-02-20 01:32:32,837 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.327,  Train_accy 83.31, Test_accy 78.07
2025-02-20 01:32:39,268 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.330,  Train_accy 83.59
2025-02-20 01:32:45,489 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.328,  Train_accy 83.63
2025-02-20 01:32:51,565 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.325,  Train_accy 83.89
2025-02-20 01:32:57,552 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.327,  Train_accy 83.83
2025-02-20 01:33:08,611 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.328,  Train_accy 83.76, Test_accy 77.96
2025-02-20 01:33:15,251 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.325,  Train_accy 84.02
2025-02-20 01:33:21,799 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.325,  Train_accy 84.28
2025-02-20 01:33:28,118 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.323,  Train_accy 83.35
2025-02-20 01:33:34,386 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.323,  Train_accy 83.38
2025-02-20 01:33:45,275 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.321,  Train_accy 84.15, Test_accy 78.07
2025-02-20 01:33:51,493 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.320,  Train_accy 83.91
2025-02-20 01:33:57,721 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.321,  Train_accy 84.15
2025-02-20 01:34:03,758 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.322,  Train_accy 83.83
2025-02-20 01:34:09,962 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.325,  Train_accy 84.06
2025-02-20 01:34:20,457 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.319,  Train_accy 83.89, Test_accy 78.36
2025-02-20 01:34:26,753 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.318,  Train_accy 83.81
2025-02-20 01:34:32,733 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.321,  Train_accy 83.83
2025-02-20 01:34:38,868 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.320,  Train_accy 83.89
2025-02-20 01:34:45,112 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.321,  Train_accy 83.81
2025-02-20 01:34:55,529 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.320,  Train_accy 84.00, Test_accy 77.33
2025-02-20 01:35:01,814 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.318,  Train_accy 83.87
2025-02-20 01:35:07,916 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.317,  Train_accy 83.59
2025-02-20 01:35:14,013 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.319,  Train_accy 84.28
2025-02-20 01:35:19,660 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.317,  Train_accy 84.09
2025-02-20 01:35:29,490 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.317,  Train_accy 84.39, Test_accy 77.89
2025-02-20 01:35:35,432 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.316,  Train_accy 83.74
2025-02-20 01:35:41,464 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.316,  Train_accy 83.85
2025-02-20 01:35:47,396 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.314,  Train_accy 83.83
2025-02-20 01:35:53,106 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.315,  Train_accy 83.96
2025-02-20 01:36:02,562 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.316,  Train_accy 84.15, Test_accy 78.53
2025-02-20 01:36:08,844 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.317,  Train_accy 84.00
2025-02-20 01:36:15,081 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.316,  Train_accy 83.51
2025-02-20 01:36:21,039 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.313,  Train_accy 83.74
2025-02-20 01:36:26,829 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.313,  Train_accy 84.15
2025-02-20 01:36:36,454 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.315,  Train_accy 84.06, Test_accy 78.60
2025-02-20 01:36:42,531 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.313,  Train_accy 84.19
2025-02-20 01:36:48,194 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.314,  Train_accy 84.24
2025-02-20 01:36:54,034 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.314,  Train_accy 83.91
2025-02-20 01:36:59,996 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.311,  Train_accy 84.43
2025-02-20 01:37:10,136 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.314,  Train_accy 83.70, Test_accy 78.42
2025-02-20 01:37:16,263 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.309,  Train_accy 84.02
2025-02-20 01:37:22,250 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.313,  Train_accy 84.22
2025-02-20 01:37:28,383 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.314,  Train_accy 83.96
2025-02-20 01:37:34,563 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.313,  Train_accy 84.06
2025-02-20 01:37:44,820 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.315,  Train_accy 84.02, Test_accy 78.31
2025-02-20 01:37:51,200 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.314,  Train_accy 83.72
2025-02-20 01:37:57,763 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.312,  Train_accy 84.13
2025-02-20 01:38:03,503 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.309,  Train_accy 84.11
2025-02-20 01:38:09,387 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.311,  Train_accy 84.06
2025-02-20 01:38:19,720 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.313,  Train_accy 83.68, Test_accy 78.44
2025-02-20 01:38:25,814 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.313,  Train_accy 84.30
2025-02-20 01:38:32,350 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.312,  Train_accy 83.35
2025-02-20 01:38:38,433 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.310,  Train_accy 83.98
2025-02-20 01:38:44,267 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.309,  Train_accy 84.22
2025-02-20 01:38:53,865 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.312,  Train_accy 84.15, Test_accy 78.22
2025-02-20 01:39:00,061 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.312,  Train_accy 83.89
2025-02-20 01:39:05,988 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.312,  Train_accy 83.94
2025-02-20 01:39:11,997 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.310,  Train_accy 84.34
2025-02-20 01:39:18,160 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.312,  Train_accy 83.83
2025-02-20 01:39:28,590 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.313,  Train_accy 83.70, Test_accy 78.22
2025-02-20 01:39:35,002 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.310,  Train_accy 84.45
2025-02-20 01:39:40,875 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.309,  Train_accy 84.09
2025-02-20 01:39:47,429 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.312,  Train_accy 84.71
2025-02-20 01:39:53,709 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.312,  Train_accy 84.11
2025-02-20 01:39:53,709 [der.py] => do not weight align student!
2025-02-20 01:39:57,536 [der.py] => darknet eval: 
2025-02-20 01:39:57,536 [der.py] => CNN top1 curve: 78.44
2025-02-20 01:39:57,536 [der.py] => CNN top5 curve: 98.27
2025-02-20 01:39:57,538 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 01:40:30,935 [der.py] => Exemplar size: 750
2025-02-20 01:40:30,936 [trainer.py] => CNN: {'total': 85.89, '0': 94.44, '1': 85.0, '2': 94.44, '3': 81.11, '4': 86.11, '5': 71.11, '6': 75.56, '7': 72.22, '8': 76.11, '9': 60.0, '10': 94.44, '11': 100.0, '12': 85.56, '13': 85.0, '14': 89.44, '15': 93.33, '16': 93.33, '17': 95.56, '18': 85.0, '19': 91.67, '20': 95.56, '21': 83.89, '22': 82.78, '23': 83.89, 'old': 83.37, 'new': 89.67}
2025-02-20 01:40:30,936 [trainer.py] => NME: {'total': 82.58, '0': 87.22, '1': 78.89, '2': 92.22, '3': 80.56, '4': 86.67, '5': 66.11, '6': 69.44, '7': 60.56, '8': 56.11, '9': 60.0, '10': 93.89, '11': 100.0, '12': 86.67, '13': 83.89, '14': 86.67, '15': 90.56, '16': 95.56, '17': 85.0, '18': 87.22, '19': 87.22, '20': 89.44, '21': 83.89, '22': 85.56, '23': 90.56, 'old': 79.26, 'new': 87.56}
2025-02-20 01:40:30,936 [trainer.py] => CNN top1 curve: [87.7, 85.89]
2025-02-20 01:40:30,936 [trainer.py] => CNN top5 curve: [98.89, 98.42]
2025-02-20 01:40:30,936 [trainer.py] => NME top1 curve: [86.19, 82.58]
2025-02-20 01:40:30,936 [trainer.py] => NME top5 curve: [98.93, 98.42]

2025-02-20 01:40:30,936 [trainer.py] => All params: 8243492
2025-02-20 01:40:30,937 [trainer.py] => Trainable params: 4137380
2025-02-20 01:40:31,071 [der.py] => Learning on 25-35
2025-02-20 01:40:31,073 [der.py] => All params: 8253742
2025-02-20 01:40:31,073 [der.py] => Trainable params: 4147630
2025-02-20 01:40:31,169 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 01:40:31,169 [der.py] => per cls weights : [1.2822048 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048
 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048
 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048 1.2822048
 1.2822048 1.2822048 1.2822048 1.2822048 0.294488  0.294488  0.294488
 0.294488  0.294488  0.294488  0.294488  0.294488  0.294488  0.294488 ]
2025-02-20 01:42:47,221 [der.py] => Task 3, Epoch 150/150 => Loss 0.048, Loss_clf 0.048, Loss_aux 2.376, Train_accy 99.96
2025-02-20 01:43:02,459 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.357,  Train_accy 29.16, Test_accy 48.44
2025-02-20 01:43:09,532 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.242,  Train_accy 34.99
2025-02-20 01:43:16,806 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 2.230,  Train_accy 37.05
2025-02-20 01:43:24,022 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 2.172,  Train_accy 38.76
2025-02-20 01:43:31,246 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 2.168,  Train_accy 40.36
2025-02-20 01:43:46,094 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.122,  Train_accy 41.77, Test_accy 53.58
2025-02-20 01:43:53,949 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 2.123,  Train_accy 42.38
2025-02-20 01:44:01,062 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 2.110,  Train_accy 42.90
2025-02-20 01:44:08,160 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 2.098,  Train_accy 43.33
2025-02-20 01:44:15,901 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 2.112,  Train_accy 43.09
2025-02-20 01:44:30,263 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.089,  Train_accy 44.04, Test_accy 47.80
2025-02-20 01:44:37,310 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.092,  Train_accy 44.29
2025-02-20 01:44:44,684 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.091,  Train_accy 44.65
2025-02-20 01:44:51,510 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.091,  Train_accy 44.93
2025-02-20 01:44:58,734 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.078,  Train_accy 45.43
2025-02-20 01:45:13,785 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.083,  Train_accy 44.97, Test_accy 40.75
2025-02-20 01:45:20,864 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.076,  Train_accy 45.58
2025-02-20 01:45:28,193 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.079,  Train_accy 44.80
2025-02-20 01:45:35,299 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.068,  Train_accy 45.49
2025-02-20 01:45:42,162 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.063,  Train_accy 45.98
2025-02-20 01:45:57,254 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.075,  Train_accy 46.44, Test_accy 53.75
2025-02-20 01:46:04,477 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.068,  Train_accy 45.31
2025-02-20 01:46:11,659 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.054,  Train_accy 46.19
2025-02-20 01:46:18,809 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.059,  Train_accy 46.19
2025-02-20 01:46:25,918 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 2.062,  Train_accy 46.53
2025-02-20 01:46:41,504 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 2.052,  Train_accy 46.11, Test_accy 53.48
2025-02-20 01:46:48,558 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 2.064,  Train_accy 45.62
2025-02-20 01:46:55,602 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 2.054,  Train_accy 47.10
2025-02-20 01:47:02,946 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 2.071,  Train_accy 46.02
2025-02-20 01:47:10,356 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 2.073,  Train_accy 45.73
2025-02-20 01:47:25,372 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 2.043,  Train_accy 46.72, Test_accy 53.54
2025-02-20 01:47:32,565 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 2.064,  Train_accy 46.63
2025-02-20 01:47:39,693 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 2.060,  Train_accy 45.79
2025-02-20 01:47:47,078 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 2.052,  Train_accy 46.95
2025-02-20 01:47:54,251 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 2.040,  Train_accy 47.16
2025-02-20 01:48:09,334 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 2.031,  Train_accy 46.44, Test_accy 51.63
2025-02-20 01:48:16,976 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 2.042,  Train_accy 46.76
2025-02-20 01:48:24,329 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 2.031,  Train_accy 47.43
2025-02-20 01:48:31,311 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 2.042,  Train_accy 46.95
2025-02-20 01:48:38,266 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 2.038,  Train_accy 47.18
2025-02-20 01:48:53,559 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 2.041,  Train_accy 46.63, Test_accy 57.65
2025-02-20 01:49:00,682 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 2.037,  Train_accy 47.14
2025-02-20 01:49:08,111 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 2.043,  Train_accy 46.97
2025-02-20 01:49:15,316 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 2.041,  Train_accy 46.84
2025-02-20 01:49:22,395 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 2.038,  Train_accy 46.93
2025-02-20 01:49:37,638 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 2.035,  Train_accy 47.12, Test_accy 52.17
2025-02-20 01:49:44,879 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 2.032,  Train_accy 47.31
2025-02-20 01:49:51,883 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 2.052,  Train_accy 46.65
2025-02-20 01:49:58,941 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 2.033,  Train_accy 46.57
2025-02-20 01:50:06,552 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 2.020,  Train_accy 47.12
2025-02-20 01:50:21,686 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 2.034,  Train_accy 46.61, Test_accy 53.42
2025-02-20 01:50:29,224 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 2.030,  Train_accy 47.26
2025-02-20 01:50:36,441 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 2.025,  Train_accy 47.09
2025-02-20 01:50:43,618 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 2.025,  Train_accy 46.88
2025-02-20 01:50:50,528 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 2.023,  Train_accy 47.31
2025-02-20 01:51:05,726 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 2.028,  Train_accy 46.99, Test_accy 43.01
2025-02-20 01:51:13,041 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 2.026,  Train_accy 47.43
2025-02-20 01:51:20,247 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 2.031,  Train_accy 47.07
2025-02-20 01:51:27,484 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 2.028,  Train_accy 47.56
2025-02-20 01:51:34,594 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 2.026,  Train_accy 47.45
2025-02-20 01:51:49,759 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 2.014,  Train_accy 48.04, Test_accy 53.80
2025-02-20 01:51:56,573 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 2.029,  Train_accy 46.88
2025-02-20 01:52:03,298 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 2.024,  Train_accy 47.45
2025-02-20 01:52:10,169 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 2.007,  Train_accy 47.07
2025-02-20 01:52:17,102 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 2.024,  Train_accy 46.30
2025-02-20 01:52:31,220 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 2.018,  Train_accy 47.33, Test_accy 52.95
2025-02-20 01:52:38,087 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 2.002,  Train_accy 47.98
2025-02-20 01:52:45,214 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 2.023,  Train_accy 47.14
2025-02-20 01:52:52,131 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 2.020,  Train_accy 47.09
2025-02-20 01:52:58,822 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 2.014,  Train_accy 47.54
2025-02-20 01:53:12,961 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 2.025,  Train_accy 46.74, Test_accy 58.31
2025-02-20 01:53:19,761 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 2.023,  Train_accy 47.22
2025-02-20 01:53:26,831 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 2.011,  Train_accy 46.90
2025-02-20 01:53:33,840 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 2.014,  Train_accy 47.66
2025-02-20 01:53:40,593 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 2.019,  Train_accy 47.58
2025-02-20 01:53:54,711 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 2.017,  Train_accy 47.35, Test_accy 57.02
2025-02-20 01:54:02,093 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 2.013,  Train_accy 47.71
2025-02-20 01:54:08,846 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 2.018,  Train_accy 46.84
2025-02-20 01:54:15,775 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 2.023,  Train_accy 46.93
2025-02-20 01:54:22,480 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 2.028,  Train_accy 47.70
2025-02-20 01:54:36,906 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 2.016,  Train_accy 47.47, Test_accy 52.60
2025-02-20 01:54:43,662 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 2.021,  Train_accy 48.10
2025-02-20 01:54:50,270 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 2.021,  Train_accy 47.54
2025-02-20 01:54:57,028 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 2.015,  Train_accy 47.58
2025-02-20 01:55:03,970 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 2.010,  Train_accy 47.62
2025-02-20 01:55:18,048 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 2.006,  Train_accy 47.94, Test_accy 50.96
2025-02-20 01:55:24,879 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 2.012,  Train_accy 47.16
2025-02-20 01:55:31,696 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 2.012,  Train_accy 47.56
2025-02-20 01:55:38,531 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 2.004,  Train_accy 46.91
2025-02-20 01:55:45,399 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 2.015,  Train_accy 47.89
2025-02-20 01:55:59,345 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 2.017,  Train_accy 47.43, Test_accy 58.06
2025-02-20 01:56:05,921 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 2.011,  Train_accy 47.12
2025-02-20 01:56:13,147 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 2.012,  Train_accy 47.26
2025-02-20 01:56:19,993 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 2.017,  Train_accy 47.66
2025-02-20 01:56:26,688 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 2.006,  Train_accy 47.35
2025-02-20 01:56:40,917 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 2.009,  Train_accy 46.78, Test_accy 59.05
2025-02-20 01:56:47,865 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 2.006,  Train_accy 47.20
2025-02-20 01:56:54,672 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 2.009,  Train_accy 47.64
2025-02-20 01:57:01,338 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 2.005,  Train_accy 47.41
2025-02-20 01:57:08,318 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 2.006,  Train_accy 47.43
2025-02-20 01:57:22,475 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 2.013,  Train_accy 47.39, Test_accy 51.64
2025-02-20 01:57:29,479 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 2.005,  Train_accy 47.49
2025-02-20 01:57:36,129 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 2.009,  Train_accy 47.83
2025-02-20 01:57:42,993 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 2.001,  Train_accy 46.78
2025-02-20 01:57:50,010 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 2.005,  Train_accy 47.28
2025-02-20 01:58:04,058 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 2.009,  Train_accy 47.16, Test_accy 52.10
2025-02-20 01:58:10,739 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 2.012,  Train_accy 47.87
2025-02-20 01:58:17,854 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 2.005,  Train_accy 47.10
2025-02-20 01:58:24,561 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.997,  Train_accy 47.09
2025-02-20 01:58:31,323 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 2.011,  Train_accy 47.81
2025-02-20 01:58:39,173 [der.py] => Task 2, Epoch 150/150 => Loss 0.005, Loss_clf 0.005, Loss_aux 2.398, Train_accy 100.00
2025-02-20 01:58:45,129 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 2.003,  Train_accy 47.03, Test_accy 57.12
2025-02-20 01:58:50,491 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.369,  Train_accy 37.64, Test_accy 54.49
2025-02-20 01:58:51,917 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 2.016,  Train_accy 47.41
2025-02-20 01:58:56,499 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.163,  Train_accy 53.35
2025-02-20 01:58:58,971 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 2.005,  Train_accy 47.90
2025-02-20 01:59:02,584 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 2.081,  Train_accy 59.90
2025-02-20 01:59:05,800 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.993,  Train_accy 47.66
2025-02-20 01:59:08,605 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 2.041,  Train_accy 64.40
2025-02-20 01:59:12,868 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 2.007,  Train_accy 47.60
2025-02-20 01:59:14,808 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 2.002,  Train_accy 66.44
2025-02-20 01:59:25,950 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.982,  Train_accy 68.24, Test_accy 65.16
2025-02-20 01:59:26,488 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 2.004,  Train_accy 47.56, Test_accy 46.62
2025-02-20 01:59:32,119 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.966,  Train_accy 69.35
2025-02-20 01:59:33,361 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 2.009,  Train_accy 47.47
2025-02-20 01:59:38,131 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.946,  Train_accy 70.91
2025-02-20 01:59:40,053 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 2.004,  Train_accy 47.20
2025-02-20 01:59:44,150 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.929,  Train_accy 72.30
2025-02-20 01:59:47,021 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 2.009,  Train_accy 48.02
2025-02-20 01:59:50,291 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.920,  Train_accy 72.44
2025-02-20 01:59:53,850 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 2.008,  Train_accy 47.52
2025-02-20 02:00:01,996 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.917,  Train_accy 73.41, Test_accy 67.29
2025-02-20 02:00:07,520 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.998,  Train_accy 47.35, Test_accy 46.40
2025-02-20 02:00:07,937 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.909,  Train_accy 73.49
2025-02-20 02:00:14,123 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.904,  Train_accy 74.81
2025-02-20 02:00:14,170 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 2.004,  Train_accy 47.45
2025-02-20 02:00:20,405 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.897,  Train_accy 75.23
2025-02-20 02:00:21,047 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 2.007,  Train_accy 47.79
2025-02-20 02:00:26,521 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.892,  Train_accy 74.53
2025-02-20 02:00:27,863 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 2.001,  Train_accy 47.60
2025-02-20 02:00:34,625 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 2.016,  Train_accy 47.77
2025-02-20 02:00:38,246 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.886,  Train_accy 75.19, Test_accy 67.54
2025-02-20 02:00:44,693 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.883,  Train_accy 75.84
2025-02-20 02:00:48,427 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 2.001,  Train_accy 47.83, Test_accy 57.60
2025-02-20 02:00:51,149 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.875,  Train_accy 76.42
2025-02-20 02:00:55,149 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 2.007,  Train_accy 47.89
2025-02-20 02:00:57,523 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.872,  Train_accy 75.74
2025-02-20 02:01:01,963 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 2.005,  Train_accy 47.09
2025-02-20 02:01:03,483 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.871,  Train_accy 77.62
2025-02-20 02:01:08,685 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 2.001,  Train_accy 47.18
2025-02-20 02:01:15,197 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.869,  Train_accy 76.26, Test_accy 68.37
2025-02-20 02:01:15,491 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 2.006,  Train_accy 47.83
2025-02-20 02:01:15,491 [der.py] => do not weight align student!
2025-02-20 02:01:21,220 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.863,  Train_accy 76.63
2025-02-20 02:01:21,530 [der.py] => darknet eval: 
2025-02-20 02:01:21,530 [der.py] => CNN top1 curve: 58.09
2025-02-20 02:01:21,530 [der.py] => CNN top5 curve: 91.56
2025-02-20 02:01:21,532 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 02:01:26,807 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.860,  Train_accy 77.60
2025-02-20 02:01:32,434 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.856,  Train_accy 77.98
2025-02-20 02:01:38,167 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.851,  Train_accy 77.39
2025-02-20 02:01:49,336 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.849,  Train_accy 77.72, Test_accy 69.51
2025-02-20 02:01:55,585 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.850,  Train_accy 77.86
2025-02-20 02:02:01,389 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.848,  Train_accy 78.26
2025-02-20 02:02:06,274 [der.py] => Exemplar size: 1350
2025-02-20 02:02:06,275 [trainer.py] => CNN: {'total': 66.46, '0': 78.33, '1': 51.11, '2': 76.67, '3': 53.33, '4': 69.44, '5': 20.56, '6': 56.67, '7': 31.67, '8': 45.56, '9': 38.33, '10': 80.56, '11': 88.33, '12': 76.67, '13': 66.67, '14': 37.22, '15': 92.22, '16': 87.22, '17': 85.0, '18': 76.67, '19': 80.56, '20': 85.0, '21': 78.33, '22': 66.67, '23': 65.0, '24': 37.78, '25': 81.11, '26': 92.22, '27': 88.33, '28': 73.89, '29': 83.33, '30': 86.11, '31': 88.33, '32': 100.0, '33': 85.56, '34': 82.22, '35': 69.44, '36': 81.67, '37': 22.78, '38': 20.0, '39': 47.78, '40': 48.89, '41': 47.22, '42': 62.22, '43': 72.78, 'old': 71.05, 'new': 50.39}
2025-02-20 02:02:06,275 [trainer.py] => NME: {'total': 67.04, '0': 53.89, '1': 55.0, '2': 74.44, '3': 43.89, '4': 72.78, '5': 32.22, '6': 59.44, '7': 32.78, '8': 51.11, '9': 42.22, '10': 75.56, '11': 83.33, '12': 75.56, '13': 60.0, '14': 39.44, '15': 86.67, '16': 80.56, '17': 73.33, '18': 70.56, '19': 78.89, '20': 79.44, '21': 66.67, '22': 70.56, '23': 53.33, '24': 33.89, '25': 58.89, '26': 88.33, '27': 81.11, '28': 62.78, '29': 86.11, '30': 73.33, '31': 77.78, '32': 88.89, '33': 61.67, '34': 80.0, '35': 87.78, '36': 92.22, '37': 50.56, '38': 77.78, '39': 70.56, '40': 57.22, '41': 71.11, '42': 77.78, '43': 78.33, 'old': 65.84, 'new': 71.22}
2025-02-20 02:02:06,275 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.68, 66.46]
2025-02-20 02:02:06,275 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.62, 94.1]
2025-02-20 02:02:06,275 [trainer.py] => NME top1 curve: [86.19, 82.58, 73.21, 67.04]
2025-02-20 02:02:06,275 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.57, 93.37]

2025-02-20 02:02:06,275 [trainer.py] => All params: 8263992
2025-02-20 02:02:06,276 [trainer.py] => Trainable params: 4157880
2025-02-20 02:02:06,346 [der.py] => Learning on 45-55
2025-02-20 02:02:06,347 [der.py] => All params: 8274242
2025-02-20 02:02:06,347 [der.py] => Trainable params: 4168130
2025-02-20 02:02:06,473 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 02:02:06,474 [der.py] => per cls weights : [1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807 1.11898807
 1.11898807 1.11898807 1.11898807 0.4645537  0.4645537  0.4645537
 0.4645537  0.4645537  0.4645537  0.4645537  0.4645537  0.4645537
 0.4645537 ]
2025-02-20 02:02:07,036 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.844,  Train_accy 78.53
2025-02-20 02:02:12,371 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.846,  Train_accy 78.30
2025-02-20 02:02:22,389 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.843,  Train_accy 78.10, Test_accy 68.62
2025-02-20 02:02:27,943 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.845,  Train_accy 78.65
2025-02-20 02:02:33,911 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.840,  Train_accy 79.03
2025-02-20 02:02:39,538 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.839,  Train_accy 78.22
2025-02-20 02:02:45,054 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.842,  Train_accy 78.32
2025-02-20 02:02:54,970 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.837,  Train_accy 79.17, Test_accy 69.59
2025-02-20 02:03:00,421 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.835,  Train_accy 78.79
2025-02-20 02:03:05,929 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.831,  Train_accy 78.46
2025-02-20 02:03:11,326 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.832,  Train_accy 78.89
2025-02-20 02:03:16,775 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.830,  Train_accy 78.44
2025-02-20 02:03:27,628 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.830,  Train_accy 79.66, Test_accy 70.40
2025-02-20 02:03:33,007 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.830,  Train_accy 78.93
2025-02-20 02:03:38,404 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.830,  Train_accy 79.03
2025-02-20 02:03:44,054 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.829,  Train_accy 78.83
2025-02-20 02:03:49,379 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.828,  Train_accy 79.60
2025-02-20 02:04:00,151 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.827,  Train_accy 79.27, Test_accy 69.48
2025-02-20 02:04:05,479 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.824,  Train_accy 78.99
2025-02-20 02:04:11,488 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.825,  Train_accy 79.58
2025-02-20 02:04:16,896 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.823,  Train_accy 79.86
2025-02-20 02:04:22,232 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.822,  Train_accy 79.49
2025-02-20 02:04:32,156 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.823,  Train_accy 79.60, Test_accy 68.79
2025-02-20 02:04:38,270 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.820,  Train_accy 78.77
2025-02-20 02:04:43,733 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.822,  Train_accy 79.60
2025-02-20 02:04:49,294 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.821,  Train_accy 79.60
2025-02-20 02:04:55,238 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.817,  Train_accy 79.07
2025-02-20 02:05:05,719 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.819,  Train_accy 79.25, Test_accy 70.19
2025-02-20 02:05:12,205 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.819,  Train_accy 79.15
2025-02-20 02:05:18,526 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.817,  Train_accy 79.58
2025-02-20 02:05:24,614 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.817,  Train_accy 80.26
2025-02-20 02:05:30,763 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.817,  Train_accy 79.11
2025-02-20 02:05:41,912 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.816,  Train_accy 79.47, Test_accy 70.41
2025-02-20 02:05:48,308 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.812,  Train_accy 79.72
2025-02-20 02:05:54,475 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.814,  Train_accy 80.02
2025-02-20 02:06:00,517 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.813,  Train_accy 79.76
2025-02-20 02:06:06,674 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.815,  Train_accy 79.56
2025-02-20 02:06:17,838 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.812,  Train_accy 79.62, Test_accy 70.49
2025-02-20 02:06:23,876 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.812,  Train_accy 79.74
2025-02-20 02:06:30,087 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.812,  Train_accy 79.19
2025-02-20 02:06:36,235 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.810,  Train_accy 79.43
2025-02-20 02:06:42,527 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.810,  Train_accy 79.90
2025-02-20 02:06:53,319 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.810,  Train_accy 79.90, Test_accy 70.00
2025-02-20 02:06:59,334 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.810,  Train_accy 79.33
2025-02-20 02:07:05,268 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.811,  Train_accy 80.53
2025-02-20 02:07:11,503 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.809,  Train_accy 79.37
2025-02-20 02:07:17,694 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.808,  Train_accy 79.86
2025-02-20 02:07:28,693 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.809,  Train_accy 79.74, Test_accy 70.62
2025-02-20 02:07:34,718 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.810,  Train_accy 80.04
2025-02-20 02:07:40,787 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.808,  Train_accy 79.92
2025-02-20 02:07:46,706 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.807,  Train_accy 80.12
2025-02-20 02:07:52,704 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.807,  Train_accy 79.90
2025-02-20 02:08:03,343 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.806,  Train_accy 79.98, Test_accy 70.25
2025-02-20 02:08:09,713 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.805,  Train_accy 80.20
2025-02-20 02:08:15,562 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.806,  Train_accy 80.24
2025-02-20 02:08:21,741 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.806,  Train_accy 80.34
2025-02-20 02:08:27,893 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.808,  Train_accy 80.02
2025-02-20 02:08:39,131 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.806,  Train_accy 79.88, Test_accy 70.59
2025-02-20 02:08:45,645 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.806,  Train_accy 79.98
2025-02-20 02:08:51,751 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.805,  Train_accy 80.10
2025-02-20 02:08:57,873 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.807,  Train_accy 80.32
2025-02-20 02:09:03,871 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.804,  Train_accy 79.66
2025-02-20 02:09:14,914 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.802,  Train_accy 79.70, Test_accy 70.87
2025-02-20 02:09:21,113 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.805,  Train_accy 79.78
2025-02-20 02:09:27,208 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.803,  Train_accy 80.24
2025-02-20 02:09:33,369 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.805,  Train_accy 80.51
2025-02-20 02:09:39,540 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.804,  Train_accy 79.45
2025-02-20 02:09:50,977 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.805,  Train_accy 80.10, Test_accy 70.59
2025-02-20 02:09:56,921 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.803,  Train_accy 80.53
2025-02-20 02:10:03,226 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.801,  Train_accy 80.81
2025-02-20 02:10:09,307 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.803,  Train_accy 80.77
2025-02-20 02:10:15,626 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.803,  Train_accy 79.45
2025-02-20 02:10:27,178 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.803,  Train_accy 80.28, Test_accy 70.49
2025-02-20 02:10:33,219 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.802,  Train_accy 79.70
2025-02-20 02:10:39,352 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.803,  Train_accy 80.12
2025-02-20 02:10:45,583 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.803,  Train_accy 79.92
2025-02-20 02:10:51,465 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.802,  Train_accy 80.42
2025-02-20 02:11:02,582 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.803,  Train_accy 80.18, Test_accy 70.76
2025-02-20 02:11:08,547 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.801,  Train_accy 80.24
2025-02-20 02:11:14,642 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.801,  Train_accy 80.44
2025-02-20 02:11:20,680 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.803,  Train_accy 80.28
2025-02-20 02:11:26,830 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.802,  Train_accy 80.32
2025-02-20 02:11:38,027 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.804,  Train_accy 80.32, Test_accy 70.65
2025-02-20 02:11:44,010 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.801,  Train_accy 80.26
2025-02-20 02:11:49,914 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.802,  Train_accy 80.34
2025-02-20 02:11:55,858 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.800,  Train_accy 80.16
2025-02-20 02:12:02,026 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.802,  Train_accy 80.34
2025-02-20 02:12:13,482 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.800,  Train_accy 79.96, Test_accy 70.67
2025-02-20 02:12:19,536 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.801,  Train_accy 80.53
2025-02-20 02:12:25,629 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.800,  Train_accy 80.57
2025-02-20 02:12:31,673 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.802,  Train_accy 80.32
2025-02-20 02:12:37,580 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.801,  Train_accy 79.88
2025-02-20 02:12:48,566 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.800,  Train_accy 79.74, Test_accy 70.56
2025-02-20 02:12:54,681 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.800,  Train_accy 80.24
2025-02-20 02:13:00,606 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.801,  Train_accy 80.30
2025-02-20 02:13:06,750 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.800,  Train_accy 80.18
2025-02-20 02:13:13,089 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.800,  Train_accy 80.30
2025-02-20 02:13:24,394 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.800,  Train_accy 80.46, Test_accy 70.67
2025-02-20 02:13:30,433 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.802,  Train_accy 80.53
2025-02-20 02:13:36,305 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.800,  Train_accy 80.75
2025-02-20 02:13:42,421 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.801,  Train_accy 80.67
2025-02-20 02:13:48,610 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.803,  Train_accy 79.96
2025-02-20 02:13:48,610 [der.py] => do not weight align student!
2025-02-20 02:13:52,762 [der.py] => darknet eval: 
2025-02-20 02:13:52,762 [der.py] => CNN top1 curve: 70.63
2025-02-20 02:13:52,762 [der.py] => CNN top5 curve: 95.48
2025-02-20 02:13:52,764 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 02:14:31,092 [der.py] => Exemplar size: 1050
2025-02-20 02:14:31,093 [trainer.py] => CNN: {'total': 76.92, '0': 81.11, '1': 56.11, '2': 87.78, '3': 54.44, '4': 77.22, '5': 38.33, '6': 72.78, '7': 28.89, '8': 42.22, '9': 37.22, '10': 83.33, '11': 97.78, '12': 79.44, '13': 76.11, '14': 65.0, '15': 95.0, '16': 96.11, '17': 93.33, '18': 92.22, '19': 93.89, '20': 94.44, '21': 86.67, '22': 90.0, '23': 82.22, '24': 75.0, '25': 69.44, '26': 86.11, '27': 81.67, '28': 65.0, '29': 80.56, '30': 85.0, '31': 83.89, '32': 97.78, '33': 77.78, 'old': 75.07, 'new': 81.56}
2025-02-20 02:14:31,093 [trainer.py] => NME: {'total': 73.33, '0': 86.11, '1': 57.78, '2': 78.33, '3': 53.89, '4': 82.22, '5': 37.22, '6': 65.0, '7': 33.33, '8': 50.0, '9': 50.0, '10': 83.89, '11': 89.44, '12': 80.0, '13': 72.22, '14': 65.56, '15': 90.0, '16': 93.33, '17': 85.56, '18': 86.67, '19': 85.56, '20': 87.78, '21': 81.67, '22': 78.33, '23': 53.33, '24': 54.44, '25': 63.89, '26': 88.33, '27': 82.78, '28': 57.78, '29': 77.78, '30': 80.56, '31': 80.56, '32': 91.11, '33': 72.78, 'old': 71.27, 'new': 78.5}
2025-02-20 02:14:31,093 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.92]
2025-02-20 02:14:31,093 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.67]
2025-02-20 02:14:31,093 [trainer.py] => NME top1 curve: [86.19, 82.58, 73.33]
2025-02-20 02:14:31,093 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.63]

2025-02-20 02:14:31,093 [trainer.py] => All params: 8253742
2025-02-20 02:14:31,094 [trainer.py] => Trainable params: 4147630
2025-02-20 02:14:31,271 [der.py] => Learning on 35-45
2025-02-20 02:14:31,272 [der.py] => All params: 8263992
2025-02-20 02:14:31,273 [der.py] => Trainable params: 4157880
2025-02-20 02:14:31,391 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 02:14:31,391 [der.py] => per cls weights : [1.20654005 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005
 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005
 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005
 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005
 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005
 1.20654005 1.20654005 1.20654005 1.20654005 1.20654005 0.27710984
 0.27710984 0.27710984 0.27710984 0.27710984 0.27710984 0.27710984
 0.27710984 0.27710984 0.27710984]
2025-02-20 02:25:09,846 [der.py] => Task 4, Epoch 150/150 => Loss 0.009, Loss_clf 0.009, Loss_aux 2.366, Train_accy 99.98
2025-02-20 02:25:24,554 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.010,  Train_accy 31.23, Test_accy 54.28
2025-02-20 02:25:31,744 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.847,  Train_accy 46.97
2025-02-20 02:25:38,584 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.765,  Train_accy 59.05
2025-02-20 02:25:45,513 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.727,  Train_accy 65.35
2025-02-20 02:25:52,274 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.698,  Train_accy 69.46
2025-02-20 02:26:07,331 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.683,  Train_accy 71.44, Test_accy 60.41
2025-02-20 02:26:14,360 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.670,  Train_accy 74.50
2025-02-20 02:26:21,154 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.659,  Train_accy 75.68
2025-02-20 02:26:28,113 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.645,  Train_accy 76.36
2025-02-20 02:26:35,170 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.639,  Train_accy 77.80
2025-02-20 02:26:50,201 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.635,  Train_accy 78.29, Test_accy 64.03
2025-02-20 02:26:57,099 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.638,  Train_accy 79.03
2025-02-20 02:27:04,012 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.627,  Train_accy 80.68
2025-02-20 02:27:10,971 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.624,  Train_accy 80.41
2025-02-20 02:27:18,014 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.614,  Train_accy 81.98
2025-02-20 02:27:33,022 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.609,  Train_accy 82.22, Test_accy 64.40
2025-02-20 02:27:39,947 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.613,  Train_accy 82.23
2025-02-20 02:27:47,076 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.610,  Train_accy 82.04
2025-02-20 02:27:53,900 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.606,  Train_accy 82.68
2025-02-20 02:28:00,908 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.603,  Train_accy 83.60
2025-02-20 02:28:15,899 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.600,  Train_accy 83.17, Test_accy 64.36
2025-02-20 02:28:22,897 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.602,  Train_accy 84.05
2025-02-20 02:28:29,870 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.603,  Train_accy 83.78
2025-02-20 02:28:37,025 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.598,  Train_accy 84.25
2025-02-20 02:28:43,925 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.595,  Train_accy 84.43
2025-02-20 02:28:58,801 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.599,  Train_accy 84.29, Test_accy 64.87
2025-02-20 02:29:05,715 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.595,  Train_accy 84.90
2025-02-20 02:29:12,424 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.589,  Train_accy 85.73
2025-02-20 02:29:19,174 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.590,  Train_accy 85.03
2025-02-20 02:29:26,016 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.587,  Train_accy 84.94
2025-02-20 02:29:40,320 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.586,  Train_accy 85.30, Test_accy 65.28
2025-02-20 02:29:47,409 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.586,  Train_accy 85.71
2025-02-20 02:29:54,222 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.589,  Train_accy 85.51
2025-02-20 02:30:01,104 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.582,  Train_accy 85.86
2025-02-20 02:30:08,168 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.583,  Train_accy 86.05
2025-02-20 02:30:23,281 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.581,  Train_accy 86.22, Test_accy 65.42
2025-02-20 02:30:30,226 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.581,  Train_accy 85.89
2025-02-20 02:30:37,029 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.578,  Train_accy 86.74
2025-02-20 02:30:44,234 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.577,  Train_accy 86.31
2025-02-20 02:30:51,376 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.578,  Train_accy 86.22
2025-02-20 02:31:06,840 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.575,  Train_accy 86.59, Test_accy 65.72
2025-02-20 02:31:14,173 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.577,  Train_accy 86.77
2025-02-20 02:31:21,215 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.576,  Train_accy 86.54
2025-02-20 02:31:28,258 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.574,  Train_accy 86.74
2025-02-20 02:31:35,329 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.574,  Train_accy 86.92
2025-02-20 02:31:51,313 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.575,  Train_accy 86.88, Test_accy 65.48
2025-02-20 02:31:58,333 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.573,  Train_accy 87.32
2025-02-20 02:32:05,297 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.574,  Train_accy 86.58
2025-02-20 02:32:12,061 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.573,  Train_accy 87.15
2025-02-20 02:32:19,386 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.574,  Train_accy 86.31
2025-02-20 02:32:34,145 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.568,  Train_accy 87.03, Test_accy 65.82
2025-02-20 02:32:41,125 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.574,  Train_accy 86.52
2025-02-20 02:32:48,078 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.568,  Train_accy 86.70
2025-02-20 02:32:55,358 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.569,  Train_accy 87.21
2025-02-20 02:33:02,210 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.568,  Train_accy 87.37
2025-02-20 02:33:16,581 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.569,  Train_accy 87.37, Test_accy 64.99
2025-02-20 02:33:23,936 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.567,  Train_accy 86.85
2025-02-20 02:33:30,672 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.565,  Train_accy 87.84
2025-02-20 02:33:37,795 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.568,  Train_accy 87.96
2025-02-20 02:33:44,631 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.563,  Train_accy 87.33
2025-02-20 02:33:59,463 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.566,  Train_accy 87.21, Test_accy 65.84
2025-02-20 02:34:06,389 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.564,  Train_accy 87.26
2025-02-20 02:34:13,234 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.563,  Train_accy 87.35
2025-02-20 02:34:20,250 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.567,  Train_accy 87.48
2025-02-20 02:34:27,459 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.568,  Train_accy 87.51
2025-02-20 02:34:42,021 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.563,  Train_accy 87.93, Test_accy 65.96
2025-02-20 02:34:49,072 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.564,  Train_accy 87.64
2025-02-20 02:34:56,018 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.562,  Train_accy 87.62
2025-02-20 02:35:02,923 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.565,  Train_accy 87.50
2025-02-20 02:35:09,665 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.564,  Train_accy 87.59
2025-02-20 02:35:15,339 [der.py] => Task 3, Epoch 150/150 => Loss 0.036, Loss_clf 0.036, Loss_aux 2.374, Train_accy 99.96
2025-02-20 02:35:25,082 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.559,  Train_accy 88.02, Test_accy 65.89
2025-02-20 02:35:29,860 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.388,  Train_accy 26.74, Test_accy 44.84
2025-02-20 02:35:32,295 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.562,  Train_accy 87.62
2025-02-20 02:35:36,423 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.288,  Train_accy 30.63
2025-02-20 02:35:39,097 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.561,  Train_accy 87.87
2025-02-20 02:35:43,072 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 2.264,  Train_accy 32.63
2025-02-20 02:35:45,996 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.563,  Train_accy 87.24
2025-02-20 02:35:49,872 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 2.195,  Train_accy 34.06
2025-02-20 02:35:52,808 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.562,  Train_accy 88.22
2025-02-20 02:35:56,553 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 2.193,  Train_accy 35.41
2025-02-20 02:36:07,110 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.560,  Train_accy 87.82, Test_accy 65.85
2025-02-20 02:36:11,634 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.163,  Train_accy 36.04, Test_accy 55.00
2025-02-20 02:36:13,769 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.562,  Train_accy 88.09
2025-02-20 02:36:18,238 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 2.159,  Train_accy 36.95
2025-02-20 02:36:20,450 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.563,  Train_accy 87.44
2025-02-20 02:36:25,014 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 2.140,  Train_accy 37.73
2025-02-20 02:36:27,362 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.561,  Train_accy 88.02
2025-02-20 02:36:31,983 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 2.138,  Train_accy 38.00
2025-02-20 02:36:34,223 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.559,  Train_accy 88.13
2025-02-20 02:36:39,608 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 2.165,  Train_accy 37.68
2025-02-20 02:36:48,350 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.558,  Train_accy 87.95, Test_accy 65.94
2025-02-20 02:36:53,646 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.132,  Train_accy 38.95, Test_accy 54.67
2025-02-20 02:36:54,931 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.559,  Train_accy 87.89
2025-02-20 02:37:00,383 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.124,  Train_accy 39.22
2025-02-20 02:37:01,614 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.564,  Train_accy 87.62
2025-02-20 02:37:07,128 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.129,  Train_accy 38.69
2025-02-20 02:37:08,442 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.560,  Train_accy 88.32
2025-02-20 02:37:14,243 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.124,  Train_accy 38.50
2025-02-20 02:37:15,305 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.559,  Train_accy 88.31
2025-02-20 02:37:21,035 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.125,  Train_accy 39.18
2025-02-20 02:37:29,689 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.562,  Train_accy 87.73, Test_accy 65.68
2025-02-20 02:37:34,705 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.108,  Train_accy 39.43, Test_accy 47.70
2025-02-20 02:37:36,366 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.558,  Train_accy 87.98
2025-02-20 02:37:41,438 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.111,  Train_accy 39.92
2025-02-20 02:37:43,194 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.556,  Train_accy 88.13
2025-02-20 02:37:48,141 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.118,  Train_accy 38.80
2025-02-20 02:37:49,830 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.560,  Train_accy 88.13
2025-02-20 02:37:54,869 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.112,  Train_accy 39.94
2025-02-20 02:37:56,566 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.560,  Train_accy 87.84
2025-02-20 02:38:01,832 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.097,  Train_accy 40.30
2025-02-20 02:38:10,853 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.560,  Train_accy 88.23, Test_accy 65.78
2025-02-20 02:38:15,929 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.106,  Train_accy 40.48, Test_accy 54.98
2025-02-20 02:38:17,631 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.555,  Train_accy 87.86
2025-02-20 02:38:22,815 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.103,  Train_accy 40.06
2025-02-20 02:38:24,584 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.557,  Train_accy 88.41
2025-02-20 02:38:29,437 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.090,  Train_accy 40.27
2025-02-20 02:38:31,289 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.559,  Train_accy 87.71
2025-02-20 02:38:36,367 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.097,  Train_accy 40.25
2025-02-20 02:38:38,028 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.555,  Train_accy 88.36
2025-02-20 02:38:43,105 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 2.094,  Train_accy 40.25
2025-02-20 02:38:52,037 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.558,  Train_accy 87.96, Test_accy 66.00
2025-02-20 02:38:57,388 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 2.080,  Train_accy 40.53, Test_accy 49.43
2025-02-20 02:38:58,710 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.556,  Train_accy 88.20
2025-02-20 02:39:03,961 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 2.095,  Train_accy 39.58
2025-02-20 02:39:05,316 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.556,  Train_accy 88.45
2025-02-20 02:39:10,588 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 2.086,  Train_accy 40.72
2025-02-20 02:39:12,015 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.559,  Train_accy 88.59
2025-02-20 02:39:17,345 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 2.104,  Train_accy 40.70
2025-02-20 02:39:18,882 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.555,  Train_accy 88.34
2025-02-20 02:39:24,173 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 2.090,  Train_accy 40.40
2025-02-20 02:39:32,774 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.557,  Train_accy 88.11, Test_accy 65.92
2025-02-20 02:39:38,135 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 2.075,  Train_accy 40.59, Test_accy 56.37
2025-02-20 02:39:39,252 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.557,  Train_accy 88.14
2025-02-20 02:39:44,927 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 2.090,  Train_accy 40.59
2025-02-20 02:39:45,986 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.556,  Train_accy 88.43
2025-02-20 02:39:51,469 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 2.100,  Train_accy 40.30
2025-02-20 02:39:52,722 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.554,  Train_accy 88.36
2025-02-20 02:39:58,535 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 2.086,  Train_accy 41.31
2025-02-20 02:39:59,481 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.555,  Train_accy 88.25
2025-02-20 02:40:05,227 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 2.071,  Train_accy 40.63
2025-02-20 02:40:14,117 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.556,  Train_accy 88.13, Test_accy 65.96
2025-02-20 02:40:19,219 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 2.067,  Train_accy 40.30, Test_accy 53.21
2025-02-20 02:40:21,074 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.557,  Train_accy 88.59
2025-02-20 02:40:26,010 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 2.082,  Train_accy 40.90
2025-02-20 02:40:27,647 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.557,  Train_accy 88.31
2025-02-20 02:40:33,699 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 2.057,  Train_accy 40.86
2025-02-20 02:40:34,602 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.554,  Train_accy 88.23
2025-02-20 02:40:40,449 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 2.079,  Train_accy 40.08
2025-02-20 02:40:41,468 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.555,  Train_accy 88.50
2025-02-20 02:40:46,985 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 2.069,  Train_accy 41.01
2025-02-20 02:40:55,616 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.554,  Train_accy 88.23, Test_accy 66.17
2025-02-20 02:41:00,845 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 2.075,  Train_accy 40.65, Test_accy 55.62
2025-02-20 02:41:02,187 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.558,  Train_accy 88.49
2025-02-20 02:41:07,526 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 2.069,  Train_accy 40.84
2025-02-20 02:41:08,890 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.558,  Train_accy 88.22
2025-02-20 02:41:14,113 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 2.080,  Train_accy 40.65
2025-02-20 02:41:15,654 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.558,  Train_accy 88.14
2025-02-20 02:41:20,786 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 2.064,  Train_accy 40.95
2025-02-20 02:41:22,443 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.556,  Train_accy 88.45
2025-02-20 02:41:27,471 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 2.065,  Train_accy 40.63
2025-02-20 02:41:36,442 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.553,  Train_accy 88.34, Test_accy 66.31
2025-02-20 02:41:41,727 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 2.070,  Train_accy 41.26, Test_accy 49.91
2025-02-20 02:41:43,077 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.556,  Train_accy 88.56
2025-02-20 02:41:48,317 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 2.059,  Train_accy 41.01
2025-02-20 02:41:49,847 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.558,  Train_accy 88.31
2025-02-20 02:41:55,002 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 2.119,  Train_accy 40.19
2025-02-20 02:41:56,521 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.557,  Train_accy 88.38
2025-02-20 02:42:01,805 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 2.075,  Train_accy 41.22
2025-02-20 02:42:03,493 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.555,  Train_accy 88.16
2025-02-20 02:42:08,766 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 2.060,  Train_accy 40.97
2025-02-20 02:42:17,676 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.555,  Train_accy 88.16, Test_accy 66.03
2025-02-20 02:42:22,836 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 2.075,  Train_accy 40.76, Test_accy 49.99
2025-02-20 02:42:24,416 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.553,  Train_accy 88.72
2025-02-20 02:42:29,509 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 2.070,  Train_accy 40.88
2025-02-20 02:42:31,045 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.558,  Train_accy 88.61
2025-02-20 02:42:36,229 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 2.062,  Train_accy 40.91
2025-02-20 02:42:37,792 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.556,  Train_accy 88.27
2025-02-20 02:42:42,928 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 2.058,  Train_accy 41.03
2025-02-20 02:42:44,381 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.555,  Train_accy 88.41
2025-02-20 02:42:49,886 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 2.062,  Train_accy 40.99
2025-02-20 02:42:58,301 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.555,  Train_accy 89.01, Test_accy 66.02
2025-02-20 02:43:03,719 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 2.064,  Train_accy 40.53, Test_accy 37.68
2025-02-20 02:43:05,070 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.556,  Train_accy 88.40
2025-02-20 02:43:10,391 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 2.055,  Train_accy 40.88
2025-02-20 02:43:11,742 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.556,  Train_accy 88.81
2025-02-20 02:43:17,002 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 2.074,  Train_accy 40.74
2025-02-20 02:43:18,347 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.555,  Train_accy 88.65
2025-02-20 02:43:23,901 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 2.056,  Train_accy 41.31
2025-02-20 02:43:25,071 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.552,  Train_accy 88.72
2025-02-20 02:43:25,072 [der.py] => do not weight align student!
2025-02-20 02:43:30,584 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 2.059,  Train_accy 41.66
2025-02-20 02:43:31,529 [der.py] => darknet eval: 
2025-02-20 02:43:31,530 [der.py] => CNN top1 curve: 66.12
2025-02-20 02:43:31,530 [der.py] => CNN top5 curve: 90.9
2025-02-20 02:43:31,531 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 02:43:42,970 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 2.046,  Train_accy 41.28, Test_accy 38.62
2025-02-20 02:43:49,077 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 2.061,  Train_accy 41.03
2025-02-20 02:43:55,272 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 2.058,  Train_accy 40.99
2025-02-20 02:44:01,433 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 2.045,  Train_accy 40.82
2025-02-20 02:44:07,719 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 2.049,  Train_accy 40.99
2025-02-20 02:44:21,220 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 2.053,  Train_accy 40.93, Test_accy 42.63
2025-02-20 02:44:28,117 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 2.045,  Train_accy 41.56
2025-02-20 02:44:29,066 [der.py] => Exemplar size: 1650
2025-02-20 02:44:29,066 [trainer.py] => CNN: {'total': 67.41, '0': 48.89, '1': 52.78, '2': 60.0, '3': 28.89, '4': 60.56, '5': 27.22, '6': 52.78, '7': 28.33, '8': 45.56, '9': 35.56, '10': 65.56, '11': 62.22, '12': 65.0, '13': 58.89, '14': 42.78, '15': 85.56, '16': 78.89, '17': 81.11, '18': 73.33, '19': 63.33, '20': 76.11, '21': 69.44, '22': 70.56, '23': 42.78, '24': 47.22, '25': 61.11, '26': 80.56, '27': 81.67, '28': 51.67, '29': 62.22, '30': 72.78, '31': 62.78, '32': 83.89, '33': 47.22, '34': 61.11, '35': 97.78, '36': 97.78, '37': 57.78, '38': 90.56, '39': 96.67, '40': 66.11, '41': 95.56, '42': 90.0, '43': 96.11, '44': 70.0, '45': 82.78, '46': 78.33, '47': 75.56, '48': 78.33, '49': 75.56, '50': 70.0, '51': 78.89, '52': 72.78, '53': 74.44, 'old': 65.48, 'new': 76.11}
2025-02-20 02:44:29,066 [trainer.py] => NME: {'total': 61.69, '0': 58.33, '1': 46.11, '2': 61.67, '3': 28.33, '4': 61.67, '5': 30.0, '6': 52.22, '7': 33.33, '8': 47.22, '9': 45.0, '10': 62.78, '11': 76.67, '12': 65.56, '13': 55.0, '14': 45.0, '15': 77.78, '16': 85.56, '17': 76.11, '18': 72.78, '19': 63.89, '20': 72.78, '21': 71.11, '22': 69.44, '23': 47.22, '24': 43.33, '25': 47.78, '26': 70.0, '27': 73.33, '28': 41.67, '29': 57.22, '30': 57.78, '31': 61.11, '32': 73.89, '33': 44.44, '34': 58.89, '35': 85.0, '36': 78.33, '37': 41.11, '38': 73.89, '39': 73.33, '40': 29.44, '41': 67.78, '42': 64.44, '43': 72.22, '44': 36.67, '45': 78.33, '46': 78.33, '47': 77.78, '48': 73.89, '49': 70.0, '50': 71.67, '51': 71.67, '52': 73.33, '53': 71.11, 'old': 59.05, 'new': 73.56}
2025-02-20 02:44:29,067 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.68, 66.46, 67.41]
2025-02-20 02:44:29,067 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.62, 94.1, 90.95]
2025-02-20 02:44:29,067 [trainer.py] => NME top1 curve: [86.19, 82.58, 73.21, 67.04, 61.69]
2025-02-20 02:44:29,067 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.57, 93.37, 89.98]

2025-02-20 02:44:34,384 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 2.055,  Train_accy 40.72
2025-02-20 02:44:40,410 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 2.055,  Train_accy 41.28
2025-02-20 02:44:46,466 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 2.047,  Train_accy 41.24
2025-02-20 02:44:58,593 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 2.054,  Train_accy 40.95, Test_accy 56.60
2025-02-20 02:45:04,693 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 2.057,  Train_accy 40.80
2025-02-20 02:45:10,665 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 2.052,  Train_accy 41.31
2025-02-20 02:45:16,626 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 2.049,  Train_accy 40.74
2025-02-20 02:45:22,550 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 2.054,  Train_accy 41.87
2025-02-20 02:45:34,877 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 2.052,  Train_accy 41.12, Test_accy 53.05
2025-02-20 02:45:40,693 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 2.044,  Train_accy 40.99
2025-02-20 02:45:46,766 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 2.041,  Train_accy 40.63
2025-02-20 02:45:52,908 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 2.055,  Train_accy 40.78
2025-02-20 02:45:58,831 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 2.060,  Train_accy 41.56
2025-02-20 02:46:10,882 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 2.046,  Train_accy 40.78, Test_accy 52.64
2025-02-20 02:46:16,866 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 2.047,  Train_accy 41.03
2025-02-20 02:46:22,748 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 2.054,  Train_accy 41.03
2025-02-20 02:46:28,903 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 2.047,  Train_accy 40.53
2025-02-20 02:46:34,824 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 2.045,  Train_accy 40.99
2025-02-20 02:46:46,682 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 2.039,  Train_accy 40.84, Test_accy 48.80
2025-02-20 02:46:52,598 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 2.043,  Train_accy 41.43
2025-02-20 02:46:58,611 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 2.049,  Train_accy 40.97
2025-02-20 02:47:04,651 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 2.038,  Train_accy 40.88
2025-02-20 02:47:10,612 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 2.045,  Train_accy 41.14
2025-02-20 02:47:22,642 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 2.046,  Train_accy 41.07, Test_accy 55.69
2025-02-20 02:47:28,670 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 2.035,  Train_accy 40.59
2025-02-20 02:47:34,646 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 2.043,  Train_accy 41.35
2025-02-20 02:47:40,585 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 2.048,  Train_accy 41.47
2025-02-20 02:47:46,691 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 2.041,  Train_accy 41.62
2025-02-20 02:47:58,648 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 2.045,  Train_accy 40.72, Test_accy 57.46
2025-02-20 02:48:04,759 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 2.044,  Train_accy 41.01
2025-02-20 02:48:10,685 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 2.045,  Train_accy 41.77
2025-02-20 02:48:16,623 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 2.041,  Train_accy 41.33
2025-02-20 02:48:22,533 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 2.040,  Train_accy 41.31
2025-02-20 02:48:34,458 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 2.046,  Train_accy 41.41, Test_accy 48.62
2025-02-20 02:48:40,328 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 2.043,  Train_accy 40.99
2025-02-20 02:48:46,157 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 2.042,  Train_accy 41.92
2025-02-20 02:48:52,037 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 2.032,  Train_accy 40.50
2025-02-20 02:48:58,026 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 2.039,  Train_accy 41.05
2025-02-20 02:49:10,220 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 2.044,  Train_accy 40.59, Test_accy 50.17
2025-02-20 02:49:16,305 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 2.046,  Train_accy 41.39
2025-02-20 02:49:22,265 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 2.038,  Train_accy 41.14
2025-02-20 02:49:28,192 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 2.032,  Train_accy 41.28
2025-02-20 02:49:34,295 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 2.045,  Train_accy 41.18
2025-02-20 02:49:46,373 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 2.033,  Train_accy 41.56, Test_accy 55.75
2025-02-20 02:49:53,889 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 2.049,  Train_accy 40.97
2025-02-20 02:50:00,201 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 2.038,  Train_accy 41.62
2025-02-20 02:50:06,300 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 2.030,  Train_accy 41.05
2025-02-20 02:50:12,472 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 2.040,  Train_accy 41.56
2025-02-20 02:50:24,428 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 2.041,  Train_accy 41.07, Test_accy 45.78
2025-02-20 02:50:30,419 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 2.042,  Train_accy 40.97
2025-02-20 02:50:36,544 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 2.038,  Train_accy 40.91
2025-02-20 02:50:42,583 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 2.039,  Train_accy 40.93
2025-02-20 02:50:48,741 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 2.045,  Train_accy 41.10
2025-02-20 02:51:00,831 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 2.028,  Train_accy 41.50, Test_accy 43.88
2025-02-20 02:51:06,770 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 2.041,  Train_accy 40.78
2025-02-20 02:51:12,865 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 2.039,  Train_accy 41.31
2025-02-20 02:51:18,799 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 2.039,  Train_accy 41.10
2025-02-20 02:51:24,855 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 2.046,  Train_accy 41.89
2025-02-20 02:51:36,981 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 2.033,  Train_accy 41.66, Test_accy 56.63
2025-02-20 02:51:42,946 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 2.044,  Train_accy 40.90
2025-02-20 02:51:48,767 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 2.038,  Train_accy 41.30
2025-02-20 02:51:54,642 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 2.039,  Train_accy 41.45
2025-02-20 02:52:00,722 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 2.042,  Train_accy 41.35
2025-02-20 02:52:00,723 [der.py] => do not weight align student!
2025-02-20 02:52:05,863 [der.py] => darknet eval: 
2025-02-20 02:52:05,863 [der.py] => CNN top1 curve: 56.27
2025-02-20 02:52:05,863 [der.py] => CNN top5 curve: 89.32
2025-02-20 02:52:05,865 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 02:52:45,606 [der.py] => Exemplar size: 1350
2025-02-20 02:52:45,606 [trainer.py] => CNN: {'total': 67.11, '0': 74.44, '1': 53.89, '2': 78.89, '3': 50.0, '4': 73.33, '5': 22.22, '6': 63.89, '7': 32.78, '8': 44.44, '9': 35.56, '10': 81.67, '11': 90.56, '12': 78.89, '13': 68.33, '14': 30.56, '15': 94.44, '16': 75.56, '17': 82.22, '18': 77.78, '19': 81.11, '20': 71.67, '21': 79.44, '22': 71.11, '23': 58.89, '24': 43.33, '25': 81.67, '26': 91.67, '27': 92.22, '28': 67.78, '29': 82.22, '30': 88.33, '31': 86.11, '32': 98.33, '33': 77.78, '34': 77.78, '35': 77.78, '36': 89.44, '37': 20.0, '38': 21.67, '39': 42.22, '40': 52.22, '41': 68.33, '42': 75.56, '43': 73.33, 'old': 70.25, 'new': 56.11}
2025-02-20 02:52:45,607 [trainer.py] => NME: {'total': 67.02, '0': 55.56, '1': 55.0, '2': 72.22, '3': 45.0, '4': 73.33, '5': 32.78, '6': 60.56, '7': 35.0, '8': 50.56, '9': 37.78, '10': 76.67, '11': 80.0, '12': 74.44, '13': 57.78, '14': 42.78, '15': 90.0, '16': 76.67, '17': 76.11, '18': 74.44, '19': 76.11, '20': 72.22, '21': 70.0, '22': 67.22, '23': 52.22, '24': 44.44, '25': 57.22, '26': 83.33, '27': 78.89, '28': 52.78, '29': 82.22, '30': 65.0, '31': 80.0, '32': 78.33, '33': 63.89, '34': 78.33, '35': 89.44, '36': 95.56, '37': 43.33, '38': 85.56, '39': 68.89, '40': 57.78, '41': 79.44, '42': 86.11, '43': 86.11, 'old': 64.83, 'new': 74.72}
2025-02-20 02:52:45,607 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.92, 67.11]
2025-02-20 02:52:45,607 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.67, 94.32]
2025-02-20 02:52:45,607 [trainer.py] => NME top1 curve: [86.19, 82.58, 73.33, 67.02]
2025-02-20 02:52:45,607 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.63, 93.33]

2025-02-20 02:52:45,607 [trainer.py] => All params: 8263992
2025-02-20 02:52:45,608 [trainer.py] => Trainable params: 4157880
2025-02-20 02:52:45,685 [der.py] => Learning on 45-55
2025-02-20 02:52:45,687 [der.py] => All params: 8274242
2025-02-20 02:52:45,688 [der.py] => Trainable params: 4168130
2025-02-20 02:52:45,792 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 02:52:45,792 [der.py] => per cls weights : [1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106 1.16287106
 1.16287106 1.16287106 1.16287106 0.26708025 0.26708025 0.26708025
 0.26708025 0.26708025 0.26708025 0.26708025 0.26708025 0.26708025
 0.26708025]
2025-02-20 03:13:00,015 [der.py] => Task 4, Epoch 150/150 => Loss 0.008, Loss_clf 0.008, Loss_aux 2.404, Train_accy 100.00
2025-02-20 03:13:13,049 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.042,  Train_accy 25.19, Test_accy 54.52
2025-02-20 03:13:19,360 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.899,  Train_accy 34.05
2025-02-20 03:13:25,524 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.830,  Train_accy 43.06
2025-02-20 03:13:31,711 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.802,  Train_accy 49.10
2025-02-20 03:13:37,904 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.769,  Train_accy 52.95
2025-02-20 03:13:51,421 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.757,  Train_accy 56.23, Test_accy 59.76
2025-02-20 03:13:57,577 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.749,  Train_accy 58.79
2025-02-20 03:14:03,741 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.740,  Train_accy 59.24
2025-02-20 03:14:09,925 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.730,  Train_accy 60.16
2025-02-20 03:14:16,276 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.720,  Train_accy 62.59
2025-02-20 03:14:29,692 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.712,  Train_accy 62.97, Test_accy 62.51
2025-02-20 03:14:35,989 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.715,  Train_accy 63.01
2025-02-20 03:14:42,092 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.707,  Train_accy 64.02
2025-02-20 03:14:48,464 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.706,  Train_accy 64.92
2025-02-20 03:14:54,696 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.696,  Train_accy 65.62
2025-02-20 03:15:07,847 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.695,  Train_accy 66.11, Test_accy 62.78
2025-02-20 03:15:13,942 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.696,  Train_accy 66.86
2025-02-20 03:15:20,199 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.692,  Train_accy 67.03
2025-02-20 03:15:26,482 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.686,  Train_accy 67.35
2025-02-20 03:15:32,621 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.686,  Train_accy 66.85
2025-02-20 03:15:45,729 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.681,  Train_accy 68.34, Test_accy 62.31
2025-02-20 03:15:51,951 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.686,  Train_accy 68.40
2025-02-20 03:15:58,046 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.685,  Train_accy 68.76
2025-02-20 03:16:04,143 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.680,  Train_accy 68.32
2025-02-20 03:16:10,370 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.678,  Train_accy 68.40
2025-02-20 03:16:23,487 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.681,  Train_accy 68.61, Test_accy 62.55
2025-02-20 03:16:29,805 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.675,  Train_accy 69.32
2025-02-20 03:16:35,966 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.671,  Train_accy 68.88
2025-02-20 03:16:42,138 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.671,  Train_accy 68.86
2025-02-20 03:16:48,284 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.670,  Train_accy 69.73
2025-02-20 03:17:01,244 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.668,  Train_accy 70.04, Test_accy 63.45
2025-02-20 03:17:07,380 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.670,  Train_accy 70.32
2025-02-20 03:17:13,514 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.671,  Train_accy 69.73
2025-02-20 03:17:19,733 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.664,  Train_accy 70.02
2025-02-20 03:17:25,662 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.666,  Train_accy 70.02
2025-02-20 03:17:38,543 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.667,  Train_accy 69.89, Test_accy 63.59
2025-02-20 03:17:44,638 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.667,  Train_accy 71.12
2025-02-20 03:17:50,952 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.662,  Train_accy 71.60
2025-02-20 03:17:57,190 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.663,  Train_accy 70.38
2025-02-20 03:18:03,234 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.662,  Train_accy 71.17
2025-02-20 03:18:16,168 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.660,  Train_accy 71.06, Test_accy 63.45
2025-02-20 03:18:22,397 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.662,  Train_accy 70.31
2025-02-20 03:18:28,547 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.661,  Train_accy 71.26
2025-02-20 03:18:34,689 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.657,  Train_accy 71.37
2025-02-20 03:18:40,777 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.657,  Train_accy 71.96
2025-02-20 03:18:53,885 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.656,  Train_accy 71.64, Test_accy 63.46
2025-02-20 03:19:00,052 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.657,  Train_accy 71.24
2025-02-20 03:19:06,223 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.657,  Train_accy 71.26
2025-02-20 03:19:12,355 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.655,  Train_accy 72.02
2025-02-20 03:19:18,776 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.658,  Train_accy 71.32
2025-02-20 03:19:31,868 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.652,  Train_accy 71.86, Test_accy 63.57
2025-02-20 03:19:37,971 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.656,  Train_accy 71.55
2025-02-20 03:19:44,101 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.653,  Train_accy 72.13
2025-02-20 03:19:50,185 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.653,  Train_accy 71.95
2025-02-20 03:19:56,502 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.651,  Train_accy 72.05
2025-02-20 03:20:09,759 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.654,  Train_accy 71.78, Test_accy 63.67
2025-02-20 03:20:15,838 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.652,  Train_accy 72.02
2025-02-20 03:20:22,090 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.650,  Train_accy 71.64
2025-02-20 03:20:28,335 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.653,  Train_accy 71.71
2025-02-20 03:20:34,563 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.648,  Train_accy 72.50
2025-02-20 03:20:47,437 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.650,  Train_accy 72.02, Test_accy 63.26
2025-02-20 03:20:53,777 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.650,  Train_accy 71.98
2025-02-20 03:20:59,910 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.648,  Train_accy 71.84
2025-02-20 03:21:06,049 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.651,  Train_accy 72.47
2025-02-20 03:21:12,212 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.653,  Train_accy 72.49
2025-02-20 03:21:25,242 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.648,  Train_accy 72.70, Test_accy 63.74
2025-02-20 03:21:31,380 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.648,  Train_accy 72.13
2025-02-20 03:21:37,494 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.648,  Train_accy 72.09
2025-02-20 03:21:43,797 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.650,  Train_accy 71.98
2025-02-20 03:21:50,165 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.648,  Train_accy 72.40
2025-02-20 03:22:03,145 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.644,  Train_accy 72.86, Test_accy 63.96
2025-02-20 03:22:09,306 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.645,  Train_accy 72.14
2025-02-20 03:22:15,438 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.647,  Train_accy 72.99
2025-02-20 03:22:21,745 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.648,  Train_accy 72.16
2025-02-20 03:22:28,008 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.646,  Train_accy 73.03
2025-02-20 03:22:41,013 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.644,  Train_accy 73.12, Test_accy 63.75
2025-02-20 03:22:47,257 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.646,  Train_accy 72.54
2025-02-20 03:22:53,659 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.647,  Train_accy 72.14
2025-02-20 03:22:59,716 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.646,  Train_accy 73.33
2025-02-20 03:23:06,066 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.642,  Train_accy 73.06
2025-02-20 03:23:19,181 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.644,  Train_accy 72.86, Test_accy 64.05
2025-02-20 03:23:25,404 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.644,  Train_accy 72.88
2025-02-20 03:23:31,727 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.647,  Train_accy 72.32
2025-02-20 03:23:38,168 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.645,  Train_accy 73.21
2025-02-20 03:23:44,554 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.641,  Train_accy 73.15
2025-02-20 03:23:57,912 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.646,  Train_accy 72.99, Test_accy 63.92
2025-02-20 03:24:04,093 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.644,  Train_accy 72.94
2025-02-20 03:24:10,332 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.639,  Train_accy 73.21
2025-02-20 03:24:16,644 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.646,  Train_accy 73.19
2025-02-20 03:24:22,859 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.644,  Train_accy 72.67
2025-02-20 03:24:36,045 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.645,  Train_accy 73.14, Test_accy 64.10
2025-02-20 03:24:42,104 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.639,  Train_accy 73.15
2025-02-20 03:24:48,471 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.641,  Train_accy 72.85
2025-02-20 03:24:54,911 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.641,  Train_accy 72.83
2025-02-20 03:25:01,993 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.639,  Train_accy 73.26
2025-02-20 03:25:15,067 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.642,  Train_accy 72.99, Test_accy 64.13
2025-02-20 03:25:21,387 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.640,  Train_accy 73.23
2025-02-20 03:25:27,516 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.640,  Train_accy 73.33
2025-02-20 03:25:33,706 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.642,  Train_accy 72.74
2025-02-20 03:25:39,878 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.639,  Train_accy 73.30
2025-02-20 03:25:53,059 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.642,  Train_accy 72.56, Test_accy 63.57
2025-02-20 03:25:59,180 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.641,  Train_accy 73.53
2025-02-20 03:26:05,353 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.641,  Train_accy 73.68
2025-02-20 03:26:11,515 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.637,  Train_accy 72.77
2025-02-20 03:26:17,719 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.640,  Train_accy 73.15
2025-02-20 03:26:30,788 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.639,  Train_accy 72.94, Test_accy 63.90
2025-02-20 03:26:37,026 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.642,  Train_accy 73.14
2025-02-20 03:26:43,200 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.642,  Train_accy 72.90
2025-02-20 03:26:49,525 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.638,  Train_accy 73.30
2025-02-20 03:26:55,657 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.640,  Train_accy 73.59
2025-02-20 03:27:08,775 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.639,  Train_accy 73.50, Test_accy 63.84
2025-02-20 03:27:15,021 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.642,  Train_accy 73.30
2025-02-20 03:27:21,200 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.643,  Train_accy 73.08
2025-02-20 03:27:27,354 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.642,  Train_accy 73.64
2025-02-20 03:27:33,632 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.639,  Train_accy 73.80
2025-02-20 03:27:46,847 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.638,  Train_accy 73.30, Test_accy 64.02
2025-02-20 03:27:53,186 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.640,  Train_accy 73.21
2025-02-20 03:27:59,360 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.642,  Train_accy 73.39
2025-02-20 03:28:05,483 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.640,  Train_accy 73.64
2025-02-20 03:28:11,767 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.640,  Train_accy 73.01
2025-02-20 03:28:24,791 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.640,  Train_accy 73.03, Test_accy 63.99
2025-02-20 03:28:30,969 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.638,  Train_accy 73.14
2025-02-20 03:28:37,140 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.644,  Train_accy 73.06
2025-02-20 03:28:43,258 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.639,  Train_accy 73.06
2025-02-20 03:28:49,622 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.640,  Train_accy 73.19
2025-02-20 03:29:02,707 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.640,  Train_accy 73.95, Test_accy 64.07
2025-02-20 03:29:08,809 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.639,  Train_accy 73.19
2025-02-20 03:29:14,977 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.640,  Train_accy 73.64
2025-02-20 03:29:21,157 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.639,  Train_accy 73.82
2025-02-20 03:29:27,384 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.636,  Train_accy 73.69
2025-02-20 03:29:27,385 [der.py] => do not weight align student!
2025-02-20 03:29:33,679 [der.py] => darknet eval: 
2025-02-20 03:29:33,679 [der.py] => CNN top1 curve: 64.08
2025-02-20 03:29:33,679 [der.py] => CNN top5 curve: 90.54
2025-02-20 03:29:33,682 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 03:30:19,031 [der.py] => Exemplar size: 1650
2025-02-20 03:30:19,032 [trainer.py] => CNN: {'total': 68.07, '0': 41.67, '1': 53.33, '2': 58.33, '3': 28.33, '4': 63.33, '5': 24.44, '6': 56.67, '7': 27.78, '8': 43.89, '9': 33.33, '10': 64.44, '11': 68.89, '12': 66.11, '13': 60.0, '14': 50.56, '15': 86.11, '16': 77.22, '17': 82.22, '18': 78.33, '19': 66.67, '20': 72.78, '21': 72.22, '22': 65.56, '23': 47.78, '24': 51.11, '25': 63.89, '26': 86.67, '27': 82.78, '28': 55.56, '29': 67.78, '30': 65.0, '31': 63.89, '32': 82.22, '33': 48.33, '34': 58.33, '35': 96.67, '36': 98.33, '37': 66.67, '38': 91.11, '39': 97.78, '40': 65.0, '41': 93.89, '42': 91.67, '43': 95.0, '44': 78.89, '45': 81.67, '46': 80.56, '47': 74.44, '48': 75.56, '49': 69.44, '50': 70.56, '51': 73.33, '52': 76.11, '53': 72.22, 'old': 66.46, 'new': 75.33}
2025-02-20 03:30:19,032 [trainer.py] => NME: {'total': 62.12, '0': 62.22, '1': 49.44, '2': 60.56, '3': 30.0, '4': 68.89, '5': 32.78, '6': 53.89, '7': 36.11, '8': 42.78, '9': 43.33, '10': 61.67, '11': 76.11, '12': 63.89, '13': 55.56, '14': 49.44, '15': 79.44, '16': 81.67, '17': 73.89, '18': 70.56, '19': 68.33, '20': 67.78, '21': 65.56, '22': 63.33, '23': 47.78, '24': 48.33, '25': 47.22, '26': 75.56, '27': 71.67, '28': 46.11, '29': 56.67, '30': 49.44, '31': 55.56, '32': 80.0, '33': 40.56, '34': 60.56, '35': 86.67, '36': 86.67, '37': 32.22, '38': 78.89, '39': 72.78, '40': 38.33, '41': 82.78, '42': 77.22, '43': 75.0, '44': 36.67, '45': 77.22, '46': 77.78, '47': 79.44, '48': 72.22, '49': 66.67, '50': 67.22, '51': 66.67, '52': 72.22, '53': 60.56, 'old': 60.09, 'new': 71.28}
2025-02-20 03:30:19,032 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.92, 67.11, 68.07]
2025-02-20 03:30:19,032 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.67, 94.32, 91.49]
2025-02-20 03:30:19,032 [trainer.py] => NME top1 curve: [86.19, 82.58, 73.33, 67.02, 62.12]
2025-02-20 03:30:19,032 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.63, 93.33, 90.09]

2025-02-20 13:01:16,409 [trainer.py] => 实验名称:resnet18对比实验
2025-02-20 13:01:16,471 [trainer.py] => config: ./exps/der.json
2025-02-20 13:01:16,471 [trainer.py] => experiment_name: 实验名称:resnet18对比实验
2025-02-20 13:01:16,471 [trainer.py] => prefix: reproduce
2025-02-20 13:01:16,471 [trainer.py] => dataset: xrfdataset
2025-02-20 13:01:16,471 [trainer.py] => memory_size: 1650
2025-02-20 13:01:16,471 [trainer.py] => memory_per_class: 30
2025-02-20 13:01:16,471 [trainer.py] => fixed_memory: True
2025-02-20 13:01:16,471 [trainer.py] => shuffle: True
2025-02-20 13:01:16,471 [trainer.py] => init_cls: 15
2025-02-20 13:01:16,471 [trainer.py] => increment: 10
2025-02-20 13:01:16,471 [trainer.py] => model_name: der
2025-02-20 13:01:16,471 [trainer.py] => compression_epochs: 130
2025-02-20 13:01:16,471 [trainer.py] => compression_lr: 0.1
2025-02-20 13:01:16,471 [trainer.py] => is_student_wa: False
2025-02-20 13:01:16,472 [trainer.py] => wa_value: 1
2025-02-20 13:01:16,472 [trainer.py] => T: 2
2025-02-20 13:01:16,472 [trainer.py] => convnet_type: resnet18
2025-02-20 13:01:16,472 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-20 13:01:16,472 [trainer.py] => seed: 1993
2025-02-20 13:01:16,556 [data.py] => 加载完毕XRF原始数据集
2025-02-20 13:01:16,579 [data.py] => 加载完毕XRF原始数据集
2025-02-20 13:01:16,579 [trainer.py] => All params: 0
2025-02-20 13:01:16,579 [trainer.py] => Trainable params: 0
2025-02-20 13:01:16,833 [der.py] => Learning on 0-15
2025-02-20 13:01:16,833 [der.py] => All params: 4122015
2025-02-20 13:01:16,833 [der.py] => Trainable params: 4122015
2025-02-20 13:19:36,472 [der.py] => Task 0, Epoch 150/150 => Loss 0.032, Train_accy 99.76
2025-02-20 13:19:36,495 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 13:19:59,690 [der.py] => Exemplar size: 450
2025-02-20 13:19:59,690 [trainer.py] => CNN: {'total': 87.7, '0': 98.33, '1': 92.78, '2': 95.0, '3': 85.56, '4': 89.44, '5': 80.56, '6': 76.11, '7': 87.22, '8': 84.44, '9': 66.11, '10': 95.0, '11': 100.0, '12': 87.78, '13': 86.67, 'old': 0, 'new': 87.7}
2025-02-20 13:19:59,690 [trainer.py] => NME: {'total': 86.19, '0': 98.33, '1': 94.44, '2': 91.67, '3': 81.11, '4': 88.89, '5': 73.89, '6': 69.44, '7': 88.33, '8': 86.11, '9': 63.33, '10': 93.33, '11': 100.0, '12': 86.67, '13': 86.11, 'old': 0, 'new': 86.19}
2025-02-20 13:19:59,690 [trainer.py] => CNN top1 curve: [87.7]
2025-02-20 13:19:59,690 [trainer.py] => CNN top5 curve: [98.89]
2025-02-20 13:19:59,690 [trainer.py] => NME top1 curve: [86.19]
2025-02-20 13:19:59,691 [trainer.py] => NME top5 curve: [98.93]

2025-02-20 13:19:59,691 [trainer.py] => All params: 4122015
2025-02-20 13:19:59,692 [trainer.py] => Trainable params: 4122015
2025-02-20 13:19:59,783 [der.py] => Learning on 15-25
2025-02-20 13:19:59,784 [der.py] => All params: 8243492
2025-02-20 13:19:59,784 [der.py] => Trainable params: 4137380
2025-02-20 13:19:59,846 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 13:19:59,846 [der.py] => per cls weights : [1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 0.17661843 0.17661843 0.17661843
 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843
 0.17661843]
2025-02-20 13:35:14,059 [der.py] => Task 1, Epoch 150/150 => Loss 0.003, Loss_clf 0.003, Loss_aux 2.443, Train_accy 100.00
2025-02-20 13:35:22,690 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.295,  Train_accy 20.80, Test_accy 55.80
2025-02-20 13:35:27,675 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 2.016,  Train_accy 35.25
2025-02-20 13:35:32,691 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.874,  Train_accy 45.25
2025-02-20 13:35:37,782 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.794,  Train_accy 52.06
2025-02-20 13:35:42,751 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.758,  Train_accy 53.94
2025-02-20 13:35:50,927 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.711,  Train_accy 57.16, Test_accy 66.11
2025-02-20 13:35:55,863 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.680,  Train_accy 59.98
2025-02-20 13:36:00,895 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.653,  Train_accy 62.06
2025-02-20 13:36:05,717 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.637,  Train_accy 62.65
2025-02-20 13:36:10,604 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.619,  Train_accy 63.53
2025-02-20 13:36:18,805 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.599,  Train_accy 65.35, Test_accy 66.58
2025-02-20 13:36:23,850 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.588,  Train_accy 64.95
2025-02-20 13:36:29,003 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.585,  Train_accy 65.89
2025-02-20 13:36:33,911 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.577,  Train_accy 66.17
2025-02-20 13:36:38,843 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.570,  Train_accy 66.00
2025-02-20 13:36:47,023 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.564,  Train_accy 66.77, Test_accy 68.96
2025-02-20 13:36:52,024 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.556,  Train_accy 67.38
2025-02-20 13:36:56,859 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.558,  Train_accy 66.90
2025-02-20 13:37:01,789 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.548,  Train_accy 66.80
2025-02-20 13:37:06,811 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.548,  Train_accy 68.13
2025-02-20 13:37:15,208 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.543,  Train_accy 67.27, Test_accy 69.67
2025-02-20 13:37:20,234 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.537,  Train_accy 68.52
2025-02-20 13:37:25,182 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.533,  Train_accy 68.92
2025-02-20 13:37:30,074 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.531,  Train_accy 68.82
2025-02-20 13:37:35,025 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.521,  Train_accy 68.34
2025-02-20 13:37:43,322 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.521,  Train_accy 69.08, Test_accy 70.47
2025-02-20 13:37:48,333 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.519,  Train_accy 69.27
2025-02-20 13:37:53,305 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.517,  Train_accy 69.12
2025-02-20 13:37:58,411 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.515,  Train_accy 68.62
2025-02-20 13:38:03,442 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.514,  Train_accy 69.33
2025-02-20 13:38:11,978 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.512,  Train_accy 68.75, Test_accy 70.84
2025-02-20 13:38:16,974 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.504,  Train_accy 69.81
2025-02-20 13:38:22,003 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.504,  Train_accy 69.03
2025-02-20 13:38:26,937 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.504,  Train_accy 69.14
2025-02-20 13:38:31,836 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.503,  Train_accy 69.72
2025-02-20 13:38:40,296 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.501,  Train_accy 69.44, Test_accy 70.98
2025-02-20 13:38:45,238 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.498,  Train_accy 70.02
2025-02-20 13:38:50,263 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.495,  Train_accy 69.27
2025-02-20 13:38:55,255 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.496,  Train_accy 69.85
2025-02-20 13:39:00,255 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.492,  Train_accy 70.02
2025-02-20 13:39:08,765 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.493,  Train_accy 69.61, Test_accy 71.29
2025-02-20 13:39:13,798 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.488,  Train_accy 70.32
2025-02-20 13:39:18,793 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.489,  Train_accy 69.38
2025-02-20 13:39:23,746 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.492,  Train_accy 69.33
2025-02-20 13:39:28,720 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.488,  Train_accy 69.98
2025-02-20 13:39:37,091 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.486,  Train_accy 69.35, Test_accy 70.91
2025-02-20 13:39:42,161 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.484,  Train_accy 71.18
2025-02-20 13:39:47,028 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.485,  Train_accy 69.63
2025-02-20 13:39:51,943 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.477,  Train_accy 70.62
2025-02-20 13:39:57,006 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.483,  Train_accy 69.83
2025-02-20 13:40:05,216 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.481,  Train_accy 70.54, Test_accy 71.36
2025-02-20 13:40:10,175 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.483,  Train_accy 70.22
2025-02-20 13:40:15,100 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.474,  Train_accy 70.47
2025-02-20 13:40:20,075 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.479,  Train_accy 69.81
2025-02-20 13:40:25,168 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.480,  Train_accy 70.06
2025-02-20 13:40:33,335 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.474,  Train_accy 70.43, Test_accy 72.51
2025-02-20 13:40:38,190 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.474,  Train_accy 69.83
2025-02-20 13:40:43,115 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.473,  Train_accy 70.67
2025-02-20 13:40:48,616 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.470,  Train_accy 70.43
2025-02-20 13:40:53,510 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.471,  Train_accy 70.41
2025-02-20 13:41:01,761 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.468,  Train_accy 70.39, Test_accy 72.67
2025-02-20 13:41:06,662 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.474,  Train_accy 70.80
2025-02-20 13:41:11,619 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.470,  Train_accy 69.89
2025-02-20 13:41:16,586 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.476,  Train_accy 69.63
2025-02-20 13:41:21,509 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.468,  Train_accy 70.04
2025-02-20 13:41:29,781 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.469,  Train_accy 70.22, Test_accy 72.49
2025-02-20 13:41:34,703 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.473,  Train_accy 69.87
2025-02-20 13:41:39,576 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.469,  Train_accy 70.09
2025-02-20 13:41:44,957 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.468,  Train_accy 69.98
2025-02-20 13:41:49,916 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.470,  Train_accy 70.02
2025-02-20 13:41:58,138 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.470,  Train_accy 70.58, Test_accy 72.40
2025-02-20 13:42:03,112 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.467,  Train_accy 70.43
2025-02-20 13:42:08,050 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.466,  Train_accy 70.26
2025-02-20 13:42:12,985 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.465,  Train_accy 70.62
2025-02-20 13:42:17,920 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.465,  Train_accy 70.67
2025-02-20 13:42:26,243 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.464,  Train_accy 70.80, Test_accy 72.56
2025-02-20 13:42:31,765 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.463,  Train_accy 70.37
2025-02-20 13:42:36,769 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.462,  Train_accy 70.11
2025-02-20 13:42:41,863 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.464,  Train_accy 70.24
2025-02-20 13:42:46,760 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.467,  Train_accy 70.04
2025-02-20 13:42:54,920 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.459,  Train_accy 70.75, Test_accy 72.91
2025-02-20 13:42:59,929 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.460,  Train_accy 70.56
2025-02-20 13:43:04,960 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.462,  Train_accy 70.34
2025-02-20 13:43:09,901 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.462,  Train_accy 70.43
2025-02-20 13:43:14,850 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.462,  Train_accy 70.28
2025-02-20 13:43:23,167 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.462,  Train_accy 70.58, Test_accy 72.09
2025-02-20 13:43:28,133 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.462,  Train_accy 70.19
2025-02-20 13:43:33,137 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.459,  Train_accy 70.95
2025-02-20 13:43:38,054 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.460,  Train_accy 70.58
2025-02-20 13:43:42,978 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.459,  Train_accy 70.82
2025-02-20 13:43:51,277 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.458,  Train_accy 70.43, Test_accy 72.11
2025-02-20 13:43:56,263 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.458,  Train_accy 70.90
2025-02-20 13:44:01,287 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.457,  Train_accy 70.17
2025-02-20 13:44:06,284 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.456,  Train_accy 70.52
2025-02-20 13:44:11,204 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.457,  Train_accy 70.49
2025-02-20 13:44:19,437 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.457,  Train_accy 70.77, Test_accy 73.02
2025-02-20 13:44:24,483 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.459,  Train_accy 70.49
2025-02-20 13:44:29,330 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.456,  Train_accy 70.41
2025-02-20 13:44:34,218 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.453,  Train_accy 70.84
2025-02-20 13:44:39,122 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.454,  Train_accy 70.52
2025-02-20 13:44:47,464 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.456,  Train_accy 70.22, Test_accy 72.62
2025-02-20 13:44:52,344 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.454,  Train_accy 70.84
2025-02-20 13:44:57,294 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.455,  Train_accy 70.75
2025-02-20 13:45:02,125 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.454,  Train_accy 70.32
2025-02-20 13:45:07,089 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.452,  Train_accy 70.86
2025-02-20 13:45:15,328 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.455,  Train_accy 70.65, Test_accy 72.36
2025-02-20 13:45:20,381 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.450,  Train_accy 70.54
2025-02-20 13:45:25,368 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.454,  Train_accy 70.84
2025-02-20 13:45:30,240 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.455,  Train_accy 70.49
2025-02-20 13:45:35,166 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.454,  Train_accy 70.95
2025-02-20 13:45:43,583 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.455,  Train_accy 70.84, Test_accy 72.60
2025-02-20 13:45:48,671 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.455,  Train_accy 70.95
2025-02-20 13:45:53,626 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.453,  Train_accy 70.62
2025-02-20 13:45:58,541 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.451,  Train_accy 70.52
2025-02-20 13:46:03,767 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.452,  Train_accy 70.69
2025-02-20 13:46:12,171 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.453,  Train_accy 70.52, Test_accy 73.02
2025-02-20 13:46:17,302 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.454,  Train_accy 70.77
2025-02-20 13:46:22,298 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.452,  Train_accy 70.28
2025-02-20 13:46:27,316 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.451,  Train_accy 70.90
2025-02-20 13:46:32,368 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.450,  Train_accy 71.01
2025-02-20 13:46:40,514 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.453,  Train_accy 71.33, Test_accy 72.47
2025-02-20 13:46:45,425 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.453,  Train_accy 70.32
2025-02-20 13:46:50,436 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.452,  Train_accy 71.23
2025-02-20 13:46:55,528 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.452,  Train_accy 70.06
2025-02-20 13:47:00,381 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.454,  Train_accy 70.15
2025-02-20 13:47:08,706 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.454,  Train_accy 70.49, Test_accy 72.29
2025-02-20 13:47:13,685 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.450,  Train_accy 71.01
2025-02-20 13:47:18,809 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.451,  Train_accy 70.86
2025-02-20 13:47:23,719 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.452,  Train_accy 71.03
2025-02-20 13:47:28,852 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.453,  Train_accy 70.67
2025-02-20 13:47:28,853 [der.py] => do not weight align student!
2025-02-20 13:47:31,685 [der.py] => darknet eval: 
2025-02-20 13:47:31,685 [der.py] => CNN top1 curve: 72.8
2025-02-20 13:47:31,685 [der.py] => CNN top5 curve: 98.18
2025-02-20 13:47:31,687 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 13:47:57,898 [der.py] => Exemplar size: 750
2025-02-20 13:47:57,899 [trainer.py] => CNN: {'total': 85.89, '0': 94.44, '1': 85.0, '2': 94.44, '3': 81.11, '4': 86.11, '5': 71.11, '6': 75.56, '7': 72.22, '8': 76.11, '9': 60.0, '10': 94.44, '11': 100.0, '12': 85.56, '13': 85.0, '14': 89.44, '15': 93.33, '16': 93.33, '17': 95.56, '18': 85.0, '19': 91.67, '20': 95.56, '21': 83.89, '22': 82.78, '23': 83.89, 'old': 83.37, 'new': 89.67}
2025-02-20 13:47:57,899 [trainer.py] => NME: {'total': 82.58, '0': 87.22, '1': 78.89, '2': 92.22, '3': 80.56, '4': 86.67, '5': 66.11, '6': 69.44, '7': 60.56, '8': 56.11, '9': 60.0, '10': 93.89, '11': 100.0, '12': 86.67, '13': 83.89, '14': 86.67, '15': 90.56, '16': 95.56, '17': 85.0, '18': 87.22, '19': 87.22, '20': 89.44, '21': 83.89, '22': 85.56, '23': 90.56, 'old': 79.26, 'new': 87.56}
2025-02-20 13:47:57,899 [trainer.py] => CNN top1 curve: [87.7, 85.89]
2025-02-20 13:47:57,899 [trainer.py] => CNN top5 curve: [98.89, 98.42]
2025-02-20 13:47:57,899 [trainer.py] => NME top1 curve: [86.19, 82.58]
2025-02-20 13:47:57,899 [trainer.py] => NME top5 curve: [98.93, 98.42]

2025-02-20 13:47:57,899 [trainer.py] => All params: 8243492
2025-02-20 13:47:57,900 [trainer.py] => Trainable params: 4137380
2025-02-20 13:47:57,972 [der.py] => Learning on 25-35
2025-02-20 13:47:57,973 [der.py] => All params: 8253742
2025-02-20 13:47:57,973 [der.py] => Trainable params: 4147630
2025-02-20 13:47:58,047 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 13:47:58,047 [der.py] => per cls weights : [1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388
 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388]
2025-02-20 14:04:32,433 [der.py] => Task 2, Epoch 150/150 => Loss 0.005, Loss_clf 0.005, Loss_aux 2.387, Train_accy 100.00
2025-02-20 14:04:41,894 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.390,  Train_accy 24.20, Test_accy 55.38
2025-02-20 14:04:46,873 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.235,  Train_accy 32.46
2025-02-20 14:04:51,958 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 2.154,  Train_accy 39.56
2025-02-20 14:04:57,071 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 2.121,  Train_accy 42.44
2025-02-20 14:05:02,385 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 2.095,  Train_accy 45.17
2025-02-20 14:05:12,008 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 2.074,  Train_accy 46.85, Test_accy 61.03
2025-02-20 14:05:17,036 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 2.060,  Train_accy 47.96
2025-02-20 14:05:22,330 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 2.043,  Train_accy 49.21
2025-02-20 14:05:27,535 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 2.031,  Train_accy 50.79
2025-02-20 14:05:32,608 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 2.024,  Train_accy 50.51
2025-02-20 14:05:41,634 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 2.018,  Train_accy 51.56, Test_accy 62.02
2025-02-20 14:05:46,845 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 2.013,  Train_accy 52.34
2025-02-20 14:05:52,295 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 2.005,  Train_accy 51.84
2025-02-20 14:05:57,292 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.999,  Train_accy 52.87
2025-02-20 14:06:02,338 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.996,  Train_accy 53.72
2025-02-20 14:06:11,616 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.994,  Train_accy 53.45, Test_accy 62.67
2025-02-20 14:06:16,746 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.992,  Train_accy 53.96
2025-02-20 14:06:21,781 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.980,  Train_accy 54.40
2025-02-20 14:06:27,278 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.976,  Train_accy 53.66
2025-02-20 14:06:32,332 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.972,  Train_accy 54.04
2025-02-20 14:06:41,756 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.972,  Train_accy 54.46, Test_accy 64.13
2025-02-20 14:06:46,973 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.966,  Train_accy 54.00
2025-02-20 14:06:52,065 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.963,  Train_accy 54.73
2025-02-20 14:06:57,285 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.960,  Train_accy 55.07
2025-02-20 14:07:02,475 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.957,  Train_accy 54.77
2025-02-20 14:07:11,803 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.955,  Train_accy 54.57, Test_accy 62.54
2025-02-20 14:07:16,918 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.957,  Train_accy 55.17
2025-02-20 14:07:22,005 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.954,  Train_accy 54.97
2025-02-20 14:07:27,342 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.952,  Train_accy 55.86
2025-02-20 14:07:32,683 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.952,  Train_accy 54.93
2025-02-20 14:07:42,456 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.950,  Train_accy 55.82, Test_accy 63.02
2025-02-20 14:07:47,610 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.952,  Train_accy 55.80
2025-02-20 14:07:52,883 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.945,  Train_accy 55.41
2025-02-20 14:07:58,850 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.946,  Train_accy 55.84
2025-02-20 14:08:04,102 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.949,  Train_accy 55.35
2025-02-20 14:08:14,126 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.944,  Train_accy 56.00, Test_accy 63.59
2025-02-20 14:08:19,290 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.942,  Train_accy 56.26
2025-02-20 14:08:24,472 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.938,  Train_accy 55.72
2025-02-20 14:08:29,561 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.937,  Train_accy 56.04
2025-02-20 14:08:34,757 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.936,  Train_accy 56.73
2025-02-20 14:08:43,878 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.936,  Train_accy 55.94, Test_accy 63.70
2025-02-20 14:08:49,138 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.936,  Train_accy 56.48
2025-02-20 14:08:54,209 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.936,  Train_accy 56.69
2025-02-20 14:08:59,263 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.935,  Train_accy 56.24
2025-02-20 14:09:04,326 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.932,  Train_accy 56.44
2025-02-20 14:09:13,613 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.933,  Train_accy 56.36, Test_accy 64.03
2025-02-20 14:09:18,671 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.930,  Train_accy 55.92
2025-02-20 14:09:23,694 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.930,  Train_accy 56.59
2025-02-20 14:09:28,773 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.929,  Train_accy 57.19
2025-02-20 14:09:33,815 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.928,  Train_accy 56.24
2025-02-20 14:09:43,216 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.929,  Train_accy 56.93, Test_accy 63.65
2025-02-20 14:09:48,502 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.924,  Train_accy 56.75
2025-02-20 14:09:53,560 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.926,  Train_accy 56.95
2025-02-20 14:09:58,632 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.926,  Train_accy 55.86
2025-02-20 14:10:03,720 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.924,  Train_accy 56.40
2025-02-20 14:10:13,399 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.925,  Train_accy 56.22, Test_accy 63.13
2025-02-20 14:10:18,528 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.926,  Train_accy 56.22
2025-02-20 14:10:23,718 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.923,  Train_accy 56.95
2025-02-20 14:10:28,740 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.922,  Train_accy 57.43
2025-02-20 14:10:33,921 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.922,  Train_accy 56.38
2025-02-20 14:10:43,519 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.921,  Train_accy 57.23, Test_accy 64.33
2025-02-20 14:10:48,658 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.918,  Train_accy 57.31
2025-02-20 14:10:53,744 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.920,  Train_accy 57.03
2025-02-20 14:10:58,862 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.920,  Train_accy 57.13
2025-02-20 14:11:03,990 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.920,  Train_accy 56.36
2025-02-20 14:11:13,586 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.917,  Train_accy 57.39, Test_accy 63.97
2025-02-20 14:11:18,659 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.917,  Train_accy 57.58
2025-02-20 14:11:23,891 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.917,  Train_accy 57.64
2025-02-20 14:11:28,995 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.915,  Train_accy 56.14
2025-02-20 14:11:34,056 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.915,  Train_accy 56.71
2025-02-20 14:11:43,243 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.914,  Train_accy 57.11, Test_accy 63.56
2025-02-20 14:11:48,386 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.915,  Train_accy 57.15
2025-02-20 14:11:53,937 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.915,  Train_accy 57.37
2025-02-20 14:11:59,106 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.913,  Train_accy 57.05
2025-02-20 14:12:04,212 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.912,  Train_accy 57.27
2025-02-20 14:12:13,480 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.914,  Train_accy 57.56, Test_accy 64.38
2025-02-20 14:12:18,828 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.914,  Train_accy 56.99
2025-02-20 14:12:23,947 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.912,  Train_accy 57.21
2025-02-20 14:12:28,907 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.912,  Train_accy 57.64
2025-02-20 14:12:33,989 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.912,  Train_accy 56.59
2025-02-20 14:12:43,398 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.910,  Train_accy 57.49, Test_accy 63.70
2025-02-20 14:12:48,511 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.909,  Train_accy 56.73
2025-02-20 14:12:53,554 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.910,  Train_accy 57.17
2025-02-20 14:12:58,611 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.910,  Train_accy 57.27
2025-02-20 14:13:03,801 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.912,  Train_accy 56.99
2025-02-20 14:13:13,011 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.910,  Train_accy 57.09, Test_accy 63.75
2025-02-20 14:13:18,107 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.911,  Train_accy 56.99
2025-02-20 14:13:23,207 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.909,  Train_accy 56.87
2025-02-20 14:13:28,299 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.911,  Train_accy 56.83
2025-02-20 14:13:33,600 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.907,  Train_accy 56.93
2025-02-20 14:13:42,854 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.906,  Train_accy 57.70, Test_accy 64.46
2025-02-20 14:13:47,974 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.910,  Train_accy 57.41
2025-02-20 14:13:53,107 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.907,  Train_accy 57.35
2025-02-20 14:13:58,322 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.909,  Train_accy 56.67
2025-02-20 14:14:03,425 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.908,  Train_accy 56.89
2025-02-20 14:14:12,556 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.909,  Train_accy 57.01, Test_accy 63.98
2025-02-20 14:14:17,630 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.907,  Train_accy 57.11
2025-02-20 14:14:22,818 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.905,  Train_accy 57.41
2025-02-20 14:14:28,153 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.906,  Train_accy 57.82
2025-02-20 14:14:33,231 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.908,  Train_accy 56.79
2025-02-20 14:14:42,503 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.906,  Train_accy 56.85, Test_accy 63.97
2025-02-20 14:14:47,659 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.906,  Train_accy 57.21
2025-02-20 14:14:53,046 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.907,  Train_accy 57.11
2025-02-20 14:14:58,173 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.907,  Train_accy 57.68
2025-02-20 14:15:03,262 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.906,  Train_accy 57.41
2025-02-20 14:15:12,909 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.906,  Train_accy 56.87, Test_accy 64.25
2025-02-20 14:15:18,170 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.905,  Train_accy 57.45
2025-02-20 14:15:23,325 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.904,  Train_accy 57.11
2025-02-20 14:15:28,509 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.906,  Train_accy 56.99
2025-02-20 14:15:33,658 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.906,  Train_accy 56.91
2025-02-20 14:15:43,065 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.907,  Train_accy 57.58, Test_accy 64.02
2025-02-20 14:15:48,174 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.904,  Train_accy 57.09
2025-02-20 14:15:53,264 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.905,  Train_accy 57.84
2025-02-20 14:15:58,446 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.904,  Train_accy 57.29
2025-02-20 14:16:03,529 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.906,  Train_accy 57.09
2025-02-20 14:16:12,862 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.904,  Train_accy 58.04, Test_accy 64.24
2025-02-20 14:16:17,967 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.905,  Train_accy 57.25
2025-02-20 14:16:23,089 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.903,  Train_accy 57.62
2025-02-20 14:16:28,137 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.906,  Train_accy 57.03
2025-02-20 14:16:33,298 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.905,  Train_accy 56.95
2025-02-20 14:16:42,458 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.904,  Train_accy 57.68, Test_accy 63.81
2025-02-20 14:16:47,662 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.904,  Train_accy 57.03
2025-02-20 14:16:52,744 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.905,  Train_accy 57.33
2025-02-20 14:16:58,007 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.903,  Train_accy 56.95
2025-02-20 14:17:03,255 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.904,  Train_accy 57.03
2025-02-20 14:17:12,528 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.903,  Train_accy 58.02, Test_accy 64.14
2025-02-20 14:17:17,897 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.906,  Train_accy 57.33
2025-02-20 14:17:23,077 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.904,  Train_accy 57.74
2025-02-20 14:17:28,153 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.905,  Train_accy 57.15
2025-02-20 14:17:33,222 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.907,  Train_accy 57.07
2025-02-20 14:17:33,223 [der.py] => do not weight align student!
2025-02-20 14:17:37,162 [der.py] => darknet eval: 
2025-02-20 14:17:37,162 [der.py] => CNN top1 curve: 64.54
2025-02-20 14:17:37,162 [der.py] => CNN top5 curve: 94.33
2025-02-20 14:17:37,163 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 14:18:08,918 [der.py] => Exemplar size: 1050
2025-02-20 14:18:08,918 [trainer.py] => CNN: {'total': 76.48, '0': 81.11, '1': 57.78, '2': 86.11, '3': 56.67, '4': 80.56, '5': 35.56, '6': 66.67, '7': 30.56, '8': 49.44, '9': 33.33, '10': 82.78, '11': 97.78, '12': 78.89, '13': 76.11, '14': 63.33, '15': 92.78, '16': 93.89, '17': 93.89, '18': 91.67, '19': 93.33, '20': 92.22, '21': 87.78, '22': 90.56, '23': 81.67, '24': 72.22, '25': 64.44, '26': 83.33, '27': 80.56, '28': 66.11, '29': 81.11, '30': 86.67, '31': 88.33, '32': 98.33, '33': 72.22, 'old': 74.67, 'new': 81.0}
2025-02-20 14:18:08,918 [trainer.py] => NME: {'total': 72.22, '0': 85.56, '1': 53.89, '2': 82.78, '3': 53.89, '4': 81.67, '5': 35.0, '6': 61.67, '7': 34.44, '8': 52.78, '9': 48.33, '10': 83.89, '11': 88.33, '12': 77.78, '13': 71.11, '14': 64.44, '15': 92.22, '16': 91.67, '17': 86.11, '18': 87.78, '19': 82.22, '20': 85.0, '21': 81.67, '22': 71.67, '23': 57.78, '24': 45.56, '25': 56.67, '26': 86.11, '27': 80.0, '28': 63.33, '29': 75.56, '30': 83.89, '31': 80.0, '32': 96.11, '33': 65.56, 'old': 70.29, 'new': 77.06}
2025-02-20 14:18:08,918 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.48]
2025-02-20 14:18:08,918 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.84]
2025-02-20 14:18:08,918 [trainer.py] => NME top1 curve: [86.19, 82.58, 72.22]
2025-02-20 14:18:08,918 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.67]

2025-02-20 14:18:08,919 [trainer.py] => All params: 8253742
2025-02-20 14:18:08,919 [trainer.py] => Trainable params: 4147630
2025-02-20 14:18:08,976 [der.py] => Learning on 35-45
2025-02-20 14:18:08,977 [der.py] => All params: 8263992
2025-02-20 14:18:08,977 [der.py] => Trainable params: 4157880
2025-02-20 14:18:09,057 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 14:18:09,058 [der.py] => per cls weights : [1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  0.14198023
 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023
 0.14198023 0.14198023 0.14198023]
2025-02-20 14:35:21,713 [der.py] => Task 3, Epoch 150/150 => Loss 0.067, Loss_clf 0.067, Loss_aux 2.371, Train_accy 99.92
2025-02-20 14:35:32,640 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.359,  Train_accy 21.10, Test_accy 44.63
2025-02-20 14:35:37,979 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.263,  Train_accy 22.82
2025-02-20 14:35:43,321 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 2.221,  Train_accy 24.34
2025-02-20 14:35:48,704 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 2.159,  Train_accy 24.74
2025-02-20 14:35:54,054 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 2.166,  Train_accy 25.43
2025-02-20 14:36:04,437 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.131,  Train_accy 25.71, Test_accy 51.73
2025-02-20 14:36:09,874 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 2.122,  Train_accy 26.51
2025-02-20 14:36:15,208 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 2.108,  Train_accy 26.65
2025-02-20 14:36:20,593 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 2.112,  Train_accy 26.21
2025-02-20 14:36:25,934 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 2.125,  Train_accy 26.42
2025-02-20 14:36:36,294 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.097,  Train_accy 26.88, Test_accy 49.19
2025-02-20 14:36:41,692 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.089,  Train_accy 27.16
2025-02-20 14:36:47,159 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.100,  Train_accy 27.18
2025-02-20 14:36:52,487 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.102,  Train_accy 27.24
2025-02-20 14:36:57,836 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.093,  Train_accy 27.20
2025-02-20 14:37:08,197 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.074,  Train_accy 27.33, Test_accy 45.52
2025-02-20 14:37:13,575 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.078,  Train_accy 27.47
2025-02-20 14:37:18,946 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.082,  Train_accy 27.31
2025-02-20 14:37:24,331 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.073,  Train_accy 27.90
2025-02-20 14:37:29,917 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.064,  Train_accy 27.96
2025-02-20 14:37:40,402 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.073,  Train_accy 28.19, Test_accy 46.69
2025-02-20 14:37:45,739 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.067,  Train_accy 28.00
2025-02-20 14:37:51,154 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.061,  Train_accy 27.79
2025-02-20 14:37:56,637 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.058,  Train_accy 28.00
2025-02-20 14:38:02,006 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 2.062,  Train_accy 27.87
2025-02-20 14:38:12,384 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 2.055,  Train_accy 28.15, Test_accy 46.07
2025-02-20 14:38:17,739 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 2.071,  Train_accy 27.90
2025-02-20 14:38:23,147 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 2.056,  Train_accy 28.08
2025-02-20 14:38:28,533 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 2.074,  Train_accy 28.25
2025-02-20 14:38:34,092 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 2.078,  Train_accy 27.83
2025-02-20 14:38:44,389 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 2.039,  Train_accy 28.15, Test_accy 52.02
2025-02-20 14:38:49,609 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 2.072,  Train_accy 28.06
2025-02-20 14:38:55,036 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 2.068,  Train_accy 27.90
2025-02-20 14:39:00,363 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 2.051,  Train_accy 28.13
2025-02-20 14:39:05,650 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 2.036,  Train_accy 28.70
2025-02-20 14:39:16,157 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 2.028,  Train_accy 27.89, Test_accy 48.81
2025-02-20 14:39:21,478 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 2.046,  Train_accy 28.27
2025-02-20 14:39:26,748 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 2.029,  Train_accy 28.30
2025-02-20 14:39:32,077 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 2.047,  Train_accy 27.79
2025-02-20 14:39:37,340 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 2.038,  Train_accy 28.78
2025-02-20 14:39:47,726 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 2.049,  Train_accy 28.40, Test_accy 53.27
2025-02-20 14:39:53,081 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 2.038,  Train_accy 28.63
2025-02-20 14:39:58,417 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 2.053,  Train_accy 28.48
2025-02-20 14:40:03,771 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 2.029,  Train_accy 28.42
2025-02-20 14:40:09,096 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 2.035,  Train_accy 28.44
2025-02-20 14:40:19,759 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 2.036,  Train_accy 28.36, Test_accy 47.21
2025-02-20 14:40:25,189 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 2.022,  Train_accy 28.36
2025-02-20 14:40:30,510 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 2.063,  Train_accy 28.57
2025-02-20 14:40:35,908 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 2.044,  Train_accy 28.30
2025-02-20 14:40:41,220 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 2.027,  Train_accy 28.67
2025-02-20 14:40:51,479 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 2.036,  Train_accy 28.65, Test_accy 50.02
2025-02-20 14:40:56,776 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 2.035,  Train_accy 28.82
2025-02-20 14:41:02,216 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 2.031,  Train_accy 28.42
2025-02-20 14:41:07,591 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 2.028,  Train_accy 28.40
2025-02-20 14:41:12,961 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 2.026,  Train_accy 28.72
2025-02-20 14:41:24,069 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 2.030,  Train_accy 28.50, Test_accy 37.00
2025-02-20 14:41:29,424 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 2.019,  Train_accy 28.65
2025-02-20 14:41:34,815 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 2.039,  Train_accy 28.55
2025-02-20 14:41:40,127 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 2.027,  Train_accy 28.72
2025-02-20 14:41:45,471 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 2.033,  Train_accy 28.55
2025-02-20 14:41:55,901 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 2.019,  Train_accy 28.69, Test_accy 37.91
2025-02-20 14:42:01,319 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 2.021,  Train_accy 28.63
2025-02-20 14:42:06,823 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 2.023,  Train_accy 28.42
2025-02-20 14:42:12,190 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 2.010,  Train_accy 28.53
2025-02-20 14:42:17,593 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 2.021,  Train_accy 28.51
2025-02-20 14:42:28,071 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 2.028,  Train_accy 28.78, Test_accy 47.90
2025-02-20 14:42:33,476 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 2.017,  Train_accy 28.51
2025-02-20 14:42:38,840 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 2.025,  Train_accy 28.38
2025-02-20 14:42:44,173 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 2.021,  Train_accy 28.80
2025-02-20 14:42:49,698 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 2.020,  Train_accy 28.38
2025-02-20 14:43:00,130 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 2.018,  Train_accy 28.50, Test_accy 52.48
2025-02-20 14:43:05,799 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 2.026,  Train_accy 28.40
2025-02-20 14:43:11,148 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 2.017,  Train_accy 28.65
2025-02-20 14:43:16,446 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 2.021,  Train_accy 28.48
2025-02-20 14:43:21,940 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 2.023,  Train_accy 28.86
2025-02-20 14:43:32,224 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 2.017,  Train_accy 28.78, Test_accy 52.53
2025-02-20 14:43:37,590 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 2.020,  Train_accy 28.67
2025-02-20 14:43:42,980 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 2.019,  Train_accy 28.30
2025-02-20 14:43:48,566 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 2.028,  Train_accy 28.61
2025-02-20 14:43:53,935 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 2.032,  Train_accy 29.24
2025-02-20 14:44:04,349 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 2.020,  Train_accy 28.46, Test_accy 47.14
2025-02-20 14:44:09,734 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 2.015,  Train_accy 28.65
2025-02-20 14:44:15,145 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 2.026,  Train_accy 28.19
2025-02-20 14:44:20,497 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 2.015,  Train_accy 28.72
2025-02-20 14:44:25,840 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 2.015,  Train_accy 29.10
2025-02-20 14:44:36,376 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 2.005,  Train_accy 28.40, Test_accy 46.68
2025-02-20 14:44:41,845 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 2.015,  Train_accy 28.76
2025-02-20 14:44:47,378 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 2.024,  Train_accy 28.70
2025-02-20 14:44:52,725 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 2.008,  Train_accy 28.80
2025-02-20 14:44:58,058 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 2.015,  Train_accy 28.69
2025-02-20 14:45:08,472 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 2.007,  Train_accy 28.84, Test_accy 50.93
2025-02-20 14:45:14,019 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 2.011,  Train_accy 28.97
2025-02-20 14:45:19,326 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 2.014,  Train_accy 29.05
2025-02-20 14:45:24,737 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 2.014,  Train_accy 28.91
2025-02-20 14:45:30,114 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 2.001,  Train_accy 28.53
2025-02-20 14:45:40,477 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 2.013,  Train_accy 28.59, Test_accy 54.25
2025-02-20 14:45:45,808 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 2.015,  Train_accy 28.74
2025-02-20 14:45:51,167 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 2.010,  Train_accy 29.07
2025-02-20 14:45:56,497 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 2.009,  Train_accy 28.50
2025-02-20 14:46:02,065 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 2.012,  Train_accy 28.93
2025-02-20 14:46:12,558 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 2.010,  Train_accy 28.61, Test_accy 48.16
2025-02-20 14:46:17,813 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 2.013,  Train_accy 28.46
2025-02-20 14:46:23,142 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 2.007,  Train_accy 28.59
2025-02-20 14:46:28,590 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 2.003,  Train_accy 28.88
2025-02-20 14:46:34,385 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 2.006,  Train_accy 28.80
2025-02-20 14:46:45,225 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 2.014,  Train_accy 28.67, Test_accy 47.07
2025-02-20 14:46:50,725 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 2.018,  Train_accy 29.26
2025-02-20 14:46:56,539 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 2.009,  Train_accy 28.59
2025-02-20 14:47:02,142 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.995,  Train_accy 28.90
2025-02-20 14:47:08,098 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 2.013,  Train_accy 28.88
2025-02-20 14:47:18,920 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 2.002,  Train_accy 28.44, Test_accy 51.90
2025-02-20 14:47:24,406 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 2.016,  Train_accy 28.55
2025-02-20 14:47:29,961 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 2.005,  Train_accy 28.88
2025-02-20 14:47:35,490 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.994,  Train_accy 28.29
2025-02-20 14:47:41,005 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 2.006,  Train_accy 28.72
2025-02-20 14:47:51,884 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 2.011,  Train_accy 28.86, Test_accy 40.99
2025-02-20 14:47:57,434 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 2.012,  Train_accy 28.76
2025-02-20 14:48:03,312 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 2.003,  Train_accy 28.88
2025-02-20 14:48:08,713 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 2.006,  Train_accy 28.70
2025-02-20 14:48:14,403 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 2.011,  Train_accy 28.70
2025-02-20 14:48:25,087 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.997,  Train_accy 28.67, Test_accy 40.47
2025-02-20 14:48:30,384 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 2.014,  Train_accy 28.69
2025-02-20 14:48:35,699 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 2.010,  Train_accy 28.70
2025-02-20 14:48:41,110 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 2.004,  Train_accy 28.74
2025-02-20 14:48:46,383 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 2.017,  Train_accy 28.84
2025-02-20 14:48:56,903 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 2.007,  Train_accy 28.67, Test_accy 52.59
2025-02-20 14:49:02,238 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 2.011,  Train_accy 28.78
2025-02-20 14:49:07,608 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 2.008,  Train_accy 28.93
2025-02-20 14:49:12,946 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 2.002,  Train_accy 28.51
2025-02-20 14:49:18,493 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 2.008,  Train_accy 28.78
2025-02-20 14:49:18,494 [der.py] => do not weight align student!
2025-02-20 14:49:22,611 [der.py] => darknet eval: 
2025-02-20 14:49:22,611 [der.py] => CNN top1 curve: 53.14
2025-02-20 14:49:22,611 [der.py] => CNN top5 curve: 84.27
2025-02-20 14:49:22,613 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 14:50:00,967 [der.py] => Exemplar size: 1350
2025-02-20 14:50:00,968 [trainer.py] => CNN: {'total': 66.14, '0': 83.33, '1': 51.67, '2': 80.0, '3': 48.33, '4': 71.67, '5': 25.0, '6': 60.56, '7': 36.11, '8': 46.67, '9': 36.67, '10': 77.22, '11': 93.33, '12': 78.33, '13': 62.78, '14': 40.0, '15': 90.0, '16': 82.78, '17': 86.11, '18': 82.78, '19': 80.0, '20': 67.78, '21': 71.67, '22': 67.78, '23': 60.0, '24': 45.56, '25': 79.44, '26': 88.89, '27': 87.78, '28': 65.56, '29': 83.89, '30': 85.0, '31': 86.11, '32': 98.33, '33': 79.44, '34': 83.89, '35': 79.44, '36': 89.44, '37': 20.56, '38': 22.22, '39': 33.89, '40': 51.11, '41': 55.0, '42': 62.78, '43': 70.56, 'old': 70.41, 'new': 51.17}
2025-02-20 14:50:00,968 [trainer.py] => NME: {'total': 66.59, '0': 61.11, '1': 50.0, '2': 73.33, '3': 45.56, '4': 72.22, '5': 31.67, '6': 59.44, '7': 35.56, '8': 57.22, '9': 40.0, '10': 76.11, '11': 88.33, '12': 70.56, '13': 59.44, '14': 47.22, '15': 85.56, '16': 80.0, '17': 78.89, '18': 70.56, '19': 72.22, '20': 70.0, '21': 62.78, '22': 68.89, '23': 49.44, '24': 38.89, '25': 52.22, '26': 83.33, '27': 76.67, '28': 60.0, '29': 80.56, '30': 63.33, '31': 78.33, '32': 77.22, '33': 54.44, '34': 76.67, '35': 92.22, '36': 93.33, '37': 51.11, '38': 82.78, '39': 68.89, '40': 60.56, '41': 80.0, '42': 82.78, '43': 85.0, 'old': 64.22, 'new': 74.89}
2025-02-20 14:50:00,968 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.48, 66.14]
2025-02-20 14:50:00,968 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.84, 94.01]
2025-02-20 14:50:00,968 [trainer.py] => NME top1 curve: [86.19, 82.58, 72.22, 66.59]
2025-02-20 14:50:00,968 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.67, 92.86]

2025-02-20 14:50:00,968 [trainer.py] => All params: 8263992
2025-02-20 14:50:00,969 [trainer.py] => Trainable params: 4157880
2025-02-20 14:50:01,043 [der.py] => Learning on 45-55
2025-02-20 14:50:01,045 [der.py] => All params: 8274242
2025-02-20 14:50:01,046 [der.py] => Trainable params: 4168130
2025-02-20 14:50:01,147 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-20 14:50:01,153 [der.py] => per cls weights : [1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 0.13592186 0.13592186 0.13592186
 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186
 0.13592186]
2025-02-20 15:08:53,913 [der.py] => Task 4, Epoch 150/150 => Loss 0.009, Loss_clf 0.009, Loss_aux 2.402, Train_accy 100.00
2025-02-20 15:09:06,233 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.013,  Train_accy 23.05, Test_accy 50.86
2025-02-20 15:09:12,452 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.901,  Train_accy 24.97
2025-02-20 15:09:18,611 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.846,  Train_accy 27.73
2025-02-20 15:09:24,284 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.825,  Train_accy 30.07
2025-02-20 15:09:30,131 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.806,  Train_accy 32.79
2025-02-20 15:09:42,635 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.796,  Train_accy 34.85, Test_accy 53.66
2025-02-20 15:09:49,553 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.786,  Train_accy 35.87
2025-02-20 15:09:55,130 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.773,  Train_accy 37.37
2025-02-20 15:10:00,828 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.762,  Train_accy 38.27
2025-02-20 15:10:07,675 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.756,  Train_accy 38.59
2025-02-20 15:10:20,347 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.751,  Train_accy 39.93, Test_accy 55.96
2025-02-20 15:10:26,376 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.755,  Train_accy 39.39
2025-02-20 15:10:31,968 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.748,  Train_accy 40.63
2025-02-20 15:10:37,743 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.747,  Train_accy 40.86
2025-02-20 15:10:43,411 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.736,  Train_accy 41.51
2025-02-20 15:10:55,001 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.733,  Train_accy 42.29, Test_accy 56.35
2025-02-20 15:11:00,751 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.736,  Train_accy 41.62
2025-02-20 15:11:06,302 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.733,  Train_accy 42.20
2025-02-20 15:11:12,222 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.727,  Train_accy 42.79
2025-02-20 15:11:18,179 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.727,  Train_accy 42.72
2025-02-20 15:11:29,810 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.722,  Train_accy 42.59, Test_accy 56.99
2025-02-20 15:11:35,378 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.724,  Train_accy 43.23
2025-02-20 15:11:41,089 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.724,  Train_accy 43.87
2025-02-20 15:11:47,728 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.718,  Train_accy 43.82
2025-02-20 15:11:53,297 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.719,  Train_accy 44.36
2025-02-20 15:12:05,026 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.720,  Train_accy 44.27, Test_accy 57.59
2025-02-20 15:12:10,693 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.718,  Train_accy 44.47
2025-02-20 15:12:16,540 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.714,  Train_accy 44.16
2025-02-20 15:12:22,116 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.716,  Train_accy 44.18
2025-02-20 15:12:27,668 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.712,  Train_accy 43.68
2025-02-20 15:12:39,637 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.711,  Train_accy 44.25, Test_accy 56.60
2025-02-20 15:12:45,235 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.714,  Train_accy 45.44
2025-02-20 15:12:50,843 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.714,  Train_accy 44.04
2025-02-20 15:12:56,649 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.706,  Train_accy 45.08
2025-02-20 15:13:02,244 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.710,  Train_accy 45.17
2025-02-20 15:13:14,121 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.711,  Train_accy 45.14, Test_accy 57.26
2025-02-20 15:13:19,687 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.709,  Train_accy 44.79
2025-02-20 15:13:25,356 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.704,  Train_accy 45.44
2025-02-20 15:13:31,196 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.702,  Train_accy 45.75
2025-02-20 15:13:36,730 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.704,  Train_accy 45.41
2025-02-20 15:13:48,513 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.703,  Train_accy 45.98, Test_accy 57.79
2025-02-20 15:13:54,414 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.704,  Train_accy 44.99
2025-02-20 15:13:59,991 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.707,  Train_accy 45.91
2025-02-20 15:14:05,722 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.700,  Train_accy 45.84
2025-02-20 15:14:11,698 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.700,  Train_accy 45.42
2025-02-20 15:14:23,633 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.699,  Train_accy 46.29, Test_accy 57.46
2025-02-20 15:14:29,215 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.700,  Train_accy 46.07
2025-02-20 15:14:34,815 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.702,  Train_accy 45.77
2025-02-20 15:14:40,450 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.699,  Train_accy 46.18
2025-02-20 15:14:46,382 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.700,  Train_accy 45.32
2025-02-20 15:14:58,381 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.694,  Train_accy 46.02, Test_accy 57.00
2025-02-20 15:15:04,029 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.696,  Train_accy 45.69
2025-02-20 15:15:09,637 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.696,  Train_accy 46.36
2025-02-20 15:15:15,379 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.696,  Train_accy 45.78
2025-02-20 15:15:21,000 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.696,  Train_accy 46.20
2025-02-20 15:15:32,488 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.697,  Train_accy 45.50, Test_accy 57.29
2025-02-20 15:15:38,408 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.694,  Train_accy 45.62
2025-02-20 15:15:44,119 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.693,  Train_accy 45.75
2025-02-20 15:15:50,281 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.696,  Train_accy 45.96
2025-02-20 15:15:56,055 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.692,  Train_accy 46.72
2025-02-20 15:16:07,679 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.693,  Train_accy 45.78, Test_accy 57.39
2025-02-20 15:16:13,419 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.692,  Train_accy 46.43
2025-02-20 15:16:19,360 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.691,  Train_accy 46.00
2025-02-20 15:16:25,052 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.694,  Train_accy 46.56
2025-02-20 15:16:30,757 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.695,  Train_accy 46.77
2025-02-20 15:16:42,688 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.690,  Train_accy 46.88, Test_accy 57.72
2025-02-20 15:16:48,542 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.691,  Train_accy 46.41
2025-02-20 15:16:54,297 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.691,  Train_accy 46.67
2025-02-20 15:16:59,872 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.693,  Train_accy 46.58
2025-02-20 15:17:05,666 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.691,  Train_accy 46.32
2025-02-20 15:17:17,297 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.687,  Train_accy 46.95, Test_accy 57.23
2025-02-20 15:17:23,039 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.689,  Train_accy 46.49
2025-02-20 15:17:28,574 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.688,  Train_accy 47.17
2025-02-20 15:17:34,378 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.690,  Train_accy 46.34
2025-02-20 15:17:40,374 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.690,  Train_accy 46.32
2025-02-20 15:17:52,016 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.687,  Train_accy 46.65, Test_accy 57.19
2025-02-20 15:17:57,671 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.691,  Train_accy 46.54
2025-02-20 15:18:03,568 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.691,  Train_accy 46.36
2025-02-20 15:18:09,424 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.690,  Train_accy 47.26
2025-02-20 15:18:14,987 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.686,  Train_accy 46.52
2025-02-20 15:18:26,510 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.687,  Train_accy 46.79, Test_accy 57.97
2025-02-20 15:18:32,222 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.686,  Train_accy 47.17
2025-02-20 15:18:37,864 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.691,  Train_accy 46.88
2025-02-20 15:18:43,440 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.689,  Train_accy 46.86
2025-02-20 15:18:49,194 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.684,  Train_accy 47.64
2025-02-20 15:19:00,726 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.691,  Train_accy 46.95, Test_accy 57.29
2025-02-20 15:19:06,276 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.688,  Train_accy 46.52
2025-02-20 15:19:11,888 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.681,  Train_accy 46.29
2025-02-20 15:19:17,519 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.687,  Train_accy 46.90
2025-02-20 15:19:23,095 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.687,  Train_accy 46.77
2025-02-20 15:19:34,927 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.687,  Train_accy 47.08, Test_accy 57.71
2025-02-20 15:19:40,691 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.683,  Train_accy 46.99
2025-02-20 15:19:46,456 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.683,  Train_accy 47.21
2025-02-20 15:19:52,144 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.686,  Train_accy 46.56
2025-02-20 15:19:57,823 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.682,  Train_accy 46.58
2025-02-20 15:20:10,306 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.686,  Train_accy 46.72, Test_accy 57.71
2025-02-20 15:20:16,036 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.685,  Train_accy 46.85
2025-02-20 15:20:21,566 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.684,  Train_accy 47.57
2025-02-20 15:20:27,492 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.685,  Train_accy 46.79
2025-02-20 15:20:33,015 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.682,  Train_accy 47.21
2025-02-20 15:20:44,855 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.686,  Train_accy 47.01, Test_accy 57.61
2025-02-20 15:20:50,551 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.684,  Train_accy 46.45
2025-02-20 15:20:56,476 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.683,  Train_accy 46.94
2025-02-20 15:21:02,304 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.681,  Train_accy 46.68
2025-02-20 15:21:07,932 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.683,  Train_accy 47.24
2025-02-20 15:21:19,536 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.683,  Train_accy 46.77, Test_accy 57.71
2025-02-20 15:21:25,208 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.685,  Train_accy 46.72
2025-02-20 15:21:30,986 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.685,  Train_accy 47.21
2025-02-20 15:21:36,588 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.680,  Train_accy 46.92
2025-02-20 15:21:42,180 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.684,  Train_accy 46.61
2025-02-20 15:21:53,636 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.681,  Train_accy 47.48, Test_accy 57.49
2025-02-20 15:21:59,581 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.684,  Train_accy 46.74
2025-02-20 15:22:05,058 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.685,  Train_accy 46.77
2025-02-20 15:22:10,570 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.686,  Train_accy 46.81
2025-02-20 15:22:16,164 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.682,  Train_accy 46.97
2025-02-20 15:22:28,087 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.682,  Train_accy 46.97, Test_accy 57.72
2025-02-20 15:22:33,702 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.683,  Train_accy 46.72
2025-02-20 15:22:39,235 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.686,  Train_accy 47.01
2025-02-20 15:22:44,858 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.684,  Train_accy 46.86
2025-02-20 15:22:50,499 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.683,  Train_accy 46.67
2025-02-20 15:23:02,166 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.683,  Train_accy 47.14, Test_accy 57.49
2025-02-20 15:23:07,839 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.680,  Train_accy 47.23
2025-02-20 15:23:13,349 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.687,  Train_accy 46.76
2025-02-20 15:23:19,013 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.683,  Train_accy 46.59
2025-02-20 15:23:24,798 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.683,  Train_accy 47.39
2025-02-20 15:23:37,058 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.684,  Train_accy 47.42, Test_accy 57.52
2025-02-20 15:23:42,793 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.683,  Train_accy 47.23
2025-02-20 15:23:48,513 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.682,  Train_accy 47.24
2025-02-20 15:23:54,231 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.683,  Train_accy 46.49
2025-02-20 15:23:59,802 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.680,  Train_accy 47.19
2025-02-20 15:23:59,803 [der.py] => do not weight align student!
2025-02-20 15:24:05,273 [der.py] => darknet eval: 
2025-02-20 15:24:05,273 [der.py] => CNN top1 curve: 57.72
2025-02-20 15:24:05,273 [der.py] => CNN top5 curve: 86.96
2025-02-20 15:24:05,274 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-20 15:24:50,316 [der.py] => Exemplar size: 1650
2025-02-20 15:24:50,317 [trainer.py] => CNN: {'total': 66.19, '0': 52.78, '1': 51.11, '2': 56.11, '3': 29.44, '4': 60.56, '5': 26.67, '6': 50.0, '7': 28.33, '8': 50.0, '9': 33.33, '10': 63.33, '11': 66.11, '12': 65.0, '13': 55.0, '14': 45.0, '15': 81.11, '16': 78.33, '17': 80.0, '18': 76.11, '19': 67.78, '20': 75.56, '21': 68.33, '22': 65.0, '23': 45.56, '24': 52.78, '25': 53.33, '26': 75.0, '27': 73.89, '28': 56.67, '29': 63.89, '30': 61.11, '31': 66.67, '32': 79.44, '33': 46.11, '34': 57.78, '35': 94.44, '36': 96.67, '37': 56.67, '38': 87.22, '39': 92.78, '40': 60.0, '41': 86.67, '42': 91.67, '43': 96.67, '44': 68.33, '45': 75.56, '46': 78.33, '47': 74.44, '48': 79.44, '49': 68.33, '50': 68.33, '51': 78.89, '52': 81.67, '53': 70.0, 'old': 64.19, 'new': 75.22}
2025-02-20 15:24:50,317 [trainer.py] => NME: {'total': 61.33, '0': 72.22, '1': 46.67, '2': 61.11, '3': 28.89, '4': 63.89, '5': 32.78, '6': 55.56, '7': 33.33, '8': 52.78, '9': 43.89, '10': 64.44, '11': 83.33, '12': 64.44, '13': 51.11, '14': 49.44, '15': 78.33, '16': 78.89, '17': 71.67, '18': 64.44, '19': 60.56, '20': 71.11, '21': 67.22, '22': 66.67, '23': 50.0, '24': 45.0, '25': 41.11, '26': 62.78, '27': 66.11, '28': 49.44, '29': 52.22, '30': 55.56, '31': 58.33, '32': 81.67, '33': 46.67, '34': 53.33, '35': 83.89, '36': 84.44, '37': 37.78, '38': 76.67, '39': 66.67, '40': 24.44, '41': 67.78, '42': 75.56, '43': 77.22, '44': 32.22, '45': 76.11, '46': 73.33, '47': 75.56, '48': 72.78, '49': 66.11, '50': 68.89, '51': 73.33, '52': 80.56, '53': 68.33, 'old': 58.93, 'new': 72.17}
2025-02-20 15:24:50,317 [trainer.py] => CNN top1 curve: [87.7, 85.89, 76.48, 66.14, 66.19]
2025-02-20 15:24:50,317 [trainer.py] => CNN top5 curve: [98.89, 98.42, 95.84, 94.01, 91.27]
2025-02-20 15:24:50,317 [trainer.py] => NME top1 curve: [86.19, 82.58, 72.22, 66.59, 61.33]
2025-02-20 15:24:50,317 [trainer.py] => NME top5 curve: [98.93, 98.42, 95.67, 92.86, 89.43]

2025-04-22 00:19:32,387 [trainer.py] => 实验名称:CIL实验
2025-04-22 00:19:32,486 [trainer.py] => config: ./exps/der.json
2025-04-22 00:19:32,486 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 00:19:32,486 [trainer.py] => prefix: reproduce
2025-04-22 00:19:32,486 [trainer.py] => dataset: xrfdataset
2025-04-22 00:19:32,486 [trainer.py] => memory_size: 1650
2025-04-22 00:19:32,486 [trainer.py] => memory_per_class: 30
2025-04-22 00:19:32,486 [trainer.py] => fixed_memory: True
2025-04-22 00:19:32,486 [trainer.py] => shuffle: True
2025-04-22 00:19:32,486 [trainer.py] => init_cls: 15
2025-04-22 00:19:32,486 [trainer.py] => increment: 10
2025-04-22 00:19:32,486 [trainer.py] => model_name: der
2025-04-22 00:19:32,486 [trainer.py] => compression_epochs: 1
2025-04-22 00:19:32,486 [trainer.py] => compression_lr: 0.1
2025-04-22 00:19:32,486 [trainer.py] => is_student_wa: False
2025-04-22 00:19:32,486 [trainer.py] => wa_value: 1
2025-04-22 00:19:32,486 [trainer.py] => T: 2
2025-04-22 00:19:32,486 [trainer.py] => convnet_type: resnet18
2025-04-22 00:19:32,486 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-04-22 00:19:32,486 [trainer.py] => seed: 1993
2025-04-22 00:19:32,501 [data.py] => 加载完毕XRF原始数据集
2025-04-22 00:19:32,508 [data.py] => 加载完毕XRF原始数据集
2025-04-22 00:19:32,509 [trainer.py] => All params: 0
2025-04-22 00:19:32,509 [trainer.py] => Trainable params: 0
2025-04-22 00:19:32,602 [der.py] => Learning on 0-15
2025-04-22 00:19:32,602 [der.py] => All params: 4122015
2025-04-22 00:19:32,602 [der.py] => Trainable params: 4122015
2025-04-22 00:19:56,983 [der.py] => Task 0, Epoch 2/2 => Loss 2.827, Train_accy 9.11
2025-04-22 00:19:56,984 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:20:28,452 [der.py] => Exemplar size: 450
2025-04-22 00:20:28,453 [trainer.py] => CNN: {'total': 8.67, '0': 0.0, '1': 0.0, '2': 22.22, '3': 33.89, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 21.11, '9': 0.0, '10': 0.0, '11': 5.56, '12': 0.0, '13': 47.22, 'old': 0, 'new': 8.67}
2025-04-22 00:20:28,453 [trainer.py] => NME: {'total': 12.44, '0': 30.56, '1': 8.33, '2': 11.11, '3': 0.0, '4': 0.0, '5': 46.67, '6': 1.11, '7': 17.22, '8': 7.22, '9': 34.44, '10': 2.22, '11': 17.78, '12': 2.78, '13': 2.22, 'old': 0, 'new': 12.44}
2025-04-22 00:20:28,453 [trainer.py] => CNN top1 curve: [8.67]
2025-04-22 00:20:28,453 [trainer.py] => CNN top5 curve: [43.04]
2025-04-22 00:20:28,453 [trainer.py] => NME top1 curve: [12.44]
2025-04-22 00:20:28,453 [trainer.py] => NME top5 curve: [44.93]

2025-04-22 00:20:28,453 [trainer.py] => All params: 4122015
2025-04-22 00:20:28,453 [trainer.py] => Trainable params: 4122015
2025-04-22 00:20:28,531 [der.py] => Learning on 15-25
2025-04-22 00:20:28,532 [der.py] => All params: 8243492
2025-04-22 00:20:28,532 [der.py] => Trainable params: 4137380
2025-04-22 00:20:28,619 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:20:28,620 [der.py] => per cls weights : [1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 0.17661843 0.17661843 0.17661843
 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843
 0.17661843]
2025-04-22 00:20:44,363 [der.py] => Task 1, Epoch 2/2 => Loss 5.462, Loss_clf 3.245, Loss_aux 2.217, Train_accy 17.15
2025-04-22 00:20:55,510 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 3.130,  Train_accy 10.46, Test_accy 4.11
2025-04-22 00:20:55,511 [der.py] => do not weight align student!
2025-04-22 00:20:59,631 [der.py] => darknet eval: 
2025-04-22 00:20:59,631 [der.py] => CNN top1 curve: 4.11
2025-04-22 00:20:59,631 [der.py] => CNN top5 curve: 19.89
2025-04-22 00:20:59,632 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:21:35,407 [der.py] => Exemplar size: 750
2025-04-22 00:21:35,407 [trainer.py] => CNN: {'total': 7.31, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 31.11, '16': 26.67, '17': 0.56, '18': 23.89, '19': 8.89, '20': 1.67, '21': 1.11, '22': 41.67, '23': 8.89, 'old': 0.0, 'new': 18.28}
2025-04-22 00:21:35,407 [trainer.py] => NME: {'total': 7.69, '0': 24.44, '1': 22.22, '2': 7.22, '3': 5.56, '4': 4.44, '5': 12.22, '6': 5.56, '7': 2.22, '8': 1.67, '9': 7.78, '10': 4.44, '11': 15.0, '12': 20.56, '13': 1.11, '14': 7.78, '15': 0.56, '16': 3.33, '17': 2.78, '18': 1.11, '19': 31.11, '20': 1.11, '21': 2.22, '22': 2.78, '23': 2.78, 'old': 9.48, 'new': 5.0}
2025-04-22 00:21:35,407 [trainer.py] => CNN top1 curve: [8.67, 7.31]
2025-04-22 00:21:35,407 [trainer.py] => CNN top5 curve: [43.04, 27.09]
2025-04-22 00:21:35,408 [trainer.py] => NME top1 curve: [12.44, 7.69]
2025-04-22 00:21:35,408 [trainer.py] => NME top5 curve: [44.93, 32.11]

2025-04-22 00:21:35,408 [trainer.py] => All params: 8243492
2025-04-22 00:21:35,409 [trainer.py] => Trainable params: 4137380
2025-04-22 00:21:35,487 [der.py] => Learning on 25-35
2025-04-22 00:21:35,488 [der.py] => All params: 8253742
2025-04-22 00:21:35,488 [der.py] => Trainable params: 4147630
2025-04-22 00:21:35,592 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:21:35,592 [der.py] => per cls weights : [1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388
 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388]
2025-04-22 00:24:17,150 [der.py] => Task 2, Epoch 2/2 => Loss 5.048, Loss_clf 2.603, Loss_aux 2.446, Train_accy 12.54
2025-04-22 00:24:29,387 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.370,  Train_accy 12.05, Test_accy 3.29
2025-04-22 00:24:29,388 [der.py] => do not weight align student!
2025-04-22 00:24:33,995 [der.py] => darknet eval: 
2025-04-22 00:24:33,995 [der.py] => CNN top1 curve: 3.29
2025-04-22 00:24:33,995 [der.py] => CNN top5 curve: 14.79
2025-04-22 00:24:33,996 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:25:17,696 [der.py] => Exemplar size: 1050
2025-04-22 00:25:17,697 [trainer.py] => CNN: {'total': 3.56, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 15.56, '27': 28.33, '28': 7.22, '29': 2.78, '30': 63.89, '31': 0.0, '32': 6.67, '33': 0.0, 'old': 0.0, 'new': 12.44}
2025-04-22 00:25:17,697 [trainer.py] => NME: {'total': 3.52, '0': 7.22, '1': 11.11, '2': 0.56, '3': 0.0, '4': 9.44, '5': 14.44, '6': 0.0, '7': 1.11, '8': 12.78, '9': 0.56, '10': 0.56, '11': 8.89, '12': 2.78, '13': 0.0, '14': 0.56, '15': 0.56, '16': 5.56, '17': 2.22, '18': 3.33, '19': 0.56, '20': 1.67, '21': 0.0, '22': 3.89, '23': 2.22, '24': 2.22, '25': 0.0, '26': 0.0, '27': 0.56, '28': 7.22, '29': 1.67, '30': 0.0, '31': 0.0, '32': 0.56, '33': 5.0, 'old': 3.69, 'new': 3.11}
2025-04-22 00:25:17,697 [trainer.py] => CNN top1 curve: [8.67, 7.31, 3.56]
2025-04-22 00:25:17,697 [trainer.py] => CNN top5 curve: [43.04, 27.09, 16.95]
2025-04-22 00:25:17,697 [trainer.py] => NME top1 curve: [12.44, 7.69, 3.52]
2025-04-22 00:25:17,697 [trainer.py] => NME top5 curve: [44.93, 32.11, 16.06]

2025-04-22 00:25:17,698 [trainer.py] => All params: 8253742
2025-04-22 00:25:17,698 [trainer.py] => Trainable params: 4147630
2025-04-22 00:25:17,773 [der.py] => Learning on 35-45
2025-04-22 00:25:17,774 [der.py] => All params: 8263992
2025-04-22 00:25:17,774 [der.py] => Trainable params: 4157880
2025-04-22 00:25:17,889 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:25:17,890 [der.py] => per cls weights : [1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  0.14198023
 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023
 0.14198023 0.14198023 0.14198023]
2025-04-22 01:40:51,636 [trainer.py] => 实验名称:CIL实验
2025-04-22 01:40:51,667 [trainer.py] => config: ./exps/der.json
2025-04-22 01:40:51,667 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 01:40:51,667 [trainer.py] => prefix: reproduce
2025-04-22 01:40:51,667 [trainer.py] => dataset: xrfdataset
2025-04-22 01:40:51,667 [trainer.py] => memory_size: 1650
2025-04-22 01:40:51,667 [trainer.py] => memory_per_class: 30
2025-04-22 01:40:51,667 [trainer.py] => fixed_memory: True
2025-04-22 01:40:51,667 [trainer.py] => shuffle: True
2025-04-22 01:40:51,667 [trainer.py] => init_cls: 15
2025-04-22 01:40:51,667 [trainer.py] => increment: 10
2025-04-22 01:40:51,667 [trainer.py] => model_name: der
2025-04-22 01:40:51,667 [trainer.py] => compression_epochs: 1
2025-04-22 01:40:51,667 [trainer.py] => compression_lr: 0.1
2025-04-22 01:40:51,667 [trainer.py] => is_student_wa: False
2025-04-22 01:40:51,667 [trainer.py] => wa_value: 1
2025-04-22 01:40:51,667 [trainer.py] => T: 2
2025-04-22 01:40:51,667 [trainer.py] => convnet_type: resnet18
2025-04-22 01:40:51,667 [trainer.py] => device: [device(type='cuda', index=2)]
2025-04-22 01:40:51,667 [trainer.py] => seed: 1993
2025-04-22 01:40:51,680 [data.py] => 加载完毕XRF原始数据集
2025-04-22 01:40:51,685 [data.py] => 加载完毕XRF原始数据集
2025-04-22 01:40:51,686 [trainer.py] => All params: 0
2025-04-22 01:40:51,686 [trainer.py] => Trainable params: 0
2025-04-22 01:40:51,777 [der.py] => Learning on 0-15
2025-04-22 01:40:51,777 [der.py] => All params: 4122015
2025-04-22 01:40:51,778 [der.py] => Trainable params: 4122015
2025-04-22 01:41:00,777 [der.py] => Task 0, Epoch 1/1 => Loss 4.720, Train_accy 7.65, Test_accy 7.48
2025-04-22 01:41:00,777 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:41:22,157 [der.py] => Exemplar size: 450
2025-04-22 01:41:22,157 [trainer.py] => CNN: {'total': 7.48, '0': 1.11, '1': 0.0, '2': 0.0, '3': 80.0, '4': 0.56, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.56, '9': 0.0, '10': 0.0, '11': 30.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 7.48}
2025-04-22 01:41:22,157 [trainer.py] => NME: {'total': 9.63, '0': 44.44, '1': 21.67, '2': 3.33, '3': 0.56, '4': 0.0, '5': 3.33, '6': 2.22, '7': 1.67, '8': 2.78, '9': 1.11, '10': 1.11, '11': 26.11, '12': 32.78, '13': 0.56, 'old': 0, 'new': 9.63}
2025-04-22 01:41:22,157 [trainer.py] => CNN top1 curve: [7.48]
2025-04-22 01:41:22,157 [trainer.py] => CNN top5 curve: [37.15]
2025-04-22 01:41:22,157 [trainer.py] => NME top1 curve: [9.63]
2025-04-22 01:41:22,157 [trainer.py] => NME top5 curve: [41.22]

2025-04-22 01:41:22,158 [trainer.py] => All params: 4122015
2025-04-22 01:41:22,158 [trainer.py] => Trainable params: 4122015
2025-04-22 01:41:22,235 [der.py] => Learning on 15-25
2025-04-22 01:41:22,236 [der.py] => All params: 8243492
2025-04-22 01:41:22,236 [der.py] => Trainable params: 4137380
2025-04-22 01:41:22,328 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 01:41:22,328 [der.py] => per cls weights : [1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 0.17661843 0.17661843 0.17661843
 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843
 0.17661843]
2025-04-22 01:41:29,491 [der.py] => Task 1, Epoch 1/1 => Loss 53.241, Loss_clf 50.812, Loss_aux 2.428, Train_accy 9.99, Test_accy 4.44
2025-04-22 01:41:36,709 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.766,  Train_accy 10.44, Test_accy 3.93
2025-04-22 01:41:36,710 [der.py] => do not weight align student!
2025-04-22 01:41:40,014 [der.py] => darknet eval: 
2025-04-22 01:41:40,015 [der.py] => CNN top1 curve: 3.93
2025-04-22 01:41:40,015 [der.py] => CNN top5 curve: 19.91
2025-04-22 01:41:40,016 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:42:03,304 [der.py] => Exemplar size: 750
2025-04-22 01:42:03,304 [trainer.py] => CNN: {'total': 4.44, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 78.89, '16': 0.0, '17': 0.0, '18': 31.67, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.56, '23': 0.0, 'old': 0.0, 'new': 11.11}
2025-04-22 01:42:03,304 [trainer.py] => NME: {'total': 5.82, '0': 5.56, '1': 5.56, '2': 3.33, '3': 1.67, '4': 0.56, '5': 4.44, '6': 0.0, '7': 6.67, '8': 31.67, '9': 3.89, '10': 1.67, '11': 5.0, '12': 13.89, '13': 1.11, '14': 1.67, '15': 1.67, '16': 0.0, '17': 0.56, '18': 33.33, '19': 1.67, '20': 0.56, '21': 18.33, '22': 0.56, '23': 1.67, 'old': 5.78, 'new': 5.89}
2025-04-22 01:42:03,304 [trainer.py] => CNN top1 curve: [7.48, 4.44]
2025-04-22 01:42:03,304 [trainer.py] => CNN top5 curve: [37.15, 21.0]
2025-04-22 01:42:03,304 [trainer.py] => NME top1 curve: [9.63, 5.82]
2025-04-22 01:42:03,305 [trainer.py] => NME top5 curve: [41.22, 24.51]

2025-04-22 01:42:03,305 [trainer.py] => All params: 8243492
2025-04-22 01:42:03,305 [trainer.py] => Trainable params: 4137380
2025-04-22 01:42:03,383 [der.py] => Learning on 25-35
2025-04-22 01:42:03,384 [der.py] => All params: 8253742
2025-04-22 01:42:03,384 [der.py] => Trainable params: 4147630
2025-04-22 01:42:03,474 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 01:42:03,474 [der.py] => per cls weights : [1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388
 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388]
2025-04-22 01:42:11,795 [der.py] => Task 2, Epoch 1/1 => Loss 7.264, Loss_clf 4.680, Loss_aux 2.585, Train_accy 9.16, Test_accy 3.30
2025-04-22 01:42:19,941 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.307,  Train_accy 10.56, Test_accy 3.05
2025-04-22 01:42:19,942 [der.py] => do not weight align student!
2025-04-22 01:42:24,015 [der.py] => darknet eval: 
2025-04-22 01:42:24,016 [der.py] => CNN top1 curve: 3.05
2025-04-22 01:42:24,016 [der.py] => CNN top5 curve: 15.41
2025-04-22 01:42:24,016 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:42:53,474 [der.py] => Exemplar size: 1050
2025-04-22 01:42:53,479 [trainer.py] => CNN: {'total': 3.32, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 15.0, '31': 0.0, '32': 12.22, '33': 85.56, 'old': 0.0, 'new': 11.61}
2025-04-22 01:42:53,479 [trainer.py] => NME: {'total': 4.67, '0': 4.44, '1': 15.56, '2': 10.0, '3': 1.11, '4': 0.56, '5': 3.33, '6': 0.0, '7': 5.56, '8': 3.89, '9': 5.56, '10': 1.67, '11': 11.67, '12': 3.89, '13': 0.56, '14': 11.67, '15': 0.56, '16': 12.78, '17': 0.56, '18': 4.44, '19': 1.67, '20': 3.33, '21': 0.56, '22': 3.33, '23': 2.78, '24': 5.0, '25': 1.67, '26': 19.44, '27': 0.56, '28': 3.33, '29': 0.0, '30': 5.56, '31': 0.0, '32': 0.0, '33': 18.33, 'old': 4.58, 'new': 4.89}
2025-04-22 01:42:53,479 [trainer.py] => CNN top1 curve: [7.48, 4.44, 3.32]
2025-04-22 01:42:53,479 [trainer.py] => CNN top5 curve: [37.15, 21.0, 15.49]
2025-04-22 01:42:53,479 [trainer.py] => NME top1 curve: [9.63, 5.82, 4.67]
2025-04-22 01:42:53,479 [trainer.py] => NME top5 curve: [41.22, 24.51, 18.3]

2025-04-22 01:42:53,480 [trainer.py] => All params: 8253742
2025-04-22 01:42:53,480 [trainer.py] => Trainable params: 4147630
2025-04-22 01:42:53,559 [der.py] => Learning on 35-45
2025-04-22 01:42:53,560 [der.py] => All params: 8263992
2025-04-22 01:42:53,560 [der.py] => Trainable params: 4157880
2025-04-22 01:42:53,665 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 01:42:53,665 [der.py] => per cls weights : [1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  0.14198023
 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023
 0.14198023 0.14198023 0.14198023]
2025-04-22 01:43:02,964 [der.py] => Task 3, Epoch 1/1 => Loss 12.304, Loss_clf 9.791, Loss_aux 2.513, Train_accy 9.14, Test_accy 2.94
2025-04-22 01:43:12,293 [der.py] => SNet: Task 3, Epoch 1/1 => Loss 3.196,  Train_accy 10.77, Test_accy 2.56
2025-04-22 01:43:12,293 [der.py] => do not weight align student!
2025-04-22 01:43:17,521 [der.py] => darknet eval: 
2025-04-22 01:43:17,521 [der.py] => CNN top1 curve: 2.56
2025-04-22 01:43:17,521 [der.py] => CNN top5 curve: 11.94
2025-04-22 01:43:17,522 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:43:54,886 [der.py] => Exemplar size: 1350
2025-04-22 01:43:54,886 [trainer.py] => CNN: {'total': 2.95, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 4.44, '38': 0.0, '39': 3.33, '40': 0.0, '41': 10.56, '42': 0.0, '43': 31.67, 'old': 0.0, 'new': 13.28}
2025-04-22 01:43:54,886 [trainer.py] => NME: {'total': 3.84, '0': 6.67, '1': 10.0, '2': 7.78, '3': 1.11, '4': 0.0, '5': 3.33, '6': 3.33, '7': 5.56, '8': 1.67, '9': 5.56, '10': 2.78, '11': 13.33, '12': 6.11, '13': 0.56, '14': 1.67, '15': 1.67, '16': 1.67, '17': 1.11, '18': 3.33, '19': 0.0, '20': 0.0, '21': 0.56, '22': 0.56, '23': 2.78, '24': 3.33, '25': 0.0, '26': 0.56, '27': 0.0, '28': 9.44, '29': 0.0, '30': 25.56, '31': 0.0, '32': 0.0, '33': 0.56, '34': 0.56, '35': 0.56, '36': 10.0, '37': 0.0, '38': 2.78, '39': 4.44, '40': 0.0, '41': 22.78, '42': 11.11, '43': 0.0, 'old': 3.46, 'new': 5.17}
2025-04-22 01:43:54,886 [trainer.py] => CNN top1 curve: [7.48, 4.44, 3.32, 2.95]
2025-04-22 01:43:54,886 [trainer.py] => CNN top5 curve: [37.15, 21.0, 15.49, 11.86]
2025-04-22 01:43:54,886 [trainer.py] => NME top1 curve: [9.63, 5.82, 4.67, 3.84]
2025-04-22 01:43:54,886 [trainer.py] => NME top5 curve: [41.22, 24.51, 18.3, 14.85]

2025-04-22 01:43:54,887 [trainer.py] => All params: 8263992
2025-04-22 01:43:54,887 [trainer.py] => Trainable params: 4157880
2025-04-22 01:43:55,075 [der.py] => Learning on 45-55
2025-04-22 01:43:55,076 [der.py] => All params: 8274242
2025-04-22 01:43:55,076 [der.py] => Trainable params: 4168130
2025-04-22 01:43:55,198 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 01:43:55,199 [der.py] => per cls weights : [1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 0.13592186 0.13592186 0.13592186
 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186
 0.13592186]
