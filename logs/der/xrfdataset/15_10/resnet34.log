2025-02-12 00:14:41,447 [trainer.py] => 实验名称:resnet对比实验
2025-02-12 00:14:41,448 [trainer.py] => config: ./exps/der.json
2025-02-12 00:14:41,448 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-12 00:14:41,448 [trainer.py] => prefix: reproduce
2025-02-12 00:14:41,448 [trainer.py] => dataset: xrfdataset
2025-02-12 00:14:41,448 [trainer.py] => memory_size: 1650
2025-02-12 00:14:41,448 [trainer.py] => memory_per_class: 30
2025-02-12 00:14:41,448 [trainer.py] => fixed_memory: True
2025-02-12 00:14:41,448 [trainer.py] => shuffle: True
2025-02-12 00:14:41,448 [trainer.py] => init_cls: 15
2025-02-12 00:14:41,448 [trainer.py] => increment: 10
2025-02-12 00:14:41,448 [trainer.py] => model_name: der
2025-02-12 00:14:41,448 [trainer.py] => compression_epochs: 130
2025-02-12 00:14:41,448 [trainer.py] => compression_lr: 0.1
2025-02-12 00:14:41,448 [trainer.py] => is_student_wa: False
2025-02-12 00:14:41,448 [trainer.py] => wa_value: 1
2025-02-12 00:14:41,448 [trainer.py] => T: 2
2025-02-12 00:14:41,448 [trainer.py] => convnet_type: resnet34
2025-02-12 00:14:41,448 [trainer.py] => device: [device(type='cuda', index=3), device(type='cuda', index=3)]
2025-02-12 00:14:41,448 [trainer.py] => seed: 1993
2025-02-12 00:14:41,461 [data.py] => 加载完毕XRF原始数据集
2025-02-12 00:14:41,466 [data.py] => 加载完毕XRF原始数据集
2025-02-12 00:14:41,468 [trainer.py] => All params: 0
2025-02-12 00:14:41,468 [trainer.py] => Trainable params: 0
2025-02-12 00:14:41,594 [der.py] => Learning on 0-15
2025-02-12 00:14:41,595 [der.py] => All params: 7496351
2025-02-12 00:14:41,595 [der.py] => Trainable params: 7496351
2025-02-12 00:16:58,967 [trainer.py] => 实验名称:resnet对比实验
2025-02-12 00:16:58,967 [trainer.py] => config: ./exps/der.json
2025-02-12 00:16:58,967 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-12 00:16:58,967 [trainer.py] => prefix: reproduce
2025-02-12 00:16:58,967 [trainer.py] => dataset: xrfdataset
2025-02-12 00:16:58,967 [trainer.py] => memory_size: 1650
2025-02-12 00:16:58,967 [trainer.py] => memory_per_class: 30
2025-02-12 00:16:58,967 [trainer.py] => fixed_memory: True
2025-02-12 00:16:58,968 [trainer.py] => shuffle: True
2025-02-12 00:16:58,968 [trainer.py] => init_cls: 15
2025-02-12 00:16:58,968 [trainer.py] => increment: 10
2025-02-12 00:16:58,968 [trainer.py] => model_name: der
2025-02-12 00:16:58,968 [trainer.py] => compression_epochs: 130
2025-02-12 00:16:58,968 [trainer.py] => compression_lr: 0.1
2025-02-12 00:16:58,968 [trainer.py] => is_student_wa: False
2025-02-12 00:16:58,968 [trainer.py] => wa_value: 1
2025-02-12 00:16:58,968 [trainer.py] => T: 2
2025-02-12 00:16:58,968 [trainer.py] => convnet_type: resnet34
2025-02-12 00:16:58,968 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-12 00:16:58,968 [trainer.py] => seed: 1993
2025-02-12 00:16:58,980 [data.py] => 加载完毕XRF原始数据集
2025-02-12 00:16:58,986 [data.py] => 加载完毕XRF原始数据集
2025-02-12 00:16:58,986 [trainer.py] => All params: 0
2025-02-12 00:16:58,986 [trainer.py] => Trainable params: 0
2025-02-12 00:16:59,112 [der.py] => Learning on 0-15
2025-02-12 00:16:59,112 [der.py] => All params: 7496351
2025-02-12 00:16:59,112 [der.py] => Trainable params: 7496351
2025-02-12 00:35:36,992 [der.py] => Task 0, Epoch 150/150 => Loss 0.043, Train_accy 99.62
2025-02-12 00:35:37,002 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 00:36:13,741 [der.py] => Exemplar size: 450
2025-02-12 00:36:13,742 [trainer.py] => CNN: {'total': 79.11, '0': 96.11, '1': 90.56, '2': 79.44, '3': 60.56, '4': 88.89, '5': 73.89, '6': 59.44, '7': 74.44, '8': 88.89, '9': 55.0, '10': 93.89, '11': 98.89, '12': 72.78, '13': 71.11, 'old': 0, 'new': 79.11}
2025-02-12 00:36:13,742 [trainer.py] => NME: {'total': 78.7, '0': 97.78, '1': 88.33, '2': 77.22, '3': 61.67, '4': 77.78, '5': 64.44, '6': 53.33, '7': 81.11, '8': 84.44, '9': 67.22, '10': 91.11, '11': 98.89, '12': 75.0, '13': 77.78, 'old': 0, 'new': 78.7}
2025-02-12 00:36:13,742 [trainer.py] => CNN top1 curve: [79.11]
2025-02-12 00:36:13,742 [trainer.py] => CNN top5 curve: [98.52]
2025-02-12 00:36:13,742 [trainer.py] => NME top1 curve: [78.7]
2025-02-12 00:36:13,742 [trainer.py] => NME top5 curve: [98.52]

2025-02-12 00:36:13,742 [trainer.py] => All params: 7496351
2025-02-12 00:36:13,743 [trainer.py] => Trainable params: 7496351
2025-02-12 00:36:13,846 [der.py] => Learning on 15-25
2025-02-12 00:36:13,847 [der.py] => All params: 14992164
2025-02-12 00:36:13,847 [der.py] => Trainable params: 7511716
2025-02-12 00:36:14,004 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 00:36:14,005 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-12 00:56:54,369 [der.py] => Task 1, Epoch 150/150 => Loss 0.008, Loss_clf 0.004, Loss_aux 0.004, Train_accy 99.96
2025-02-12 00:57:05,951 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.936,  Train_accy 14.73, Test_accy 6.80
2025-02-12 00:57:13,279 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 2.614,  Train_accy 23.78
2025-02-12 00:57:20,344 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 2.377,  Train_accy 33.12
2025-02-12 00:57:27,689 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 2.208,  Train_accy 39.46
2025-02-12 00:57:34,651 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 2.099,  Train_accy 45.44
2025-02-12 00:57:46,093 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 2.051,  Train_accy 47.98, Test_accy 22.18
2025-02-12 00:57:53,169 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.950,  Train_accy 52.39
2025-02-12 00:58:00,838 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.835,  Train_accy 58.26
2025-02-12 00:58:07,678 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.815,  Train_accy 58.06
2025-02-12 00:58:14,960 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.725,  Train_accy 62.47
2025-02-12 00:58:26,545 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.672,  Train_accy 64.54, Test_accy 29.64
2025-02-12 00:58:33,673 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.635,  Train_accy 66.75
2025-02-12 00:58:40,864 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.597,  Train_accy 67.18
2025-02-12 00:58:47,814 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.542,  Train_accy 70.67
2025-02-12 00:58:55,036 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.510,  Train_accy 71.23
2025-02-12 00:59:06,674 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.500,  Train_accy 71.68, Test_accy 32.89
2025-02-12 00:59:13,599 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.402,  Train_accy 76.17
2025-02-12 00:59:20,596 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.392,  Train_accy 76.15
2025-02-12 00:59:27,885 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.380,  Train_accy 76.34
2025-02-12 00:59:35,004 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.343,  Train_accy 78.95
2025-02-12 00:59:46,370 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.319,  Train_accy 79.08, Test_accy 37.62
2025-02-12 00:59:53,652 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.275,  Train_accy 81.27
2025-02-12 01:00:00,829 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.266,  Train_accy 81.40
2025-02-12 01:00:08,074 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.208,  Train_accy 84.43
2025-02-12 01:00:15,365 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.184,  Train_accy 84.99
2025-02-12 01:00:26,463 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.170,  Train_accy 86.13, Test_accy 47.16
2025-02-12 01:00:33,835 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.127,  Train_accy 88.52
2025-02-12 01:00:41,124 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.118,  Train_accy 88.54
2025-02-12 01:00:48,345 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.113,  Train_accy 89.08
2025-02-12 01:00:55,595 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.098,  Train_accy 89.25
2025-02-12 01:01:06,848 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.084,  Train_accy 90.37, Test_accy 49.27
2025-02-12 01:01:14,101 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.086,  Train_accy 90.11
2025-02-12 01:01:21,311 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.080,  Train_accy 90.02
2025-02-12 01:01:28,432 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.055,  Train_accy 91.35
2025-02-12 01:01:35,509 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.033,  Train_accy 92.56
2025-02-12 01:01:47,357 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.036,  Train_accy 92.41, Test_accy 54.22
2025-02-12 01:01:54,527 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.017,  Train_accy 93.01
2025-02-12 01:02:01,762 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.004,  Train_accy 93.59
2025-02-12 01:02:09,068 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.995,  Train_accy 94.04
2025-02-12 01:02:16,194 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.968,  Train_accy 95.33
2025-02-12 01:02:27,764 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.978,  Train_accy 94.86, Test_accy 54.62
2025-02-12 01:02:34,983 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.985,  Train_accy 94.60
2025-02-12 01:02:41,961 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.973,  Train_accy 94.92
2025-02-12 01:02:49,190 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.951,  Train_accy 95.70
2025-02-12 01:02:56,371 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.942,  Train_accy 96.58
2025-02-12 01:03:07,750 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.945,  Train_accy 96.09, Test_accy 58.42
2025-02-12 01:03:14,451 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.941,  Train_accy 96.15
2025-02-12 01:03:21,483 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.923,  Train_accy 96.49
2025-02-12 01:03:29,033 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.915,  Train_accy 97.68
2025-02-12 01:03:36,380 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.917,  Train_accy 97.18
2025-02-12 01:03:47,855 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.918,  Train_accy 97.20, Test_accy 59.29
2025-02-12 01:03:55,175 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.908,  Train_accy 97.59
2025-02-12 01:04:02,612 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.897,  Train_accy 97.51
2025-02-12 01:04:09,912 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.906,  Train_accy 97.61
2025-02-12 01:04:17,106 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.902,  Train_accy 97.76
2025-02-12 01:04:28,622 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.892,  Train_accy 98.00, Test_accy 61.31
2025-02-12 01:04:35,865 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.898,  Train_accy 97.46
2025-02-12 01:04:43,068 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.897,  Train_accy 97.83
2025-02-12 01:04:50,384 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.882,  Train_accy 98.13
2025-02-12 01:04:57,335 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.884,  Train_accy 98.04
2025-02-12 01:05:08,501 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.876,  Train_accy 98.26, Test_accy 61.29
2025-02-12 01:05:15,954 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.877,  Train_accy 97.96
2025-02-12 01:05:23,234 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.873,  Train_accy 98.47
2025-02-12 01:05:30,256 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.864,  Train_accy 98.45
2025-02-12 01:05:37,961 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.877,  Train_accy 97.96
2025-02-12 01:05:49,496 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.868,  Train_accy 98.52, Test_accy 63.49
2025-02-12 01:05:56,753 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.858,  Train_accy 98.52
2025-02-12 01:06:03,728 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.858,  Train_accy 98.45
2025-02-12 01:06:10,677 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.860,  Train_accy 98.34
2025-02-12 01:06:18,019 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.853,  Train_accy 98.62
2025-02-12 01:06:29,451 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.851,  Train_accy 98.73, Test_accy 63.91
2025-02-12 01:06:36,716 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.850,  Train_accy 98.80
2025-02-12 01:06:43,482 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.848,  Train_accy 98.75
2025-02-12 01:06:50,813 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.846,  Train_accy 98.86
2025-02-12 01:06:58,049 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.852,  Train_accy 98.39
2025-02-12 01:07:09,722 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.851,  Train_accy 98.77, Test_accy 63.78
2025-02-12 01:07:16,758 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.845,  Train_accy 98.71
2025-02-12 01:07:24,067 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.843,  Train_accy 98.95
2025-02-12 01:07:31,352 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.844,  Train_accy 98.80
2025-02-12 01:07:38,568 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.843,  Train_accy 98.80
2025-02-12 01:07:50,063 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.845,  Train_accy 98.45, Test_accy 64.20
2025-02-12 01:07:57,215 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.838,  Train_accy 98.92
2025-02-12 01:08:04,582 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.837,  Train_accy 98.65
2025-02-12 01:08:11,862 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.836,  Train_accy 98.67
2025-02-12 01:08:19,222 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.838,  Train_accy 98.58
2025-02-12 01:08:30,467 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.834,  Train_accy 98.77, Test_accy 64.71
2025-02-12 01:08:37,622 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.837,  Train_accy 98.80
2025-02-12 01:08:44,694 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.833,  Train_accy 98.80
2025-02-12 01:08:51,665 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.831,  Train_accy 98.82
2025-02-12 01:08:59,276 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.831,  Train_accy 98.97
2025-02-12 01:09:11,574 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.832,  Train_accy 98.77, Test_accy 64.69
2025-02-12 01:09:18,836 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.831,  Train_accy 98.90
2025-02-12 01:09:26,184 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.829,  Train_accy 99.01
2025-02-12 01:09:33,325 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.835,  Train_accy 98.69
2025-02-12 01:09:40,438 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.832,  Train_accy 98.71
2025-02-12 01:09:51,781 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.828,  Train_accy 98.84, Test_accy 64.44
2025-02-12 01:09:59,022 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.826,  Train_accy 99.03
2025-02-12 01:10:06,025 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.826,  Train_accy 98.75
2025-02-12 01:10:13,037 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.824,  Train_accy 98.80
2025-02-12 01:10:20,231 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.827,  Train_accy 98.95
2025-02-12 01:10:31,472 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.823,  Train_accy 98.82, Test_accy 64.51
2025-02-12 01:10:38,654 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.825,  Train_accy 98.95
2025-02-12 01:10:45,514 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.823,  Train_accy 98.56
2025-02-12 01:10:52,950 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.824,  Train_accy 98.84
2025-02-12 01:11:00,187 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.824,  Train_accy 98.75
2025-02-12 01:11:11,456 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.825,  Train_accy 98.99, Test_accy 64.67
2025-02-12 01:11:18,428 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.827,  Train_accy 98.77
2025-02-12 01:11:25,720 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.818,  Train_accy 98.84
2025-02-12 01:11:32,749 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.828,  Train_accy 98.73
2025-02-12 01:11:40,028 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.821,  Train_accy 99.05
2025-02-12 01:11:51,279 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.821,  Train_accy 98.75, Test_accy 64.82
2025-02-12 01:11:58,356 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.822,  Train_accy 99.03
2025-02-12 01:12:05,666 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.823,  Train_accy 98.92
2025-02-12 01:12:12,961 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.821,  Train_accy 98.82
2025-02-12 01:12:20,157 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.822,  Train_accy 99.05
2025-02-12 01:12:31,406 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.818,  Train_accy 98.86, Test_accy 64.89
2025-02-12 01:12:38,869 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.819,  Train_accy 99.08
2025-02-12 01:12:46,169 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.820,  Train_accy 99.05
2025-02-12 01:12:53,544 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.820,  Train_accy 98.75
2025-02-12 01:13:00,496 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.821,  Train_accy 98.92
2025-02-12 01:13:11,906 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.822,  Train_accy 99.08, Test_accy 65.31
2025-02-12 01:13:19,166 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.819,  Train_accy 98.86
2025-02-12 01:13:26,353 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.818,  Train_accy 98.92
2025-02-12 01:13:33,502 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.816,  Train_accy 98.86
2025-02-12 01:13:40,346 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.819,  Train_accy 98.67
2025-02-12 01:13:51,887 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.820,  Train_accy 98.97, Test_accy 64.98
2025-02-12 01:13:59,013 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.823,  Train_accy 98.88
2025-02-12 01:14:05,993 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.818,  Train_accy 98.95
2025-02-12 01:14:12,491 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.818,  Train_accy 98.75
2025-02-12 01:14:19,547 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.828,  Train_accy 98.69
2025-02-12 01:14:19,547 [der.py] => do not weight align student!
2025-02-12 01:14:23,046 [der.py] => darknet eval: 
2025-02-12 01:14:23,046 [der.py] => CNN top1 curve: 64.8
2025-02-12 01:14:23,046 [der.py] => CNN top5 curve: 90.29
2025-02-12 01:14:23,050 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 01:15:06,172 [der.py] => Exemplar size: 750
2025-02-12 01:15:06,172 [trainer.py] => CNN: {'total': 79.33, '0': 87.22, '1': 71.11, '2': 81.11, '3': 70.56, '4': 82.78, '5': 61.11, '6': 50.0, '7': 59.44, '8': 56.11, '9': 63.33, '10': 95.0, '11': 98.89, '12': 71.11, '13': 72.22, '14': 77.22, '15': 83.33, '16': 91.11, '17': 92.22, '18': 91.67, '19': 88.89, '20': 95.0, '21': 85.0, '22': 88.89, '23': 84.44, 'old': 73.15, 'new': 88.61}
2025-02-12 01:15:06,172 [trainer.py] => NME: {'total': 76.78, '0': 82.22, '1': 61.67, '2': 75.56, '3': 60.0, '4': 76.11, '5': 56.11, '6': 51.11, '7': 47.78, '8': 32.22, '9': 66.67, '10': 90.0, '11': 98.89, '12': 75.56, '13': 73.89, '14': 78.89, '15': 80.0, '16': 92.22, '17': 91.11, '18': 91.11, '19': 86.11, '20': 92.22, '21': 91.11, '22': 95.0, '23': 87.22, 'old': 68.44, 'new': 89.28}
2025-02-12 01:15:06,172 [trainer.py] => CNN top1 curve: [79.11, 79.33]
2025-02-12 01:15:06,172 [trainer.py] => CNN top5 curve: [98.52, 97.96]
2025-02-12 01:15:06,172 [trainer.py] => NME top1 curve: [78.7, 76.78]
2025-02-12 01:15:06,172 [trainer.py] => NME top5 curve: [98.52, 97.73]

2025-02-12 01:15:06,173 [trainer.py] => All params: 14992164
2025-02-12 01:15:06,174 [trainer.py] => Trainable params: 7511716
2025-02-12 01:15:06,278 [der.py] => Learning on 25-35
2025-02-12 01:15:06,279 [der.py] => All params: 15002414
2025-02-12 01:15:06,279 [der.py] => Trainable params: 7521966
2025-02-12 01:15:06,535 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 01:15:06,536 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-12 01:39:47,269 [der.py] => Task 2, Epoch 150/150 => Loss 0.025, Loss_clf 0.006, Loss_aux 0.018, Train_accy 99.86
2025-02-12 01:40:00,725 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 3.465,  Train_accy 3.27, Test_accy 3.62
2025-02-12 01:40:11,193 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 3.213,  Train_accy 3.49
2025-02-12 01:40:18,915 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 3.033,  Train_accy 5.37
2025-02-12 01:40:29,025 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 2.976,  Train_accy 6.79
2025-02-12 01:40:36,741 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 2.893,  Train_accy 9.35
2025-02-12 01:40:52,926 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 2.820,  Train_accy 10.87, Test_accy 12.71
2025-02-12 01:41:00,331 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 2.776,  Train_accy 13.41
2025-02-12 01:41:07,759 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 2.710,  Train_accy 15.23
2025-02-12 01:41:15,363 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 2.668,  Train_accy 16.40
2025-02-12 01:41:23,072 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 2.616,  Train_accy 17.98
2025-02-12 01:41:35,921 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 2.600,  Train_accy 18.71, Test_accy 18.32
2025-02-12 01:41:43,990 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 2.554,  Train_accy 20.22
2025-02-12 01:41:51,596 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 2.497,  Train_accy 22.71
2025-02-12 01:41:59,049 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 2.478,  Train_accy 22.83
2025-02-12 01:42:11,909 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 2.449,  Train_accy 24.20
2025-02-12 01:42:24,813 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 2.442,  Train_accy 25.01, Test_accy 21.73
2025-02-12 01:42:32,436 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 2.407,  Train_accy 26.06
2025-02-12 01:42:40,073 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 2.377,  Train_accy 26.93
2025-02-12 01:42:47,183 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 2.364,  Train_accy 27.41
2025-02-12 01:42:55,640 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 2.323,  Train_accy 30.61
2025-02-12 01:43:08,551 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 2.280,  Train_accy 30.79, Test_accy 28.41
2025-02-12 01:43:16,288 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 2.270,  Train_accy 32.59
2025-02-12 01:43:23,417 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 2.250,  Train_accy 32.93
2025-02-12 01:43:31,443 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 2.247,  Train_accy 33.27
2025-02-12 01:43:42,622 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 2.207,  Train_accy 34.32
2025-02-12 01:43:55,434 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 2.215,  Train_accy 35.17, Test_accy 31.59
2025-02-12 01:44:05,981 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 2.200,  Train_accy 36.02
2025-02-12 01:44:13,429 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 2.158,  Train_accy 38.30
2025-02-12 01:44:20,845 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 2.148,  Train_accy 38.08
2025-02-12 01:44:29,383 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 2.141,  Train_accy 38.20
2025-02-12 01:44:41,956 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 2.121,  Train_accy 38.57, Test_accy 34.46
2025-02-12 01:44:58,603 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 2.103,  Train_accy 40.20
2025-02-12 01:45:05,995 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 2.090,  Train_accy 40.30
2025-02-12 01:45:13,545 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 2.068,  Train_accy 41.78
2025-02-12 01:45:21,651 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 2.071,  Train_accy 41.80
2025-02-12 01:45:34,454 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 2.076,  Train_accy 40.48, Test_accy 36.46
2025-02-12 01:45:42,623 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 2.034,  Train_accy 42.77
2025-02-12 01:45:50,334 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 2.031,  Train_accy 42.97
2025-02-12 01:45:58,241 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 2.012,  Train_accy 42.99
2025-02-12 01:46:06,038 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 2.018,  Train_accy 43.01
2025-02-12 01:46:19,768 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 2.006,  Train_accy 44.12, Test_accy 38.37
2025-02-12 01:46:26,882 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.990,  Train_accy 45.29
2025-02-12 01:46:34,548 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.987,  Train_accy 44.83
2025-02-12 01:46:42,145 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.972,  Train_accy 44.99
2025-02-12 01:46:49,817 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.949,  Train_accy 45.86
2025-02-12 01:47:06,508 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.946,  Train_accy 46.36, Test_accy 41.05
2025-02-12 01:47:14,382 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.941,  Train_accy 45.98
2025-02-12 01:47:24,985 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.940,  Train_accy 46.20
2025-02-12 01:47:33,918 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.933,  Train_accy 46.44
2025-02-12 01:47:41,390 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.930,  Train_accy 46.28
2025-02-12 01:47:57,095 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.911,  Train_accy 47.94, Test_accy 41.54
2025-02-12 01:48:04,527 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.905,  Train_accy 47.54
2025-02-12 01:48:11,892 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.900,  Train_accy 48.22
2025-02-12 01:48:21,332 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.894,  Train_accy 48.04
2025-02-12 01:48:28,803 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.891,  Train_accy 48.06
2025-02-12 01:48:45,761 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.888,  Train_accy 48.06, Test_accy 43.65
2025-02-12 01:48:53,089 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.874,  Train_accy 48.87
2025-02-12 01:49:00,703 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.875,  Train_accy 48.14
2025-02-12 01:49:12,889 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.871,  Train_accy 48.34
2025-02-12 01:49:20,217 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.866,  Train_accy 49.58
2025-02-12 01:49:32,850 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.868,  Train_accy 48.67, Test_accy 44.00
2025-02-12 01:49:40,427 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.857,  Train_accy 49.68
2025-02-12 01:49:52,894 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.852,  Train_accy 49.62
2025-02-12 01:50:00,408 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.843,  Train_accy 50.08
2025-02-12 01:50:07,343 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.840,  Train_accy 50.00
2025-02-12 01:50:20,257 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.837,  Train_accy 49.54, Test_accy 44.24
2025-02-12 01:50:27,803 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.841,  Train_accy 49.52
2025-02-12 01:50:39,826 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.829,  Train_accy 50.61
2025-02-12 01:50:47,472 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.830,  Train_accy 50.06
2025-02-12 01:50:55,058 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.821,  Train_accy 50.02
2025-02-12 01:51:11,287 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.822,  Train_accy 50.97, Test_accy 44.60
2025-02-12 01:51:18,398 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.817,  Train_accy 50.55
2025-02-12 01:51:26,104 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.816,  Train_accy 50.65
2025-02-12 01:51:33,659 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.818,  Train_accy 50.40
2025-02-12 01:51:41,181 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.817,  Train_accy 50.67
2025-02-12 01:51:58,131 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.814,  Train_accy 50.42, Test_accy 46.05
2025-02-12 01:52:05,636 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.811,  Train_accy 51.43
2025-02-12 01:52:13,211 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.802,  Train_accy 50.67
2025-02-12 01:52:26,818 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.802,  Train_accy 51.11
2025-02-12 01:52:34,036 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.804,  Train_accy 51.07
2025-02-12 01:52:56,971 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.801,  Train_accy 50.97, Test_accy 45.65
2025-02-12 01:53:04,604 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.805,  Train_accy 50.02
2025-02-12 01:53:11,364 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.801,  Train_accy 50.59
2025-02-12 01:53:19,888 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.793,  Train_accy 52.14
2025-02-12 01:53:27,467 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.793,  Train_accy 50.61
2025-02-12 01:53:40,554 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.792,  Train_accy 51.19, Test_accy 46.14
2025-02-12 01:53:47,804 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.793,  Train_accy 51.31
2025-02-12 01:53:55,329 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.791,  Train_accy 51.94
2025-02-12 01:54:02,948 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.790,  Train_accy 50.81
2025-02-12 01:54:10,355 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.790,  Train_accy 51.90
2025-02-12 01:54:24,629 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.789,  Train_accy 51.35, Test_accy 46.48
2025-02-12 01:54:32,136 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.786,  Train_accy 51.29
2025-02-12 01:54:39,753 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.787,  Train_accy 51.33
2025-02-12 01:54:52,018 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.789,  Train_accy 51.74
2025-02-12 01:54:59,121 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.787,  Train_accy 50.91
2025-02-12 01:55:18,668 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.783,  Train_accy 51.60, Test_accy 46.59
2025-02-12 01:55:26,119 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.783,  Train_accy 51.47
2025-02-12 01:55:35,996 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.781,  Train_accy 51.66
2025-02-12 01:55:43,241 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.778,  Train_accy 51.21
2025-02-12 01:55:50,825 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.779,  Train_accy 51.54
2025-02-12 01:56:03,720 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.780,  Train_accy 51.64, Test_accy 47.00
2025-02-12 01:56:10,822 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.779,  Train_accy 51.27
2025-02-12 01:56:18,393 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.779,  Train_accy 51.52
2025-02-12 01:56:25,822 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.777,  Train_accy 51.74
2025-02-12 01:56:38,888 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.777,  Train_accy 52.30
2025-02-12 01:56:51,886 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.776,  Train_accy 51.54, Test_accy 46.84
2025-02-12 01:56:59,568 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.775,  Train_accy 50.87
2025-02-12 01:57:07,417 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.776,  Train_accy 51.56
2025-02-12 01:57:14,845 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.769,  Train_accy 51.68
2025-02-12 01:57:26,338 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.776,  Train_accy 51.60
2025-02-12 01:57:40,800 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.769,  Train_accy 51.88, Test_accy 46.87
2025-02-12 01:57:48,511 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.773,  Train_accy 51.68
2025-02-12 01:57:56,041 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.769,  Train_accy 51.45
2025-02-12 01:58:03,695 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.772,  Train_accy 51.92
2025-02-12 01:58:11,324 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.770,  Train_accy 51.76
2025-02-12 01:58:26,431 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.772,  Train_accy 51.88, Test_accy 46.95
2025-02-12 01:58:33,977 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.769,  Train_accy 51.84
2025-02-12 01:58:41,469 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.771,  Train_accy 51.90
2025-02-12 01:58:48,940 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.771,  Train_accy 51.64
2025-02-12 01:59:06,199 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.768,  Train_accy 51.49
2025-02-12 01:59:25,146 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.771,  Train_accy 51.90, Test_accy 46.68
2025-02-12 01:59:32,564 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.772,  Train_accy 51.60
2025-02-12 01:59:40,173 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.768,  Train_accy 51.98
2025-02-12 01:59:47,368 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.772,  Train_accy 51.39
2025-02-12 02:00:07,293 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.773,  Train_accy 51.21
2025-02-12 02:00:19,714 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.770,  Train_accy 51.60, Test_accy 46.43
2025-02-12 02:00:27,853 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.768,  Train_accy 52.04
2025-02-12 02:00:35,610 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.768,  Train_accy 52.67
2025-02-12 02:00:43,050 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.771,  Train_accy 51.41
2025-02-12 02:00:50,200 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.769,  Train_accy 51.52
2025-02-12 02:00:50,201 [der.py] => do not weight align student!
2025-02-12 02:00:55,310 [der.py] => darknet eval: 
2025-02-12 02:00:55,311 [der.py] => CNN top1 curve: 47.0
2025-02-12 02:00:55,311 [der.py] => CNN top5 curve: 83.49
2025-02-12 02:00:55,313 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 02:02:16,117 [der.py] => Exemplar size: 1050
2025-02-12 02:02:16,117 [trainer.py] => CNN: {'total': 56.16, '0': 55.56, '1': 42.78, '2': 46.67, '3': 28.89, '4': 43.89, '5': 22.22, '6': 23.33, '7': 31.11, '8': 36.67, '9': 29.44, '10': 60.0, '11': 61.67, '12': 37.78, '13': 45.0, '14': 58.33, '15': 93.33, '16': 96.11, '17': 91.67, '18': 91.67, '19': 91.11, '20': 96.11, '21': 88.89, '22': 89.44, '23': 92.78, '24': 90.0, '25': 38.33, '26': 28.89, '27': 30.56, '28': 37.78, '29': 49.44, '30': 37.78, '31': 52.78, '32': 42.22, '33': 57.22, 'old': 61.78, 'new': 42.11}
2025-02-12 02:02:16,117 [trainer.py] => NME: {'total': 62.6, '0': 67.22, '1': 33.89, '2': 43.33, '3': 22.78, '4': 33.89, '5': 20.56, '6': 17.22, '7': 30.0, '8': 39.44, '9': 29.44, '10': 54.44, '11': 60.0, '12': 30.56, '13': 45.56, '14': 37.78, '15': 90.0, '16': 97.22, '17': 87.22, '18': 85.56, '19': 84.44, '20': 90.56, '21': 85.56, '22': 90.56, '23': 77.22, '24': 54.44, '25': 75.0, '26': 78.33, '27': 89.44, '28': 69.44, '29': 75.0, '30': 80.0, '31': 78.33, '32': 98.33, '33': 65.56, 'old': 56.36, 'new': 78.22}
2025-02-12 02:02:16,117 [trainer.py] => CNN top1 curve: [79.11, 79.33, 56.16]
2025-02-12 02:02:16,117 [trainer.py] => CNN top5 curve: [98.52, 97.96, 86.54]
2025-02-12 02:02:16,117 [trainer.py] => NME top1 curve: [78.7, 76.78, 62.6]
2025-02-12 02:02:16,117 [trainer.py] => NME top5 curve: [98.52, 97.73, 86.56]

2025-02-12 02:02:16,118 [trainer.py] => All params: 15002414
2025-02-12 02:02:16,119 [trainer.py] => Trainable params: 7521966
2025-02-12 02:02:16,230 [der.py] => Learning on 35-45
2025-02-12 02:02:16,231 [der.py] => All params: 15012664
2025-02-12 02:02:16,231 [der.py] => Trainable params: 7532216
2025-02-12 02:02:16,522 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 02:02:16,523 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-12 02:28:15,962 [der.py] => Task 3, Epoch 150/150 => Loss 0.332, Loss_clf 0.109, Loss_aux 0.223, Train_accy 99.81
2025-02-12 02:28:31,029 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 3.728,  Train_accy 1.43, Test_accy 2.28
2025-02-12 02:28:42,405 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 3.569,  Train_accy 1.83
2025-02-12 02:28:50,684 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 3.307,  Train_accy 2.42
2025-02-12 02:28:59,010 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 3.167,  Train_accy 3.62
2025-02-12 02:29:07,154 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 3.073,  Train_accy 3.94
2025-02-12 02:29:27,017 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 3.118,  Train_accy 3.92, Test_accy 6.11
2025-02-12 02:29:40,027 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 3.076,  Train_accy 3.41
2025-02-12 02:29:48,230 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 3.065,  Train_accy 4.17
2025-02-12 02:29:56,428 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 3.164,  Train_accy 4.19
2025-02-12 02:30:04,708 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 3.018,  Train_accy 3.90
2025-02-12 02:30:19,689 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.901,  Train_accy 4.59, Test_accy 7.60
2025-02-12 02:30:30,548 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.792,  Train_accy 6.06
2025-02-12 02:30:38,897 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.738,  Train_accy 6.95
2025-02-12 02:30:51,539 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.710,  Train_accy 7.41
2025-02-12 02:30:59,624 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.700,  Train_accy 6.84
2025-02-12 02:31:18,835 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.633,  Train_accy 9.10, Test_accy 10.80
2025-02-12 02:31:26,783 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.593,  Train_accy 9.12
2025-02-12 02:31:34,737 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.557,  Train_accy 9.68
2025-02-12 02:31:47,085 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.557,  Train_accy 9.68
2025-02-12 02:31:55,130 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.518,  Train_accy 10.42
2025-02-12 02:32:12,576 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.437,  Train_accy 11.41, Test_accy 12.91
2025-02-12 02:32:20,178 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.435,  Train_accy 11.26
2025-02-12 02:32:28,097 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.394,  Train_accy 12.08
2025-02-12 02:32:36,723 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.381,  Train_accy 12.19
2025-02-12 02:32:44,523 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 2.334,  Train_accy 14.06
2025-02-12 02:32:58,944 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 2.544,  Train_accy 10.19, Test_accy 14.94
2025-02-12 02:33:06,768 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 2.388,  Train_accy 12.63
2025-02-12 02:33:14,734 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 2.464,  Train_accy 11.70
2025-02-12 02:33:29,843 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 2.323,  Train_accy 13.66
2025-02-12 02:33:37,685 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 2.265,  Train_accy 13.83
2025-02-12 02:33:52,838 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 2.239,  Train_accy 15.01, Test_accy 17.00
2025-02-12 02:34:00,841 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 2.173,  Train_accy 16.59
2025-02-12 02:34:08,415 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 2.189,  Train_accy 16.04
2025-02-12 02:34:16,443 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 2.183,  Train_accy 16.63
2025-02-12 02:34:24,556 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 2.158,  Train_accy 16.69
2025-02-12 02:34:38,740 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 2.180,  Train_accy 17.03, Test_accy 19.16
2025-02-12 02:34:46,121 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 2.119,  Train_accy 17.70
2025-02-12 02:35:01,068 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 2.079,  Train_accy 18.57
2025-02-12 02:35:08,945 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 2.047,  Train_accy 19.66
2025-02-12 02:35:21,019 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 2.007,  Train_accy 21.05
2025-02-12 02:35:35,903 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 2.025,  Train_accy 20.57, Test_accy 21.38
2025-02-12 02:35:43,820 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 2.022,  Train_accy 20.51
2025-02-12 02:35:55,710 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.951,  Train_accy 21.60
2025-02-12 02:36:04,110 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.942,  Train_accy 22.44
2025-02-12 02:36:12,238 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.940,  Train_accy 22.74
2025-02-12 02:36:30,093 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.922,  Train_accy 23.03, Test_accy 24.99
2025-02-12 02:36:38,032 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.921,  Train_accy 24.38
2025-02-12 02:36:49,743 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.892,  Train_accy 23.41
2025-02-12 02:36:57,803 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.847,  Train_accy 25.01
2025-02-12 02:37:05,465 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.858,  Train_accy 23.87
2025-02-12 02:37:19,930 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.804,  Train_accy 26.17, Test_accy 25.59
2025-02-12 02:37:27,932 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.802,  Train_accy 26.17
2025-02-12 02:37:38,403 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.899,  Train_accy 24.40
2025-02-12 02:37:46,195 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.837,  Train_accy 25.49
2025-02-12 02:37:54,098 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.759,  Train_accy 27.22
2025-02-12 02:38:20,445 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.750,  Train_accy 27.70, Test_accy 28.54
2025-02-12 02:38:28,645 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.767,  Train_accy 27.54
2025-02-12 02:38:36,763 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.834,  Train_accy 26.06
2025-02-12 02:38:44,979 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.865,  Train_accy 24.11
2025-02-12 02:38:56,254 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.753,  Train_accy 28.13
2025-02-12 02:39:11,410 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.698,  Train_accy 27.92, Test_accy 29.33
2025-02-12 02:39:19,624 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.747,  Train_accy 28.11
2025-02-12 02:39:27,388 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.688,  Train_accy 29.07
2025-02-12 02:39:35,622 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.694,  Train_accy 28.97
2025-02-12 02:39:43,815 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.648,  Train_accy 29.81
2025-02-12 02:39:57,881 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.641,  Train_accy 29.66, Test_accy 30.25
2025-02-12 02:40:07,257 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.715,  Train_accy 28.40
2025-02-12 02:40:15,363 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.684,  Train_accy 29.35
2025-02-12 02:40:23,114 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.643,  Train_accy 29.98
2025-02-12 02:40:31,388 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.625,  Train_accy 30.11
2025-02-12 02:40:45,488 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.616,  Train_accy 30.15, Test_accy 27.93
2025-02-12 02:40:53,481 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.589,  Train_accy 30.51
2025-02-12 02:41:04,634 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.588,  Train_accy 31.35
2025-02-12 02:41:12,441 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.593,  Train_accy 30.70
2025-02-12 02:41:20,672 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.577,  Train_accy 30.84
2025-02-12 02:41:40,582 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.551,  Train_accy 31.03, Test_accy 34.52
2025-02-12 02:41:48,574 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.551,  Train_accy 31.58
2025-02-12 02:42:00,912 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.546,  Train_accy 31.33
2025-02-12 02:42:09,214 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.530,  Train_accy 31.71
2025-02-12 02:42:17,455 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.533,  Train_accy 32.15
2025-02-12 02:42:31,608 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.537,  Train_accy 31.20, Test_accy 31.38
2025-02-12 02:42:39,760 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.550,  Train_accy 31.56
2025-02-12 02:42:48,067 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.548,  Train_accy 32.38
2025-02-12 02:42:56,289 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.513,  Train_accy 31.56
2025-02-12 02:43:04,415 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.474,  Train_accy 31.87
2025-02-12 02:43:19,193 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.514,  Train_accy 31.96, Test_accy 31.64
2025-02-12 02:43:27,146 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.484,  Train_accy 32.38
2025-02-12 02:43:35,320 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.481,  Train_accy 32.57
2025-02-12 02:43:43,470 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.484,  Train_accy 32.04
2025-02-12 02:43:51,699 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.479,  Train_accy 32.13
2025-02-12 02:44:05,939 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.470,  Train_accy 31.89, Test_accy 32.12
2025-02-12 02:44:14,842 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.465,  Train_accy 32.46
2025-02-12 02:44:22,717 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.460,  Train_accy 32.00
2025-02-12 02:44:30,555 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.451,  Train_accy 32.86
2025-02-12 02:44:38,615 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.464,  Train_accy 32.17
2025-02-12 02:44:52,752 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.459,  Train_accy 32.11, Test_accy 31.57
2025-02-12 02:45:04,585 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.455,  Train_accy 32.55
2025-02-12 02:45:12,062 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.458,  Train_accy 32.27
2025-02-12 02:45:19,522 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.438,  Train_accy 32.13
2025-02-12 02:45:31,527 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.438,  Train_accy 32.08
2025-02-12 02:45:46,208 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.423,  Train_accy 33.09, Test_accy 33.80
2025-02-12 02:45:57,646 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.434,  Train_accy 32.27
2025-02-12 02:46:05,616 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.430,  Train_accy 32.19
2025-02-12 02:46:13,802 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.414,  Train_accy 32.69
2025-02-12 02:46:22,202 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.427,  Train_accy 32.48
2025-02-12 02:46:36,744 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.431,  Train_accy 32.93, Test_accy 34.40
2025-02-12 02:46:44,766 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.426,  Train_accy 33.03
2025-02-12 02:46:53,475 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.421,  Train_accy 32.65
2025-02-12 02:47:01,402 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.405,  Train_accy 33.33
2025-02-12 02:47:09,303 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.428,  Train_accy 32.84
2025-02-12 02:47:24,025 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.401,  Train_accy 32.44, Test_accy 35.25
2025-02-12 02:47:35,058 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.411,  Train_accy 32.50
2025-02-12 02:47:45,725 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.397,  Train_accy 32.82
2025-02-12 02:47:53,590 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.404,  Train_accy 33.10
2025-02-12 02:48:01,811 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.419,  Train_accy 32.69
2025-02-12 02:48:20,337 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.413,  Train_accy 32.25, Test_accy 35.30
2025-02-12 02:48:28,459 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.403,  Train_accy 33.14
2025-02-12 02:48:36,454 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.402,  Train_accy 32.34
2025-02-12 02:48:44,604 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.396,  Train_accy 32.74
2025-02-12 02:48:52,571 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.417,  Train_accy 32.63
2025-02-12 02:49:07,351 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.431,  Train_accy 33.12, Test_accy 34.73
2025-02-12 02:49:15,259 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.420,  Train_accy 33.07
2025-02-12 02:49:23,032 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.410,  Train_accy 32.76
2025-02-12 02:49:31,315 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.403,  Train_accy 33.35
2025-02-12 02:49:39,264 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.402,  Train_accy 32.53
2025-02-12 02:49:57,011 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.407,  Train_accy 33.16, Test_accy 35.94
2025-02-12 02:50:10,041 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.409,  Train_accy 33.16
2025-02-12 02:50:18,200 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.393,  Train_accy 32.86
2025-02-12 02:50:25,879 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.382,  Train_accy 32.38
2025-02-12 02:50:33,086 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.425,  Train_accy 32.30
2025-02-12 02:50:33,087 [der.py] => do not weight align student!
2025-02-12 02:50:41,999 [der.py] => darknet eval: 
2025-02-12 02:50:41,999 [der.py] => CNN top1 curve: 35.33
2025-02-12 02:50:41,999 [der.py] => CNN top5 curve: 70.95
2025-02-12 02:50:42,001 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 02:51:41,339 [der.py] => Exemplar size: 1350
2025-02-12 02:51:41,339 [trainer.py] => CNN: {'total': 44.98, '0': 21.11, '1': 35.0, '2': 45.56, '3': 28.33, '4': 37.22, '5': 17.22, '6': 29.44, '7': 38.33, '8': 38.89, '9': 27.22, '10': 58.33, '11': 67.22, '12': 35.0, '13': 47.78, '14': 37.78, '15': 45.56, '16': 51.67, '17': 45.56, '18': 51.11, '19': 52.22, '20': 63.89, '21': 53.33, '22': 58.89, '23': 47.78, '24': 40.56, '25': 78.33, '26': 76.11, '27': 78.33, '28': 61.67, '29': 69.44, '30': 76.11, '31': 78.89, '32': 85.0, '33': 72.78, '34': 55.56, '35': 45.56, '36': 53.33, '37': 4.44, '38': 5.0, '39': 16.67, '40': 7.78, '41': 20.0, '42': 20.56, '43': 39.44, 'old': 51.63, 'new': 21.67}
2025-02-12 02:51:41,339 [trainer.py] => NME: {'total': 49.57, '0': 45.56, '1': 35.56, '2': 42.22, '3': 21.67, '4': 32.78, '5': 20.56, '6': 29.44, '7': 32.22, '8': 42.78, '9': 23.89, '10': 62.22, '11': 60.0, '12': 26.67, '13': 47.22, '14': 38.33, '15': 41.67, '16': 53.89, '17': 46.11, '18': 48.33, '19': 47.78, '20': 46.11, '21': 38.33, '22': 54.44, '23': 51.67, '24': 51.11, '25': 63.89, '26': 62.22, '27': 65.0, '28': 48.33, '29': 66.11, '30': 59.44, '31': 68.89, '32': 71.67, '33': 50.0, '34': 52.22, '35': 80.56, '36': 81.11, '37': 45.0, '38': 69.44, '39': 56.67, '40': 46.11, '41': 52.22, '42': 58.89, '43': 62.22, 'old': 47.1, 'new': 58.22}
2025-02-12 02:51:41,340 [trainer.py] => CNN top1 curve: [79.11, 79.33, 56.16, 44.98]
2025-02-12 02:51:41,340 [trainer.py] => CNN top5 curve: [98.52, 97.96, 86.54, 79.7]
2025-02-12 02:51:41,340 [trainer.py] => NME top1 curve: [78.7, 76.78, 62.6, 49.57]
2025-02-12 02:51:41,340 [trainer.py] => NME top5 curve: [98.52, 97.73, 86.56, 79.85]

2025-02-12 02:51:41,341 [trainer.py] => All params: 15012664
2025-02-12 02:51:41,341 [trainer.py] => Trainable params: 7532216
2025-02-12 02:51:41,446 [der.py] => Learning on 45-55
2025-02-12 02:51:41,447 [der.py] => All params: 15022914
2025-02-12 02:51:41,448 [der.py] => Trainable params: 7542466
2025-02-12 02:51:41,822 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 02:51:41,823 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-12 03:19:27,320 [der.py] => Task 4, Epoch 150/150 => Loss 0.023, Loss_clf 0.009, Loss_aux 0.015, Train_accy 99.89
2025-02-12 03:19:43,180 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.938,  Train_accy 1.19, Test_accy 3.24
2025-02-12 03:19:50,731 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 3.724,  Train_accy 1.73
2025-02-12 03:19:59,291 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 3.597,  Train_accy 2.34
2025-02-12 03:20:06,911 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 3.518,  Train_accy 3.06
2025-02-12 03:20:14,943 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 3.462,  Train_accy 3.68
2025-02-12 03:20:29,774 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 3.411,  Train_accy 4.59, Test_accy 8.23
2025-02-12 03:20:37,413 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 3.350,  Train_accy 4.79
2025-02-12 03:20:45,026 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 3.309,  Train_accy 6.27
2025-02-12 03:20:53,986 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 3.281,  Train_accy 7.08
2025-02-12 03:21:01,598 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 3.233,  Train_accy 7.75
2025-02-12 03:21:16,349 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 3.197,  Train_accy 8.77, Test_accy 11.64
2025-02-12 03:21:24,279 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 3.150,  Train_accy 10.76
2025-02-12 03:21:31,803 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 3.132,  Train_accy 11.46
2025-02-12 03:21:39,085 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 3.095,  Train_accy 12.09
2025-02-12 03:21:46,697 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 3.039,  Train_accy 13.66
2025-02-12 03:22:06,178 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 3.023,  Train_accy 15.30, Test_accy 16.99
2025-02-12 03:22:13,875 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 3.013,  Train_accy 15.28
2025-02-12 03:22:21,723 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.974,  Train_accy 16.79
2025-02-12 03:22:29,532 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.939,  Train_accy 18.00
2025-02-12 03:22:37,174 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.931,  Train_accy 18.22
2025-02-12 03:22:51,883 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.887,  Train_accy 20.22, Test_accy 20.44
2025-02-12 03:22:59,575 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.864,  Train_accy 21.23
2025-02-12 03:23:07,226 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.855,  Train_accy 21.57
2025-02-12 03:23:15,030 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.819,  Train_accy 23.35
2025-02-12 03:23:22,731 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.807,  Train_accy 23.48
2025-02-12 03:23:37,297 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.769,  Train_accy 25.84, Test_accy 24.30
2025-02-12 03:23:44,904 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.733,  Train_accy 26.27
2025-02-12 03:23:54,763 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.747,  Train_accy 26.40
2025-02-12 03:24:03,450 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.710,  Train_accy 27.91
2025-02-12 03:24:10,617 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.710,  Train_accy 27.91
2025-02-12 03:24:25,339 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.677,  Train_accy 29.46, Test_accy 27.48
2025-02-12 03:24:32,982 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.668,  Train_accy 30.29
2025-02-12 03:24:40,584 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.650,  Train_accy 31.50
2025-02-12 03:24:48,102 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.626,  Train_accy 31.78
2025-02-12 03:24:55,620 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.629,  Train_accy 32.02
2025-02-12 03:25:10,811 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.604,  Train_accy 33.82, Test_accy 31.87
2025-02-12 03:25:18,413 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.590,  Train_accy 33.89
2025-02-12 03:25:26,011 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.562,  Train_accy 36.16
2025-02-12 03:25:35,359 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.539,  Train_accy 36.77
2025-02-12 03:25:43,159 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.542,  Train_accy 37.24
2025-02-12 03:26:00,229 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.525,  Train_accy 37.57, Test_accy 32.52
2025-02-12 03:26:07,756 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.508,  Train_accy 37.95
2025-02-12 03:26:15,309 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.494,  Train_accy 39.42
2025-02-12 03:26:22,880 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.479,  Train_accy 40.54
2025-02-12 03:26:30,315 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.465,  Train_accy 40.41
2025-02-12 03:26:44,828 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.459,  Train_accy 41.26, Test_accy 36.29
2025-02-12 03:26:52,496 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.439,  Train_accy 41.46
2025-02-12 03:26:59,985 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.440,  Train_accy 41.77
2025-02-12 03:27:07,820 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.464,  Train_accy 41.32
2025-02-12 03:27:15,478 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.437,  Train_accy 42.36
2025-02-12 03:27:31,072 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.413,  Train_accy 42.76, Test_accy 37.52
2025-02-12 03:27:38,535 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.408,  Train_accy 43.59
2025-02-12 03:27:45,831 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.408,  Train_accy 44.05
2025-02-12 03:27:53,302 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.408,  Train_accy 44.16
2025-02-12 03:28:00,758 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.395,  Train_accy 43.53
2025-02-12 03:28:15,195 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.378,  Train_accy 45.19, Test_accy 39.04
2025-02-12 03:28:22,939 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.373,  Train_accy 45.53
2025-02-12 03:28:30,556 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.358,  Train_accy 45.59
2025-02-12 03:28:38,212 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.355,  Train_accy 46.27
2025-02-12 03:28:45,663 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.350,  Train_accy 47.08
2025-02-12 03:29:00,501 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.356,  Train_accy 45.51, Test_accy 40.08
2025-02-12 03:29:07,833 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.350,  Train_accy 46.90
2025-02-12 03:29:15,197 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.343,  Train_accy 46.34
2025-02-12 03:29:25,167 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.335,  Train_accy 47.06
2025-02-12 03:29:32,722 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.329,  Train_accy 47.19
2025-02-12 03:29:47,163 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.327,  Train_accy 48.07, Test_accy 40.80
2025-02-12 03:29:54,627 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.322,  Train_accy 47.41
2025-02-12 03:30:02,766 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.315,  Train_accy 47.26
2025-02-12 03:30:10,142 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.324,  Train_accy 47.73
2025-02-12 03:30:17,536 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.314,  Train_accy 47.93
2025-02-12 03:30:32,397 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.313,  Train_accy 48.31, Test_accy 42.17
2025-02-12 03:30:39,918 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.316,  Train_accy 48.36
2025-02-12 03:30:47,551 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.310,  Train_accy 48.20
2025-02-12 03:30:55,122 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.304,  Train_accy 48.59
2025-02-12 03:31:02,668 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.301,  Train_accy 48.43
2025-02-12 03:31:17,220 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.302,  Train_accy 48.38, Test_accy 41.91
2025-02-12 03:31:24,614 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.301,  Train_accy 48.52
2025-02-12 03:31:32,045 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.299,  Train_accy 48.45
2025-02-12 03:31:39,469 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.288,  Train_accy 49.32
2025-02-12 03:31:46,929 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.289,  Train_accy 49.14
2025-02-12 03:32:01,033 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.292,  Train_accy 49.84, Test_accy 42.29
2025-02-12 03:32:08,403 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.287,  Train_accy 49.66
2025-02-12 03:32:15,935 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.279,  Train_accy 48.74
2025-02-12 03:32:23,465 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.280,  Train_accy 49.51
2025-02-12 03:32:31,218 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.281,  Train_accy 48.92
2025-02-12 03:32:45,687 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.277,  Train_accy 49.23, Test_accy 43.02
2025-02-12 03:32:53,067 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.281,  Train_accy 50.09
2025-02-12 03:33:00,403 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.280,  Train_accy 49.24
2025-02-12 03:33:07,830 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.275,  Train_accy 49.86
2025-02-12 03:33:15,296 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.269,  Train_accy 49.78
2025-02-12 03:33:29,972 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.274,  Train_accy 49.60, Test_accy 42.92
2025-02-12 03:33:38,581 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.265,  Train_accy 49.69
2025-02-12 03:33:46,071 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.270,  Train_accy 49.93
2025-02-12 03:33:53,482 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.266,  Train_accy 49.82
2025-02-12 03:34:00,891 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.271,  Train_accy 50.02
2025-02-12 03:34:15,652 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.266,  Train_accy 50.29, Test_accy 43.01
2025-02-12 03:34:23,144 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.261,  Train_accy 50.52
2025-02-12 03:34:30,356 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.264,  Train_accy 49.82
2025-02-12 03:34:37,434 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.265,  Train_accy 50.47
2025-02-12 03:34:44,924 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.260,  Train_accy 50.86
2025-02-12 03:34:59,709 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.266,  Train_accy 49.89, Test_accy 43.41
2025-02-12 03:35:07,107 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.260,  Train_accy 50.92
2025-02-12 03:35:14,411 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.258,  Train_accy 50.14
2025-02-12 03:35:21,817 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.256,  Train_accy 50.20
2025-02-12 03:35:29,276 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.258,  Train_accy 50.56
2025-02-12 03:35:43,670 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.258,  Train_accy 50.85, Test_accy 43.18
2025-02-12 03:35:50,969 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.257,  Train_accy 50.94
2025-02-12 03:35:58,452 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.256,  Train_accy 50.36
2025-02-12 03:36:06,148 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.257,  Train_accy 50.63
2025-02-12 03:36:13,829 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.260,  Train_accy 50.13
2025-02-12 03:36:28,473 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.254,  Train_accy 51.41, Test_accy 43.21
2025-02-12 03:36:35,931 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.260,  Train_accy 49.64
2025-02-12 03:36:43,264 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.252,  Train_accy 50.47
2025-02-12 03:36:50,838 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.253,  Train_accy 50.81
2025-02-12 03:36:58,270 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.251,  Train_accy 50.16
2025-02-12 03:37:12,329 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.255,  Train_accy 50.97, Test_accy 42.79
2025-02-12 03:37:19,637 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.251,  Train_accy 50.76
2025-02-12 03:37:26,977 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.252,  Train_accy 50.23
2025-02-12 03:37:34,404 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.254,  Train_accy 50.29
2025-02-12 03:37:41,967 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.253,  Train_accy 49.96
2025-02-12 03:37:56,722 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.251,  Train_accy 50.54, Test_accy 43.16
2025-02-12 03:38:04,361 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.252,  Train_accy 50.65
2025-02-12 03:38:11,911 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.253,  Train_accy 50.79
2025-02-12 03:38:19,364 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.250,  Train_accy 50.50
2025-02-12 03:38:26,879 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.252,  Train_accy 51.08
2025-02-12 03:38:42,023 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.252,  Train_accy 50.61, Test_accy 43.31
2025-02-12 03:38:49,492 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.250,  Train_accy 51.19
2025-02-12 03:38:57,144 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.251,  Train_accy 50.86
2025-02-12 03:39:04,713 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.248,  Train_accy 50.92
2025-02-12 03:39:12,186 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.252,  Train_accy 50.88
2025-02-12 03:39:12,187 [der.py] => do not weight align student!
2025-02-12 03:39:18,209 [der.py] => darknet eval: 
2025-02-12 03:39:18,209 [der.py] => CNN top1 curve: 43.35
2025-02-12 03:39:18,210 [der.py] => CNN top5 curve: 74.4
2025-02-12 03:39:18,212 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 03:40:14,678 [der.py] => Exemplar size: 1650
2025-02-12 03:40:14,679 [trainer.py] => CNN: {'total': 43.62, '0': 32.22, '1': 35.0, '2': 37.22, '3': 22.78, '4': 27.22, '5': 22.22, '6': 23.89, '7': 31.67, '8': 41.67, '9': 19.44, '10': 55.56, '11': 49.44, '12': 36.11, '13': 36.11, '14': 31.67, '15': 45.0, '16': 38.33, '17': 40.0, '18': 28.89, '19': 40.0, '20': 47.78, '21': 40.0, '22': 43.89, '23': 41.11, '24': 38.33, '25': 41.67, '26': 54.44, '27': 44.44, '28': 36.11, '29': 37.78, '30': 40.0, '31': 39.44, '32': 62.78, '33': 40.0, '34': 28.89, '35': 86.11, '36': 88.89, '37': 40.0, '38': 77.22, '39': 77.78, '40': 58.33, '41': 88.33, '42': 81.11, '43': 78.89, '44': 52.22, '45': 25.0, '46': 37.22, '47': 27.22, '48': 36.67, '49': 38.33, '50': 30.0, '51': 28.89, '52': 42.78, '53': 37.78, 'old': 45.78, 'new': 33.89}
2025-02-12 03:40:14,679 [trainer.py] => NME: {'total': 42.12, '0': 41.11, '1': 26.67, '2': 35.0, '3': 21.67, '4': 21.67, '5': 15.56, '6': 27.78, '7': 33.33, '8': 33.33, '9': 17.22, '10': 52.22, '11': 48.33, '12': 31.67, '13': 37.78, '14': 23.33, '15': 37.22, '16': 43.33, '17': 35.0, '18': 36.67, '19': 40.56, '20': 35.56, '21': 34.44, '22': 52.22, '23': 40.0, '24': 38.89, '25': 42.78, '26': 49.44, '27': 34.44, '28': 31.11, '29': 33.33, '30': 40.0, '31': 36.11, '32': 56.67, '33': 34.44, '34': 25.56, '35': 48.33, '36': 65.56, '37': 12.78, '38': 65.0, '39': 43.33, '40': 27.22, '41': 61.11, '42': 66.11, '43': 59.44, '44': 19.44, '45': 73.33, '46': 61.67, '47': 70.56, '48': 56.11, '49': 56.67, '50': 51.11, '51': 62.22, '52': 59.44, '53': 54.44, 'old': 38.06, 'new': 60.39}
2025-02-12 03:40:14,679 [trainer.py] => CNN top1 curve: [79.11, 79.33, 56.16, 44.98, 43.62]
2025-02-12 03:40:14,679 [trainer.py] => CNN top5 curve: [98.52, 97.96, 86.54, 79.7, 74.96]
2025-02-12 03:40:14,679 [trainer.py] => NME top1 curve: [78.7, 76.78, 62.6, 49.57, 42.12]
2025-02-12 03:40:14,679 [trainer.py] => NME top5 curve: [98.52, 97.73, 86.56, 79.85, 75.42]

2025-02-12 13:42:28,693 [trainer.py] => 实验名称:resnet对比实验
2025-02-12 13:42:28,767 [trainer.py] => config: ./exps/der.json
2025-02-12 13:42:28,767 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-12 13:42:28,768 [trainer.py] => prefix: reproduce
2025-02-12 13:42:28,768 [trainer.py] => dataset: xrfdataset
2025-02-12 13:42:28,768 [trainer.py] => memory_size: 1650
2025-02-12 13:42:28,768 [trainer.py] => memory_per_class: 30
2025-02-12 13:42:28,768 [trainer.py] => fixed_memory: True
2025-02-12 13:42:28,768 [trainer.py] => shuffle: True
2025-02-12 13:42:28,768 [trainer.py] => init_cls: 15
2025-02-12 13:42:28,768 [trainer.py] => increment: 10
2025-02-12 13:42:28,768 [trainer.py] => model_name: der
2025-02-12 13:42:28,768 [trainer.py] => compression_epochs: 130
2025-02-12 13:42:28,768 [trainer.py] => compression_lr: 0.1
2025-02-12 13:42:28,768 [trainer.py] => is_student_wa: False
2025-02-12 13:42:28,769 [trainer.py] => wa_value: 1
2025-02-12 13:42:28,769 [trainer.py] => T: 2
2025-02-12 13:42:28,769 [trainer.py] => convnet_type: resnet34
2025-02-12 13:42:28,769 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-12 13:42:28,769 [trainer.py] => seed: 1993
2025-02-12 13:42:28,820 [data.py] => 加载完毕XRF原始数据集
2025-02-12 13:42:28,845 [data.py] => 加载完毕XRF原始数据集
2025-02-12 13:42:28,846 [trainer.py] => All params: 0
2025-02-12 13:42:28,846 [trainer.py] => Trainable params: 0
2025-02-12 13:42:28,979 [der.py] => Learning on 0-15
2025-02-12 13:42:28,979 [der.py] => All params: 7496351
2025-02-12 13:42:28,980 [der.py] => Trainable params: 7496351
2025-02-12 14:07:52,532 [der.py] => Task 0, Epoch 200/200 => Loss 0.032, Train_accy 99.70
2025-02-12 14:07:52,533 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 14:08:17,371 [der.py] => Exemplar size: 450
2025-02-12 14:08:17,371 [trainer.py] => CNN: {'total': 80.59, '0': 96.67, '1': 90.56, '2': 77.22, '3': 66.11, '4': 86.11, '5': 74.44, '6': 57.78, '7': 82.78, '8': 88.33, '9': 59.44, '10': 96.11, '11': 98.89, '12': 75.0, '13': 74.44, 'old': 0, 'new': 80.59}
2025-02-12 14:08:17,371 [trainer.py] => NME: {'total': 79.15, '0': 98.33, '1': 90.56, '2': 75.0, '3': 66.67, '4': 77.22, '5': 63.89, '6': 52.22, '7': 83.33, '8': 83.89, '9': 65.56, '10': 92.22, '11': 98.89, '12': 77.78, '13': 77.22, 'old': 0, 'new': 79.15}
2025-02-12 14:08:17,371 [trainer.py] => CNN top1 curve: [80.59]
2025-02-12 14:08:17,371 [trainer.py] => CNN top5 curve: [98.48]
2025-02-12 14:08:17,371 [trainer.py] => NME top1 curve: [79.15]
2025-02-12 14:08:17,371 [trainer.py] => NME top5 curve: [98.74]

2025-02-12 14:08:17,372 [trainer.py] => All params: 7496351
2025-02-12 14:08:17,372 [trainer.py] => Trainable params: 7496351
2025-02-12 14:08:17,470 [der.py] => Learning on 15-25
2025-02-12 14:08:17,471 [der.py] => All params: 14992164
2025-02-12 14:08:17,472 [der.py] => Trainable params: 7511716
2025-02-12 14:08:17,534 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 14:08:17,534 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-12 14:26:22,959 [der.py] => Task 1, Epoch 150/150 => Loss 0.004, Loss_clf 0.002, Loss_aux 0.002, Train_accy 100.00
2025-02-12 14:26:33,057 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 3.013,  Train_accy 13.61, Test_accy 5.64
2025-02-12 14:26:39,358 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 2.621,  Train_accy 24.80
2025-02-12 14:26:45,627 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 2.367,  Train_accy 32.15
2025-02-12 14:26:51,732 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 2.214,  Train_accy 39.27
2025-02-12 14:26:57,925 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 2.145,  Train_accy 43.01
2025-02-12 14:27:07,763 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 2.025,  Train_accy 48.54, Test_accy 19.58
2025-02-12 14:27:14,107 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.972,  Train_accy 50.65
2025-02-12 14:27:20,314 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.885,  Train_accy 55.42
2025-02-12 14:27:26,631 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.813,  Train_accy 59.12
2025-02-12 14:27:32,935 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.776,  Train_accy 60.13
2025-02-12 14:27:43,236 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.734,  Train_accy 62.88, Test_accy 25.27
2025-02-12 14:27:49,513 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.678,  Train_accy 64.04
2025-02-12 14:27:55,622 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.576,  Train_accy 68.43
2025-02-12 14:28:01,749 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.528,  Train_accy 70.90
2025-02-12 14:28:07,988 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.482,  Train_accy 72.54
2025-02-12 14:28:18,039 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.460,  Train_accy 73.98, Test_accy 36.53
2025-02-12 14:28:24,169 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.423,  Train_accy 75.63
2025-02-12 14:28:30,306 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.388,  Train_accy 77.48
2025-02-12 14:28:36,481 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.346,  Train_accy 80.06
2025-02-12 14:28:42,744 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.333,  Train_accy 79.51
2025-02-12 14:28:52,717 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.311,  Train_accy 80.41, Test_accy 43.64
2025-02-12 14:28:58,800 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.273,  Train_accy 83.12
2025-02-12 14:29:05,106 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.243,  Train_accy 83.68
2025-02-12 14:29:11,328 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.219,  Train_accy 85.03
2025-02-12 14:29:17,497 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.213,  Train_accy 85.81
2025-02-12 14:29:27,368 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.204,  Train_accy 85.74, Test_accy 49.91
2025-02-12 14:29:33,352 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.168,  Train_accy 86.77
2025-02-12 14:29:39,543 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.147,  Train_accy 88.71
2025-02-12 14:29:45,572 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.127,  Train_accy 89.55
2025-02-12 14:29:51,688 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.117,  Train_accy 89.38
2025-02-12 14:30:01,595 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.100,  Train_accy 90.77, Test_accy 50.69
2025-02-12 14:30:07,582 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.096,  Train_accy 90.90
2025-02-12 14:30:13,748 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.089,  Train_accy 91.57
2025-02-12 14:30:19,987 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.058,  Train_accy 92.22
2025-02-12 14:30:26,115 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.044,  Train_accy 93.14
2025-02-12 14:30:35,910 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.034,  Train_accy 93.55, Test_accy 58.73
2025-02-12 14:30:42,252 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.035,  Train_accy 94.00
2025-02-12 14:30:48,389 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.027,  Train_accy 94.02
2025-02-12 14:30:54,677 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.028,  Train_accy 94.22
2025-02-12 14:31:00,959 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.013,  Train_accy 94.34
2025-02-12 14:31:10,984 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.007,  Train_accy 94.58, Test_accy 58.84
2025-02-12 14:31:17,295 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.011,  Train_accy 94.22
2025-02-12 14:31:23,372 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.005,  Train_accy 94.75
2025-02-12 14:31:29,654 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.996,  Train_accy 95.23
2025-02-12 14:31:35,833 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.982,  Train_accy 95.74
2025-02-12 14:31:45,750 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.977,  Train_accy 96.11, Test_accy 59.98
2025-02-12 14:31:51,878 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.963,  Train_accy 95.63
2025-02-12 14:31:57,983 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.961,  Train_accy 96.43
2025-02-12 14:32:04,154 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.966,  Train_accy 96.43
2025-02-12 14:32:10,406 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.976,  Train_accy 95.98
2025-02-12 14:32:20,222 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.961,  Train_accy 96.04, Test_accy 60.56
2025-02-12 14:32:26,583 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.955,  Train_accy 96.47
2025-02-12 14:32:32,719 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.946,  Train_accy 96.52
2025-02-12 14:32:38,846 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.943,  Train_accy 96.86
2025-02-12 14:32:45,153 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.934,  Train_accy 97.25
2025-02-12 14:32:55,031 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.934,  Train_accy 97.18, Test_accy 62.89
2025-02-12 14:33:01,172 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.933,  Train_accy 97.31
2025-02-12 14:33:07,392 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.923,  Train_accy 97.38
2025-02-12 14:33:13,700 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.923,  Train_accy 97.29
2025-02-12 14:33:19,800 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.931,  Train_accy 97.18
2025-02-12 14:33:29,616 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.921,  Train_accy 96.95, Test_accy 63.71
2025-02-12 14:33:35,726 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.919,  Train_accy 97.59
2025-02-12 14:33:41,977 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.919,  Train_accy 97.12
2025-02-12 14:33:48,204 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.920,  Train_accy 97.16
2025-02-12 14:33:54,242 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.915,  Train_accy 97.76
2025-02-12 14:34:04,019 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.906,  Train_accy 97.59, Test_accy 64.60
2025-02-12 14:34:10,208 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.902,  Train_accy 97.70
2025-02-12 14:34:16,377 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.900,  Train_accy 97.57
2025-02-12 14:34:22,452 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.901,  Train_accy 97.85
2025-02-12 14:34:28,667 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.905,  Train_accy 97.48
2025-02-12 14:34:38,635 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.898,  Train_accy 97.55, Test_accy 64.89
2025-02-12 14:34:44,656 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.895,  Train_accy 97.61
2025-02-12 14:34:50,719 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.892,  Train_accy 97.66
2025-02-12 14:34:56,787 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.892,  Train_accy 97.72
2025-02-12 14:35:02,932 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.893,  Train_accy 97.72
2025-02-12 14:35:13,191 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.892,  Train_accy 97.78, Test_accy 65.29
2025-02-12 14:35:19,354 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.892,  Train_accy 97.89
2025-02-12 14:35:25,553 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.891,  Train_accy 98.06
2025-02-12 14:35:31,464 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.888,  Train_accy 97.87
2025-02-12 14:35:37,511 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.898,  Train_accy 97.57
2025-02-12 14:35:47,468 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.902,  Train_accy 97.46, Test_accy 64.69
2025-02-12 14:35:53,526 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.894,  Train_accy 97.74
2025-02-12 14:35:59,651 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.887,  Train_accy 98.06
2025-02-12 14:36:05,730 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.888,  Train_accy 97.68
2025-02-12 14:36:11,806 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.882,  Train_accy 98.00
2025-02-12 14:36:21,638 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.884,  Train_accy 97.76, Test_accy 65.64
2025-02-12 14:36:27,846 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.882,  Train_accy 97.76
2025-02-12 14:36:33,817 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.888,  Train_accy 97.74
2025-02-12 14:36:39,936 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.881,  Train_accy 97.87
2025-02-12 14:36:45,927 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.879,  Train_accy 98.00
2025-02-12 14:36:55,935 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.878,  Train_accy 97.94, Test_accy 65.29
2025-02-12 14:37:02,123 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.878,  Train_accy 98.11
2025-02-12 14:37:08,195 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.872,  Train_accy 97.76
2025-02-12 14:37:14,321 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.876,  Train_accy 97.87
2025-02-12 14:37:20,460 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.875,  Train_accy 97.94
2025-02-12 14:37:30,480 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.879,  Train_accy 97.61, Test_accy 65.31
2025-02-12 14:37:36,484 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.873,  Train_accy 98.06
2025-02-12 14:37:42,695 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.870,  Train_accy 97.98
2025-02-12 14:37:48,801 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.872,  Train_accy 97.81
2025-02-12 14:37:54,974 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.874,  Train_accy 98.04
2025-02-12 14:38:05,632 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.872,  Train_accy 97.89, Test_accy 66.07
2025-02-12 14:38:11,956 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.875,  Train_accy 98.11
2025-02-12 14:38:18,208 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.869,  Train_accy 98.02
2025-02-12 14:38:24,617 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.872,  Train_accy 97.81
2025-02-12 14:38:30,750 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.876,  Train_accy 97.74
2025-02-12 14:38:40,895 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.872,  Train_accy 97.91, Test_accy 66.22
2025-02-12 14:38:47,009 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.868,  Train_accy 97.78
2025-02-12 14:38:53,309 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.869,  Train_accy 98.00
2025-02-12 14:38:59,515 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.866,  Train_accy 97.87
2025-02-12 14:39:06,049 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.870,  Train_accy 98.22
2025-02-12 14:39:15,938 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.869,  Train_accy 97.85, Test_accy 65.84
2025-02-12 14:39:22,003 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.869,  Train_accy 97.94
2025-02-12 14:39:28,235 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.870,  Train_accy 97.85
2025-02-12 14:39:34,453 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.869,  Train_accy 98.00
2025-02-12 14:39:40,648 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.873,  Train_accy 97.91
2025-02-12 14:39:50,445 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.869,  Train_accy 97.94, Test_accy 65.71
2025-02-12 14:39:56,495 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.870,  Train_accy 97.78
2025-02-12 14:40:02,663 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.868,  Train_accy 97.91
2025-02-12 14:40:08,736 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.866,  Train_accy 97.78
2025-02-12 14:40:14,841 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.868,  Train_accy 98.06
2025-02-12 14:40:24,788 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.868,  Train_accy 97.85, Test_accy 65.87
2025-02-12 14:40:31,030 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.869,  Train_accy 97.89
2025-02-12 14:40:37,116 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.865,  Train_accy 97.83
2025-02-12 14:40:43,237 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.867,  Train_accy 98.19
2025-02-12 14:40:49,319 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.869,  Train_accy 97.98
2025-02-12 14:40:59,176 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.869,  Train_accy 97.87, Test_accy 66.11
2025-02-12 14:41:05,337 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.864,  Train_accy 98.04
2025-02-12 14:41:11,516 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.866,  Train_accy 97.89
2025-02-12 14:41:17,689 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.867,  Train_accy 97.96
2025-02-12 14:41:23,902 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.869,  Train_accy 97.91
2025-02-12 14:41:23,903 [der.py] => do not weight align student!
2025-02-12 14:41:27,101 [der.py] => darknet eval: 
2025-02-12 14:41:27,101 [der.py] => CNN top1 curve: 65.98
2025-02-12 14:41:27,101 [der.py] => CNN top5 curve: 90.11
2025-02-12 14:41:27,103 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 14:41:58,084 [der.py] => Exemplar size: 750
2025-02-12 14:41:58,084 [trainer.py] => CNN: {'total': 80.04, '0': 91.11, '1': 76.67, '2': 81.67, '3': 66.67, '4': 82.78, '5': 66.11, '6': 47.78, '7': 60.0, '8': 67.22, '9': 62.78, '10': 93.33, '11': 98.89, '12': 77.78, '13': 72.78, '14': 77.22, '15': 89.44, '16': 90.56, '17': 93.89, '18': 93.33, '19': 87.22, '20': 92.78, '21': 84.44, '22': 80.0, '23': 78.33, 'old': 74.85, 'new': 87.83}
2025-02-12 14:41:58,084 [trainer.py] => NME: {'total': 77.36, '0': 89.44, '1': 59.44, '2': 74.44, '3': 60.56, '4': 77.22, '5': 58.33, '6': 50.56, '7': 47.22, '8': 39.44, '9': 67.22, '10': 90.56, '11': 98.89, '12': 72.78, '13': 75.0, '14': 75.56, '15': 87.78, '16': 91.67, '17': 91.11, '18': 92.78, '19': 87.78, '20': 91.67, '21': 86.11, '22': 92.22, '23': 83.33, 'old': 69.11, 'new': 89.72}
2025-02-12 14:41:58,084 [trainer.py] => CNN top1 curve: [80.59, 80.04]
2025-02-12 14:41:58,084 [trainer.py] => CNN top5 curve: [98.48, 98.47]
2025-02-12 14:41:58,084 [trainer.py] => NME top1 curve: [79.15, 77.36]
2025-02-12 14:41:58,084 [trainer.py] => NME top5 curve: [98.74, 97.78]

2025-02-12 14:41:58,085 [trainer.py] => All params: 14992164
2025-02-12 14:41:58,086 [trainer.py] => Trainable params: 7511716
2025-02-12 14:41:58,185 [der.py] => Learning on 25-35
2025-02-12 14:41:58,186 [der.py] => All params: 15002414
2025-02-12 14:41:58,186 [der.py] => Trainable params: 7521966
2025-02-12 14:41:58,261 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 14:41:58,262 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-12 15:02:05,852 [der.py] => Task 2, Epoch 150/150 => Loss 0.007, Loss_clf 0.002, Loss_aux 0.005, Train_accy 100.00
2025-02-12 15:02:17,281 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 3.503,  Train_accy 5.29, Test_accy 2.92
2025-02-12 15:02:24,617 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 3.231,  Train_accy 7.39
2025-02-12 15:02:31,005 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 3.066,  Train_accy 10.12
2025-02-12 15:02:37,517 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 2.964,  Train_accy 11.01
2025-02-12 15:02:43,923 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 2.888,  Train_accy 14.24
2025-02-12 15:02:55,645 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 2.807,  Train_accy 16.44, Test_accy 13.37
2025-02-12 15:03:02,017 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 2.737,  Train_accy 18.38
2025-02-12 15:03:09,448 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 2.713,  Train_accy 19.15
2025-02-12 15:03:15,941 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 2.654,  Train_accy 21.58
2025-02-12 15:03:23,863 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 2.610,  Train_accy 22.99
2025-02-12 15:03:35,321 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 2.560,  Train_accy 26.28, Test_accy 19.25
2025-02-12 15:03:41,751 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 2.500,  Train_accy 27.49
2025-02-12 15:03:48,412 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 2.467,  Train_accy 27.84
2025-02-12 15:03:54,966 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 2.438,  Train_accy 28.73
2025-02-12 15:04:01,366 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 2.420,  Train_accy 30.08
2025-02-12 15:04:12,796 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 2.396,  Train_accy 31.84, Test_accy 24.14
2025-02-12 15:04:19,129 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 2.355,  Train_accy 33.31
2025-02-12 15:04:25,550 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 2.322,  Train_accy 34.44
2025-02-12 15:04:32,190 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 2.302,  Train_accy 35.49
2025-02-12 15:04:38,744 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 2.267,  Train_accy 36.44
2025-02-12 15:04:50,151 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 2.223,  Train_accy 38.79, Test_accy 29.54
2025-02-12 15:04:56,847 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 2.207,  Train_accy 39.43
2025-02-12 15:05:04,223 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 2.203,  Train_accy 39.62
2025-02-12 15:05:10,723 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 2.193,  Train_accy 40.81
2025-02-12 15:05:17,074 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 2.162,  Train_accy 41.17
2025-02-12 15:05:30,068 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 2.140,  Train_accy 43.84, Test_accy 33.98
2025-02-12 15:05:36,508 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 2.119,  Train_accy 44.42
2025-02-12 15:05:43,051 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 2.105,  Train_accy 44.34
2025-02-12 15:05:49,415 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 2.087,  Train_accy 44.83
2025-02-12 15:05:56,123 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 2.060,  Train_accy 46.65
2025-02-12 15:06:07,524 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 2.041,  Train_accy 47.29, Test_accy 36.41
2025-02-12 15:06:16,093 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 2.022,  Train_accy 47.96
2025-02-12 15:06:22,757 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 2.005,  Train_accy 48.85
2025-02-12 15:06:29,321 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.982,  Train_accy 50.10
2025-02-12 15:06:37,004 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.976,  Train_accy 50.53
2025-02-12 15:06:48,313 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.948,  Train_accy 51.19, Test_accy 38.46
2025-02-12 15:06:54,920 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.939,  Train_accy 51.92
2025-02-12 15:07:01,267 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.936,  Train_accy 52.53
2025-02-12 15:07:07,774 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.925,  Train_accy 52.85
2025-02-12 15:07:15,162 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.909,  Train_accy 53.31
2025-02-12 15:07:26,506 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.902,  Train_accy 54.04, Test_accy 41.73
2025-02-12 15:07:34,351 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.889,  Train_accy 54.26
2025-02-12 15:07:41,196 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.892,  Train_accy 54.73
2025-02-12 15:07:47,442 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.886,  Train_accy 54.77
2025-02-12 15:07:53,868 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.866,  Train_accy 55.39
2025-02-12 15:08:06,799 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.857,  Train_accy 55.39, Test_accy 41.78
2025-02-12 15:08:13,174 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.835,  Train_accy 56.73
2025-02-12 15:08:19,757 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.826,  Train_accy 57.23
2025-02-12 15:08:26,143 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.817,  Train_accy 56.75
2025-02-12 15:08:32,573 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.818,  Train_accy 57.27
2025-02-12 15:08:44,933 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.821,  Train_accy 57.41, Test_accy 44.71
2025-02-12 15:08:51,353 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.802,  Train_accy 57.56
2025-02-12 15:08:57,790 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.798,  Train_accy 57.78
2025-02-12 15:09:04,417 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.787,  Train_accy 59.13
2025-02-12 15:09:10,907 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.788,  Train_accy 58.28
2025-02-12 15:09:22,153 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.779,  Train_accy 58.91, Test_accy 45.37
2025-02-12 15:09:28,906 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.773,  Train_accy 59.27
2025-02-12 15:09:35,348 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.774,  Train_accy 59.37
2025-02-12 15:09:43,252 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.760,  Train_accy 59.56
2025-02-12 15:09:49,791 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.765,  Train_accy 59.05
2025-02-12 15:10:01,430 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.754,  Train_accy 59.84, Test_accy 45.90
2025-02-12 15:10:08,380 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.751,  Train_accy 59.35
2025-02-12 15:10:14,917 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.742,  Train_accy 59.45
2025-02-12 15:10:21,626 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.740,  Train_accy 59.88
2025-02-12 15:10:28,309 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.738,  Train_accy 60.40
2025-02-12 15:10:39,626 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.733,  Train_accy 60.28, Test_accy 47.49
2025-02-12 15:10:47,762 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.731,  Train_accy 60.16
2025-02-12 15:10:54,331 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.732,  Train_accy 60.75
2025-02-12 15:11:00,890 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.731,  Train_accy 59.84
2025-02-12 15:11:07,303 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.722,  Train_accy 60.28
2025-02-12 15:11:18,924 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.720,  Train_accy 60.65, Test_accy 47.48
2025-02-12 15:11:25,572 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.721,  Train_accy 60.48
2025-02-12 15:11:32,143 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.713,  Train_accy 60.59
2025-02-12 15:11:38,780 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.718,  Train_accy 60.00
2025-02-12 15:11:45,292 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.719,  Train_accy 60.40
2025-02-12 15:11:58,093 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.714,  Train_accy 60.75, Test_accy 48.16
2025-02-12 15:12:04,737 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.709,  Train_accy 61.29
2025-02-12 15:12:11,960 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.703,  Train_accy 61.21
2025-02-12 15:12:18,332 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.707,  Train_accy 61.31
2025-02-12 15:12:24,985 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.705,  Train_accy 61.03
2025-02-12 15:12:36,336 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.703,  Train_accy 60.85, Test_accy 47.35
2025-02-12 15:12:42,832 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.700,  Train_accy 61.47
2025-02-12 15:12:50,740 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.696,  Train_accy 60.87
2025-02-12 15:12:57,140 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.698,  Train_accy 61.49
2025-02-12 15:13:03,550 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.695,  Train_accy 60.99
2025-02-12 15:13:14,843 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.696,  Train_accy 61.11, Test_accy 47.81
2025-02-12 15:13:21,278 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.692,  Train_accy 61.19
2025-02-12 15:13:28,198 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.693,  Train_accy 60.75
2025-02-12 15:13:34,589 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.693,  Train_accy 61.29
2025-02-12 15:13:41,022 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.692,  Train_accy 60.65
2025-02-12 15:13:52,434 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.689,  Train_accy 61.13, Test_accy 48.46
2025-02-12 15:13:58,986 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.689,  Train_accy 60.83
2025-02-12 15:14:05,556 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.691,  Train_accy 60.91
2025-02-12 15:14:12,143 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.689,  Train_accy 60.85
2025-02-12 15:14:18,699 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.689,  Train_accy 60.87
2025-02-12 15:14:30,049 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.686,  Train_accy 61.17, Test_accy 48.25
2025-02-12 15:14:36,430 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.686,  Train_accy 61.35
2025-02-12 15:14:44,432 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.686,  Train_accy 61.72
2025-02-12 15:14:51,098 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.685,  Train_accy 61.03
2025-02-12 15:14:58,005 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.682,  Train_accy 61.60
2025-02-12 15:15:09,947 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.683,  Train_accy 60.24, Test_accy 48.79
2025-02-12 15:15:16,354 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.680,  Train_accy 61.82
2025-02-12 15:15:24,066 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.679,  Train_accy 60.85
2025-02-12 15:15:30,508 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.679,  Train_accy 61.25
2025-02-12 15:15:36,935 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.679,  Train_accy 61.27
2025-02-12 15:15:48,373 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.680,  Train_accy 60.79, Test_accy 48.75
2025-02-12 15:15:54,856 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.677,  Train_accy 60.85
2025-02-12 15:16:02,849 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.683,  Train_accy 61.27
2025-02-12 15:16:09,318 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.678,  Train_accy 61.15
2025-02-12 15:16:15,711 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.679,  Train_accy 61.13
2025-02-12 15:16:27,210 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.675,  Train_accy 61.82, Test_accy 48.83
2025-02-12 15:16:33,898 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.680,  Train_accy 61.33
2025-02-12 15:16:41,117 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.677,  Train_accy 62.26
2025-02-12 15:16:47,669 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.676,  Train_accy 61.66
2025-02-12 15:16:54,137 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.676,  Train_accy 61.86
2025-02-12 15:17:06,604 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.675,  Train_accy 61.68, Test_accy 48.90
2025-02-12 15:17:13,294 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.675,  Train_accy 61.49
2025-02-12 15:17:19,879 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.676,  Train_accy 61.88
2025-02-12 15:17:27,700 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.675,  Train_accy 60.93
2025-02-12 15:17:34,268 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.676,  Train_accy 61.43
2025-02-12 15:17:45,654 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.674,  Train_accy 61.39, Test_accy 49.11
2025-02-12 15:17:52,269 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.675,  Train_accy 61.35
2025-02-12 15:17:58,828 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.675,  Train_accy 61.29
2025-02-12 15:18:05,448 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.673,  Train_accy 61.98
2025-02-12 15:18:12,049 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.676,  Train_accy 60.91
2025-02-12 15:18:23,238 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.671,  Train_accy 61.29, Test_accy 48.94
2025-02-12 15:18:29,794 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.670,  Train_accy 61.76
2025-02-12 15:18:36,257 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.671,  Train_accy 61.41
2025-02-12 15:18:42,803 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.676,  Train_accy 61.27
2025-02-12 15:18:49,349 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.675,  Train_accy 60.63
2025-02-12 15:18:49,349 [der.py] => do not weight align student!
2025-02-12 15:18:53,345 [der.py] => darknet eval: 
2025-02-12 15:18:53,345 [der.py] => CNN top1 curve: 49.38
2025-02-12 15:18:53,345 [der.py] => CNN top5 curve: 83.19
2025-02-12 15:18:53,347 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 15:19:30,843 [der.py] => Exemplar size: 1050
2025-02-12 15:19:30,843 [trainer.py] => CNN: {'total': 59.21, '0': 62.78, '1': 36.11, '2': 50.56, '3': 33.89, '4': 38.89, '5': 26.11, '6': 31.67, '7': 30.56, '8': 36.67, '9': 41.11, '10': 57.78, '11': 70.56, '12': 46.11, '13': 35.0, '14': 46.67, '15': 90.56, '16': 98.89, '17': 90.56, '18': 91.67, '19': 93.89, '20': 95.0, '21': 93.89, '22': 92.78, '23': 94.44, '24': 87.78, '25': 24.44, '26': 42.78, '27': 52.78, '28': 40.56, '29': 56.67, '30': 44.44, '31': 55.56, '32': 48.89, '33': 65.56, 'old': 62.96, 'new': 49.83}
2025-02-12 15:19:30,843 [trainer.py] => NME: {'total': 64.03, '0': 64.44, '1': 43.89, '2': 47.22, '3': 31.11, '4': 35.56, '5': 20.0, '6': 26.67, '7': 31.11, '8': 43.33, '9': 36.11, '10': 58.33, '11': 64.44, '12': 40.56, '13': 33.89, '14': 37.78, '15': 91.67, '16': 98.33, '17': 85.0, '18': 87.78, '19': 86.11, '20': 93.33, '21': 90.56, '22': 87.78, '23': 65.0, '24': 63.33, '25': 66.67, '26': 82.22, '27': 87.78, '28': 66.67, '29': 68.33, '30': 80.56, '31': 82.78, '32': 98.33, '33': 72.22, 'old': 58.53, 'new': 77.78}
2025-02-12 15:19:30,843 [trainer.py] => CNN top1 curve: [80.59, 80.04, 59.21]
2025-02-12 15:19:30,843 [trainer.py] => CNN top5 curve: [98.48, 98.47, 87.79]
2025-02-12 15:19:30,843 [trainer.py] => NME top1 curve: [79.15, 77.36, 64.03]
2025-02-12 15:19:30,843 [trainer.py] => NME top5 curve: [98.74, 97.78, 87.08]

2025-02-12 15:19:30,844 [trainer.py] => All params: 15002414
2025-02-12 15:19:30,845 [trainer.py] => Trainable params: 7521966
2025-02-12 15:19:30,951 [der.py] => Learning on 35-45
2025-02-12 15:19:30,952 [der.py] => All params: 15012664
2025-02-12 15:19:30,952 [der.py] => Trainable params: 7532216
2025-02-12 15:19:31,039 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 15:19:31,039 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-12 15:40:42,174 [der.py] => Task 3, Epoch 150/150 => Loss 0.139, Loss_clf 0.007, Loss_aux 0.132, Train_accy 99.87
2025-02-12 15:40:55,176 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 3.566,  Train_accy 5.03, Test_accy 3.51
2025-02-12 15:41:02,010 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 3.338,  Train_accy 7.03
2025-02-12 15:41:08,593 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 3.415,  Train_accy 6.50
2025-02-12 15:41:15,333 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 3.216,  Train_accy 7.85
2025-02-12 15:41:22,175 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 3.031,  Train_accy 8.38
2025-02-12 15:41:34,952 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.908,  Train_accy 10.48, Test_accy 6.35
2025-02-12 15:41:41,951 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 2.868,  Train_accy 10.88
2025-02-12 15:41:48,699 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 2.793,  Train_accy 11.60
2025-02-12 15:41:55,751 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 2.760,  Train_accy 13.28
2025-02-12 15:42:02,470 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 2.659,  Train_accy 14.32
2025-02-12 15:42:15,312 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.573,  Train_accy 15.62, Test_accy 10.17
2025-02-12 15:42:22,339 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.502,  Train_accy 16.30
2025-02-12 15:42:29,182 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.483,  Train_accy 18.30
2025-02-12 15:42:35,969 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.457,  Train_accy 18.74
2025-02-12 15:42:42,744 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.389,  Train_accy 18.93
2025-02-12 15:42:55,617 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.290,  Train_accy 20.86, Test_accy 14.00
2025-02-12 15:43:02,519 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.251,  Train_accy 22.00
2025-02-12 15:43:09,357 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.252,  Train_accy 22.30
2025-02-12 15:43:16,282 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.240,  Train_accy 23.09
2025-02-12 15:43:23,146 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.168,  Train_accy 24.65
2025-02-12 15:43:35,991 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.146,  Train_accy 24.32, Test_accy 15.99
2025-02-12 15:43:42,764 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.071,  Train_accy 25.96
2025-02-12 15:43:49,513 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.020,  Train_accy 27.16
2025-02-12 15:43:56,695 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.018,  Train_accy 29.10
2025-02-12 15:44:03,559 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.944,  Train_accy 28.46
2025-02-12 15:44:16,370 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.922,  Train_accy 30.23, Test_accy 19.22
2025-02-12 15:44:23,285 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.905,  Train_accy 30.32
2025-02-12 15:44:30,330 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.853,  Train_accy 32.61
2025-02-12 15:44:37,183 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.813,  Train_accy 33.07
2025-02-12 15:44:44,068 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.795,  Train_accy 33.10
2025-02-12 15:44:56,904 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.781,  Train_accy 34.11, Test_accy 21.11
2025-02-12 15:45:03,771 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.764,  Train_accy 34.50
2025-02-12 15:45:10,579 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.719,  Train_accy 36.17
2025-02-12 15:45:17,381 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.756,  Train_accy 34.59
2025-02-12 15:45:24,243 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.646,  Train_accy 37.64
2025-02-12 15:45:37,010 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.643,  Train_accy 36.99, Test_accy 22.06
2025-02-12 15:45:43,847 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.606,  Train_accy 37.77
2025-02-12 15:45:50,718 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.601,  Train_accy 39.16
2025-02-12 15:45:57,686 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.596,  Train_accy 38.53
2025-02-12 15:46:04,711 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.500,  Train_accy 40.30
2025-02-12 15:46:17,535 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.504,  Train_accy 40.86, Test_accy 26.84
2025-02-12 15:46:24,346 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.477,  Train_accy 41.71
2025-02-12 15:46:31,218 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.469,  Train_accy 41.85
2025-02-12 15:46:37,935 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.435,  Train_accy 41.12
2025-02-12 15:46:44,737 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.419,  Train_accy 42.51
2025-02-12 15:46:57,580 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.404,  Train_accy 43.64, Test_accy 28.75
2025-02-12 15:47:04,282 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.406,  Train_accy 43.50
2025-02-12 15:47:11,042 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.403,  Train_accy 43.26
2025-02-12 15:47:17,930 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.347,  Train_accy 44.74
2025-02-12 15:47:24,722 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.324,  Train_accy 44.27
2025-02-12 15:47:37,471 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.324,  Train_accy 44.76, Test_accy 34.11
2025-02-12 15:47:44,311 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.334,  Train_accy 44.80
2025-02-12 15:47:51,366 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.299,  Train_accy 45.18
2025-02-12 15:47:58,219 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.270,  Train_accy 45.37
2025-02-12 15:48:04,899 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.246,  Train_accy 46.02
2025-02-12 15:48:17,819 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.236,  Train_accy 47.28, Test_accy 35.10
2025-02-12 15:48:24,906 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.247,  Train_accy 46.36
2025-02-12 15:48:31,788 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.250,  Train_accy 46.53
2025-02-12 15:48:38,723 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.212,  Train_accy 46.27
2025-02-12 15:48:45,557 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.204,  Train_accy 46.86
2025-02-12 15:48:59,075 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.171,  Train_accy 46.80, Test_accy 32.36
2025-02-12 15:49:05,944 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.209,  Train_accy 47.35
2025-02-12 15:49:12,842 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.195,  Train_accy 46.90
2025-02-12 15:49:19,747 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.161,  Train_accy 47.81
2025-02-12 15:49:26,533 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.173,  Train_accy 47.03
2025-02-12 15:49:39,548 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.150,  Train_accy 47.33, Test_accy 37.15
2025-02-12 15:49:46,213 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.155,  Train_accy 47.90
2025-02-12 15:49:53,268 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.115,  Train_accy 48.00
2025-02-12 15:50:00,148 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.140,  Train_accy 47.37
2025-02-12 15:50:07,258 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.135,  Train_accy 48.10
2025-02-12 15:50:20,704 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.147,  Train_accy 47.77, Test_accy 37.96
2025-02-12 15:50:27,806 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.137,  Train_accy 47.70
2025-02-12 15:50:34,928 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.107,  Train_accy 48.15
2025-02-12 15:50:41,835 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.091,  Train_accy 48.02
2025-02-12 15:50:48,732 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.101,  Train_accy 47.64
2025-02-12 15:51:01,797 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.092,  Train_accy 48.13, Test_accy 39.00
2025-02-12 15:51:08,618 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.088,  Train_accy 48.29
2025-02-12 15:51:15,373 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.064,  Train_accy 48.23
2025-02-12 15:51:22,430 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.064,  Train_accy 48.57
2025-02-12 15:51:29,233 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.077,  Train_accy 48.53
2025-02-12 15:51:42,455 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.055,  Train_accy 48.15, Test_accy 36.63
2025-02-12 15:51:49,316 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.057,  Train_accy 48.34
2025-02-12 15:51:56,044 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.052,  Train_accy 48.13
2025-02-12 15:52:02,876 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.096,  Train_accy 48.30
2025-02-12 15:52:09,751 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.048,  Train_accy 48.11
2025-02-12 15:52:22,947 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.055,  Train_accy 48.86, Test_accy 40.95
2025-02-12 15:52:29,799 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.014,  Train_accy 48.40
2025-02-12 15:52:36,630 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.050,  Train_accy 48.51
2025-02-12 15:52:43,491 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.052,  Train_accy 48.11
2025-02-12 15:52:50,308 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.031,  Train_accy 48.30
2025-02-12 15:53:03,344 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.040,  Train_accy 48.76, Test_accy 41.31
2025-02-12 15:53:10,319 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.012,  Train_accy 47.89
2025-02-12 15:53:17,151 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.017,  Train_accy 48.13
2025-02-12 15:53:24,088 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.028,  Train_accy 48.46
2025-02-12 15:53:31,015 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.018,  Train_accy 48.19
2025-02-12 15:53:43,908 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.023,  Train_accy 48.27, Test_accy 38.21
2025-02-12 15:53:50,799 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.027,  Train_accy 48.29
2025-02-12 15:53:57,680 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.003,  Train_accy 48.78
2025-02-12 15:54:04,459 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.018,  Train_accy 48.65
2025-02-12 15:54:11,254 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.000,  Train_accy 47.92
2025-02-12 15:54:24,106 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.001,  Train_accy 48.59, Test_accy 40.93
2025-02-12 15:54:31,021 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.022,  Train_accy 48.32
2025-02-12 15:54:38,170 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.026,  Train_accy 48.44
2025-02-12 15:54:45,124 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.021,  Train_accy 48.32
2025-02-12 15:54:52,151 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.994,  Train_accy 48.57
2025-02-12 15:55:05,183 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.013,  Train_accy 48.13, Test_accy 38.14
2025-02-12 15:55:12,163 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.011,  Train_accy 48.06
2025-02-12 15:55:19,119 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.008,  Train_accy 48.50
2025-02-12 15:55:26,074 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.002,  Train_accy 48.76
2025-02-12 15:55:33,053 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.004,  Train_accy 48.74
2025-02-12 15:55:46,021 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 0.996,  Train_accy 48.84, Test_accy 38.31
2025-02-12 15:55:53,080 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.992,  Train_accy 48.13
2025-02-12 15:56:00,020 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 0.969,  Train_accy 47.89
2025-02-12 15:56:07,284 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 0.977,  Train_accy 48.46
2025-02-12 15:56:13,891 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.980,  Train_accy 48.32
2025-02-12 15:56:27,819 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.970,  Train_accy 48.44, Test_accy 41.95
2025-02-12 15:56:35,186 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 0.969,  Train_accy 48.48
2025-02-12 15:56:42,677 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 0.993,  Train_accy 48.46
2025-02-12 15:56:50,068 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.981,  Train_accy 48.27
2025-02-12 15:56:57,516 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.974,  Train_accy 48.36
2025-02-12 15:57:11,020 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.980,  Train_accy 48.63, Test_accy 39.57
2025-02-12 15:57:18,779 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.012,  Train_accy 48.63
2025-02-12 15:57:25,791 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.000,  Train_accy 48.36
2025-02-12 15:57:32,822 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.983,  Train_accy 48.48
2025-02-12 15:57:39,974 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 0.992,  Train_accy 48.42
2025-02-12 15:57:53,321 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 0.999,  Train_accy 48.57, Test_accy 42.74
2025-02-12 15:58:00,253 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 0.996,  Train_accy 48.08
2025-02-12 15:58:07,158 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.969,  Train_accy 48.36
2025-02-12 15:58:14,133 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 0.979,  Train_accy 48.42
2025-02-12 15:58:21,127 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.992,  Train_accy 48.00
2025-02-12 15:58:21,128 [der.py] => do not weight align student!
2025-02-12 15:58:26,271 [der.py] => darknet eval: 
2025-02-12 15:58:26,271 [der.py] => CNN top1 curve: 39.77
2025-02-12 15:58:26,271 [der.py] => CNN top5 curve: 72.96
2025-02-12 15:58:26,273 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 15:59:10,205 [der.py] => Exemplar size: 1350
2025-02-12 15:59:10,205 [trainer.py] => CNN: {'total': 48.05, '0': 53.33, '1': 44.44, '2': 45.0, '3': 26.11, '4': 32.78, '5': 19.44, '6': 24.44, '7': 22.22, '8': 44.44, '9': 36.11, '10': 53.33, '11': 55.0, '12': 33.89, '13': 28.89, '14': 26.67, '15': 50.0, '16': 38.89, '17': 44.44, '18': 58.33, '19': 45.56, '20': 36.11, '21': 45.56, '22': 61.11, '23': 47.78, '24': 51.67, '25': 67.22, '26': 79.44, '27': 85.0, '28': 65.0, '29': 66.11, '30': 80.0, '31': 86.11, '32': 97.78, '33': 79.44, '34': 72.22, '35': 64.44, '36': 83.89, '37': 0.0, '38': 9.44, '39': 32.78, '40': 3.89, '41': 53.89, '42': 63.89, '43': 44.44, 'old': 51.54, 'new': 35.83}
2025-02-12 15:59:10,205 [trainer.py] => NME: {'total': 54.59, '0': 48.89, '1': 34.44, '2': 47.22, '3': 23.89, '4': 33.33, '5': 22.22, '6': 27.22, '7': 28.89, '8': 49.44, '9': 32.78, '10': 55.0, '11': 57.78, '12': 35.0, '13': 30.56, '14': 33.89, '15': 40.56, '16': 53.89, '17': 45.0, '18': 60.56, '19': 38.89, '20': 49.44, '21': 52.22, '22': 68.33, '23': 45.0, '24': 60.0, '25': 54.44, '26': 63.89, '27': 77.22, '28': 53.33, '29': 67.78, '30': 58.89, '31': 69.44, '32': 65.0, '33': 51.11, '34': 67.78, '35': 95.0, '36': 93.33, '37': 54.44, '38': 87.78, '39': 85.56, '40': 57.78, '41': 71.67, '42': 87.22, '43': 80.56, 'old': 48.67, 'new': 75.33}
2025-02-12 15:59:10,205 [trainer.py] => CNN top1 curve: [80.59, 80.04, 59.21, 48.05]
2025-02-12 15:59:10,205 [trainer.py] => CNN top5 curve: [98.48, 98.47, 87.79, 80.8]
2025-02-12 15:59:10,205 [trainer.py] => NME top1 curve: [79.15, 77.36, 64.03, 54.59]
2025-02-12 15:59:10,205 [trainer.py] => NME top5 curve: [98.74, 97.78, 87.08, 82.54]

2025-02-12 15:59:10,206 [trainer.py] => All params: 15012664
2025-02-12 15:59:10,207 [trainer.py] => Trainable params: 7532216
2025-02-12 15:59:10,307 [der.py] => Learning on 45-55
2025-02-12 15:59:10,309 [der.py] => All params: 15022914
2025-02-12 15:59:10,309 [der.py] => Trainable params: 7542466
2025-02-12 15:59:10,420 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-12 15:59:10,421 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-12 16:22:16,528 [der.py] => Task 4, Epoch 150/150 => Loss 0.020, Loss_clf 0.007, Loss_aux 0.013, Train_accy 99.95
2025-02-12 16:22:31,352 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.928,  Train_accy 1.10, Test_accy 3.01
2025-02-12 16:22:38,689 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 3.748,  Train_accy 1.28
2025-02-12 16:22:45,966 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 3.588,  Train_accy 1.87
2025-02-12 16:22:53,251 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 3.498,  Train_accy 2.61
2025-02-12 16:23:00,356 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 3.469,  Train_accy 2.45
2025-02-12 16:23:15,240 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 3.404,  Train_accy 3.82, Test_accy 7.01
2025-02-12 16:23:22,593 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 3.340,  Train_accy 5.01
2025-02-12 16:23:30,046 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 3.284,  Train_accy 5.75
2025-02-12 16:23:37,244 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 3.244,  Train_accy 6.67
2025-02-12 16:23:44,592 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 3.197,  Train_accy 8.27
2025-02-12 16:23:59,354 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 3.167,  Train_accy 8.81, Test_accy 11.46
2025-02-12 16:24:06,669 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 3.130,  Train_accy 10.45
2025-02-12 16:24:13,983 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 3.103,  Train_accy 11.55
2025-02-12 16:24:21,177 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 3.063,  Train_accy 12.18
2025-02-12 16:24:28,364 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 3.021,  Train_accy 13.46
2025-02-12 16:24:42,841 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.993,  Train_accy 14.52, Test_accy 17.55
2025-02-12 16:24:50,177 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.968,  Train_accy 16.05
2025-02-12 16:24:57,563 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.917,  Train_accy 17.44
2025-02-12 16:25:04,849 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.898,  Train_accy 18.41
2025-02-12 16:25:12,261 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.871,  Train_accy 18.83
2025-02-12 16:25:26,880 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.850,  Train_accy 20.31, Test_accy 19.89
2025-02-12 16:25:34,058 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.822,  Train_accy 20.95
2025-02-12 16:25:41,512 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.784,  Train_accy 23.32
2025-02-12 16:25:49,150 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.777,  Train_accy 23.71
2025-02-12 16:25:56,269 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.747,  Train_accy 24.83
2025-02-12 16:26:10,798 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.739,  Train_accy 24.79, Test_accy 26.52
2025-02-12 16:26:18,164 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.701,  Train_accy 26.59
2025-02-12 16:26:25,465 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.679,  Train_accy 28.04
2025-02-12 16:26:32,722 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.650,  Train_accy 29.69
2025-02-12 16:26:39,887 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.630,  Train_accy 30.20
2025-02-12 16:26:54,526 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.626,  Train_accy 30.88, Test_accy 30.13
2025-02-12 16:27:02,288 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.596,  Train_accy 32.05
2025-02-12 16:27:09,538 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.578,  Train_accy 33.77
2025-02-12 16:27:16,862 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.586,  Train_accy 33.30
2025-02-12 16:27:24,107 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.574,  Train_accy 33.82
2025-02-12 16:27:38,707 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.528,  Train_accy 35.87, Test_accy 33.70
2025-02-12 16:27:45,858 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.510,  Train_accy 36.72
2025-02-12 16:27:53,207 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.498,  Train_accy 37.48
2025-02-12 16:28:00,339 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.502,  Train_accy 37.89
2025-02-12 16:28:07,717 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.483,  Train_accy 37.73
2025-02-12 16:28:22,480 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.466,  Train_accy 39.32, Test_accy 36.40
2025-02-12 16:28:29,921 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.439,  Train_accy 40.32
2025-02-12 16:28:37,351 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.446,  Train_accy 40.72
2025-02-12 16:28:44,681 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.427,  Train_accy 40.29
2025-02-12 16:28:51,890 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.419,  Train_accy 41.30
2025-02-12 16:29:06,613 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.397,  Train_accy 42.00, Test_accy 36.52
2025-02-12 16:29:13,571 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.397,  Train_accy 41.62
2025-02-12 16:29:20,979 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.388,  Train_accy 42.74
2025-02-12 16:29:28,407 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.397,  Train_accy 41.60
2025-02-12 16:29:35,731 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.372,  Train_accy 43.75
2025-02-12 16:29:50,459 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.375,  Train_accy 43.73, Test_accy 38.89
2025-02-12 16:29:57,774 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.350,  Train_accy 44.63
2025-02-12 16:30:05,117 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.338,  Train_accy 45.62
2025-02-12 16:30:12,503 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.342,  Train_accy 44.14
2025-02-12 16:30:19,836 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.348,  Train_accy 44.81
2025-02-12 16:30:34,398 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.340,  Train_accy 45.44, Test_accy 40.53
2025-02-12 16:30:41,701 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.330,  Train_accy 45.05
2025-02-12 16:30:48,941 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.323,  Train_accy 45.64
2025-02-12 16:30:56,384 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.318,  Train_accy 46.14
2025-02-12 16:31:03,545 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.323,  Train_accy 45.71
2025-02-12 16:31:18,115 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.308,  Train_accy 46.34, Test_accy 40.00
2025-02-12 16:31:25,486 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.300,  Train_accy 47.21
2025-02-12 16:31:32,718 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.299,  Train_accy 46.77
2025-02-12 16:31:40,010 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.294,  Train_accy 46.70
2025-02-12 16:31:47,155 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.289,  Train_accy 46.59
2025-02-12 16:32:01,439 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.290,  Train_accy 47.59, Test_accy 41.35
2025-02-12 16:32:08,817 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.284,  Train_accy 47.15
2025-02-12 16:32:16,141 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.283,  Train_accy 48.41
2025-02-12 16:32:23,495 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.279,  Train_accy 47.51
2025-02-12 16:32:30,708 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.280,  Train_accy 48.14
2025-02-12 16:32:45,224 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.277,  Train_accy 47.68, Test_accy 41.73
2025-02-12 16:32:52,464 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.266,  Train_accy 48.04
2025-02-12 16:32:59,640 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.264,  Train_accy 48.20
2025-02-12 16:33:06,895 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.261,  Train_accy 48.02
2025-02-12 16:33:14,039 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.261,  Train_accy 48.20
2025-02-12 16:33:28,475 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.261,  Train_accy 47.78, Test_accy 42.84
2025-02-12 16:33:35,847 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.257,  Train_accy 48.38
2025-02-12 16:33:43,108 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.253,  Train_accy 48.25
2025-02-12 16:33:50,369 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.248,  Train_accy 48.99
2025-02-12 16:33:57,687 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.250,  Train_accy 48.95
2025-02-12 16:34:12,445 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.250,  Train_accy 48.77, Test_accy 42.37
2025-02-12 16:34:19,568 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.245,  Train_accy 48.58
2025-02-12 16:34:26,819 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.244,  Train_accy 49.01
2025-02-12 16:34:34,341 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.245,  Train_accy 48.67
2025-02-12 16:34:41,726 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.245,  Train_accy 48.72
2025-02-12 16:34:56,376 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.239,  Train_accy 49.23, Test_accy 42.76
2025-02-12 16:35:03,655 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.239,  Train_accy 48.74
2025-02-12 16:35:10,837 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.247,  Train_accy 48.92
2025-02-12 16:35:18,154 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.233,  Train_accy 49.64
2025-02-12 16:35:25,358 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.239,  Train_accy 48.92
2025-02-12 16:35:40,057 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.233,  Train_accy 49.37, Test_accy 42.73
2025-02-12 16:35:47,457 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.233,  Train_accy 49.37
2025-02-12 16:35:54,813 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.227,  Train_accy 49.42
2025-02-12 16:36:02,305 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.229,  Train_accy 48.97
2025-02-12 16:36:09,524 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.226,  Train_accy 49.17
2025-02-12 16:36:24,473 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.226,  Train_accy 49.86, Test_accy 42.94
2025-02-12 16:36:31,671 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.230,  Train_accy 49.62
2025-02-12 16:36:39,038 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.227,  Train_accy 48.83
2025-02-12 16:36:46,289 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.231,  Train_accy 49.69
2025-02-12 16:36:53,565 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.225,  Train_accy 49.12
2025-02-12 16:37:08,246 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.225,  Train_accy 49.93, Test_accy 42.90
2025-02-12 16:37:15,700 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.228,  Train_accy 49.62
2025-02-12 16:37:23,065 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.223,  Train_accy 49.23
2025-02-12 16:37:30,322 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.225,  Train_accy 49.35
2025-02-12 16:37:37,538 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.222,  Train_accy 49.53
2025-02-12 16:37:52,094 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.220,  Train_accy 49.46, Test_accy 43.26
2025-02-12 16:37:59,563 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.224,  Train_accy 49.55
2025-02-12 16:38:06,885 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.225,  Train_accy 49.64
2025-02-12 16:38:14,128 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.220,  Train_accy 49.91
2025-02-12 16:38:21,455 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.218,  Train_accy 50.67
2025-02-12 16:38:35,917 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.220,  Train_accy 49.62, Test_accy 43.11
2025-02-12 16:38:43,373 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.217,  Train_accy 49.59
2025-02-12 16:38:50,687 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.219,  Train_accy 49.82
2025-02-12 16:38:57,889 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.217,  Train_accy 49.87
2025-02-12 16:39:05,247 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.215,  Train_accy 49.19
2025-02-12 16:39:20,126 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.217,  Train_accy 50.13, Test_accy 43.04
2025-02-12 16:39:27,300 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.217,  Train_accy 49.37
2025-02-12 16:39:34,666 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.215,  Train_accy 50.05
2025-02-12 16:39:42,140 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.223,  Train_accy 49.37
2025-02-12 16:39:49,381 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.219,  Train_accy 50.65
2025-02-12 16:40:04,018 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.220,  Train_accy 50.00, Test_accy 43.10
2025-02-12 16:40:11,184 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.216,  Train_accy 49.55
2025-02-12 16:40:18,404 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.216,  Train_accy 49.42
2025-02-12 16:40:25,799 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.216,  Train_accy 49.82
2025-02-12 16:40:33,261 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.215,  Train_accy 49.60
2025-02-12 16:40:48,394 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.212,  Train_accy 49.41, Test_accy 43.42
2025-02-12 16:40:55,542 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.213,  Train_accy 49.44
2025-02-12 16:41:02,889 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.215,  Train_accy 49.53
2025-02-12 16:41:10,150 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.212,  Train_accy 49.89
2025-02-12 16:41:17,433 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.215,  Train_accy 49.73
2025-02-12 16:41:17,434 [der.py] => do not weight align student!
2025-02-12 16:41:23,628 [der.py] => darknet eval: 
2025-02-12 16:41:23,628 [der.py] => CNN top1 curve: 43.31
2025-02-12 16:41:23,628 [der.py] => CNN top5 curve: 74.47
2025-02-12 16:41:23,631 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-12 16:42:15,179 [der.py] => Exemplar size: 1650
2025-02-12 16:42:15,180 [trainer.py] => CNN: {'total': 44.47, '0': 42.22, '1': 31.67, '2': 41.11, '3': 20.56, '4': 35.0, '5': 20.0, '6': 19.44, '7': 26.11, '8': 48.33, '9': 26.11, '10': 42.22, '11': 51.67, '12': 32.78, '13': 37.22, '14': 36.11, '15': 43.89, '16': 49.44, '17': 34.44, '18': 46.67, '19': 35.56, '20': 49.44, '21': 40.0, '22': 47.22, '23': 33.33, '24': 41.67, '25': 42.78, '26': 45.0, '27': 49.44, '28': 21.67, '29': 32.78, '30': 43.33, '31': 36.67, '32': 67.78, '33': 36.67, '34': 28.33, '35': 91.67, '36': 92.78, '37': 36.67, '38': 75.56, '39': 77.78, '40': 57.78, '41': 91.67, '42': 88.33, '43': 87.78, '44': 46.11, '45': 26.67, '46': 37.78, '47': 34.44, '48': 40.0, '49': 41.11, '50': 30.0, '51': 45.56, '52': 43.33, '53': 30.0, 'old': 46.28, 'new': 36.33}
2025-02-12 16:42:15,180 [trainer.py] => NME: {'total': 44.65, '0': 47.78, '1': 30.0, '2': 41.11, '3': 16.67, '4': 30.0, '5': 25.0, '6': 19.44, '7': 23.89, '8': 47.78, '9': 28.33, '10': 32.78, '11': 52.22, '12': 32.22, '13': 31.67, '14': 31.11, '15': 40.56, '16': 44.44, '17': 36.67, '18': 51.11, '19': 37.78, '20': 45.0, '21': 41.11, '22': 36.67, '23': 42.78, '24': 32.78, '25': 33.33, '26': 30.0, '27': 40.56, '28': 21.11, '29': 25.0, '30': 31.67, '31': 25.0, '32': 62.78, '33': 29.44, '34': 29.44, '35': 72.78, '36': 70.56, '37': 21.11, '38': 52.78, '39': 51.67, '40': 22.78, '41': 85.56, '42': 76.67, '43': 65.56, '44': 17.78, '45': 69.44, '46': 65.0, '47': 68.89, '48': 76.11, '49': 72.78, '50': 65.56, '51': 77.78, '52': 67.78, '53': 66.11, 'old': 39.21, 'new': 69.11}
2025-02-12 16:42:15,180 [trainer.py] => CNN top1 curve: [80.59, 80.04, 59.21, 48.05, 44.47]
2025-02-12 16:42:15,180 [trainer.py] => CNN top5 curve: [98.48, 98.47, 87.79, 80.8, 76.57]
2025-02-12 16:42:15,180 [trainer.py] => NME top1 curve: [79.15, 77.36, 64.03, 54.59, 44.65]
2025-02-12 16:42:15,180 [trainer.py] => NME top5 curve: [98.74, 97.78, 87.08, 82.54, 76.35]

2025-02-16 00:18:01,408 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 00:18:03,933 [trainer.py] => config: ./exps/der.json
2025-02-16 00:18:03,934 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 00:18:03,934 [trainer.py] => prefix: reproduce
2025-02-16 00:18:03,934 [trainer.py] => dataset: xrfdataset
2025-02-16 00:18:03,934 [trainer.py] => memory_size: 1650
2025-02-16 00:18:03,934 [trainer.py] => memory_per_class: 30
2025-02-16 00:18:03,934 [trainer.py] => fixed_memory: True
2025-02-16 00:18:03,934 [trainer.py] => shuffle: True
2025-02-16 00:18:03,934 [trainer.py] => init_cls: 15
2025-02-16 00:18:03,934 [trainer.py] => increment: 10
2025-02-16 00:18:03,934 [trainer.py] => model_name: der
2025-02-16 00:18:03,935 [trainer.py] => compression_epochs: 1
2025-02-16 00:18:03,935 [trainer.py] => compression_lr: 0.1
2025-02-16 00:18:03,935 [trainer.py] => is_student_wa: False
2025-02-16 00:18:03,935 [trainer.py] => wa_value: 1
2025-02-16 00:18:03,935 [trainer.py] => T: 2
2025-02-16 00:18:03,935 [trainer.py] => convnet_type: resnet34
2025-02-16 00:18:03,935 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 00:18:03,935 [trainer.py] => seed: 1993
2025-02-16 00:18:03,962 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:18:03,968 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:18:03,969 [trainer.py] => All params: 0
2025-02-16 00:18:03,969 [trainer.py] => Trainable params: 0
2025-02-16 00:18:04,107 [der.py] => Learning on 0-15
2025-02-16 00:18:04,107 [der.py] => All params: 7496351
2025-02-16 00:18:04,107 [der.py] => Trainable params: 7496351
2025-02-16 00:20:50,551 [der.py] => Task 0, Epoch 1/1 => Loss 4.146, Train_accy 6.57, Test_accy 8.04
2025-02-16 00:20:53,233 [der.py] => Exemplar size: 0
2025-02-16 00:20:53,233 [trainer.py] => No NME accuracy.
2025-02-16 00:20:53,233 [trainer.py] => CNN: {'total': 8.04, '0': 0.56, '1': 0.0, '2': 52.78, '3': 0.0, '4': 0.0, '5': 7.22, '6': 0.0, '7': 0.0, '8': 0.0, '9': 5.0, '10': 55.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 8.04}
2025-02-16 00:20:53,233 [trainer.py] => CNN top1 curve: [8.04]
2025-02-16 00:20:53,233 [trainer.py] => CNN top5 curve: [35.7]

2025-02-16 00:20:53,234 [trainer.py] => All params: 7496351
2025-02-16 00:20:53,235 [trainer.py] => Trainable params: 7496351
2025-02-16 00:20:53,372 [der.py] => Learning on 15-25
2025-02-16 00:20:53,375 [der.py] => All params: 14992164
2025-02-16 00:20:53,376 [der.py] => Trainable params: 7511716
2025-02-16 00:20:53,455 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:20:53,455 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 00:23:25,049 [der.py] => Task 1, Epoch 1/1 => Loss 5.431, Loss_clf 3.045, Loss_aux 2.386, Train_accy 9.50, Test_accy 4.13
2025-02-16 00:28:21,641 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 00:28:21,642 [trainer.py] => config: ./exps/der.json
2025-02-16 00:28:21,642 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 00:28:21,642 [trainer.py] => prefix: reproduce
2025-02-16 00:28:21,642 [trainer.py] => dataset: xrfdataset
2025-02-16 00:28:21,642 [trainer.py] => memory_size: 1650
2025-02-16 00:28:21,642 [trainer.py] => memory_per_class: 30
2025-02-16 00:28:21,642 [trainer.py] => fixed_memory: True
2025-02-16 00:28:21,642 [trainer.py] => shuffle: True
2025-02-16 00:28:21,642 [trainer.py] => init_cls: 15
2025-02-16 00:28:21,642 [trainer.py] => increment: 10
2025-02-16 00:28:21,642 [trainer.py] => model_name: der
2025-02-16 00:28:21,642 [trainer.py] => compression_epochs: 1
2025-02-16 00:28:21,642 [trainer.py] => compression_lr: 0.1
2025-02-16 00:28:21,642 [trainer.py] => is_student_wa: False
2025-02-16 00:28:21,643 [trainer.py] => wa_value: 1
2025-02-16 00:28:21,643 [trainer.py] => T: 2
2025-02-16 00:28:21,643 [trainer.py] => convnet_type: resnet34
2025-02-16 00:28:21,643 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 00:28:21,643 [trainer.py] => seed: 1993
2025-02-16 00:28:21,656 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:28:21,661 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:28:21,662 [trainer.py] => All params: 0
2025-02-16 00:28:21,662 [trainer.py] => Trainable params: 0
2025-02-16 00:28:21,791 [der.py] => Learning on 0-15
2025-02-16 00:28:21,791 [der.py] => All params: 7496351
2025-02-16 00:28:21,792 [der.py] => Trainable params: 7496351
2025-02-16 00:28:37,303 [der.py] => Task 0, Epoch 1/1 => Loss 4.146, Train_accy 6.57, Test_accy 8.04
2025-02-16 00:28:40,098 [der.py] => Exemplar size: 0
2025-02-16 00:28:40,099 [trainer.py] => No NME accuracy.
2025-02-16 00:28:40,099 [trainer.py] => CNN: {'total': 8.04, '0': 0.56, '1': 0.0, '2': 52.78, '3': 0.0, '4': 0.0, '5': 7.22, '6': 0.0, '7': 0.0, '8': 0.0, '9': 5.0, '10': 55.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 8.04}
2025-02-16 00:28:40,099 [trainer.py] => CNN top1 curve: [8.04]
2025-02-16 00:28:40,099 [trainer.py] => CNN top5 curve: [35.7]

2025-02-16 00:28:40,099 [trainer.py] => All params: 7496351
2025-02-16 00:28:40,100 [trainer.py] => Trainable params: 7496351
2025-02-16 00:28:40,215 [der.py] => Learning on 15-25
2025-02-16 00:28:40,216 [der.py] => All params: 14992164
2025-02-16 00:28:40,217 [der.py] => Trainable params: 7511716
2025-02-16 00:28:40,284 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:28:40,284 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 00:28:50,921 [der.py] => Task 1, Epoch 1/1 => Loss 5.431, Loss_clf 3.045, Loss_aux 2.386, Train_accy 9.50, Test_accy 4.13
2025-02-16 00:29:01,459 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.940,  Train_accy 9.71, Test_accy 4.11
2025-02-16 00:29:01,460 [der.py] => do not weight align student!
2025-02-16 00:29:05,111 [der.py] => darknet eval: 
2025-02-16 00:29:05,111 [der.py] => CNN top1 curve: 4.11
2025-02-16 00:29:05,111 [der.py] => CNN top5 curve: 19.93
2025-02-16 00:29:08,937 [der.py] => Exemplar size: 0
2025-02-16 00:29:08,938 [trainer.py] => No NME accuracy.
2025-02-16 00:29:08,938 [trainer.py] => CNN: {'total': 4.11, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 1.67, '16': 92.78, '17': 2.22, '18': 0.0, '19': 0.0, '20': 1.11, '21': 5.0, '22': 0.0, '23': 0.0, 'old': 0.0, 'new': 10.28}
2025-02-16 00:29:08,938 [trainer.py] => CNN top1 curve: [8.04, 4.11]
2025-02-16 00:29:08,938 [trainer.py] => CNN top5 curve: [35.7, 19.82]

2025-02-16 00:29:08,939 [trainer.py] => All params: 14992164
2025-02-16 00:29:08,939 [trainer.py] => Trainable params: 7511716
2025-02-16 00:29:09,056 [der.py] => Learning on 25-35
2025-02-16 00:29:09,057 [der.py] => All params: 15002414
2025-02-16 00:29:09,058 [der.py] => Trainable params: 7521966
2025-02-16 00:29:09,138 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:29:09,139 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-16 00:31:41,583 [der.py] => Task 2, Epoch 1/1 => Loss 5.535, Loss_clf 3.159, Loss_aux 2.377, Train_accy 9.36, Test_accy 2.92
2025-02-16 00:32:01,443 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 2.795,  Train_accy 10.12, Test_accy 2.86
2025-02-16 00:32:01,444 [der.py] => do not weight align student!
2025-02-16 00:32:06,050 [der.py] => darknet eval: 
2025-02-16 00:32:06,050 [der.py] => CNN top1 curve: 2.86
2025-02-16 00:32:06,050 [der.py] => CNN top5 curve: 14.33
2025-02-16 00:32:11,062 [der.py] => Exemplar size: 0
2025-02-16 00:32:11,062 [trainer.py] => No NME accuracy.
2025-02-16 00:32:11,062 [trainer.py] => CNN: {'total': 2.92, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 50.56, '27': 0.0, '28': 14.44, '29': 25.0, '30': 11.11, '31': 0.0, '32': 0.0, '33': 0.0, 'old': 0.0, 'new': 10.22}
2025-02-16 00:32:11,062 [trainer.py] => CNN top1 curve: [8.04, 4.11, 2.92]
2025-02-16 00:32:11,062 [trainer.py] => CNN top5 curve: [35.7, 19.82, 14.7]

2025-02-16 00:32:11,063 [trainer.py] => All params: 15002414
2025-02-16 00:32:11,064 [trainer.py] => Trainable params: 7521966
2025-02-16 00:32:11,183 [der.py] => Learning on 35-45
2025-02-16 00:32:11,184 [der.py] => All params: 15012664
2025-02-16 00:32:11,184 [der.py] => Trainable params: 7532216
2025-02-16 00:32:11,274 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:32:11,275 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-16 00:35:24,845 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 00:35:24,857 [trainer.py] => config: ./exps/der.json
2025-02-16 00:35:24,857 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 00:35:24,857 [trainer.py] => prefix: reproduce
2025-02-16 00:35:24,857 [trainer.py] => dataset: xrfdataset
2025-02-16 00:35:24,857 [trainer.py] => memory_size: 1650
2025-02-16 00:35:24,857 [trainer.py] => memory_per_class: 30
2025-02-16 00:35:24,857 [trainer.py] => fixed_memory: True
2025-02-16 00:35:24,857 [trainer.py] => shuffle: True
2025-02-16 00:35:24,857 [trainer.py] => init_cls: 15
2025-02-16 00:35:24,857 [trainer.py] => increment: 10
2025-02-16 00:35:24,857 [trainer.py] => model_name: der
2025-02-16 00:35:24,858 [trainer.py] => compression_epochs: 1
2025-02-16 00:35:24,858 [trainer.py] => compression_lr: 0.1
2025-02-16 00:35:24,858 [trainer.py] => is_student_wa: False
2025-02-16 00:35:24,858 [trainer.py] => wa_value: 1
2025-02-16 00:35:24,858 [trainer.py] => T: 2
2025-02-16 00:35:24,858 [trainer.py] => convnet_type: resnet34
2025-02-16 00:35:24,858 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 00:35:24,858 [trainer.py] => seed: 1993
2025-02-16 00:35:24,879 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:35:24,884 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:35:24,885 [trainer.py] => All params: 0
2025-02-16 00:35:24,885 [trainer.py] => Trainable params: 0
2025-02-16 00:35:25,018 [der.py] => Learning on 0-15
2025-02-16 00:35:25,019 [der.py] => All params: 7496351
2025-02-16 00:35:25,019 [der.py] => Trainable params: 7496351
2025-02-16 00:35:40,748 [der.py] => Task 0, Epoch 1/1 => Loss 4.146, Train_accy 6.57, Test_accy 8.04
2025-02-16 00:35:43,230 [der.py] => Exemplar size: 0
2025-02-16 00:35:43,230 [trainer.py] => No NME accuracy.
2025-02-16 00:35:43,231 [trainer.py] => CNN: {'total': 8.04, '0': 0.56, '1': 0.0, '2': 52.78, '3': 0.0, '4': 0.0, '5': 7.22, '6': 0.0, '7': 0.0, '8': 0.0, '9': 5.0, '10': 55.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 8.04}
2025-02-16 00:35:43,231 [trainer.py] => CNN top1 curve: [8.04]
2025-02-16 00:35:43,231 [trainer.py] => CNN top5 curve: [35.7]

2025-02-16 00:35:43,232 [trainer.py] => All params: 7496351
2025-02-16 00:35:43,232 [trainer.py] => Trainable params: 7496351
2025-02-16 00:35:43,362 [der.py] => Learning on 15-25
2025-02-16 00:35:43,363 [der.py] => All params: 14992164
2025-02-16 00:35:43,364 [der.py] => Trainable params: 7511716
2025-02-16 00:35:43,433 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:35:43,434 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 00:36:22,600 [der.py] => Task 1, Epoch 1/1 => Loss 5.431, Loss_clf 3.045, Loss_aux 2.386, Train_accy 9.50, Test_accy 4.13
2025-02-16 00:39:50,050 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 00:39:50,050 [trainer.py] => config: ./exps/der.json
2025-02-16 00:39:50,050 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 00:39:50,050 [trainer.py] => prefix: reproduce
2025-02-16 00:39:50,050 [trainer.py] => dataset: xrfdataset
2025-02-16 00:39:50,050 [trainer.py] => memory_size: 1650
2025-02-16 00:39:50,050 [trainer.py] => memory_per_class: 30
2025-02-16 00:39:50,051 [trainer.py] => fixed_memory: True
2025-02-16 00:39:50,051 [trainer.py] => shuffle: True
2025-02-16 00:39:50,051 [trainer.py] => init_cls: 15
2025-02-16 00:39:50,051 [trainer.py] => increment: 10
2025-02-16 00:39:50,051 [trainer.py] => model_name: der
2025-02-16 00:39:50,051 [trainer.py] => compression_epochs: 1
2025-02-16 00:39:50,051 [trainer.py] => compression_lr: 0.1
2025-02-16 00:39:50,051 [trainer.py] => is_student_wa: False
2025-02-16 00:39:50,051 [trainer.py] => wa_value: 1
2025-02-16 00:39:50,051 [trainer.py] => T: 2
2025-02-16 00:39:50,051 [trainer.py] => convnet_type: resnet34
2025-02-16 00:39:50,051 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 00:39:50,051 [trainer.py] => seed: 1993
2025-02-16 00:39:50,064 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:39:50,070 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:39:50,070 [trainer.py] => All params: 0
2025-02-16 00:39:50,070 [trainer.py] => Trainable params: 0
2025-02-16 00:39:50,197 [der.py] => Learning on 0-15
2025-02-16 00:39:50,198 [der.py] => All params: 7496351
2025-02-16 00:39:50,198 [der.py] => Trainable params: 7496351
2025-02-16 00:40:06,070 [der.py] => Task 0, Epoch 1/1 => Loss 4.146, Train_accy 6.57, Test_accy 8.04
2025-02-16 00:40:08,617 [der.py] => Exemplar size: 0
2025-02-16 00:40:08,617 [trainer.py] => No NME accuracy.
2025-02-16 00:40:08,617 [trainer.py] => CNN: {'total': 8.04, '0': 0.56, '1': 0.0, '2': 52.78, '3': 0.0, '4': 0.0, '5': 7.22, '6': 0.0, '7': 0.0, '8': 0.0, '9': 5.0, '10': 55.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 8.04}
2025-02-16 00:40:08,618 [trainer.py] => CNN top1 curve: [8.04]
2025-02-16 00:40:08,618 [trainer.py] => CNN top5 curve: [35.7]

2025-02-16 00:40:08,619 [trainer.py] => All params: 7496351
2025-02-16 00:40:08,619 [trainer.py] => Trainable params: 7496351
2025-02-16 00:40:08,750 [der.py] => Learning on 15-25
2025-02-16 00:40:08,752 [der.py] => All params: 14992164
2025-02-16 00:40:08,752 [der.py] => Trainable params: 7511716
2025-02-16 00:40:08,830 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:40:08,831 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 00:40:19,227 [der.py] => Task 1, Epoch 1/1 => Loss 5.431, Loss_clf 3.045, Loss_aux 2.386, Train_accy 9.50, Test_accy 4.13
2025-02-16 00:42:05,971 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 00:42:05,972 [trainer.py] => config: ./exps/der.json
2025-02-16 00:42:05,972 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 00:42:05,972 [trainer.py] => prefix: reproduce
2025-02-16 00:42:05,972 [trainer.py] => dataset: xrfdataset
2025-02-16 00:42:05,972 [trainer.py] => memory_size: 1650
2025-02-16 00:42:05,972 [trainer.py] => memory_per_class: 30
2025-02-16 00:42:05,972 [trainer.py] => fixed_memory: True
2025-02-16 00:42:05,972 [trainer.py] => shuffle: True
2025-02-16 00:42:05,972 [trainer.py] => init_cls: 15
2025-02-16 00:42:05,972 [trainer.py] => increment: 10
2025-02-16 00:42:05,972 [trainer.py] => model_name: der
2025-02-16 00:42:05,972 [trainer.py] => compression_epochs: 1
2025-02-16 00:42:05,973 [trainer.py] => compression_lr: 0.1
2025-02-16 00:42:05,973 [trainer.py] => is_student_wa: False
2025-02-16 00:42:05,973 [trainer.py] => wa_value: 1
2025-02-16 00:42:05,973 [trainer.py] => T: 2
2025-02-16 00:42:05,973 [trainer.py] => convnet_type: resnet34
2025-02-16 00:42:05,973 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 00:42:05,973 [trainer.py] => seed: 1993
2025-02-16 00:42:05,985 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:42:05,990 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:42:05,991 [trainer.py] => All params: 0
2025-02-16 00:42:05,991 [trainer.py] => Trainable params: 0
2025-02-16 00:42:06,122 [der.py] => Learning on 0-15
2025-02-16 00:42:06,122 [der.py] => All params: 7496351
2025-02-16 00:42:06,122 [der.py] => Trainable params: 7496351
2025-02-16 00:42:22,104 [der.py] => Task 0, Epoch 1/1 => Loss 4.146, Train_accy 6.57, Test_accy 8.04
2025-02-16 00:42:24,689 [der.py] => Exemplar size: 0
2025-02-16 00:42:24,689 [trainer.py] => No NME accuracy.
2025-02-16 00:42:24,690 [trainer.py] => CNN: {'total': 8.04, '0': 0.56, '1': 0.0, '2': 52.78, '3': 0.0, '4': 0.0, '5': 7.22, '6': 0.0, '7': 0.0, '8': 0.0, '9': 5.0, '10': 55.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 8.04}
2025-02-16 00:42:24,690 [trainer.py] => CNN top1 curve: [8.04]
2025-02-16 00:42:24,690 [trainer.py] => CNN top5 curve: [35.7]

2025-02-16 00:42:24,691 [trainer.py] => All params: 7496351
2025-02-16 00:42:24,692 [trainer.py] => Trainable params: 7496351
2025-02-16 00:42:24,808 [der.py] => Learning on 15-25
2025-02-16 00:42:24,809 [der.py] => All params: 14992164
2025-02-16 00:42:24,810 [der.py] => Trainable params: 7511716
2025-02-16 00:42:24,880 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:42:24,880 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 00:42:35,467 [der.py] => Task 1, Epoch 1/1 => Loss 5.431, Loss_clf 3.045, Loss_aux 2.386, Train_accy 9.50, Test_accy 4.13
2025-02-16 00:42:46,107 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.657,  Train_accy 10.64, Test_accy 4.11
2025-02-16 00:42:46,108 [der.py] => do not weight align student!
2025-02-16 00:42:49,721 [der.py] => darknet eval: 
2025-02-16 00:42:49,721 [der.py] => CNN top1 curve: 4.11
2025-02-16 00:42:49,721 [der.py] => CNN top5 curve: 20.18
2025-02-16 00:42:53,520 [der.py] => Exemplar size: 0
2025-02-16 00:42:53,520 [trainer.py] => No NME accuracy.
2025-02-16 00:42:53,520 [trainer.py] => CNN: {'total': 4.11, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 1.67, '16': 92.78, '17': 2.22, '18': 0.0, '19': 0.0, '20': 1.11, '21': 5.0, '22': 0.0, '23': 0.0, 'old': 0.0, 'new': 10.28}
2025-02-16 00:42:53,520 [trainer.py] => CNN top1 curve: [8.04, 4.11]
2025-02-16 00:42:53,520 [trainer.py] => CNN top5 curve: [35.7, 19.82]

2025-02-16 00:42:53,522 [trainer.py] => All params: 14992164
2025-02-16 00:42:53,523 [trainer.py] => Trainable params: 7511716
2025-02-16 00:42:53,638 [der.py] => Learning on 25-35
2025-02-16 00:42:53,639 [der.py] => All params: 15002414
2025-02-16 00:42:53,640 [der.py] => Trainable params: 7521966
2025-02-16 00:42:53,717 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:42:53,717 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-16 00:43:13,166 [der.py] => Task 2, Epoch 1/1 => Loss 5.430, Loss_clf 3.036, Loss_aux 2.394, Train_accy 9.33, Test_accy 3.24
2025-02-16 00:43:25,033 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 2.342,  Train_accy 11.05, Test_accy 3.27
2025-02-16 00:43:25,034 [der.py] => do not weight align student!
2025-02-16 00:43:29,785 [der.py] => darknet eval: 
2025-02-16 00:43:29,785 [der.py] => CNN top1 curve: 3.27
2025-02-16 00:43:29,785 [der.py] => CNN top5 curve: 14.52
2025-02-16 00:43:34,776 [der.py] => Exemplar size: 0
2025-02-16 00:43:34,776 [trainer.py] => No NME accuracy.
2025-02-16 00:43:34,777 [trainer.py] => CNN: {'total': 3.22, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 24.44, '27': 0.0, '28': 6.67, '29': 0.56, '30': 73.33, '31': 5.56, '32': 0.0, '33': 0.0, 'old': 0.0, 'new': 11.28}
2025-02-16 00:43:34,777 [trainer.py] => CNN top1 curve: [8.04, 4.11, 3.22]
2025-02-16 00:43:34,777 [trainer.py] => CNN top5 curve: [35.7, 19.82, 14.73]

2025-02-16 00:43:34,778 [trainer.py] => All params: 15002414
2025-02-16 00:43:34,779 [trainer.py] => Trainable params: 7521966
2025-02-16 00:43:34,893 [der.py] => Learning on 35-45
2025-02-16 00:43:34,894 [der.py] => All params: 15012664
2025-02-16 00:43:34,895 [der.py] => Trainable params: 7532216
2025-02-16 00:43:34,982 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:43:34,982 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-16 00:44:55,648 [der.py] => Task 3, Epoch 1/1 => Loss 5.880, Loss_clf 3.483, Loss_aux 2.397, Train_accy 9.83, Test_accy 2.44
2025-02-16 00:45:08,406 [der.py] => SNet: Task 3, Epoch 1/1 => Loss 2.295,  Train_accy 11.31, Test_accy 2.72
2025-02-16 00:45:08,407 [der.py] => do not weight align student!
2025-02-16 00:45:14,107 [der.py] => darknet eval: 
2025-02-16 00:45:14,108 [der.py] => CNN top1 curve: 2.72
2025-02-16 00:45:14,108 [der.py] => CNN top5 curve: 11.21
2025-02-16 00:45:20,108 [der.py] => Exemplar size: 0
2025-02-16 00:45:20,108 [trainer.py] => No NME accuracy.
2025-02-16 00:45:20,108 [trainer.py] => CNN: {'total': 2.44, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.56, '37': 7.22, '38': 93.89, '39': 1.11, '40': 0.0, '41': 0.0, '42': 7.22, '43': 0.0, 'old': 0.0, 'new': 11.0}
2025-02-16 00:45:20,108 [trainer.py] => CNN top1 curve: [8.04, 4.11, 3.22, 2.44]
2025-02-16 00:45:20,108 [trainer.py] => CNN top5 curve: [35.7, 19.82, 14.73, 11.44]

2025-02-16 00:45:20,110 [trainer.py] => All params: 15012664
2025-02-16 00:45:20,111 [trainer.py] => Trainable params: 7532216
2025-02-16 00:45:20,225 [der.py] => Learning on 45-55
2025-02-16 00:45:20,226 [der.py] => All params: 15022914
2025-02-16 00:45:20,227 [der.py] => Trainable params: 7542466
2025-02-16 00:45:20,327 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 00:45:20,328 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-16 00:46:46,714 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 00:46:46,715 [trainer.py] => config: ./exps/der.json
2025-02-16 00:46:46,715 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 00:46:46,715 [trainer.py] => prefix: reproduce
2025-02-16 00:46:46,715 [trainer.py] => dataset: xrfdataset
2025-02-16 00:46:46,715 [trainer.py] => memory_size: 1650
2025-02-16 00:46:46,715 [trainer.py] => memory_per_class: 30
2025-02-16 00:46:46,715 [trainer.py] => fixed_memory: True
2025-02-16 00:46:46,715 [trainer.py] => shuffle: True
2025-02-16 00:46:46,715 [trainer.py] => init_cls: 15
2025-02-16 00:46:46,715 [trainer.py] => increment: 10
2025-02-16 00:46:46,715 [trainer.py] => model_name: der
2025-02-16 00:46:46,715 [trainer.py] => compression_epochs: 130
2025-02-16 00:46:46,715 [trainer.py] => compression_lr: 0.1
2025-02-16 00:46:46,715 [trainer.py] => is_student_wa: False
2025-02-16 00:46:46,715 [trainer.py] => wa_value: 1
2025-02-16 00:46:46,715 [trainer.py] => T: 2
2025-02-16 00:46:46,715 [trainer.py] => convnet_type: resnet34
2025-02-16 00:46:46,715 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 00:46:46,715 [trainer.py] => seed: 1993
2025-02-16 00:46:46,727 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:46:46,732 [data.py] => 加载完毕XRF原始数据集
2025-02-16 00:46:46,733 [trainer.py] => All params: 0
2025-02-16 00:46:46,733 [trainer.py] => Trainable params: 0
2025-02-16 00:46:46,856 [der.py] => Learning on 0-15
2025-02-16 00:46:46,857 [der.py] => All params: 7496351
2025-02-16 00:46:46,857 [der.py] => Trainable params: 7496351
2025-02-16 01:03:41,855 [der.py] => Task 0, Epoch 150/150 => Loss 0.043, Train_accy 99.62
2025-02-16 01:03:44,261 [der.py] => Exemplar size: 0
2025-02-16 01:03:44,262 [trainer.py] => No NME accuracy.
2025-02-16 01:03:44,262 [trainer.py] => CNN: {'total': 79.11, '0': 96.11, '1': 90.56, '2': 79.44, '3': 60.56, '4': 88.89, '5': 73.89, '6': 59.44, '7': 74.44, '8': 88.89, '9': 55.0, '10': 93.89, '11': 98.89, '12': 72.78, '13': 71.11, 'old': 0, 'new': 79.11}
2025-02-16 01:03:44,262 [trainer.py] => CNN top1 curve: [79.11]
2025-02-16 01:03:44,262 [trainer.py] => CNN top5 curve: [98.52]

2025-02-16 01:03:44,263 [trainer.py] => All params: 7496351
2025-02-16 01:03:44,264 [trainer.py] => Trainable params: 7496351
2025-02-16 01:03:44,381 [der.py] => Learning on 15-25
2025-02-16 01:03:44,382 [der.py] => All params: 14992164
2025-02-16 01:03:44,383 [der.py] => Trainable params: 7511716
2025-02-16 01:03:44,452 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 01:03:44,453 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 01:18:59,499 [der.py] => Task 1, Epoch 150/150 => Loss 0.002, Loss_clf 0.001, Loss_aux 0.001, Train_accy 100.00
2025-02-16 01:19:09,000 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 1.809,  Train_accy 42.38, Test_accy 20.51
2025-02-16 01:19:14,843 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.434,  Train_accy 60.26
2025-02-16 01:19:20,277 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.232,  Train_accy 73.24
2025-02-16 01:19:25,924 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.135,  Train_accy 80.69
2025-02-16 01:19:31,725 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.050,  Train_accy 85.67
2025-02-16 01:19:41,226 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.998,  Train_accy 88.95, Test_accy 32.76
2025-02-16 01:19:46,850 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 0.950,  Train_accy 92.40
2025-02-16 01:19:52,744 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.917,  Train_accy 94.19
2025-02-16 01:19:58,568 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.891,  Train_accy 95.93
2025-02-16 01:20:04,243 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.871,  Train_accy 97.02
2025-02-16 01:20:13,486 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.860,  Train_accy 97.69, Test_accy 35.44
2025-02-16 01:20:19,416 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.849,  Train_accy 98.05
2025-02-16 01:20:25,188 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.834,  Train_accy 99.00
2025-02-16 01:20:30,899 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.831,  Train_accy 99.00
2025-02-16 01:20:36,469 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.823,  Train_accy 99.36
2025-02-16 01:20:45,903 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.820,  Train_accy 99.29, Test_accy 36.58
2025-02-16 01:20:51,742 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.821,  Train_accy 99.36
2025-02-16 01:20:57,621 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.816,  Train_accy 99.40
2025-02-16 01:21:03,285 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.814,  Train_accy 99.43
2025-02-16 01:21:09,038 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.808,  Train_accy 99.69
2025-02-16 01:21:18,367 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.807,  Train_accy 99.81, Test_accy 37.47
2025-02-16 01:21:24,148 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.802,  Train_accy 99.90
2025-02-16 01:21:29,943 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.803,  Train_accy 99.79
2025-02-16 01:21:35,612 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.802,  Train_accy 99.86
2025-02-16 01:21:41,401 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.800,  Train_accy 99.81
2025-02-16 01:21:50,568 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.795,  Train_accy 99.95, Test_accy 37.69
2025-02-16 01:21:56,544 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.795,  Train_accy 99.95
2025-02-16 01:22:02,385 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.795,  Train_accy 99.86
2025-02-16 01:22:08,128 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.791,  Train_accy 99.93
2025-02-16 01:22:14,067 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.793,  Train_accy 99.93
2025-02-16 01:22:23,582 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.793,  Train_accy 99.93, Test_accy 37.49
2025-02-16 01:22:29,511 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.788,  Train_accy 99.98
2025-02-16 01:22:35,199 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.789,  Train_accy 99.93
2025-02-16 01:22:41,008 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.790,  Train_accy 99.93
2025-02-16 01:22:46,719 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.789,  Train_accy 99.98
2025-02-16 01:22:56,553 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.789,  Train_accy 99.93, Test_accy 37.96
2025-02-16 01:23:02,358 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.787,  Train_accy 99.95
2025-02-16 01:23:08,373 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.788,  Train_accy 99.95
2025-02-16 01:23:13,910 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.787,  Train_accy 99.90
2025-02-16 01:23:19,667 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.786,  Train_accy 100.00
2025-02-16 01:23:29,018 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.784,  Train_accy 99.90, Test_accy 37.80
2025-02-16 01:23:34,703 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.784,  Train_accy 99.95
2025-02-16 01:23:40,567 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.783,  Train_accy 100.00
2025-02-16 01:23:46,432 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.783,  Train_accy 100.00
2025-02-16 01:23:52,347 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.782,  Train_accy 99.98
2025-02-16 01:24:01,831 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.782,  Train_accy 100.00, Test_accy 37.91
2025-02-16 01:24:07,414 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.784,  Train_accy 100.00
2025-02-16 01:24:13,292 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.782,  Train_accy 99.98
2025-02-16 01:24:19,118 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.781,  Train_accy 100.00
2025-02-16 01:24:24,414 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.781,  Train_accy 100.00
2025-02-16 01:24:33,877 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.781,  Train_accy 100.00, Test_accy 37.67
2025-02-16 01:24:39,651 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.780,  Train_accy 99.95
2025-02-16 01:24:45,731 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.779,  Train_accy 100.00
2025-02-16 01:24:51,441 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.779,  Train_accy 99.98
2025-02-16 01:24:56,907 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.782,  Train_accy 99.93
2025-02-16 01:25:06,455 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.779,  Train_accy 99.93, Test_accy 38.11
2025-02-16 01:25:12,182 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.776,  Train_accy 99.98
2025-02-16 01:25:17,815 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.778,  Train_accy 99.98
2025-02-16 01:25:23,467 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.777,  Train_accy 100.00
2025-02-16 01:25:29,302 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.777,  Train_accy 100.00
2025-02-16 01:25:58,683 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 01:25:58,683 [trainer.py] => config: ./exps/der.json
2025-02-16 01:25:58,684 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 01:25:58,684 [trainer.py] => prefix: reproduce
2025-02-16 01:25:58,684 [trainer.py] => dataset: xrfdataset
2025-02-16 01:25:58,684 [trainer.py] => memory_size: 1650
2025-02-16 01:25:58,684 [trainer.py] => memory_per_class: 30
2025-02-16 01:25:58,684 [trainer.py] => fixed_memory: True
2025-02-16 01:25:58,684 [trainer.py] => shuffle: True
2025-02-16 01:25:58,684 [trainer.py] => init_cls: 15
2025-02-16 01:25:58,684 [trainer.py] => increment: 10
2025-02-16 01:25:58,684 [trainer.py] => model_name: der
2025-02-16 01:25:58,684 [trainer.py] => compression_epochs: 130
2025-02-16 01:25:58,684 [trainer.py] => compression_lr: 0.1
2025-02-16 01:25:58,684 [trainer.py] => is_student_wa: False
2025-02-16 01:25:58,684 [trainer.py] => wa_value: 1
2025-02-16 01:25:58,684 [trainer.py] => T: 2
2025-02-16 01:25:58,684 [trainer.py] => convnet_type: resnet34
2025-02-16 01:25:58,684 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-16 01:25:58,684 [trainer.py] => seed: 1993
2025-02-16 01:25:58,696 [data.py] => 加载完毕XRF原始数据集
2025-02-16 01:25:58,701 [data.py] => 加载完毕XRF原始数据集
2025-02-16 01:25:58,702 [trainer.py] => All params: 0
2025-02-16 01:25:58,702 [trainer.py] => Trainable params: 0
2025-02-16 01:25:58,829 [der.py] => Learning on 0-15
2025-02-16 01:25:58,830 [der.py] => All params: 7496351
2025-02-16 01:25:58,830 [der.py] => Trainable params: 7496351
2025-02-16 01:43:26,337 [der.py] => Task 0, Epoch 150/150 => Loss 0.043, Train_accy 99.62
2025-02-16 01:43:26,338 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 01:43:51,392 [der.py] => Exemplar size: 450
2025-02-16 01:43:51,392 [trainer.py] => CNN: {'total': 79.11, '0': 96.11, '1': 90.56, '2': 79.44, '3': 60.56, '4': 88.89, '5': 73.89, '6': 59.44, '7': 74.44, '8': 88.89, '9': 55.0, '10': 93.89, '11': 98.89, '12': 72.78, '13': 71.11, 'old': 0, 'new': 79.11}
2025-02-16 01:43:51,392 [trainer.py] => NME: {'total': 78.7, '0': 97.78, '1': 88.33, '2': 77.22, '3': 61.67, '4': 77.78, '5': 64.44, '6': 53.33, '7': 81.11, '8': 84.44, '9': 67.22, '10': 91.11, '11': 98.89, '12': 75.0, '13': 77.78, 'old': 0, 'new': 78.7}
2025-02-16 01:43:51,392 [trainer.py] => CNN top1 curve: [79.11]
2025-02-16 01:43:51,392 [trainer.py] => CNN top5 curve: [98.52]
2025-02-16 01:43:51,392 [trainer.py] => NME top1 curve: [78.7]
2025-02-16 01:43:51,392 [trainer.py] => NME top5 curve: [98.52]

2025-02-16 01:43:51,393 [trainer.py] => All params: 7496351
2025-02-16 01:43:51,393 [trainer.py] => Trainable params: 7496351
2025-02-16 01:43:51,496 [der.py] => Learning on 15-25
2025-02-16 01:43:51,496 [der.py] => All params: 14992164
2025-02-16 01:43:51,497 [der.py] => Trainable params: 7511716
2025-02-16 01:43:51,564 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 01:43:51,564 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 01:59:37,617 [der.py] => Task 1, Epoch 150/150 => Loss 0.008, Loss_clf 0.004, Loss_aux 0.004, Train_accy 99.96
2025-02-16 01:59:46,938 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.186,  Train_accy 35.74, Test_accy 42.71
2025-02-16 01:59:53,231 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.705,  Train_accy 58.13
2025-02-16 01:59:59,269 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.519,  Train_accy 67.31
2025-02-16 02:00:05,454 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.411,  Train_accy 72.80
2025-02-16 02:00:11,496 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.299,  Train_accy 78.43
2025-02-16 02:00:21,206 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.235,  Train_accy 81.70, Test_accy 52.36
2025-02-16 02:00:27,229 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.182,  Train_accy 84.28
2025-02-16 02:00:33,243 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.136,  Train_accy 86.99
2025-02-16 02:00:39,204 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.096,  Train_accy 88.28
2025-02-16 02:00:45,273 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.046,  Train_accy 91.33
2025-02-16 02:00:54,446 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.007,  Train_accy 92.99, Test_accy 60.33
2025-02-16 02:01:00,494 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.989,  Train_accy 93.91
2025-02-16 02:01:07,396 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.988,  Train_accy 93.55
2025-02-16 02:01:13,233 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.961,  Train_accy 94.95
2025-02-16 02:01:19,314 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.951,  Train_accy 95.29
2025-02-16 02:01:28,634 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.963,  Train_accy 94.58, Test_accy 64.44
2025-02-16 02:01:34,617 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.946,  Train_accy 95.01
2025-02-16 02:01:41,287 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.919,  Train_accy 96.75
2025-02-16 02:01:47,807 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.908,  Train_accy 97.25
2025-02-16 02:01:53,868 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.904,  Train_accy 97.27
2025-02-16 02:02:03,477 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.898,  Train_accy 96.97, Test_accy 68.49
2025-02-16 02:02:09,540 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.887,  Train_accy 97.66
2025-02-16 02:02:15,782 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.880,  Train_accy 97.72
2025-02-16 02:02:21,967 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.875,  Train_accy 97.85
2025-02-16 02:02:28,099 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.873,  Train_accy 97.68
2025-02-16 02:02:38,916 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.866,  Train_accy 98.04, Test_accy 70.20
2025-02-16 02:02:44,987 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.863,  Train_accy 98.19
2025-02-16 02:02:51,208 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.860,  Train_accy 98.11
2025-02-16 02:02:57,860 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.861,  Train_accy 98.11
2025-02-16 02:03:03,939 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.856,  Train_accy 98.11
2025-02-16 02:03:13,243 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.859,  Train_accy 97.89, Test_accy 70.69
2025-02-16 02:03:19,736 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.864,  Train_accy 97.87
2025-02-16 02:03:25,850 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.857,  Train_accy 98.11
2025-02-16 02:03:31,945 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.849,  Train_accy 98.04
2025-02-16 02:03:38,066 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.852,  Train_accy 98.04
2025-02-16 02:03:47,797 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.848,  Train_accy 98.30, Test_accy 72.78
2025-02-16 02:03:54,216 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.843,  Train_accy 98.52
2025-02-16 02:04:00,246 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.845,  Train_accy 98.39
2025-02-16 02:04:06,598 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.842,  Train_accy 98.28
2025-02-16 02:04:12,650 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.839,  Train_accy 98.49
2025-02-16 02:04:22,614 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.840,  Train_accy 98.15, Test_accy 72.22
2025-02-16 02:04:28,516 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.841,  Train_accy 98.13
2025-02-16 02:04:34,405 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.837,  Train_accy 98.17
2025-02-16 02:04:40,510 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.831,  Train_accy 98.32
2025-02-16 02:04:46,453 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.832,  Train_accy 98.37
2025-02-16 02:04:55,886 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.830,  Train_accy 98.04, Test_accy 72.58
2025-02-16 02:05:01,876 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.831,  Train_accy 98.56
2025-02-16 02:05:07,845 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.828,  Train_accy 98.58
2025-02-16 02:05:13,998 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.826,  Train_accy 98.47
2025-02-16 02:05:19,876 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.828,  Train_accy 98.34
2025-02-16 02:05:29,166 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.829,  Train_accy 98.30, Test_accy 72.27
2025-02-16 02:05:34,970 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.829,  Train_accy 98.60
2025-02-16 02:05:40,961 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.824,  Train_accy 98.39
2025-02-16 02:05:46,907 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.826,  Train_accy 98.19
2025-02-16 02:05:52,860 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.824,  Train_accy 98.56
2025-02-16 02:06:02,819 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.825,  Train_accy 98.56, Test_accy 72.58
2025-02-16 02:06:08,869 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.824,  Train_accy 98.41
2025-02-16 02:06:15,035 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.818,  Train_accy 98.39
2025-02-16 02:06:20,922 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.817,  Train_accy 98.39
2025-02-16 02:06:27,418 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.818,  Train_accy 98.32
2025-02-16 02:06:36,669 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.818,  Train_accy 98.52, Test_accy 73.11
2025-02-16 02:06:42,947 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.818,  Train_accy 98.32
2025-02-16 02:06:48,937 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.815,  Train_accy 98.62
2025-02-16 02:06:54,900 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.814,  Train_accy 98.62
2025-02-16 02:07:00,829 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.817,  Train_accy 98.73
2025-02-16 02:07:10,278 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.815,  Train_accy 98.37, Test_accy 73.38
2025-02-16 02:07:16,208 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.817,  Train_accy 98.45
2025-02-16 02:07:22,064 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.814,  Train_accy 98.24
2025-02-16 02:07:28,280 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.814,  Train_accy 98.62
2025-02-16 02:07:34,210 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.811,  Train_accy 98.24
2025-02-16 02:07:43,986 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.812,  Train_accy 98.47, Test_accy 72.91
2025-02-16 02:07:50,152 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.811,  Train_accy 98.56
2025-02-16 02:07:56,146 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.810,  Train_accy 98.56
2025-02-16 02:08:02,109 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.809,  Train_accy 98.84
2025-02-16 02:08:08,016 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.810,  Train_accy 98.56
2025-02-16 02:08:17,882 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.810,  Train_accy 98.65, Test_accy 73.53
2025-02-16 02:08:23,707 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.808,  Train_accy 98.41
2025-02-16 02:08:29,901 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.808,  Train_accy 98.52
2025-02-16 02:08:35,810 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.809,  Train_accy 98.54
2025-02-16 02:08:41,801 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.806,  Train_accy 98.71
2025-02-16 02:08:51,369 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.807,  Train_accy 98.67, Test_accy 73.16
2025-02-16 02:08:57,631 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.805,  Train_accy 98.62
2025-02-16 02:09:03,780 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.806,  Train_accy 98.56
2025-02-16 02:09:09,638 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.802,  Train_accy 98.60
2025-02-16 02:09:15,527 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.804,  Train_accy 98.62
2025-02-16 02:09:25,009 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.803,  Train_accy 98.58, Test_accy 73.51
2025-02-16 02:09:31,844 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.807,  Train_accy 98.49
2025-02-16 02:09:37,930 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.804,  Train_accy 98.54
2025-02-16 02:09:44,385 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.805,  Train_accy 98.34
2025-02-16 02:09:50,468 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.804,  Train_accy 98.56
2025-02-16 02:10:01,125 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.802,  Train_accy 98.43, Test_accy 73.24
2025-02-16 02:10:07,876 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.805,  Train_accy 98.69
2025-02-16 02:10:14,531 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.803,  Train_accy 98.49
2025-02-16 02:10:20,380 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.805,  Train_accy 98.65
2025-02-16 02:10:26,657 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.804,  Train_accy 98.49
2025-02-16 02:10:36,675 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.802,  Train_accy 98.73, Test_accy 74.20
2025-02-16 02:10:42,579 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.802,  Train_accy 98.71
2025-02-16 02:10:48,857 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.805,  Train_accy 98.56
2025-02-16 02:10:54,760 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.802,  Train_accy 98.65
2025-02-16 02:11:01,038 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.802,  Train_accy 98.52
2025-02-16 02:11:10,482 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.803,  Train_accy 98.69, Test_accy 73.40
2025-02-16 02:11:16,450 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.802,  Train_accy 98.73
2025-02-16 02:11:22,417 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.800,  Train_accy 98.47
2025-02-16 02:11:28,185 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.802,  Train_accy 98.52
2025-02-16 02:11:34,275 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.802,  Train_accy 98.37
2025-02-16 02:11:43,411 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.805,  Train_accy 98.65, Test_accy 73.62
2025-02-16 02:11:49,341 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.805,  Train_accy 98.88
2025-02-16 02:11:55,116 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.798,  Train_accy 98.56
2025-02-16 02:12:01,065 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.803,  Train_accy 98.71
2025-02-16 02:12:06,957 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.802,  Train_accy 98.65
2025-02-16 02:12:16,236 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.800,  Train_accy 98.67, Test_accy 73.56
2025-02-16 02:12:22,213 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.800,  Train_accy 98.52
2025-02-16 02:12:28,020 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.801,  Train_accy 98.67
2025-02-16 02:12:33,963 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.801,  Train_accy 98.60
2025-02-16 02:12:39,738 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.799,  Train_accy 98.71
2025-02-16 02:12:49,017 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.797,  Train_accy 98.52, Test_accy 73.38
2025-02-16 02:12:54,865 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.799,  Train_accy 98.77
2025-02-16 02:13:00,682 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.800,  Train_accy 98.73
2025-02-16 02:13:06,537 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.800,  Train_accy 98.56
2025-02-16 02:13:12,410 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.803,  Train_accy 98.58
2025-02-16 02:13:21,832 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.801,  Train_accy 98.69, Test_accy 73.71
2025-02-16 02:13:27,643 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.797,  Train_accy 98.60
2025-02-16 02:13:33,896 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.798,  Train_accy 98.77
2025-02-16 02:13:39,691 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.798,  Train_accy 98.58
2025-02-16 02:13:45,594 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.799,  Train_accy 98.58
2025-02-16 02:13:55,432 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.800,  Train_accy 98.69, Test_accy 73.67
2025-02-16 02:14:01,869 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.800,  Train_accy 98.67
2025-02-16 02:14:07,655 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.800,  Train_accy 98.67
2025-02-16 02:14:14,186 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.801,  Train_accy 98.34
2025-02-16 02:14:21,078 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.805,  Train_accy 98.58
2025-02-16 02:14:21,079 [der.py] => do not weight align student!
2025-02-16 02:14:24,303 [der.py] => darknet eval: 
2025-02-16 02:14:24,304 [der.py] => CNN top1 curve: 73.78
2025-02-16 02:14:24,304 [der.py] => CNN top5 curve: 96.67
2025-02-16 02:14:24,306 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 02:14:51,683 [der.py] => Exemplar size: 750
2025-02-16 02:14:51,683 [trainer.py] => CNN: {'total': 79.33, '0': 87.22, '1': 71.11, '2': 81.11, '3': 70.56, '4': 82.78, '5': 61.11, '6': 50.0, '7': 59.44, '8': 56.11, '9': 63.33, '10': 95.0, '11': 98.89, '12': 71.11, '13': 72.22, '14': 77.22, '15': 83.33, '16': 91.11, '17': 92.22, '18': 91.67, '19': 88.89, '20': 95.0, '21': 85.0, '22': 88.89, '23': 84.44, 'old': 73.15, 'new': 88.61}
2025-02-16 02:14:51,683 [trainer.py] => NME: {'total': 76.78, '0': 82.22, '1': 61.67, '2': 75.56, '3': 60.0, '4': 76.11, '5': 56.11, '6': 51.11, '7': 47.78, '8': 32.22, '9': 66.67, '10': 90.0, '11': 98.89, '12': 75.56, '13': 73.89, '14': 78.89, '15': 80.0, '16': 92.22, '17': 91.11, '18': 91.11, '19': 86.11, '20': 92.22, '21': 91.11, '22': 95.0, '23': 87.22, 'old': 68.44, 'new': 89.28}
2025-02-16 02:14:51,683 [trainer.py] => CNN top1 curve: [79.11, 79.33]
2025-02-16 02:14:51,683 [trainer.py] => CNN top5 curve: [98.52, 97.96]
2025-02-16 02:14:51,683 [trainer.py] => NME top1 curve: [78.7, 76.78]
2025-02-16 02:14:51,683 [trainer.py] => NME top5 curve: [98.52, 97.73]

2025-02-16 02:14:51,684 [trainer.py] => All params: 14992164
2025-02-16 02:14:51,685 [trainer.py] => Trainable params: 7511716
2025-02-16 02:14:51,793 [der.py] => Learning on 25-35
2025-02-16 02:14:51,794 [der.py] => All params: 15002414
2025-02-16 02:14:51,794 [der.py] => Trainable params: 7521966
2025-02-16 02:14:51,871 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 02:14:51,872 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-16 02:31:31,016 [der.py] => Task 2, Epoch 150/150 => Loss 0.005, Loss_clf 0.003, Loss_aux 0.002, Train_accy 100.00
2025-02-16 02:31:41,748 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.233,  Train_accy 47.68, Test_accy 51.35
2025-02-16 02:31:48,042 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.938,  Train_accy 65.96
2025-02-16 02:31:54,701 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.832,  Train_accy 72.79
2025-02-16 02:32:01,065 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.760,  Train_accy 78.04
2025-02-16 02:32:07,386 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.684,  Train_accy 82.63
2025-02-16 02:32:18,333 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.651,  Train_accy 84.36, Test_accy 56.78
2025-02-16 02:32:24,560 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.602,  Train_accy 87.35
2025-02-16 02:32:30,834 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.570,  Train_accy 89.03
2025-02-16 02:32:37,305 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.558,  Train_accy 90.40
2025-02-16 02:32:43,750 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.529,  Train_accy 92.02
2025-02-16 02:32:54,231 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.514,  Train_accy 92.67, Test_accy 61.08
2025-02-16 02:33:00,486 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.506,  Train_accy 93.31
2025-02-16 02:33:06,850 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.490,  Train_accy 93.49
2025-02-16 02:33:12,969 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.481,  Train_accy 94.18
2025-02-16 02:33:19,232 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.472,  Train_accy 94.85
2025-02-16 02:33:29,678 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.466,  Train_accy 95.27, Test_accy 64.37
2025-02-16 02:33:36,107 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.458,  Train_accy 95.07
2025-02-16 02:33:42,362 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.449,  Train_accy 95.78
2025-02-16 02:33:48,647 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.448,  Train_accy 95.37
2025-02-16 02:33:54,958 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.445,  Train_accy 95.94
2025-02-16 02:34:05,327 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.439,  Train_accy 95.88, Test_accy 65.46
2025-02-16 02:34:11,583 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.433,  Train_accy 96.08
2025-02-16 02:34:17,699 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.429,  Train_accy 96.20
2025-02-16 02:34:23,937 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.430,  Train_accy 95.96
2025-02-16 02:34:30,215 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.425,  Train_accy 96.63
2025-02-16 02:34:40,714 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.420,  Train_accy 96.28, Test_accy 65.97
2025-02-16 02:34:47,014 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.418,  Train_accy 96.59
2025-02-16 02:34:53,388 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.417,  Train_accy 96.65
2025-02-16 02:34:59,574 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.412,  Train_accy 96.61
2025-02-16 02:35:05,981 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.413,  Train_accy 96.65
2025-02-16 02:35:16,559 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.409,  Train_accy 96.71, Test_accy 65.94
2025-02-16 02:35:22,953 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.409,  Train_accy 97.13
2025-02-16 02:35:29,222 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.410,  Train_accy 97.09
2025-02-16 02:35:35,398 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.406,  Train_accy 96.97
2025-02-16 02:35:41,521 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.402,  Train_accy 97.07
2025-02-16 02:35:52,785 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.404,  Train_accy 96.83, Test_accy 66.79
2025-02-16 02:35:59,253 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.399,  Train_accy 97.09
2025-02-16 02:36:05,507 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.398,  Train_accy 97.05
2025-02-16 02:36:11,847 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.401,  Train_accy 97.21
2025-02-16 02:36:18,179 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.397,  Train_accy 97.19
2025-02-16 02:36:28,624 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.396,  Train_accy 97.66, Test_accy 66.94
2025-02-16 02:36:34,746 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.393,  Train_accy 97.52
2025-02-16 02:36:41,022 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.393,  Train_accy 97.43
2025-02-16 02:36:47,402 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.392,  Train_accy 97.45
2025-02-16 02:36:53,917 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.390,  Train_accy 97.39
2025-02-16 02:37:04,502 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.391,  Train_accy 97.39, Test_accy 66.22
2025-02-16 02:37:10,871 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.390,  Train_accy 97.27
2025-02-16 02:37:17,195 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.390,  Train_accy 97.07
2025-02-16 02:37:23,615 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.391,  Train_accy 97.45
2025-02-16 02:37:29,886 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.387,  Train_accy 97.47
2025-02-16 02:37:40,938 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.387,  Train_accy 97.56, Test_accy 66.73
2025-02-16 02:37:47,638 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.386,  Train_accy 97.43
2025-02-16 02:37:54,602 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.384,  Train_accy 97.54
2025-02-16 02:38:01,416 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.384,  Train_accy 97.39
2025-02-16 02:38:07,712 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.381,  Train_accy 97.49
2025-02-16 02:38:19,051 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.382,  Train_accy 97.54, Test_accy 67.25
2025-02-16 02:38:26,017 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.380,  Train_accy 97.33
2025-02-16 02:38:32,831 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.384,  Train_accy 97.78
2025-02-16 02:38:39,211 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.383,  Train_accy 97.43
2025-02-16 02:38:45,767 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.382,  Train_accy 97.43
2025-02-16 02:38:56,456 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.382,  Train_accy 97.52, Test_accy 66.89
2025-02-16 02:39:02,810 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.382,  Train_accy 97.35
2025-02-16 02:39:09,105 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.380,  Train_accy 97.60
2025-02-16 02:39:15,247 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.377,  Train_accy 97.58
2025-02-16 02:39:21,710 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.377,  Train_accy 97.52
2025-02-16 02:39:32,165 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.378,  Train_accy 97.45, Test_accy 67.63
2025-02-16 02:39:38,871 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.377,  Train_accy 97.68
2025-02-16 02:39:45,207 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.373,  Train_accy 97.64
2025-02-16 02:39:51,422 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.375,  Train_accy 97.52
2025-02-16 02:39:57,628 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.374,  Train_accy 97.47
2025-02-16 02:40:08,329 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.374,  Train_accy 97.80, Test_accy 67.11
2025-02-16 02:40:14,529 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.374,  Train_accy 97.56
2025-02-16 02:40:20,893 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.373,  Train_accy 97.47
2025-02-16 02:40:27,099 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.373,  Train_accy 97.58
2025-02-16 02:40:33,268 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.376,  Train_accy 97.56
2025-02-16 02:40:43,788 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.372,  Train_accy 97.60, Test_accy 66.92
2025-02-16 02:40:50,148 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.373,  Train_accy 97.66
2025-02-16 02:40:56,297 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.372,  Train_accy 97.82
2025-02-16 02:41:02,565 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.371,  Train_accy 97.70
2025-02-16 02:41:08,829 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.370,  Train_accy 97.58
2025-02-16 02:41:19,100 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.370,  Train_accy 97.66, Test_accy 67.06
2025-02-16 02:41:25,334 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.373,  Train_accy 97.47
2025-02-16 02:41:31,728 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.371,  Train_accy 97.74
2025-02-16 02:41:38,046 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.369,  Train_accy 97.64
2025-02-16 02:41:44,385 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.370,  Train_accy 97.56
2025-02-16 02:41:55,158 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.371,  Train_accy 97.52, Test_accy 67.14
2025-02-16 02:42:01,364 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.372,  Train_accy 97.76
2025-02-16 02:42:07,660 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.369,  Train_accy 97.92
2025-02-16 02:42:13,981 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.370,  Train_accy 97.86
2025-02-16 02:42:20,291 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.368,  Train_accy 97.94
2025-02-16 02:42:31,249 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.369,  Train_accy 97.94, Test_accy 67.52
2025-02-16 02:42:37,587 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.369,  Train_accy 97.88
2025-02-16 02:42:43,748 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.369,  Train_accy 97.62
2025-02-16 02:42:50,000 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.368,  Train_accy 97.68
2025-02-16 02:42:56,145 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.368,  Train_accy 97.70
2025-02-16 02:43:06,725 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.368,  Train_accy 97.74, Test_accy 67.22
2025-02-16 02:43:12,872 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.368,  Train_accy 97.80
2025-02-16 02:43:19,159 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.369,  Train_accy 97.88
2025-02-16 02:43:25,412 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.368,  Train_accy 97.84
2025-02-16 02:43:31,620 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.368,  Train_accy 97.78
2025-02-16 02:43:41,942 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.367,  Train_accy 97.82, Test_accy 67.11
2025-02-16 02:43:48,256 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.366,  Train_accy 97.47
2025-02-16 02:43:54,760 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.367,  Train_accy 97.54
2025-02-16 02:44:01,006 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.366,  Train_accy 97.70
2025-02-16 02:44:07,316 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.368,  Train_accy 97.86
2025-02-16 02:44:18,342 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.366,  Train_accy 97.70, Test_accy 67.21
2025-02-16 02:44:25,237 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.366,  Train_accy 97.96
2025-02-16 02:44:32,027 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.367,  Train_accy 98.04
2025-02-16 02:44:39,111 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.364,  Train_accy 97.86
2025-02-16 02:44:45,715 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.366,  Train_accy 97.90
2025-02-16 02:44:57,984 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.366,  Train_accy 98.10, Test_accy 66.97
2025-02-16 02:45:04,840 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.365,  Train_accy 97.80
2025-02-16 02:45:12,069 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.365,  Train_accy 98.10
2025-02-16 02:45:18,591 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.366,  Train_accy 97.80
2025-02-16 02:45:25,552 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.365,  Train_accy 97.74
2025-02-16 02:45:36,880 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.365,  Train_accy 97.80, Test_accy 67.49
2025-02-16 02:45:43,828 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.366,  Train_accy 97.94
2025-02-16 02:45:50,757 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.367,  Train_accy 97.92
2025-02-16 02:45:57,375 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.366,  Train_accy 97.96
2025-02-16 02:46:03,643 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.364,  Train_accy 97.68
2025-02-16 02:46:14,196 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.365,  Train_accy 97.84, Test_accy 67.29
2025-02-16 02:46:20,425 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.366,  Train_accy 97.88
2025-02-16 02:46:26,871 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.365,  Train_accy 97.82
2025-02-16 02:46:33,067 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.365,  Train_accy 97.84
2025-02-16 02:46:39,403 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.366,  Train_accy 97.94
2025-02-16 02:46:49,991 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.364,  Train_accy 97.86, Test_accy 67.83
2025-02-16 02:46:56,481 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.365,  Train_accy 98.10
2025-02-16 02:47:02,828 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.366,  Train_accy 97.64
2025-02-16 02:47:09,195 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.365,  Train_accy 97.74
2025-02-16 02:47:15,778 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.366,  Train_accy 97.94
2025-02-16 02:47:15,779 [der.py] => do not weight align student!
2025-02-16 02:47:19,458 [der.py] => darknet eval: 
2025-02-16 02:47:19,458 [der.py] => CNN top1 curve: 67.57
2025-02-16 02:47:19,458 [der.py] => CNN top5 curve: 94.1
2025-02-16 02:47:19,461 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 02:47:54,794 [der.py] => Exemplar size: 1050
2025-02-16 02:47:54,794 [trainer.py] => CNN: {'total': 69.68, '0': 59.44, '1': 44.44, '2': 58.33, '3': 38.89, '4': 72.78, '5': 26.67, '6': 36.11, '7': 29.44, '8': 26.11, '9': 48.33, '10': 83.89, '11': 97.22, '12': 50.0, '13': 49.44, '14': 36.67, '15': 91.67, '16': 93.33, '17': 96.11, '18': 92.78, '19': 96.11, '20': 91.67, '21': 88.89, '22': 91.67, '23': 83.89, '24': 60.0, '25': 70.0, '26': 82.78, '27': 83.33, '28': 60.56, '29': 80.56, '30': 71.67, '31': 87.22, '32': 97.78, '33': 73.89, 'old': 65.76, 'new': 79.5}
2025-02-16 02:47:54,795 [trainer.py] => NME: {'total': 67.4, '0': 65.0, '1': 40.56, '2': 53.33, '3': 38.33, '4': 71.67, '5': 32.22, '6': 35.56, '7': 38.89, '8': 34.44, '9': 56.67, '10': 83.33, '11': 93.33, '12': 49.44, '13': 43.33, '14': 28.89, '15': 90.0, '16': 87.78, '17': 90.0, '18': 81.11, '19': 89.44, '20': 87.78, '21': 82.78, '22': 82.22, '23': 55.56, '24': 40.56, '25': 73.89, '26': 87.22, '27': 91.67, '28': 60.56, '29': 78.33, '30': 75.0, '31': 86.11, '32': 98.33, '33': 69.44, 'old': 62.09, 'new': 80.67}
2025-02-16 02:47:54,795 [trainer.py] => CNN top1 curve: [79.11, 79.33, 69.68]
2025-02-16 02:47:54,795 [trainer.py] => CNN top5 curve: [98.52, 97.96, 94.22]
2025-02-16 02:47:54,795 [trainer.py] => NME top1 curve: [78.7, 76.78, 67.4]
2025-02-16 02:47:54,795 [trainer.py] => NME top5 curve: [98.52, 97.73, 94.57]

2025-02-16 02:47:54,796 [trainer.py] => All params: 15002414
2025-02-16 02:47:54,796 [trainer.py] => Trainable params: 7521966
2025-02-16 02:47:54,898 [der.py] => Learning on 35-45
2025-02-16 02:47:54,899 [der.py] => All params: 15012664
2025-02-16 02:47:54,900 [der.py] => Trainable params: 7532216
2025-02-16 02:47:54,984 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 02:47:54,984 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-16 03:06:41,868 [der.py] => Task 3, Epoch 150/150 => Loss 0.105, Loss_clf 0.038, Loss_aux 0.067, Train_accy 99.98
2025-02-16 03:06:53,620 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.041,  Train_accy 48.42, Test_accy 40.85
2025-02-16 03:07:00,479 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.818,  Train_accy 62.86
2025-02-16 03:07:07,397 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.713,  Train_accy 67.16
2025-02-16 03:07:14,389 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.634,  Train_accy 70.30
2025-02-16 03:07:21,412 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.605,  Train_accy 73.62
2025-02-16 03:07:33,840 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.576,  Train_accy 73.03, Test_accy 48.67
2025-02-16 03:07:40,600 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.540,  Train_accy 75.16
2025-02-16 03:07:47,454 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.551,  Train_accy 75.79
2025-02-16 03:07:54,401 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.547,  Train_accy 76.70
2025-02-16 03:08:01,441 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.490,  Train_accy 78.42
2025-02-16 03:08:13,721 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.491,  Train_accy 78.13, Test_accy 51.67
2025-02-16 03:08:20,531 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.481,  Train_accy 77.75
2025-02-16 03:08:27,560 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.472,  Train_accy 79.09
2025-02-16 03:08:34,137 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.478,  Train_accy 79.14
2025-02-16 03:08:40,805 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.463,  Train_accy 79.73
2025-02-16 03:08:53,255 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.447,  Train_accy 79.58, Test_accy 52.19
2025-02-16 03:08:59,909 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.444,  Train_accy 80.06
2025-02-16 03:09:06,686 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.437,  Train_accy 80.32
2025-02-16 03:09:13,721 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.446,  Train_accy 79.58
2025-02-16 03:09:20,492 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.417,  Train_accy 80.08
2025-02-16 03:09:33,867 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.460,  Train_accy 80.55, Test_accy 54.63
2025-02-16 03:09:40,564 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.429,  Train_accy 80.48
2025-02-16 03:09:47,899 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.419,  Train_accy 80.61
2025-02-16 03:09:54,614 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.419,  Train_accy 80.55
2025-02-16 03:10:01,446 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.403,  Train_accy 80.57
2025-02-16 03:10:13,622 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.420,  Train_accy 80.36, Test_accy 50.53
2025-02-16 03:10:20,476 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.431,  Train_accy 80.93
2025-02-16 03:10:27,157 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.414,  Train_accy 80.53
2025-02-16 03:10:33,911 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.414,  Train_accy 80.78
2025-02-16 03:10:40,626 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.428,  Train_accy 80.11
2025-02-16 03:10:52,824 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.407,  Train_accy 80.86, Test_accy 50.96
2025-02-16 03:10:59,494 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.409,  Train_accy 81.14
2025-02-16 03:11:06,381 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.397,  Train_accy 80.90
2025-02-16 03:11:13,122 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.436,  Train_accy 79.94
2025-02-16 03:11:19,915 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.413,  Train_accy 80.86
2025-02-16 03:11:32,574 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.402,  Train_accy 81.58, Test_accy 56.83
2025-02-16 03:11:39,881 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.414,  Train_accy 81.16
2025-02-16 03:11:46,709 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.391,  Train_accy 80.78
2025-02-16 03:11:53,495 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.401,  Train_accy 81.66
2025-02-16 03:12:00,464 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.398,  Train_accy 81.33
2025-02-16 03:12:12,712 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.392,  Train_accy 81.12, Test_accy 54.84
2025-02-16 03:12:19,642 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.426,  Train_accy 80.06
2025-02-16 03:12:26,833 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.392,  Train_accy 80.82
2025-02-16 03:12:33,733 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.382,  Train_accy 81.20
2025-02-16 03:12:40,892 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.374,  Train_accy 81.47
2025-02-16 03:12:52,693 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.374,  Train_accy 81.09, Test_accy 55.00
2025-02-16 03:12:59,260 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.395,  Train_accy 81.01
2025-02-16 03:13:05,970 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.407,  Train_accy 80.99
2025-02-16 03:13:13,102 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.382,  Train_accy 81.71
2025-02-16 03:13:19,691 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.370,  Train_accy 81.73
2025-02-16 03:13:32,058 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.379,  Train_accy 81.62, Test_accy 53.43
2025-02-16 03:13:38,817 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.387,  Train_accy 82.06
2025-02-16 03:13:45,791 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.396,  Train_accy 81.43
2025-02-16 03:13:52,885 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.401,  Train_accy 80.97
2025-02-16 03:13:59,593 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.376,  Train_accy 81.68
2025-02-16 03:14:11,859 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.379,  Train_accy 81.83, Test_accy 56.70
2025-02-16 03:14:18,638 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.387,  Train_accy 81.18
2025-02-16 03:14:25,426 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.365,  Train_accy 80.95
2025-02-16 03:14:32,103 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.393,  Train_accy 81.33
2025-02-16 03:14:38,877 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.372,  Train_accy 81.68
2025-02-16 03:14:50,813 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.366,  Train_accy 81.28, Test_accy 59.62
2025-02-16 03:14:57,537 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.359,  Train_accy 81.24
2025-02-16 03:15:04,741 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.357,  Train_accy 81.43
2025-02-16 03:15:11,594 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.380,  Train_accy 81.94
2025-02-16 03:15:18,364 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.363,  Train_accy 82.00
2025-02-16 03:15:30,843 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.366,  Train_accy 81.10, Test_accy 57.41
2025-02-16 03:15:37,881 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.365,  Train_accy 81.50
2025-02-16 03:15:44,577 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.355,  Train_accy 81.71
2025-02-16 03:15:51,921 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.369,  Train_accy 81.18
2025-02-16 03:15:58,936 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.352,  Train_accy 81.56
2025-02-16 03:16:10,596 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.359,  Train_accy 81.58, Test_accy 52.85
2025-02-16 03:16:17,141 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.336,  Train_accy 81.90
2025-02-16 03:16:24,206 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.379,  Train_accy 81.94
2025-02-16 03:16:30,942 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.380,  Train_accy 80.95
2025-02-16 03:16:37,615 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.364,  Train_accy 81.81
2025-02-16 03:16:50,058 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.362,  Train_accy 81.70, Test_accy 56.07
2025-02-16 03:16:56,951 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.357,  Train_accy 81.94
2025-02-16 03:17:03,679 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.356,  Train_accy 81.33
2025-02-16 03:17:10,448 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.367,  Train_accy 81.98
2025-02-16 03:17:17,009 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.348,  Train_accy 81.58
2025-02-16 03:17:29,416 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.350,  Train_accy 81.77, Test_accy 55.86
2025-02-16 03:17:36,088 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.363,  Train_accy 81.75
2025-02-16 03:17:42,965 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.366,  Train_accy 82.04
2025-02-16 03:17:49,589 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.353,  Train_accy 81.45
2025-02-16 03:17:56,303 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.339,  Train_accy 81.30
2025-02-16 03:18:09,071 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.347,  Train_accy 81.50, Test_accy 52.30
2025-02-16 03:18:15,968 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.341,  Train_accy 82.17
2025-02-16 03:18:22,535 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.327,  Train_accy 82.19
2025-02-16 03:18:29,217 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.354,  Train_accy 81.18
2025-02-16 03:18:36,166 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.318,  Train_accy 81.89
2025-02-16 03:18:47,790 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.343,  Train_accy 81.49, Test_accy 49.68
2025-02-16 03:18:54,959 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.356,  Train_accy 81.85
2025-02-16 03:19:02,351 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.349,  Train_accy 81.92
2025-02-16 03:19:09,355 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.358,  Train_accy 81.37
2025-02-16 03:19:16,474 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.344,  Train_accy 81.92
2025-02-16 03:19:29,661 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.346,  Train_accy 81.75, Test_accy 55.77
2025-02-16 03:19:36,905 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.330,  Train_accy 82.30
2025-02-16 03:19:43,512 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.333,  Train_accy 81.73
2025-02-16 03:19:50,459 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.352,  Train_accy 81.71
2025-02-16 03:19:57,050 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.351,  Train_accy 81.30
2025-02-16 03:20:09,812 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.348,  Train_accy 81.62, Test_accy 57.67
2025-02-16 03:20:16,529 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.348,  Train_accy 82.02
2025-02-16 03:20:23,359 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.343,  Train_accy 81.96
2025-02-16 03:20:30,396 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.344,  Train_accy 81.79
2025-02-16 03:20:37,570 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.349,  Train_accy 82.08
2025-02-16 03:20:50,776 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.357,  Train_accy 81.87, Test_accy 55.38
2025-02-16 03:20:57,496 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.353,  Train_accy 81.79
2025-02-16 03:21:04,603 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.334,  Train_accy 81.79
2025-02-16 03:21:11,267 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.328,  Train_accy 81.37
2025-02-16 03:21:18,602 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.343,  Train_accy 81.83
2025-02-16 03:21:32,627 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.353,  Train_accy 81.98, Test_accy 58.00
2025-02-16 03:21:39,252 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.322,  Train_accy 82.15
2025-02-16 03:21:46,407 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.346,  Train_accy 81.81
2025-02-16 03:21:53,430 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.346,  Train_accy 81.49
2025-02-16 03:22:00,086 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.367,  Train_accy 82.06
2025-02-16 03:22:12,340 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.311,  Train_accy 81.71, Test_accy 55.20
2025-02-16 03:22:19,554 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.342,  Train_accy 81.54
2025-02-16 03:22:26,385 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.333,  Train_accy 81.49
2025-02-16 03:22:33,440 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.329,  Train_accy 81.79
2025-02-16 03:22:40,090 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.342,  Train_accy 81.26
2025-02-16 03:22:52,702 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.348,  Train_accy 81.96, Test_accy 55.05
2025-02-16 03:22:59,456 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.351,  Train_accy 81.71
2025-02-16 03:23:06,061 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.310,  Train_accy 81.62
2025-02-16 03:23:12,779 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.345,  Train_accy 81.71
2025-02-16 03:23:19,636 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.336,  Train_accy 82.11
2025-02-16 03:23:32,064 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.353,  Train_accy 81.75, Test_accy 53.06
2025-02-16 03:23:39,103 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.329,  Train_accy 81.85
2025-02-16 03:23:46,321 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.334,  Train_accy 81.62
2025-02-16 03:23:53,276 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.315,  Train_accy 81.83
2025-02-16 03:23:59,899 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.351,  Train_accy 81.81
2025-02-16 03:23:59,900 [der.py] => do not weight align student!
2025-02-16 03:24:04,849 [der.py] => darknet eval: 
2025-02-16 03:24:04,849 [der.py] => CNN top1 curve: 54.57
2025-02-16 03:24:04,849 [der.py] => CNN top5 curve: 87.96
2025-02-16 03:24:04,851 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 03:24:49,175 [der.py] => Exemplar size: 1350
2025-02-16 03:24:49,176 [trainer.py] => CNN: {'total': 63.78, '0': 48.89, '1': 28.89, '2': 50.0, '3': 35.0, '4': 74.44, '5': 12.78, '6': 27.22, '7': 29.44, '8': 48.33, '9': 43.89, '10': 82.22, '11': 92.22, '12': 31.67, '13': 37.78, '14': 18.89, '15': 80.0, '16': 80.56, '17': 82.78, '18': 80.0, '19': 85.56, '20': 67.78, '21': 81.11, '22': 72.78, '23': 29.44, '24': 30.56, '25': 80.56, '26': 89.44, '27': 94.44, '28': 67.78, '29': 81.11, '30': 83.33, '31': 87.78, '32': 99.44, '33': 76.67, '34': 77.22, '35': 84.44, '36': 96.67, '37': 50.56, '38': 33.89, '39': 74.44, '40': 40.56, '41': 69.44, '42': 93.33, '43': 81.11, 'old': 62.57, 'new': 68.0}
2025-02-16 03:24:49,176 [trainer.py] => NME: {'total': 66.23, '0': 51.67, '1': 38.33, '2': 47.78, '3': 35.56, '4': 66.67, '5': 18.33, '6': 37.22, '7': 40.0, '8': 46.11, '9': 47.78, '10': 78.33, '11': 87.78, '12': 43.33, '13': 45.56, '14': 23.33, '15': 76.11, '16': 74.44, '17': 81.11, '18': 81.67, '19': 80.0, '20': 78.33, '21': 73.33, '22': 72.22, '23': 45.56, '24': 39.44, '25': 71.11, '26': 87.78, '27': 90.56, '28': 60.0, '29': 76.67, '30': 74.44, '31': 78.33, '32': 93.89, '33': 48.89, '34': 79.44, '35': 93.33, '36': 90.56, '37': 59.44, '38': 91.11, '39': 87.22, '40': 57.78, '41': 73.33, '42': 91.67, '43': 95.0, 'old': 62.03, 'new': 80.94}
2025-02-16 03:24:49,176 [trainer.py] => CNN top1 curve: [79.11, 79.33, 69.68, 63.78]
2025-02-16 03:24:49,176 [trainer.py] => CNN top5 curve: [98.52, 97.96, 94.22, 91.75]
2025-02-16 03:24:49,176 [trainer.py] => NME top1 curve: [78.7, 76.78, 67.4, 66.23]
2025-02-16 03:24:49,176 [trainer.py] => NME top5 curve: [98.52, 97.73, 94.57, 93.07]

2025-02-16 03:24:49,177 [trainer.py] => All params: 15012664
2025-02-16 03:24:49,177 [trainer.py] => Trainable params: 7532216
2025-02-16 03:24:49,283 [der.py] => Learning on 45-55
2025-02-16 03:24:49,284 [der.py] => All params: 15022914
2025-02-16 03:24:49,284 [der.py] => Trainable params: 7542466
2025-02-16 03:24:49,380 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 03:24:49,380 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-16 03:47:44,280 [der.py] => Task 4, Epoch 150/150 => Loss 0.010, Loss_clf 0.007, Loss_aux 0.003, Train_accy 100.00
2025-02-16 03:47:57,976 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.946,  Train_accy 40.05, Test_accy 50.69
2025-02-16 03:48:04,858 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.668,  Train_accy 60.07
2025-02-16 03:48:12,682 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.536,  Train_accy 71.82
2025-02-16 03:48:19,919 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.455,  Train_accy 77.75
2025-02-16 03:48:27,131 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.408,  Train_accy 81.98
2025-02-16 03:48:41,279 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.374,  Train_accy 84.81, Test_accy 57.05
2025-02-16 03:48:48,285 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.335,  Train_accy 88.09
2025-02-16 03:48:55,327 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.306,  Train_accy 90.90
2025-02-16 03:49:02,179 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.299,  Train_accy 91.55
2025-02-16 03:49:09,155 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.288,  Train_accy 92.00
2025-02-16 03:49:22,705 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.271,  Train_accy 93.41, Test_accy 59.85
2025-02-16 03:49:29,663 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.271,  Train_accy 93.15
2025-02-16 03:49:36,677 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.260,  Train_accy 94.36
2025-02-16 03:49:43,388 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.246,  Train_accy 95.23
2025-02-16 03:49:50,446 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.233,  Train_accy 95.66
2025-02-16 03:50:03,625 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.226,  Train_accy 96.22, Test_accy 60.25
2025-02-16 03:50:11,020 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.221,  Train_accy 96.20
2025-02-16 03:50:18,186 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.218,  Train_accy 96.54
2025-02-16 03:50:25,362 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.209,  Train_accy 96.97
2025-02-16 03:50:32,445 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.213,  Train_accy 96.83
2025-02-16 03:50:46,211 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.205,  Train_accy 97.30, Test_accy 61.17
2025-02-16 03:50:53,507 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.199,  Train_accy 97.42
2025-02-16 03:51:00,610 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.198,  Train_accy 97.62
2025-02-16 03:51:07,914 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.194,  Train_accy 97.53
2025-02-16 03:51:15,052 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.189,  Train_accy 97.62
2025-02-16 03:51:28,549 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.195,  Train_accy 97.87, Test_accy 60.73
2025-02-16 03:51:35,536 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.191,  Train_accy 97.60
2025-02-16 03:51:42,784 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.189,  Train_accy 97.87
2025-02-16 03:51:49,817 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.188,  Train_accy 97.80
2025-02-16 03:51:56,781 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.191,  Train_accy 97.78
2025-02-16 03:52:10,152 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.185,  Train_accy 98.04, Test_accy 61.72
2025-02-16 03:52:17,422 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.181,  Train_accy 97.84
2025-02-16 03:52:24,603 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.181,  Train_accy 97.98
2025-02-16 03:52:31,704 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.177,  Train_accy 98.09
2025-02-16 03:52:38,619 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.180,  Train_accy 98.16
2025-02-16 03:52:52,182 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.179,  Train_accy 98.20, Test_accy 62.01
2025-02-16 03:52:59,200 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.178,  Train_accy 98.41
2025-02-16 03:53:06,337 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.178,  Train_accy 98.34
2025-02-16 03:53:13,185 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.176,  Train_accy 98.14
2025-02-16 03:53:20,412 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.171,  Train_accy 98.72
2025-02-16 03:53:35,663 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.171,  Train_accy 98.38, Test_accy 62.41
2025-02-16 03:53:42,821 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.169,  Train_accy 98.85
2025-02-16 03:53:49,803 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.168,  Train_accy 98.32
2025-02-16 03:53:59,114 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.174,  Train_accy 98.47
2025-02-16 03:54:05,933 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.168,  Train_accy 98.32
2025-02-16 03:54:19,543 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.168,  Train_accy 98.49, Test_accy 62.75
2025-02-16 03:54:26,385 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.161,  Train_accy 98.72
2025-02-16 03:54:33,588 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.163,  Train_accy 98.65
2025-02-16 03:54:40,638 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.165,  Train_accy 98.63
2025-02-16 03:54:47,927 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.160,  Train_accy 98.59
2025-02-16 03:55:01,850 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.162,  Train_accy 98.70, Test_accy 63.36
2025-02-16 03:55:09,159 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.165,  Train_accy 98.50
2025-02-16 03:55:16,665 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.164,  Train_accy 98.68
2025-02-16 03:55:23,541 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.160,  Train_accy 98.72
2025-02-16 03:55:30,618 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.157,  Train_accy 98.72
2025-02-16 03:55:44,511 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.158,  Train_accy 98.72, Test_accy 63.36
2025-02-16 03:55:52,013 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.157,  Train_accy 98.54
2025-02-16 03:55:59,472 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.154,  Train_accy 98.67
2025-02-16 03:56:07,690 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.159,  Train_accy 98.81
2025-02-16 03:56:14,741 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.157,  Train_accy 98.63
2025-02-16 03:56:28,358 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.158,  Train_accy 98.65, Test_accy 63.48
2025-02-16 03:56:35,654 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.159,  Train_accy 98.70
2025-02-16 03:56:43,350 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.156,  Train_accy 98.50
2025-02-16 03:56:50,655 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.152,  Train_accy 98.79
2025-02-16 03:56:58,014 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.155,  Train_accy 98.90
2025-02-16 03:57:11,281 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.152,  Train_accy 98.77, Test_accy 63.44
2025-02-16 03:57:18,632 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.155,  Train_accy 98.83
2025-02-16 03:57:25,669 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.150,  Train_accy 98.77
2025-02-16 03:57:32,726 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.151,  Train_accy 98.56
2025-02-16 03:57:39,577 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.151,  Train_accy 98.86
2025-02-16 03:57:52,793 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.152,  Train_accy 98.68, Test_accy 63.94
2025-02-16 03:57:59,996 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.152,  Train_accy 98.81
2025-02-16 03:58:07,541 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.151,  Train_accy 98.85
2025-02-16 03:58:14,377 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.151,  Train_accy 98.88
2025-02-16 03:58:21,193 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.148,  Train_accy 98.79
2025-02-16 03:58:34,796 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.153,  Train_accy 98.88, Test_accy 63.26
2025-02-16 03:58:41,925 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.150,  Train_accy 98.94
2025-02-16 03:58:49,267 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.150,  Train_accy 99.08
2025-02-16 03:58:56,545 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.147,  Train_accy 99.03
2025-02-16 03:59:03,750 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.147,  Train_accy 98.90
2025-02-16 03:59:16,990 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.149,  Train_accy 98.83, Test_accy 63.39
2025-02-16 03:59:24,333 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.150,  Train_accy 98.67
2025-02-16 03:59:31,794 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.147,  Train_accy 98.85
2025-02-16 03:59:38,669 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.146,  Train_accy 99.12
2025-02-16 03:59:46,144 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.147,  Train_accy 99.19
2025-02-16 03:59:59,805 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.146,  Train_accy 98.94, Test_accy 64.43
2025-02-16 04:00:07,069 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.146,  Train_accy 98.94
2025-02-16 04:00:14,089 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.147,  Train_accy 98.81
2025-02-16 04:00:21,089 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.146,  Train_accy 98.90
2025-02-16 04:00:28,125 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.145,  Train_accy 98.92
2025-02-16 04:00:41,483 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.146,  Train_accy 98.79, Test_accy 63.45
2025-02-16 04:00:48,459 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.145,  Train_accy 99.12
2025-02-16 04:00:55,258 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.145,  Train_accy 98.90
2025-02-16 04:01:02,047 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.145,  Train_accy 98.99
2025-02-16 04:01:08,960 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.144,  Train_accy 98.86
2025-02-16 04:01:22,264 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.145,  Train_accy 99.05, Test_accy 63.75
2025-02-16 04:01:28,994 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.142,  Train_accy 98.88
2025-02-16 04:01:36,174 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.145,  Train_accy 99.08
2025-02-16 04:01:43,440 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.144,  Train_accy 98.97
2025-02-16 04:01:51,132 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.143,  Train_accy 99.12
2025-02-16 04:02:04,322 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.143,  Train_accy 98.94, Test_accy 63.71
2025-02-16 04:02:11,499 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.143,  Train_accy 98.95
2025-02-16 04:02:18,403 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.141,  Train_accy 99.03
2025-02-16 04:02:25,773 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.142,  Train_accy 99.01
2025-02-16 04:02:32,637 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.142,  Train_accy 99.03
2025-02-16 04:02:45,807 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.144,  Train_accy 99.03, Test_accy 63.94
2025-02-16 04:02:52,814 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.143,  Train_accy 98.95
2025-02-16 04:03:00,058 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.141,  Train_accy 99.12
2025-02-16 04:03:07,109 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.142,  Train_accy 99.10
2025-02-16 04:03:14,163 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.146,  Train_accy 98.85
2025-02-16 04:03:27,823 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.141,  Train_accy 99.06, Test_accy 63.73
2025-02-16 04:03:34,878 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.145,  Train_accy 98.90
2025-02-16 04:03:41,835 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.144,  Train_accy 99.10
2025-02-16 04:03:48,957 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.142,  Train_accy 98.99
2025-02-16 04:03:56,265 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.143,  Train_accy 98.99
2025-02-16 04:04:10,126 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.144,  Train_accy 99.14, Test_accy 63.84
2025-02-16 04:04:17,310 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.142,  Train_accy 98.95
2025-02-16 04:04:24,607 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.142,  Train_accy 98.97
2025-02-16 04:04:32,041 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.142,  Train_accy 98.92
2025-02-16 04:04:38,933 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.142,  Train_accy 98.95
2025-02-16 04:04:52,848 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.140,  Train_accy 99.08, Test_accy 63.86
2025-02-16 04:04:59,904 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.141,  Train_accy 98.81
2025-02-16 04:05:06,746 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.143,  Train_accy 98.92
2025-02-16 04:05:13,950 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.142,  Train_accy 98.90
2025-02-16 04:05:20,957 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.140,  Train_accy 99.12
2025-02-16 04:05:33,906 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.142,  Train_accy 99.12, Test_accy 64.12
2025-02-16 04:05:40,898 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.143,  Train_accy 99.15
2025-02-16 04:05:47,548 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.142,  Train_accy 99.24
2025-02-16 04:05:54,415 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.140,  Train_accy 99.10
2025-02-16 04:06:01,498 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.142,  Train_accy 98.95
2025-02-16 04:06:01,499 [der.py] => do not weight align student!
2025-02-16 04:06:06,769 [der.py] => darknet eval: 
2025-02-16 04:06:06,769 [der.py] => CNN top1 curve: 63.63
2025-02-16 04:06:06,769 [der.py] => CNN top5 curve: 88.91
2025-02-16 04:06:06,771 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 04:06:58,495 [der.py] => Exemplar size: 1650
2025-02-16 04:06:58,495 [trainer.py] => CNN: {'total': 61.24, '0': 23.33, '1': 38.33, '2': 46.67, '3': 25.0, '4': 52.78, '5': 20.56, '6': 43.89, '7': 30.0, '8': 46.11, '9': 33.89, '10': 64.44, '11': 64.44, '12': 35.56, '13': 41.67, '14': 26.67, '15': 62.22, '16': 70.56, '17': 72.78, '18': 70.56, '19': 70.56, '20': 72.78, '21': 49.44, '22': 65.0, '23': 28.33, '24': 42.78, '25': 57.22, '26': 71.11, '27': 83.33, '28': 42.22, '29': 57.22, '30': 56.11, '31': 63.89, '32': 82.22, '33': 31.67, '34': 51.11, '35': 97.78, '36': 98.89, '37': 72.78, '38': 93.33, '39': 96.67, '40': 65.56, '41': 97.22, '42': 98.89, '43': 91.11, '44': 56.11, '45': 77.22, '46': 80.0, '47': 64.44, '48': 71.11, '49': 67.22, '50': 64.44, '51': 73.33, '52': 76.11, '53': 61.67, 'old': 59.17, 'new': 70.56}
2025-02-16 04:06:58,495 [trainer.py] => NME: {'total': 57.41, '0': 43.33, '1': 38.89, '2': 33.89, '3': 21.11, '4': 52.78, '5': 32.78, '6': 43.89, '7': 33.89, '8': 44.44, '9': 40.0, '10': 70.56, '11': 70.56, '12': 32.78, '13': 42.78, '14': 26.67, '15': 57.78, '16': 65.56, '17': 76.67, '18': 60.0, '19': 62.78, '20': 69.44, '21': 45.0, '22': 58.33, '23': 30.56, '24': 36.67, '25': 47.22, '26': 62.22, '27': 75.0, '28': 41.11, '29': 52.22, '30': 50.0, '31': 56.67, '32': 80.56, '33': 32.22, '34': 56.67, '35': 82.78, '36': 83.33, '37': 51.11, '38': 86.11, '39': 64.44, '40': 39.44, '41': 93.33, '42': 96.67, '43': 89.44, '44': 23.89, '45': 72.78, '46': 80.0, '47': 71.11, '48': 69.44, '49': 71.11, '50': 64.44, '51': 73.33, '52': 72.22, '53': 58.33, 'old': 54.57, 'new': 70.22}
2025-02-16 04:06:58,495 [trainer.py] => CNN top1 curve: [79.11, 79.33, 69.68, 63.78, 61.24]
2025-02-16 04:06:58,495 [trainer.py] => CNN top5 curve: [98.52, 97.96, 94.22, 91.75, 88.53]
2025-02-16 04:06:58,495 [trainer.py] => NME top1 curve: [78.7, 76.78, 67.4, 66.23, 57.41]
2025-02-16 04:06:58,495 [trainer.py] => NME top5 curve: [98.52, 97.73, 94.57, 93.07, 87.59]

2025-02-16 14:58:43,399 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 14:58:43,418 [trainer.py] => config: ./exps/der.json
2025-02-16 14:58:43,418 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 14:58:43,418 [trainer.py] => prefix: reproduce
2025-02-16 14:58:43,418 [trainer.py] => dataset: xrfdataset
2025-02-16 14:58:43,418 [trainer.py] => memory_size: 1650
2025-02-16 14:58:43,418 [trainer.py] => memory_per_class: 30
2025-02-16 14:58:43,418 [trainer.py] => fixed_memory: True
2025-02-16 14:58:43,418 [trainer.py] => shuffle: True
2025-02-16 14:58:43,418 [trainer.py] => init_cls: 15
2025-02-16 14:58:43,418 [trainer.py] => increment: 10
2025-02-16 14:58:43,419 [trainer.py] => model_name: der
2025-02-16 14:58:43,419 [trainer.py] => compression_epochs: 1
2025-02-16 14:58:43,419 [trainer.py] => compression_lr: 0.1
2025-02-16 14:58:43,419 [trainer.py] => is_student_wa: False
2025-02-16 14:58:43,419 [trainer.py] => wa_value: 1
2025-02-16 14:58:43,419 [trainer.py] => T: 2
2025-02-16 14:58:43,419 [trainer.py] => convnet_type: resnet34
2025-02-16 14:58:43,419 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=3)]
2025-02-16 14:58:43,419 [trainer.py] => seed: 1993
2025-02-16 14:58:43,523 [data.py] => 加载完毕XRF原始数据集
2025-02-16 14:58:43,546 [data.py] => 加载完毕XRF原始数据集
2025-02-16 14:58:43,546 [trainer.py] => All params: 0
2025-02-16 14:58:43,546 [trainer.py] => Trainable params: 0
2025-02-16 14:58:43,832 [der.py] => Learning on 0-15
2025-02-16 14:58:43,833 [der.py] => All params: 7496351
2025-02-16 14:58:43,833 [der.py] => Trainable params: 7496351
2025-02-16 15:02:48,930 [der.py] => Task 0, Epoch 1/1 => Loss 4.146, Train_accy 6.57, Test_accy 8.04
2025-02-16 15:02:48,932 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 15:03:12,226 [der.py] => Exemplar size: 450
2025-02-16 15:03:12,227 [trainer.py] => CNN: {'total': 8.04, '0': 0.56, '1': 0.0, '2': 52.78, '3': 0.0, '4': 0.0, '5': 7.22, '6': 0.0, '7': 0.0, '8': 0.0, '9': 5.0, '10': 55.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 8.04}
2025-02-16 15:03:12,227 [trainer.py] => NME: {'total': 8.07, '0': 0.56, '1': 0.0, '2': 28.89, '3': 1.11, '4': 0.0, '5': 3.33, '6': 0.0, '7': 0.0, '8': 41.67, '9': 0.0, '10': 11.11, '11': 0.0, '12': 0.0, '13': 32.78, 'old': 0, 'new': 8.07}
2025-02-16 15:03:12,227 [trainer.py] => CNN top1 curve: [8.04]
2025-02-16 15:03:12,227 [trainer.py] => CNN top5 curve: [35.7]
2025-02-16 15:03:12,227 [trainer.py] => NME top1 curve: [8.07]
2025-02-16 15:03:12,227 [trainer.py] => NME top5 curve: [37.56]

2025-02-16 15:03:12,227 [trainer.py] => All params: 7496351
2025-02-16 15:03:12,228 [trainer.py] => Trainable params: 7496351
2025-02-16 15:03:12,346 [der.py] => Learning on 15-25
2025-02-16 15:03:12,347 [der.py] => All params: 14992164
2025-02-16 15:03:12,348 [der.py] => Trainable params: 7511716
2025-02-16 15:03:12,420 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 15:03:12,421 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 15:05:45,992 [der.py] => Task 1, Epoch 1/1 => Loss 5.606, Loss_clf 3.158, Loss_aux 2.448, Train_accy 8.95, Test_accy 4.11
2025-02-16 15:05:56,994 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.961,  Train_accy 9.12, Test_accy 4.00
2025-02-16 15:05:56,994 [der.py] => do not weight align student!
2025-02-16 15:06:00,533 [der.py] => darknet eval: 
2025-02-16 15:06:00,533 [der.py] => CNN top1 curve: 4.0
2025-02-16 15:06:00,533 [der.py] => CNN top5 curve: 20.22
2025-02-16 15:06:00,535 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 15:06:30,468 [der.py] => Exemplar size: 750
2025-02-16 15:06:30,468 [trainer.py] => CNN: {'total': 4.18, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 96.67, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 7.78, 'old': 0.0, 'new': 10.44}
2025-02-16 15:06:30,469 [trainer.py] => NME: {'total': 5.42, '0': 0.0, '1': 0.0, '2': 23.33, '3': 0.0, '4': 0.0, '5': 0.0, '6': 2.78, '7': 0.0, '8': 0.0, '9': 0.0, '10': 30.56, '11': 0.0, '12': 0.0, '13': 30.56, '14': 0.0, '15': 0.0, '16': 26.11, '17': 5.0, '18': 7.22, '19': 0.0, '20': 0.0, '21': 0.0, '22': 10.0, '23': 0.0, 'old': 5.81, 'new': 4.83}
2025-02-16 15:06:30,469 [trainer.py] => CNN top1 curve: [8.04, 4.18]
2025-02-16 15:06:30,469 [trainer.py] => CNN top5 curve: [35.7, 21.04]
2025-02-16 15:06:30,469 [trainer.py] => NME top1 curve: [8.07, 5.42]
2025-02-16 15:06:30,469 [trainer.py] => NME top5 curve: [37.56, 24.51]

2025-02-16 15:06:30,470 [trainer.py] => All params: 14992164
2025-02-16 15:06:30,471 [trainer.py] => Trainable params: 7511716
2025-02-16 15:06:30,576 [der.py] => Learning on 25-35
2025-02-16 15:06:30,577 [der.py] => All params: 15002414
2025-02-16 15:06:30,577 [der.py] => Trainable params: 7521966
2025-02-16 15:06:30,660 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 15:06:30,660 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-16 15:09:05,017 [der.py] => Task 2, Epoch 1/1 => Loss 8.957, Loss_clf 6.540, Loss_aux 2.418, Train_accy 7.19, Test_accy 3.16
2025-02-16 15:09:19,291 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.395,  Train_accy 8.93, Test_accy 3.17
2025-02-16 15:09:19,292 [der.py] => do not weight align student!
2025-02-16 15:09:23,789 [der.py] => darknet eval: 
2025-02-16 15:09:23,789 [der.py] => CNN top1 curve: 3.17
2025-02-16 15:09:23,789 [der.py] => CNN top5 curve: 14.29
2025-02-16 15:09:23,792 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 15:10:02,812 [der.py] => Exemplar size: 1050
2025-02-16 15:10:02,813 [trainer.py] => CNN: {'total': 3.06, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 8.33, '26': 9.44, '27': 0.0, '28': 0.0, '29': 25.56, '30': 61.11, '31': 0.0, '32': 0.0, '33': 2.78, 'old': 0.0, 'new': 10.72}
2025-02-16 15:10:02,813 [trainer.py] => NME: {'total': 3.6, '0': 0.0, '1': 0.0, '2': 13.33, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 46.11, '11': 0.0, '12': 0.0, '13': 1.11, '14': 0.0, '15': 0.0, '16': 17.78, '17': 1.67, '18': 7.22, '19': 0.0, '20': 0.0, '21': 0.56, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 31.11, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 4.44, '32': 0.0, '33': 0.0, 'old': 3.51, 'new': 3.83}
2025-02-16 15:10:02,813 [trainer.py] => CNN top1 curve: [8.04, 4.18, 3.06]
2025-02-16 15:10:02,813 [trainer.py] => CNN top5 curve: [35.7, 21.04, 14.24]
2025-02-16 15:10:02,813 [trainer.py] => NME top1 curve: [8.07, 5.42, 3.6]
2025-02-16 15:10:02,813 [trainer.py] => NME top5 curve: [37.56, 24.51, 16.67]

2025-02-16 15:10:02,814 [trainer.py] => All params: 15002414
2025-02-16 15:10:02,814 [trainer.py] => Trainable params: 7521966
2025-02-16 15:10:02,922 [der.py] => Learning on 35-45
2025-02-16 15:10:02,923 [der.py] => All params: 15012664
2025-02-16 15:10:02,923 [der.py] => Trainable params: 7532216
2025-02-16 15:10:03,012 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 15:10:03,012 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-16 15:20:42,976 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 15:20:43,009 [trainer.py] => config: ./exps/der.json
2025-02-16 15:20:43,009 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 15:20:43,009 [trainer.py] => prefix: reproduce
2025-02-16 15:20:43,009 [trainer.py] => dataset: xrfdataset
2025-02-16 15:20:43,009 [trainer.py] => memory_size: 1650
2025-02-16 15:20:43,009 [trainer.py] => memory_per_class: 30
2025-02-16 15:20:43,009 [trainer.py] => fixed_memory: True
2025-02-16 15:20:43,009 [trainer.py] => shuffle: True
2025-02-16 15:20:43,009 [trainer.py] => init_cls: 15
2025-02-16 15:20:43,009 [trainer.py] => increment: 10
2025-02-16 15:20:43,009 [trainer.py] => model_name: der
2025-02-16 15:20:43,010 [trainer.py] => compression_epochs: 130
2025-02-16 15:20:43,010 [trainer.py] => compression_lr: 0.1
2025-02-16 15:20:43,010 [trainer.py] => is_student_wa: False
2025-02-16 15:20:43,010 [trainer.py] => wa_value: 1
2025-02-16 15:20:43,010 [trainer.py] => T: 2
2025-02-16 15:20:43,010 [trainer.py] => convnet_type: resnet34
2025-02-16 15:20:43,010 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=3)]
2025-02-16 15:20:43,010 [trainer.py] => seed: 1993
2025-02-16 15:20:43,032 [data.py] => 加载完毕XRF原始数据集
2025-02-16 15:20:43,038 [data.py] => 加载完毕XRF原始数据集
2025-02-16 15:20:43,038 [trainer.py] => All params: 0
2025-02-16 15:20:43,038 [trainer.py] => Trainable params: 0
2025-02-16 15:20:43,179 [der.py] => Learning on 0-15
2025-02-16 15:20:43,180 [der.py] => All params: 7496351
2025-02-16 15:20:43,180 [der.py] => Trainable params: 7496351
2025-02-16 15:43:52,513 [der.py] => Task 0, Epoch 200/200 => Loss 0.032, Train_accy 99.70
2025-02-16 15:43:52,534 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 15:44:17,228 [der.py] => Exemplar size: 450
2025-02-16 15:44:17,228 [trainer.py] => CNN: {'total': 80.59, '0': 96.67, '1': 90.56, '2': 77.22, '3': 66.11, '4': 86.11, '5': 74.44, '6': 57.78, '7': 82.78, '8': 88.33, '9': 59.44, '10': 96.11, '11': 98.89, '12': 75.0, '13': 74.44, 'old': 0, 'new': 80.59}
2025-02-16 15:44:17,228 [trainer.py] => NME: {'total': 79.15, '0': 98.33, '1': 90.56, '2': 75.0, '3': 66.67, '4': 77.22, '5': 63.89, '6': 52.22, '7': 83.33, '8': 83.89, '9': 65.56, '10': 92.22, '11': 98.89, '12': 77.78, '13': 77.22, 'old': 0, 'new': 79.15}
2025-02-16 15:44:17,228 [trainer.py] => CNN top1 curve: [80.59]
2025-02-16 15:44:17,228 [trainer.py] => CNN top5 curve: [98.48]
2025-02-16 15:44:17,228 [trainer.py] => NME top1 curve: [79.15]
2025-02-16 15:44:17,228 [trainer.py] => NME top5 curve: [98.74]

2025-02-16 15:44:17,229 [trainer.py] => All params: 7496351
2025-02-16 15:44:17,229 [trainer.py] => Trainable params: 7496351
2025-02-16 15:44:17,329 [der.py] => Learning on 15-25
2025-02-16 15:44:17,330 [der.py] => All params: 14992164
2025-02-16 15:44:17,330 [der.py] => Trainable params: 7511716
2025-02-16 15:44:17,395 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 15:44:17,396 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 16:06:15,597 [der.py] => Task 1, Epoch 170/170 => Loss 0.007, Loss_clf 0.003, Loss_aux 0.004, Train_accy 100.00
2025-02-16 16:22:15,331 [trainer.py] => 实验名称:resnet对比实验
2025-02-16 16:22:15,389 [trainer.py] => config: ./exps/der.json
2025-02-16 16:22:15,389 [trainer.py] => experiment_name: 实验名称:resnet对比实验
2025-02-16 16:22:15,389 [trainer.py] => prefix: reproduce
2025-02-16 16:22:15,389 [trainer.py] => dataset: xrfdataset
2025-02-16 16:22:15,389 [trainer.py] => memory_size: 1650
2025-02-16 16:22:15,390 [trainer.py] => memory_per_class: 30
2025-02-16 16:22:15,390 [trainer.py] => fixed_memory: True
2025-02-16 16:22:15,390 [trainer.py] => shuffle: True
2025-02-16 16:22:15,390 [trainer.py] => init_cls: 15
2025-02-16 16:22:15,390 [trainer.py] => increment: 10
2025-02-16 16:22:15,390 [trainer.py] => model_name: der
2025-02-16 16:22:15,390 [trainer.py] => compression_epochs: 130
2025-02-16 16:22:15,390 [trainer.py] => compression_lr: 0.1
2025-02-16 16:22:15,390 [trainer.py] => is_student_wa: False
2025-02-16 16:22:15,390 [trainer.py] => wa_value: 1
2025-02-16 16:22:15,390 [trainer.py] => T: 2
2025-02-16 16:22:15,390 [trainer.py] => convnet_type: resnet34
2025-02-16 16:22:15,390 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=3)]
2025-02-16 16:22:15,390 [trainer.py] => seed: 1993
2025-02-16 16:22:15,470 [data.py] => 加载完毕XRF原始数据集
2025-02-16 16:22:15,491 [data.py] => 加载完毕XRF原始数据集
2025-02-16 16:22:15,492 [trainer.py] => All params: 0
2025-02-16 16:22:15,492 [trainer.py] => Trainable params: 0
2025-02-16 16:22:15,790 [der.py] => Learning on 0-15
2025-02-16 16:22:15,790 [der.py] => All params: 7496351
2025-02-16 16:22:15,791 [der.py] => Trainable params: 7496351
2025-02-16 16:51:40,926 [der.py] => Task 0, Epoch 200/200 => Loss 0.032, Train_accy 99.70
2025-02-16 16:51:40,939 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 16:52:07,396 [der.py] => Exemplar size: 450
2025-02-16 16:52:07,396 [trainer.py] => CNN: {'total': 80.59, '0': 96.67, '1': 90.56, '2': 77.22, '3': 66.11, '4': 86.11, '5': 74.44, '6': 57.78, '7': 82.78, '8': 88.33, '9': 59.44, '10': 96.11, '11': 98.89, '12': 75.0, '13': 74.44, 'old': 0, 'new': 80.59}
2025-02-16 16:52:07,396 [trainer.py] => NME: {'total': 79.15, '0': 98.33, '1': 90.56, '2': 75.0, '3': 66.67, '4': 77.22, '5': 63.89, '6': 52.22, '7': 83.33, '8': 83.89, '9': 65.56, '10': 92.22, '11': 98.89, '12': 77.78, '13': 77.22, 'old': 0, 'new': 79.15}
2025-02-16 16:52:07,397 [trainer.py] => CNN top1 curve: [80.59]
2025-02-16 16:52:07,397 [trainer.py] => CNN top5 curve: [98.48]
2025-02-16 16:52:07,397 [trainer.py] => NME top1 curve: [79.15]
2025-02-16 16:52:07,397 [trainer.py] => NME top5 curve: [98.74]

2025-02-16 16:52:07,397 [trainer.py] => All params: 7496351
2025-02-16 16:52:07,398 [trainer.py] => Trainable params: 7496351
2025-02-16 16:52:07,543 [der.py] => Learning on 15-25
2025-02-16 16:52:07,544 [der.py] => All params: 14992164
2025-02-16 16:52:07,544 [der.py] => Trainable params: 7511716
2025-02-16 16:52:07,634 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 16:52:07,635 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 17:16:15,778 [der.py] => Task 1, Epoch 170/170 => Loss 0.007, Loss_clf 0.003, Loss_aux 0.004, Train_accy 100.00
2025-02-16 17:18:12,577 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.200,  Train_accy 36.22, Test_accy 38.49
2025-02-16 17:18:19,975 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.722,  Train_accy 56.71
2025-02-16 17:18:27,061 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.526,  Train_accy 67.70
2025-02-16 17:18:33,896 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.392,  Train_accy 73.74
2025-02-16 17:18:41,017 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.338,  Train_accy 76.11
2025-02-16 17:18:52,769 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.278,  Train_accy 79.76, Test_accy 50.56
2025-02-16 17:18:59,741 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.185,  Train_accy 83.59
2025-02-16 17:19:06,979 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.144,  Train_accy 86.34
2025-02-16 17:19:14,090 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.079,  Train_accy 89.63
2025-02-16 17:19:21,373 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.049,  Train_accy 90.80
2025-02-16 17:19:33,160 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.020,  Train_accy 92.45, Test_accy 58.53
2025-02-16 17:19:40,216 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.004,  Train_accy 93.51
2025-02-16 17:19:47,278 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.987,  Train_accy 93.68
2025-02-16 17:19:53,675 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.977,  Train_accy 94.13
2025-02-16 17:20:00,885 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.953,  Train_accy 95.40
2025-02-16 17:20:12,157 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.939,  Train_accy 95.66, Test_accy 66.69
2025-02-16 17:20:19,316 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.938,  Train_accy 95.74
2025-02-16 17:20:26,436 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.934,  Train_accy 96.00
2025-02-16 17:20:33,389 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.925,  Train_accy 96.22
2025-02-16 17:20:40,499 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.914,  Train_accy 97.12
2025-02-16 17:20:51,774 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.902,  Train_accy 96.77, Test_accy 69.91
2025-02-16 17:20:59,752 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.904,  Train_accy 97.10
2025-02-16 17:21:08,054 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.900,  Train_accy 96.84
2025-02-16 17:21:15,636 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.890,  Train_accy 97.42
2025-02-16 17:21:23,594 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.886,  Train_accy 97.70
2025-02-16 17:21:36,413 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.884,  Train_accy 97.27, Test_accy 68.62
2025-02-16 17:21:43,761 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.879,  Train_accy 97.38
2025-02-16 17:21:50,927 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.882,  Train_accy 97.66
2025-02-16 17:21:58,102 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.877,  Train_accy 97.40
2025-02-16 17:22:04,971 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.876,  Train_accy 97.63
2025-02-16 17:22:16,579 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.870,  Train_accy 97.48, Test_accy 71.20
2025-02-16 17:22:24,503 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.870,  Train_accy 97.72
2025-02-16 17:22:31,450 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.866,  Train_accy 97.59
2025-02-16 17:22:38,245 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.865,  Train_accy 97.68
2025-02-16 17:22:45,329 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.860,  Train_accy 97.48
2025-02-16 17:22:57,104 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.868,  Train_accy 97.38, Test_accy 70.56
2025-02-16 17:23:04,257 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.874,  Train_accy 97.70
2025-02-16 17:23:11,526 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.858,  Train_accy 97.68
2025-02-16 17:23:18,601 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.855,  Train_accy 97.83
2025-02-16 17:23:25,663 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.856,  Train_accy 97.91
2025-02-16 17:23:37,273 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.851,  Train_accy 97.76, Test_accy 72.87
2025-02-16 17:23:44,279 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.850,  Train_accy 97.96
2025-02-16 17:23:51,317 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.846,  Train_accy 97.72
2025-02-16 17:23:58,094 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.847,  Train_accy 97.78
2025-02-16 17:24:04,882 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.845,  Train_accy 97.81
2025-02-16 17:24:17,089 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.841,  Train_accy 97.85, Test_accy 73.07
2025-02-16 17:24:23,900 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.840,  Train_accy 98.13
2025-02-16 17:24:30,817 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.841,  Train_accy 98.00
2025-02-16 17:24:37,789 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.842,  Train_accy 97.87
2025-02-16 17:24:44,819 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.842,  Train_accy 97.96
2025-02-16 17:24:56,255 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.842,  Train_accy 97.94, Test_accy 73.36
2025-02-16 17:25:03,528 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.835,  Train_accy 98.04
2025-02-16 17:25:11,395 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.833,  Train_accy 97.91
2025-02-16 17:25:18,852 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.833,  Train_accy 97.87
2025-02-16 17:25:26,289 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.835,  Train_accy 97.83
2025-02-16 17:25:38,609 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.833,  Train_accy 97.96, Test_accy 73.93
2025-02-16 17:25:45,785 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.837,  Train_accy 98.09
2025-02-16 17:25:52,538 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.837,  Train_accy 98.00
2025-02-16 17:25:59,143 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.833,  Train_accy 98.06
2025-02-16 17:26:06,512 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.838,  Train_accy 97.59
2025-02-16 17:26:18,530 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.834,  Train_accy 97.98, Test_accy 73.04
2025-02-16 17:26:25,772 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.834,  Train_accy 98.06
2025-02-16 17:26:32,844 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.831,  Train_accy 98.06
2025-02-16 17:26:39,668 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.831,  Train_accy 98.00
2025-02-16 17:26:46,628 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.828,  Train_accy 98.17
2025-02-16 17:26:58,375 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.830,  Train_accy 98.26, Test_accy 73.89
2025-02-16 17:27:05,507 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.826,  Train_accy 98.11
2025-02-16 17:27:12,962 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.832,  Train_accy 97.94
2025-02-16 17:27:20,048 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.830,  Train_accy 98.19
2025-02-16 17:27:26,929 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.829,  Train_accy 97.87
2025-02-16 17:27:38,669 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.827,  Train_accy 98.28, Test_accy 73.89
2025-02-16 17:27:45,500 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.825,  Train_accy 98.24
2025-02-16 17:27:52,217 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.819,  Train_accy 98.13
2025-02-16 17:27:59,634 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.823,  Train_accy 98.11
2025-02-16 17:28:06,601 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.823,  Train_accy 98.06
2025-02-16 17:28:18,214 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.828,  Train_accy 98.00, Test_accy 74.58
2025-02-16 17:28:26,414 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.823,  Train_accy 98.19
2025-02-16 17:28:33,037 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.820,  Train_accy 97.96
2025-02-16 17:28:39,718 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.825,  Train_accy 98.09
2025-02-16 17:28:46,637 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.825,  Train_accy 98.06
2025-02-16 17:28:58,097 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.822,  Train_accy 98.24, Test_accy 74.51
2025-02-16 17:29:05,153 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.824,  Train_accy 98.02
2025-02-16 17:29:12,258 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.819,  Train_accy 98.22
2025-02-16 17:29:19,155 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.819,  Train_accy 98.28
2025-02-16 17:29:26,456 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.824,  Train_accy 98.11
2025-02-16 17:29:38,109 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.823,  Train_accy 98.19, Test_accy 74.33
2025-02-16 17:29:45,179 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.818,  Train_accy 98.22
2025-02-16 17:29:52,680 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.820,  Train_accy 98.30
2025-02-16 17:30:00,016 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.815,  Train_accy 98.43
2025-02-16 17:30:07,369 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.819,  Train_accy 98.19
2025-02-16 17:30:19,032 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.819,  Train_accy 98.19, Test_accy 74.18
2025-02-16 17:30:26,218 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.817,  Train_accy 98.41
2025-02-16 17:30:33,331 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.818,  Train_accy 98.09
2025-02-16 17:30:40,587 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.817,  Train_accy 98.15
2025-02-16 17:30:47,809 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.819,  Train_accy 98.13
2025-02-16 17:30:59,545 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.820,  Train_accy 98.15, Test_accy 74.78
2025-02-16 17:31:06,476 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.818,  Train_accy 98.34
2025-02-16 17:31:13,571 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.817,  Train_accy 98.39
2025-02-16 17:31:20,474 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.813,  Train_accy 98.19
2025-02-16 17:31:26,932 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.817,  Train_accy 98.06
2025-02-16 17:31:37,037 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.817,  Train_accy 98.22, Test_accy 74.73
2025-02-16 17:31:43,243 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.817,  Train_accy 98.26
2025-02-16 17:31:49,765 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.814,  Train_accy 98.34
2025-02-16 17:31:56,485 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.815,  Train_accy 98.37
2025-02-16 17:32:03,146 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.817,  Train_accy 98.19
2025-02-16 17:32:14,440 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.816,  Train_accy 98.11, Test_accy 74.96
2025-02-16 17:32:23,811 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.812,  Train_accy 98.26
2025-02-16 17:32:30,904 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.813,  Train_accy 98.26
2025-02-16 17:32:37,690 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.816,  Train_accy 98.28
2025-02-16 17:32:44,659 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.819,  Train_accy 98.26
2025-02-16 17:32:56,138 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.816,  Train_accy 98.39, Test_accy 74.96
2025-02-16 17:33:03,479 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.815,  Train_accy 98.39
2025-02-16 17:33:10,196 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.815,  Train_accy 98.43
2025-02-16 17:33:16,983 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.815,  Train_accy 98.30
2025-02-16 17:33:23,590 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.814,  Train_accy 98.17
2025-02-16 17:33:34,471 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.815,  Train_accy 98.22, Test_accy 74.56
2025-02-16 17:33:41,319 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.814,  Train_accy 98.52
2025-02-16 17:33:48,139 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.819,  Train_accy 97.78
2025-02-16 17:33:54,871 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.812,  Train_accy 98.47
2025-02-16 17:34:01,583 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.813,  Train_accy 98.28
2025-02-16 17:34:12,655 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.815,  Train_accy 98.30, Test_accy 74.80
2025-02-16 17:34:19,704 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.811,  Train_accy 98.49
2025-02-16 17:34:26,347 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.813,  Train_accy 98.24
2025-02-16 17:34:33,058 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.813,  Train_accy 98.34
2025-02-16 17:34:39,856 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.816,  Train_accy 98.17
2025-02-16 17:34:50,751 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.812,  Train_accy 98.32, Test_accy 74.73
2025-02-16 17:34:57,551 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.812,  Train_accy 98.13
2025-02-16 17:35:04,345 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.817,  Train_accy 98.34
2025-02-16 17:35:11,195 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.814,  Train_accy 98.39
2025-02-16 17:35:18,048 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.811,  Train_accy 98.28
2025-02-16 17:35:18,049 [der.py] => do not weight align student!
2025-02-16 17:35:45,864 [der.py] => darknet eval: 
2025-02-16 17:35:48,279 [der.py] => CNN top1 curve: 74.78
2025-02-16 17:35:48,280 [der.py] => CNN top5 curve: 96.93
2025-02-16 17:35:48,281 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 17:36:23,266 [der.py] => Exemplar size: 750
2025-02-16 17:36:23,266 [trainer.py] => CNN: {'total': 79.84, '0': 91.11, '1': 76.11, '2': 81.11, '3': 66.67, '4': 82.78, '5': 66.11, '6': 47.78, '7': 58.33, '8': 61.67, '9': 62.22, '10': 93.33, '11': 98.89, '12': 77.22, '13': 72.22, '14': 76.67, '15': 89.44, '16': 91.11, '17': 92.78, '18': 94.44, '19': 85.56, '20': 92.78, '21': 87.78, '22': 82.22, '23': 80.0, 'old': 74.15, 'new': 88.39}
2025-02-16 17:36:23,266 [trainer.py] => NME: {'total': 77.24, '0': 87.78, '1': 59.44, '2': 73.89, '3': 61.67, '4': 77.22, '5': 58.33, '6': 49.44, '7': 45.56, '8': 39.44, '9': 66.11, '10': 91.11, '11': 98.89, '12': 72.78, '13': 73.33, '14': 74.44, '15': 86.11, '16': 92.78, '17': 91.11, '18': 95.0, '19': 88.33, '20': 90.0, '21': 88.33, '22': 93.33, '23': 84.44, 'old': 68.63, 'new': 90.17}
2025-02-16 17:36:23,266 [trainer.py] => CNN top1 curve: [80.59, 79.84]
2025-02-16 17:36:23,266 [trainer.py] => CNN top5 curve: [98.48, 98.29]
2025-02-16 17:36:23,266 [trainer.py] => NME top1 curve: [79.15, 77.24]
2025-02-16 17:36:23,267 [trainer.py] => NME top5 curve: [98.74, 97.8]

2025-02-16 17:36:23,267 [trainer.py] => All params: 14992164
2025-02-16 17:36:23,268 [trainer.py] => Trainable params: 7511716
2025-02-16 17:36:26,214 [der.py] => Learning on 25-35
2025-02-16 17:36:26,215 [der.py] => All params: 15002414
2025-02-16 17:36:26,215 [der.py] => Trainable params: 7521966
2025-02-16 17:36:26,323 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 17:36:26,323 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-16 18:09:39,371 [der.py] => Task 2, Epoch 170/170 => Loss 0.006, Loss_clf 0.003, Loss_aux 0.003, Train_accy 100.00
2025-02-16 18:09:54,369 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.273,  Train_accy 45.11, Test_accy 52.89
2025-02-16 18:10:02,304 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.977,  Train_accy 65.29
2025-02-16 18:10:11,279 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.870,  Train_accy 73.68
2025-02-16 18:10:19,387 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.809,  Train_accy 76.97
2025-02-16 18:10:26,698 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.728,  Train_accy 82.04
2025-02-16 18:10:40,147 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.688,  Train_accy 84.28, Test_accy 60.71
2025-02-16 18:10:47,355 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.646,  Train_accy 87.37
2025-02-16 18:10:54,557 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.633,  Train_accy 87.96
2025-02-16 18:11:01,803 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.609,  Train_accy 89.64
2025-02-16 18:11:09,075 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.582,  Train_accy 92.00
2025-02-16 18:11:21,932 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.567,  Train_accy 92.77, Test_accy 62.05
2025-02-16 18:11:29,346 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.550,  Train_accy 92.81
2025-02-16 18:11:36,436 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.535,  Train_accy 93.86
2025-02-16 18:11:43,575 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.522,  Train_accy 94.83
2025-02-16 18:11:50,855 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.523,  Train_accy 94.20
2025-02-16 18:12:04,347 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.512,  Train_accy 94.87, Test_accy 63.97
2025-02-16 18:12:12,360 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.510,  Train_accy 95.25
2025-02-16 18:12:20,138 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.506,  Train_accy 95.19
2025-02-16 18:12:27,866 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.494,  Train_accy 95.78
2025-02-16 18:12:36,249 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.498,  Train_accy 95.72
2025-02-16 18:12:51,170 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.488,  Train_accy 96.24, Test_accy 65.44
2025-02-16 18:12:59,407 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.486,  Train_accy 95.88
2025-02-16 18:13:07,472 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.477,  Train_accy 95.84
2025-02-16 18:13:15,973 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.479,  Train_accy 96.53
2025-02-16 18:13:24,196 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.476,  Train_accy 96.22
2025-02-16 18:13:38,581 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.469,  Train_accy 96.36, Test_accy 66.84
2025-02-16 18:13:46,890 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.471,  Train_accy 96.67
2025-02-16 18:13:55,174 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.470,  Train_accy 96.20
2025-02-16 18:14:03,421 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.469,  Train_accy 96.61
2025-02-16 18:14:11,541 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.463,  Train_accy 96.97
2025-02-16 18:14:26,517 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.459,  Train_accy 96.77, Test_accy 67.30
2025-02-16 18:14:34,747 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.462,  Train_accy 96.69
2025-02-16 18:14:43,048 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.456,  Train_accy 97.03
2025-02-16 18:14:51,310 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.458,  Train_accy 96.71
2025-02-16 18:14:59,716 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.461,  Train_accy 96.61
2025-02-16 18:15:14,400 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.454,  Train_accy 96.91, Test_accy 66.92
2025-02-16 18:15:22,579 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.457,  Train_accy 96.61
2025-02-16 18:15:30,604 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.449,  Train_accy 97.01
2025-02-16 18:15:39,134 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.448,  Train_accy 96.85
2025-02-16 18:15:47,657 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.450,  Train_accy 97.13
2025-02-16 18:16:01,938 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.448,  Train_accy 96.77, Test_accy 67.76
2025-02-16 18:16:10,225 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.445,  Train_accy 97.29
2025-02-16 18:16:18,341 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.445,  Train_accy 96.81
2025-02-16 18:16:26,199 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.445,  Train_accy 97.17
2025-02-16 18:16:34,406 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.442,  Train_accy 97.13
2025-02-16 18:16:48,609 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.441,  Train_accy 97.29, Test_accy 67.86
2025-02-16 18:16:56,822 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.441,  Train_accy 97.09
2025-02-16 18:17:04,856 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.439,  Train_accy 97.39
2025-02-16 18:17:13,047 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.440,  Train_accy 96.97
2025-02-16 18:17:21,143 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.438,  Train_accy 96.89
2025-02-16 18:17:35,849 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.440,  Train_accy 97.27, Test_accy 67.38
2025-02-16 18:17:44,286 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.438,  Train_accy 96.93
2025-02-16 18:17:52,552 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.437,  Train_accy 97.56
2025-02-16 18:18:00,766 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.437,  Train_accy 97.39
2025-02-16 18:18:09,087 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.435,  Train_accy 97.25
2025-02-16 18:18:23,399 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.437,  Train_accy 97.43, Test_accy 68.21
2025-02-16 18:18:31,765 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.434,  Train_accy 97.41
2025-02-16 18:18:39,899 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.434,  Train_accy 97.05
2025-02-16 18:18:48,020 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.432,  Train_accy 97.60
2025-02-16 18:18:55,980 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.433,  Train_accy 97.31
2025-02-16 18:19:10,197 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.433,  Train_accy 97.56, Test_accy 68.19
2025-02-16 18:19:18,223 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.432,  Train_accy 97.23
2025-02-16 18:19:26,427 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.429,  Train_accy 97.21
2025-02-16 18:19:34,969 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.431,  Train_accy 97.43
2025-02-16 18:19:43,310 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.430,  Train_accy 97.37
2025-02-16 18:19:57,630 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.431,  Train_accy 97.52, Test_accy 68.92
2025-02-16 18:20:05,739 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.430,  Train_accy 97.58
2025-02-16 18:20:13,744 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.431,  Train_accy 97.39
2025-02-16 18:20:22,305 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.428,  Train_accy 97.19
2025-02-16 18:20:30,826 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.428,  Train_accy 97.43
2025-02-16 18:20:45,097 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.425,  Train_accy 97.41, Test_accy 68.49
2025-02-16 18:20:53,299 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.427,  Train_accy 97.62
2025-02-16 18:21:01,469 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.427,  Train_accy 97.37
2025-02-16 18:21:09,652 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.427,  Train_accy 97.68
2025-02-16 18:21:17,723 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.427,  Train_accy 97.52
2025-02-16 18:21:32,704 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.425,  Train_accy 97.03, Test_accy 68.30
2025-02-16 18:21:41,156 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.425,  Train_accy 97.70
2025-02-16 18:21:49,530 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.425,  Train_accy 97.82
2025-02-16 18:21:57,499 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.424,  Train_accy 97.17
2025-02-16 18:22:05,465 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.424,  Train_accy 97.27
2025-02-16 18:22:20,391 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.423,  Train_accy 97.52, Test_accy 68.17
2025-02-16 18:22:28,418 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.423,  Train_accy 97.54
2025-02-16 18:22:36,724 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.423,  Train_accy 97.49
2025-02-16 18:22:44,773 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.421,  Train_accy 97.54
2025-02-16 18:22:53,158 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.424,  Train_accy 97.60
2025-02-16 18:23:07,780 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.422,  Train_accy 97.58, Test_accy 68.63
2025-02-16 18:23:15,814 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.421,  Train_accy 97.31
2025-02-16 18:23:24,321 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.421,  Train_accy 97.76
2025-02-16 18:23:32,486 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.423,  Train_accy 97.43
2025-02-16 18:23:40,910 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.420,  Train_accy 97.80
2025-02-16 18:23:54,878 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.420,  Train_accy 97.58, Test_accy 68.78
2025-02-16 18:24:03,274 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.419,  Train_accy 97.49
2025-02-16 18:24:11,527 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.421,  Train_accy 97.29
2025-02-16 18:24:19,577 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.422,  Train_accy 97.45
2025-02-16 18:24:27,586 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.421,  Train_accy 97.54
2025-02-16 18:24:42,827 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.420,  Train_accy 97.76, Test_accy 68.75
2025-02-16 18:24:51,121 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.421,  Train_accy 97.47
2025-02-16 18:24:59,091 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.420,  Train_accy 97.52
2025-02-16 18:25:07,066 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.419,  Train_accy 97.82
2025-02-16 18:25:15,442 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.420,  Train_accy 97.70
2025-02-16 18:25:29,528 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.420,  Train_accy 97.66, Test_accy 68.75
2025-02-16 18:25:37,473 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.419,  Train_accy 97.70
2025-02-16 18:25:45,610 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.419,  Train_accy 97.60
2025-02-16 18:25:53,650 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.420,  Train_accy 97.56
2025-02-16 18:26:01,573 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.419,  Train_accy 97.80
2025-02-16 18:26:15,657 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.419,  Train_accy 97.54, Test_accy 68.94
2025-02-16 18:26:23,911 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.419,  Train_accy 97.84
2025-02-16 18:26:31,897 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.418,  Train_accy 97.39
2025-02-16 18:26:40,063 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.419,  Train_accy 97.29
2025-02-16 18:26:48,200 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.418,  Train_accy 97.56
2025-02-16 18:27:02,764 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.418,  Train_accy 97.62, Test_accy 68.94
2025-02-16 18:27:11,135 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.418,  Train_accy 97.68
2025-02-16 18:27:19,312 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.419,  Train_accy 97.68
2025-02-16 18:27:27,673 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.418,  Train_accy 97.80
2025-02-16 18:27:35,731 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.417,  Train_accy 97.86
2025-02-16 18:27:49,979 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.418,  Train_accy 97.66, Test_accy 68.67
2025-02-16 18:27:58,070 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.417,  Train_accy 97.62
2025-02-16 18:28:06,247 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.418,  Train_accy 97.80
2025-02-16 18:28:14,381 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.419,  Train_accy 97.19
2025-02-16 18:28:22,273 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.417,  Train_accy 97.58
2025-02-16 18:28:36,346 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.418,  Train_accy 97.84, Test_accy 69.19
2025-02-16 18:28:44,320 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.417,  Train_accy 97.56
2025-02-16 18:28:52,409 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.418,  Train_accy 97.56
2025-02-16 18:29:00,837 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.418,  Train_accy 97.78
2025-02-16 18:29:09,093 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.417,  Train_accy 97.74
2025-02-16 18:29:23,186 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.417,  Train_accy 97.94, Test_accy 69.17
2025-02-16 18:29:31,530 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.417,  Train_accy 97.70
2025-02-16 18:29:39,850 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.418,  Train_accy 97.64
2025-02-16 18:29:48,105 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.416,  Train_accy 97.45
2025-02-16 18:29:56,194 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.418,  Train_accy 97.68
2025-02-16 18:29:56,194 [der.py] => do not weight align student!
2025-02-16 18:30:00,918 [der.py] => darknet eval: 
2025-02-16 18:30:00,918 [der.py] => CNN top1 curve: 69.0
2025-02-16 18:30:00,918 [der.py] => CNN top5 curve: 93.57
2025-02-16 18:30:00,920 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 18:30:44,475 [der.py] => Exemplar size: 1050
2025-02-16 18:30:44,475 [trainer.py] => CNN: {'total': 69.24, '0': 57.78, '1': 35.56, '2': 62.22, '3': 42.78, '4': 63.33, '5': 30.0, '6': 40.56, '7': 26.11, '8': 28.89, '9': 47.22, '10': 86.67, '11': 91.67, '12': 49.44, '13': 50.56, '14': 39.44, '15': 96.11, '16': 94.44, '17': 93.33, '18': 93.33, '19': 96.11, '20': 95.0, '21': 91.11, '22': 94.44, '23': 84.44, '24': 58.33, '25': 68.89, '26': 82.22, '27': 80.0, '28': 55.56, '29': 72.78, '30': 71.11, '31': 84.44, '32': 97.78, '33': 80.0, 'old': 65.96, 'new': 77.44}
2025-02-16 18:30:44,475 [trainer.py] => NME: {'total': 67.49, '0': 65.56, '1': 36.67, '2': 57.78, '3': 47.22, '4': 63.89, '5': 27.78, '6': 33.33, '7': 41.11, '8': 39.44, '9': 58.33, '10': 85.0, '11': 84.44, '12': 46.11, '13': 47.78, '14': 35.0, '15': 91.67, '16': 90.0, '17': 86.11, '18': 89.44, '19': 93.33, '20': 86.11, '21': 90.0, '22': 88.33, '23': 60.0, '24': 46.11, '25': 72.22, '26': 85.56, '27': 87.22, '28': 51.67, '29': 71.11, '30': 71.67, '31': 83.33, '32': 99.44, '33': 69.44, 'old': 63.62, 'new': 77.17}
2025-02-16 18:30:44,475 [trainer.py] => CNN top1 curve: [80.59, 79.84, 69.24]
2025-02-16 18:30:44,475 [trainer.py] => CNN top5 curve: [98.48, 98.29, 93.63]
2025-02-16 18:30:44,475 [trainer.py] => NME top1 curve: [79.15, 77.24, 67.49]
2025-02-16 18:30:44,475 [trainer.py] => NME top5 curve: [98.74, 97.8, 94.19]

2025-02-16 18:30:44,476 [trainer.py] => All params: 15002414
2025-02-16 18:30:44,477 [trainer.py] => Trainable params: 7521966
2025-02-16 18:30:44,599 [der.py] => Learning on 35-45
2025-02-16 18:30:44,600 [der.py] => All params: 15012664
2025-02-16 18:30:44,601 [der.py] => Trainable params: 7532216
2025-02-16 18:30:44,728 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 18:30:44,732 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-16 19:00:33,179 [der.py] => Task 3, Epoch 170/170 => Loss 0.045, Loss_clf 0.002, Loss_aux 0.043, Train_accy 99.98
2025-02-16 19:00:49,359 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.006,  Train_accy 45.14, Test_accy 42.00
2025-02-16 19:00:57,971 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.859,  Train_accy 55.12
2025-02-16 19:01:06,397 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.739,  Train_accy 58.82
2025-02-16 19:01:15,320 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.682,  Train_accy 62.80
2025-02-16 19:01:23,899 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.618,  Train_accy 65.10
2025-02-16 19:01:40,066 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.616,  Train_accy 65.14, Test_accy 47.80
2025-02-16 19:01:48,504 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.621,  Train_accy 64.48
2025-02-16 19:01:57,168 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.541,  Train_accy 67.70
2025-02-16 19:02:05,782 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.570,  Train_accy 67.16
2025-02-16 19:02:14,260 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.554,  Train_accy 67.77
2025-02-16 19:02:29,833 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.539,  Train_accy 68.15, Test_accy 49.63
2025-02-16 19:02:38,610 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.524,  Train_accy 68.02
2025-02-16 19:02:47,225 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.532,  Train_accy 69.10
2025-02-16 19:02:55,831 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.565,  Train_accy 67.77
2025-02-16 19:03:04,403 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.494,  Train_accy 69.28
2025-02-16 19:03:20,291 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.544,  Train_accy 68.59, Test_accy 45.67
2025-02-16 19:03:28,856 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.485,  Train_accy 70.15
2025-02-16 19:03:37,204 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.482,  Train_accy 70.11
2025-02-16 19:03:45,887 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.451,  Train_accy 70.23
2025-02-16 19:03:54,668 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.491,  Train_accy 70.32
2025-02-16 19:04:10,303 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.458,  Train_accy 70.21, Test_accy 49.56
2025-02-16 19:04:19,027 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.461,  Train_accy 70.50
2025-02-16 19:04:27,504 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.435,  Train_accy 71.05
2025-02-16 19:04:36,035 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.459,  Train_accy 70.86
2025-02-16 19:04:44,597 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.454,  Train_accy 70.78
2025-02-16 19:05:00,996 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.458,  Train_accy 70.06, Test_accy 56.68
2025-02-16 19:05:09,496 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.426,  Train_accy 71.31
2025-02-16 19:05:18,327 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.449,  Train_accy 70.69
2025-02-16 19:05:26,805 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.446,  Train_accy 71.03
2025-02-16 19:05:35,271 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.414,  Train_accy 71.26
2025-02-16 19:05:52,091 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.438,  Train_accy 71.24, Test_accy 53.83
2025-02-16 19:06:01,148 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.425,  Train_accy 70.97
2025-02-16 19:06:09,758 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.433,  Train_accy 71.10
2025-02-16 19:06:18,329 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.392,  Train_accy 71.71
2025-02-16 19:06:27,367 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.431,  Train_accy 70.99
2025-02-16 19:06:44,219 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.435,  Train_accy 70.70, Test_accy 56.35
2025-02-16 19:06:52,864 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.445,  Train_accy 70.93
2025-02-16 19:07:01,175 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.405,  Train_accy 71.30
2025-02-16 19:07:09,882 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.413,  Train_accy 70.80
2025-02-16 19:07:18,355 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.416,  Train_accy 71.68
2025-02-16 19:07:34,533 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.428,  Train_accy 71.81, Test_accy 51.73
2025-02-16 19:07:43,183 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.421,  Train_accy 71.47
2025-02-16 19:07:51,740 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.400,  Train_accy 71.62
2025-02-16 19:07:59,944 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.426,  Train_accy 71.05
2025-02-16 19:08:08,679 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.414,  Train_accy 71.22
2025-02-16 19:08:24,451 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.437,  Train_accy 70.80, Test_accy 49.86
2025-02-16 19:08:33,042 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.447,  Train_accy 70.61
2025-02-16 19:08:41,748 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.406,  Train_accy 71.16
2025-02-16 19:08:50,407 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.410,  Train_accy 71.35
2025-02-16 19:08:58,765 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.414,  Train_accy 71.14
2025-02-16 19:09:14,585 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.398,  Train_accy 71.60, Test_accy 44.60
2025-02-16 19:09:23,229 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.391,  Train_accy 71.43
2025-02-16 19:09:31,689 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.386,  Train_accy 71.58
2025-02-16 19:09:40,237 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.400,  Train_accy 71.16
2025-02-16 19:09:48,904 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.414,  Train_accy 71.07
2025-02-16 19:10:04,761 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.385,  Train_accy 71.56, Test_accy 57.19
2025-02-16 19:10:13,031 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.372,  Train_accy 72.23
2025-02-16 19:10:21,538 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.405,  Train_accy 70.91
2025-02-16 19:10:30,205 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.385,  Train_accy 71.70
2025-02-16 19:10:38,707 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.378,  Train_accy 71.66
2025-02-16 19:10:55,178 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.369,  Train_accy 72.27, Test_accy 51.33
2025-02-16 19:11:03,610 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.394,  Train_accy 71.70
2025-02-16 19:11:11,542 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.420,  Train_accy 71.98
2025-02-16 19:11:19,607 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.387,  Train_accy 71.60
2025-02-16 19:11:27,539 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.397,  Train_accy 71.68
2025-02-16 19:11:42,616 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.391,  Train_accy 72.02, Test_accy 54.00
2025-02-16 19:11:50,314 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.394,  Train_accy 71.62
2025-02-16 19:11:57,984 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.379,  Train_accy 71.79
2025-02-16 19:12:05,576 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.370,  Train_accy 71.56
2025-02-16 19:12:13,187 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.386,  Train_accy 71.68
2025-02-16 19:12:27,674 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.366,  Train_accy 72.10, Test_accy 49.47
2025-02-16 19:12:35,311 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.405,  Train_accy 71.83
2025-02-16 19:12:43,162 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.388,  Train_accy 71.45
2025-02-16 19:12:50,988 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.367,  Train_accy 71.45
2025-02-16 19:12:58,878 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.395,  Train_accy 71.70
2025-02-16 19:13:14,497 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.392,  Train_accy 71.70, Test_accy 59.27
2025-02-16 19:13:22,475 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.383,  Train_accy 71.62
2025-02-16 19:13:30,609 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.376,  Train_accy 72.15
2025-02-16 19:13:38,625 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.386,  Train_accy 71.58
2025-02-16 19:13:47,060 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.389,  Train_accy 71.77
2025-02-16 19:14:03,816 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.387,  Train_accy 71.83, Test_accy 57.04
2025-02-16 19:14:12,751 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.392,  Train_accy 71.52
2025-02-16 19:14:21,473 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.388,  Train_accy 72.08
2025-02-16 19:14:29,913 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.368,  Train_accy 72.02
2025-02-16 19:14:38,818 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.376,  Train_accy 71.45
2025-02-16 19:14:54,967 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.375,  Train_accy 71.75, Test_accy 59.95
2025-02-16 19:15:03,671 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.373,  Train_accy 72.04
2025-02-16 19:15:12,358 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.365,  Train_accy 71.87
2025-02-16 19:15:21,044 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.354,  Train_accy 71.56
2025-02-16 19:15:29,542 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.364,  Train_accy 71.87
2025-02-16 19:15:45,764 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.365,  Train_accy 72.29, Test_accy 53.51
2025-02-16 19:15:54,584 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.349,  Train_accy 71.98
2025-02-16 19:16:03,336 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.393,  Train_accy 71.81
2025-02-16 19:16:11,823 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.345,  Train_accy 72.44
2025-02-16 19:16:20,416 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.384,  Train_accy 71.87
2025-02-16 19:16:37,058 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.371,  Train_accy 71.94, Test_accy 59.17
2025-02-16 19:16:45,477 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.376,  Train_accy 71.75
2025-02-16 19:16:54,477 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.346,  Train_accy 71.83
2025-02-16 19:17:03,078 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.376,  Train_accy 71.98
2025-02-16 19:17:11,612 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.382,  Train_accy 71.98
2025-02-16 19:17:27,797 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.369,  Train_accy 71.56, Test_accy 57.09
2025-02-16 19:17:36,342 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.366,  Train_accy 72.40
2025-02-16 19:17:44,885 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.377,  Train_accy 72.15
2025-02-16 19:17:53,407 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.370,  Train_accy 71.92
2025-02-16 19:18:02,403 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.362,  Train_accy 72.32
2025-02-16 19:18:19,105 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.371,  Train_accy 71.96, Test_accy 58.22
2025-02-16 19:18:27,847 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.370,  Train_accy 71.94
2025-02-16 19:18:36,088 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.375,  Train_accy 72.17
2025-02-16 19:18:44,732 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.377,  Train_accy 72.02
2025-02-16 19:18:53,843 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.362,  Train_accy 72.13
2025-02-16 19:19:10,021 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.375,  Train_accy 71.73, Test_accy 56.14
2025-02-16 19:19:18,236 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.369,  Train_accy 71.96
2025-02-16 19:19:27,011 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.354,  Train_accy 71.68
2025-02-16 19:19:36,008 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.370,  Train_accy 72.11
2025-02-16 19:19:44,479 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.371,  Train_accy 72.25
2025-02-16 19:20:00,639 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.363,  Train_accy 71.92, Test_accy 55.90
2025-02-16 19:20:09,146 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.376,  Train_accy 72.02
2025-02-16 19:20:17,593 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.363,  Train_accy 71.39
2025-02-16 19:20:26,017 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.361,  Train_accy 71.68
2025-02-16 19:20:34,722 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.367,  Train_accy 71.96
2025-02-16 19:20:51,256 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.352,  Train_accy 72.06, Test_accy 59.17
2025-02-16 19:20:59,566 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.367,  Train_accy 72.02
2025-02-16 19:21:08,084 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.327,  Train_accy 72.13
2025-02-16 19:21:16,447 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.373,  Train_accy 71.47
2025-02-16 19:21:24,988 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.380,  Train_accy 72.08
2025-02-16 19:21:41,110 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.375,  Train_accy 71.68, Test_accy 56.19
2025-02-16 19:21:50,181 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.373,  Train_accy 72.06
2025-02-16 19:21:58,731 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.376,  Train_accy 72.13
2025-02-16 19:22:07,236 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.362,  Train_accy 71.87
2025-02-16 19:22:15,535 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.352,  Train_accy 72.42
2025-02-16 19:22:15,536 [der.py] => do not weight align student!
2025-02-16 19:22:21,766 [der.py] => darknet eval: 
2025-02-16 19:22:21,766 [der.py] => CNN top1 curve: 55.78
2025-02-16 19:22:21,766 [der.py] => CNN top5 curve: 89.47
2025-02-16 19:22:21,769 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 19:23:12,621 [der.py] => Exemplar size: 1350
2025-02-16 19:23:12,622 [trainer.py] => CNN: {'total': 62.73, '0': 50.0, '1': 38.89, '2': 48.33, '3': 35.56, '4': 68.33, '5': 16.11, '6': 30.0, '7': 23.89, '8': 40.56, '9': 39.44, '10': 80.0, '11': 82.22, '12': 44.44, '13': 39.44, '14': 28.33, '15': 83.89, '16': 79.44, '17': 87.22, '18': 79.44, '19': 73.33, '20': 72.22, '21': 77.22, '22': 81.67, '23': 46.67, '24': 27.78, '25': 92.22, '26': 89.44, '27': 94.44, '28': 68.33, '29': 86.67, '30': 82.78, '31': 85.56, '32': 98.89, '33': 80.56, '34': 80.56, '35': 96.67, '36': 89.44, '37': 24.44, '38': 14.44, '39': 70.56, '40': 38.89, '41': 59.44, '42': 90.56, '43': 76.11, 'old': 63.83, 'new': 58.89}
2025-02-16 19:23:12,622 [trainer.py] => NME: {'total': 66.63, '0': 47.78, '1': 43.33, '2': 51.11, '3': 32.78, '4': 57.78, '5': 16.67, '6': 33.89, '7': 32.78, '8': 48.89, '9': 54.44, '10': 76.67, '11': 78.33, '12': 43.89, '13': 48.89, '14': 36.11, '15': 85.0, '16': 80.0, '17': 82.78, '18': 83.89, '19': 78.33, '20': 73.33, '21': 81.11, '22': 77.22, '23': 49.44, '24': 31.67, '25': 68.89, '26': 85.0, '27': 85.56, '28': 65.0, '29': 80.0, '30': 75.56, '31': 83.33, '32': 87.78, '33': 54.44, '34': 78.89, '35': 97.78, '36': 93.89, '37': 60.56, '38': 93.33, '39': 90.0, '40': 66.67, '41': 75.56, '42': 91.11, '43': 81.67, 'old': 62.59, 'new': 80.78}
2025-02-16 19:23:12,622 [trainer.py] => CNN top1 curve: [80.59, 79.84, 69.24, 62.73]
2025-02-16 19:23:12,622 [trainer.py] => CNN top5 curve: [98.48, 98.29, 93.63, 91.67]
2025-02-16 19:23:12,622 [trainer.py] => NME top1 curve: [79.15, 77.24, 67.49, 66.63]
2025-02-16 19:23:12,622 [trainer.py] => NME top5 curve: [98.74, 97.8, 94.19, 92.81]

2025-02-16 19:23:12,623 [trainer.py] => All params: 15012664
2025-02-16 19:23:12,624 [trainer.py] => Trainable params: 7532216
2025-02-16 19:23:12,763 [der.py] => Learning on 45-55
2025-02-16 19:23:12,765 [der.py] => All params: 15022914
2025-02-16 19:23:12,765 [der.py] => Trainable params: 7542466
2025-02-16 19:23:12,893 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 19:23:12,894 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-16 19:56:23,146 [der.py] => Task 4, Epoch 170/170 => Loss 0.009, Loss_clf 0.007, Loss_aux 0.002, Train_accy 100.00
2025-02-16 19:56:42,064 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.910,  Train_accy 39.69, Test_accy 51.98
2025-02-16 19:56:51,193 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.643,  Train_accy 60.41
2025-02-16 19:57:00,310 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.521,  Train_accy 70.92
2025-02-16 19:57:09,658 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.454,  Train_accy 76.68
2025-02-16 19:57:18,702 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.403,  Train_accy 81.42
2025-02-16 19:57:37,840 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.361,  Train_accy 85.51, Test_accy 58.09
2025-02-16 19:57:47,025 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.341,  Train_accy 87.42
2025-02-16 19:57:56,194 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.320,  Train_accy 88.76
2025-02-16 19:58:05,475 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.290,  Train_accy 90.95
2025-02-16 19:58:15,152 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.277,  Train_accy 92.92
2025-02-16 19:58:33,616 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.266,  Train_accy 93.62, Test_accy 60.10
2025-02-16 19:58:42,774 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.257,  Train_accy 93.96
2025-02-16 19:58:51,724 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.247,  Train_accy 95.21
2025-02-16 19:59:00,944 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.241,  Train_accy 94.88
2025-02-16 19:59:09,794 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.236,  Train_accy 95.32
2025-02-16 19:59:29,095 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.230,  Train_accy 96.04, Test_accy 61.02
2025-02-16 19:59:38,382 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.228,  Train_accy 96.00
2025-02-16 19:59:47,541 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.225,  Train_accy 96.31
2025-02-16 19:59:57,056 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.222,  Train_accy 96.20
2025-02-16 20:00:06,244 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.212,  Train_accy 96.81
2025-02-16 20:00:25,190 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.210,  Train_accy 96.67, Test_accy 60.69
2025-02-16 20:00:34,317 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.211,  Train_accy 96.94
2025-02-16 20:00:43,209 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.205,  Train_accy 97.21
2025-02-16 20:00:52,277 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.205,  Train_accy 97.12
2025-02-16 20:01:01,575 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.208,  Train_accy 97.15
2025-02-16 20:01:19,968 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.202,  Train_accy 97.46, Test_accy 61.88
2025-02-16 20:01:29,382 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.205,  Train_accy 97.32
2025-02-16 20:01:38,367 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.199,  Train_accy 97.60
2025-02-16 20:01:47,555 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.196,  Train_accy 97.59
2025-02-16 20:01:56,605 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.191,  Train_accy 97.60
2025-02-16 20:02:15,213 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.193,  Train_accy 97.66, Test_accy 62.74
2025-02-16 20:02:24,511 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.190,  Train_accy 97.39
2025-02-16 20:02:33,687 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.189,  Train_accy 97.96
2025-02-16 20:02:42,969 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.185,  Train_accy 97.69
2025-02-16 20:02:52,063 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.181,  Train_accy 98.02
2025-02-16 20:03:10,482 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.183,  Train_accy 98.02, Test_accy 62.87
2025-02-16 20:03:19,746 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.182,  Train_accy 97.96
2025-02-16 20:03:28,911 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.181,  Train_accy 98.11
2025-02-16 20:03:38,054 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.185,  Train_accy 97.96
2025-02-16 20:03:47,155 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.185,  Train_accy 98.05
2025-02-16 20:04:06,315 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.181,  Train_accy 97.91, Test_accy 62.65
2025-02-16 20:04:15,425 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.178,  Train_accy 98.32
2025-02-16 20:04:24,531 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.177,  Train_accy 98.31
2025-02-16 20:04:33,882 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.176,  Train_accy 97.95
2025-02-16 20:04:43,084 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.179,  Train_accy 98.18
2025-02-16 20:05:01,616 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.177,  Train_accy 98.00, Test_accy 63.57
2025-02-16 20:05:10,709 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.174,  Train_accy 98.22
2025-02-16 20:05:20,013 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.172,  Train_accy 98.02
2025-02-16 20:05:29,163 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.169,  Train_accy 98.18
2025-02-16 20:05:38,318 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.172,  Train_accy 98.05
2025-02-16 20:05:56,646 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.175,  Train_accy 98.23, Test_accy 62.54
2025-02-16 20:06:05,855 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.174,  Train_accy 98.29
2025-02-16 20:06:15,034 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.171,  Train_accy 98.45
2025-02-16 20:06:23,997 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.171,  Train_accy 98.34
2025-02-16 20:06:33,142 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.169,  Train_accy 98.36
2025-02-16 20:06:51,888 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.171,  Train_accy 98.45, Test_accy 62.91
2025-02-16 20:07:01,161 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.164,  Train_accy 98.45
2025-02-16 20:07:10,457 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.172,  Train_accy 98.31
2025-02-16 20:07:19,538 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.170,  Train_accy 98.36
2025-02-16 20:07:28,671 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.165,  Train_accy 98.29
2025-02-16 20:07:47,676 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.166,  Train_accy 98.50, Test_accy 63.39
2025-02-16 20:07:56,835 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.165,  Train_accy 98.25
2025-02-16 20:08:06,396 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.167,  Train_accy 98.56
2025-02-16 20:08:15,444 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.163,  Train_accy 98.25
2025-02-16 20:08:24,566 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.162,  Train_accy 98.38
2025-02-16 20:08:43,448 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.161,  Train_accy 98.40, Test_accy 63.68
2025-02-16 20:08:52,544 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.164,  Train_accy 98.72
2025-02-16 20:09:02,316 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.164,  Train_accy 98.47
2025-02-16 20:09:11,350 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.158,  Train_accy 98.31
2025-02-16 20:09:20,486 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.162,  Train_accy 98.49
2025-02-16 20:09:38,723 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.162,  Train_accy 98.54, Test_accy 64.00
2025-02-16 20:09:48,376 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.161,  Train_accy 98.56
2025-02-16 20:09:57,869 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.158,  Train_accy 98.41
2025-02-16 20:10:07,284 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.161,  Train_accy 98.56
2025-02-16 20:10:16,376 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.158,  Train_accy 98.67
2025-02-16 20:10:35,022 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.159,  Train_accy 98.54, Test_accy 63.61
2025-02-16 20:10:43,912 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.160,  Train_accy 98.65
2025-02-16 20:10:53,245 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.161,  Train_accy 98.61
2025-02-16 20:11:02,186 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.157,  Train_accy 98.81
2025-02-16 20:11:11,248 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.157,  Train_accy 98.58
2025-02-16 20:11:29,226 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.159,  Train_accy 98.58, Test_accy 63.77
2025-02-16 20:11:38,638 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.156,  Train_accy 98.63
2025-02-16 20:11:47,496 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.157,  Train_accy 98.83
2025-02-16 20:11:56,507 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.158,  Train_accy 98.56
2025-02-16 20:12:05,484 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.158,  Train_accy 98.88
2025-02-16 20:12:23,090 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.155,  Train_accy 98.56, Test_accy 63.99
2025-02-16 20:12:32,646 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.156,  Train_accy 98.58
2025-02-16 20:12:41,880 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.156,  Train_accy 98.59
2025-02-16 20:12:50,907 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.156,  Train_accy 98.83
2025-02-16 20:12:59,668 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.155,  Train_accy 98.47
2025-02-16 20:13:17,606 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.156,  Train_accy 98.54, Test_accy 63.59
2025-02-16 20:13:26,237 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.153,  Train_accy 98.76
2025-02-16 20:13:35,302 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.155,  Train_accy 98.67
2025-02-16 20:13:44,321 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.153,  Train_accy 98.90
2025-02-16 20:13:53,146 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.152,  Train_accy 98.65
2025-02-16 20:14:10,513 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.154,  Train_accy 98.61, Test_accy 63.76
2025-02-16 20:14:19,282 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.153,  Train_accy 98.95
2025-02-16 20:14:28,361 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.154,  Train_accy 98.59
2025-02-16 20:14:37,468 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.155,  Train_accy 98.74
2025-02-16 20:14:46,715 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.154,  Train_accy 98.92
2025-02-16 20:15:04,502 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.154,  Train_accy 98.81, Test_accy 64.06
2025-02-16 20:15:13,246 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.156,  Train_accy 98.50
2025-02-16 20:15:22,214 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.153,  Train_accy 98.72
2025-02-16 20:15:30,987 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.153,  Train_accy 98.65
2025-02-16 20:15:39,673 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.152,  Train_accy 98.61
2025-02-16 20:15:57,454 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.154,  Train_accy 98.74, Test_accy 63.74
2025-02-16 20:16:06,130 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.149,  Train_accy 98.83
2025-02-16 20:16:14,783 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.152,  Train_accy 98.72
2025-02-16 20:16:23,468 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.153,  Train_accy 98.67
2025-02-16 20:16:32,715 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.151,  Train_accy 98.74
2025-02-16 20:16:50,315 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.153,  Train_accy 98.94, Test_accy 63.97
2025-02-16 20:16:59,671 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.150,  Train_accy 98.76
2025-02-16 20:17:08,463 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.152,  Train_accy 98.92
2025-02-16 20:17:17,326 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.153,  Train_accy 98.70
2025-02-16 20:17:26,604 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.152,  Train_accy 98.67
2025-02-16 20:17:44,453 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.150,  Train_accy 98.95, Test_accy 63.38
2025-02-16 20:17:53,431 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.152,  Train_accy 98.58
2025-02-16 20:18:02,224 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.153,  Train_accy 98.76
2025-02-16 20:18:11,338 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.151,  Train_accy 98.76
2025-02-16 20:18:20,169 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.149,  Train_accy 98.63
2025-02-16 20:18:41,964 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.152,  Train_accy 98.72, Test_accy 63.99
2025-02-16 20:18:50,034 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.152,  Train_accy 98.68
2025-02-16 20:18:58,278 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.151,  Train_accy 98.92
2025-02-16 20:19:06,646 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.152,  Train_accy 98.68
2025-02-16 20:19:14,933 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.150,  Train_accy 98.76
2025-02-16 20:19:31,170 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.152,  Train_accy 98.90, Test_accy 63.94
2025-02-16 20:19:39,102 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.152,  Train_accy 98.72
2025-02-16 20:19:47,118 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.150,  Train_accy 98.70
2025-02-16 20:19:55,263 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.152,  Train_accy 98.72
2025-02-16 20:20:03,108 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.150,  Train_accy 98.90
2025-02-16 20:20:03,108 [der.py] => do not weight align student!
2025-02-16 20:20:23,195 [der.py] => darknet eval: 
2025-02-16 20:20:23,195 [der.py] => CNN top1 curve: 63.59
2025-02-16 20:20:23,195 [der.py] => CNN top5 curve: 88.64
2025-02-16 20:20:23,196 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 20:21:25,873 [der.py] => Exemplar size: 1650
2025-02-16 20:21:27,710 [trainer.py] => CNN: {'total': 61.56, '0': 31.67, '1': 36.67, '2': 47.22, '3': 20.56, '4': 55.56, '5': 25.56, '6': 26.67, '7': 30.0, '8': 46.67, '9': 39.44, '10': 66.11, '11': 66.11, '12': 33.33, '13': 47.22, '14': 33.33, '15': 78.33, '16': 75.56, '17': 73.89, '18': 56.67, '19': 65.56, '20': 65.0, '21': 62.22, '22': 70.0, '23': 38.33, '24': 37.78, '25': 52.78, '26': 71.11, '27': 78.33, '28': 41.67, '29': 55.56, '30': 58.89, '31': 54.44, '32': 83.89, '33': 33.33, '34': 58.33, '35': 98.89, '36': 98.89, '37': 63.89, '38': 93.33, '39': 97.78, '40': 73.33, '41': 96.67, '42': 96.67, '43': 97.22, '44': 68.33, '45': 77.78, '46': 74.44, '47': 63.89, '48': 58.89, '49': 67.22, '50': 61.67, '51': 77.22, '52': 73.89, '53': 60.56, 'old': 60.06, 'new': 68.28}
2025-02-16 20:21:27,710 [trainer.py] => NME: {'total': 57.78, '0': 40.56, '1': 40.0, '2': 40.56, '3': 13.33, '4': 57.78, '5': 29.44, '6': 31.67, '7': 37.78, '8': 50.0, '9': 45.56, '10': 72.22, '11': 85.56, '12': 30.0, '13': 47.22, '14': 29.44, '15': 76.11, '16': 71.11, '17': 70.56, '18': 52.22, '19': 56.67, '20': 64.44, '21': 59.44, '22': 61.11, '23': 39.44, '24': 33.33, '25': 47.78, '26': 66.11, '27': 70.56, '28': 40.0, '29': 57.78, '30': 51.11, '31': 52.78, '32': 80.56, '33': 31.67, '34': 59.44, '35': 85.56, '36': 82.22, '37': 35.56, '38': 77.78, '39': 78.33, '40': 42.78, '41': 91.67, '42': 93.89, '43': 90.56, '44': 37.22, '45': 70.0, '46': 71.11, '47': 69.44, '48': 67.22, '49': 68.89, '50': 61.11, '51': 70.0, '52': 71.67, '53': 56.11, 'old': 55.75, 'new': 66.89}
2025-02-16 20:21:27,711 [trainer.py] => CNN top1 curve: [80.59, 79.84, 69.24, 62.73, 61.56]
2025-02-16 20:21:27,711 [trainer.py] => CNN top5 curve: [98.48, 98.29, 93.63, 91.67, 88.81]
2025-02-16 20:21:27,711 [trainer.py] => NME top1 curve: [79.15, 77.24, 67.49, 66.63, 57.78]
2025-02-16 20:21:27,711 [trainer.py] => NME top5 curve: [98.74, 97.8, 94.19, 92.81, 88.07]

2025-04-22 00:40:20,832 [trainer.py] => 实验名称:CIL实验
2025-04-22 00:40:20,846 [trainer.py] => config: ./exps/der.json
2025-04-22 00:40:20,846 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 00:40:20,846 [trainer.py] => prefix: reproduce
2025-04-22 00:40:20,846 [trainer.py] => dataset: xrfdataset
2025-04-22 00:40:20,847 [trainer.py] => memory_size: 1650
2025-04-22 00:40:20,847 [trainer.py] => memory_per_class: 30
2025-04-22 00:40:20,847 [trainer.py] => fixed_memory: True
2025-04-22 00:40:20,847 [trainer.py] => shuffle: True
2025-04-22 00:40:20,847 [trainer.py] => init_cls: 15
2025-04-22 00:40:20,847 [trainer.py] => increment: 10
2025-04-22 00:40:20,847 [trainer.py] => model_name: der
2025-04-22 00:40:20,847 [trainer.py] => compression_epochs: 1
2025-04-22 00:40:20,847 [trainer.py] => compression_lr: 0.1
2025-04-22 00:40:20,847 [trainer.py] => is_student_wa: False
2025-04-22 00:40:20,847 [trainer.py] => wa_value: 1
2025-04-22 00:40:20,847 [trainer.py] => T: 2
2025-04-22 00:40:20,847 [trainer.py] => convnet_type: resnet34
2025-04-22 00:40:20,847 [trainer.py] => device: [device(type='cuda', index=1)]
2025-04-22 00:40:20,847 [trainer.py] => seed: 1993
2025-04-22 00:40:20,863 [data.py] => 加载完毕XRF原始数据集
2025-04-22 00:40:20,868 [data.py] => 加载完毕XRF原始数据集
2025-04-22 00:40:20,869 [trainer.py] => All params: 0
2025-04-22 00:40:20,870 [trainer.py] => Trainable params: 0
2025-04-22 00:40:21,021 [der.py] => Learning on 0-15
2025-04-22 00:40:21,022 [der.py] => All params: 7496351
2025-04-22 00:40:21,023 [der.py] => Trainable params: 7496351
2025-04-22 00:40:30,502 [der.py] => Task 0, Epoch 1/1 => Loss 4.457, Train_accy 6.92, Test_accy 6.85
2025-04-22 00:40:30,503 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:40:51,367 [der.py] => Exemplar size: 450
2025-04-22 00:40:51,367 [trainer.py] => CNN: {'total': 6.85, '0': 0.56, '1': 97.22, '2': 5.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 6.85}
2025-04-22 00:40:51,368 [trainer.py] => NME: {'total': 10.44, '0': 32.78, '1': 36.67, '2': 1.11, '3': 0.0, '4': 0.0, '5': 28.89, '6': 0.0, '7': 12.22, '8': 1.11, '9': 0.0, '10': 1.67, '11': 38.89, '12': 3.33, '13': 0.0, 'old': 0, 'new': 10.44}
2025-04-22 00:40:51,368 [trainer.py] => CNN top1 curve: [6.85]
2025-04-22 00:40:51,368 [trainer.py] => CNN top5 curve: [34.52]
2025-04-22 00:40:51,368 [trainer.py] => NME top1 curve: [10.44]
2025-04-22 00:40:51,368 [trainer.py] => NME top5 curve: [37.96]

2025-04-22 00:40:51,368 [trainer.py] => All params: 7496351
2025-04-22 00:40:51,369 [trainer.py] => Trainable params: 7496351
2025-04-22 00:40:51,506 [der.py] => Learning on 15-25
2025-04-22 00:40:51,507 [der.py] => All params: 14992164
2025-04-22 00:40:51,508 [der.py] => Trainable params: 7511716
2025-04-22 00:40:51,594 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:40:51,595 [der.py] => per cls weights : [1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 0.17661843 0.17661843 0.17661843
 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843
 0.17661843]
2025-04-22 00:40:59,227 [der.py] => Task 1, Epoch 1/1 => Loss 5.008, Loss_clf 2.657, Loss_aux 2.351, Train_accy 11.03, Test_accy 5.00
2025-04-22 00:41:06,884 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 3.050,  Train_accy 11.20, Test_accy 3.73
2025-04-22 00:41:06,885 [der.py] => do not weight align student!
2025-04-22 00:41:10,168 [der.py] => darknet eval: 
2025-04-22 00:41:10,168 [der.py] => CNN top1 curve: 3.73
2025-04-22 00:41:10,168 [der.py] => CNN top5 curve: 20.44
2025-04-22 00:41:10,169 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:41:34,288 [der.py] => Exemplar size: 750
2025-04-22 00:41:34,289 [trainer.py] => CNN: {'total': 4.98, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 25.56, '16': 0.0, '17': 0.0, '18': 6.11, '19': 0.0, '20': 0.0, '21': 0.0, '22': 13.33, '23': 4.44, 'old': 0.0, 'new': 12.44}
2025-04-22 00:41:34,289 [trainer.py] => NME: {'total': 4.91, '0': 6.67, '1': 37.22, '2': 4.44, '3': 12.22, '4': 0.0, '5': 0.56, '6': 2.22, '7': 3.89, '8': 2.22, '9': 0.0, '10': 6.67, '11': 2.22, '12': 2.78, '13': 7.78, '14': 11.11, '15': 0.56, '16': 0.56, '17': 0.56, '18': 0.0, '19': 0.56, '20': 0.0, '21': 3.33, '22': 0.0, '23': 1.11, 'old': 6.67, 'new': 2.28}
2025-04-22 00:41:34,289 [trainer.py] => CNN top1 curve: [6.85, 4.98]
2025-04-22 00:41:34,289 [trainer.py] => CNN top5 curve: [34.52, 22.64]
2025-04-22 00:41:34,289 [trainer.py] => NME top1 curve: [10.44, 4.91]
2025-04-22 00:41:34,289 [trainer.py] => NME top5 curve: [37.96, 22.56]

2025-04-22 00:41:34,290 [trainer.py] => All params: 14992164
2025-04-22 00:41:34,291 [trainer.py] => Trainable params: 7511716
2025-04-22 00:41:34,428 [der.py] => Learning on 25-35
2025-04-22 00:41:34,430 [der.py] => All params: 15002414
2025-04-22 00:41:34,431 [der.py] => Trainable params: 7521966
2025-04-22 00:41:34,544 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:41:34,545 [der.py] => per cls weights : [1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388
 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388]
2025-04-22 00:41:43,422 [der.py] => Task 2, Epoch 1/1 => Loss 6.655, Loss_clf 4.260, Loss_aux 2.395, Train_accy 9.04, Test_accy 3.25
2025-04-22 00:41:53,007 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.231,  Train_accy 10.51, Test_accy 2.89
2025-04-22 00:41:53,007 [der.py] => do not weight align student!
2025-04-22 00:41:57,640 [der.py] => darknet eval: 
2025-04-22 00:41:57,640 [der.py] => CNN top1 curve: 2.89
2025-04-22 00:41:57,640 [der.py] => CNN top5 curve: 14.68
2025-04-22 00:41:57,641 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:42:27,838 [der.py] => Exemplar size: 1050
2025-04-22 00:42:27,839 [trainer.py] => CNN: {'total': 3.25, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 86.67, '26': 0.0, '27': 6.11, '28': 0.0, '29': 10.0, '30': 0.0, '31': 1.11, '32': 6.67, '33': 3.33, 'old': 0.0, 'new': 11.39}
2025-04-22 00:42:27,839 [trainer.py] => NME: {'total': 3.38, '0': 2.22, '1': 11.11, '2': 0.56, '3': 0.56, '4': 0.56, '5': 0.56, '6': 2.22, '7': 6.67, '8': 0.56, '9': 0.56, '10': 3.33, '11': 1.67, '12': 5.0, '13': 0.0, '14': 13.33, '15': 2.22, '16': 0.0, '17': 0.56, '18': 1.67, '19': 1.11, '20': 15.0, '21': 0.56, '22': 0.0, '23': 0.56, '24': 2.78, '25': 0.0, '26': 0.0, '27': 8.89, '28': 33.89, '29': 0.56, '30': 0.56, '31': 0.0, '32': 0.0, '33': 0.56, 'old': 2.93, 'new': 4.5}
2025-04-22 00:42:27,839 [trainer.py] => CNN top1 curve: [6.85, 4.98, 3.25]
2025-04-22 00:42:27,839 [trainer.py] => CNN top5 curve: [34.52, 22.64, 15.02]
2025-04-22 00:42:27,839 [trainer.py] => NME top1 curve: [10.44, 4.91, 3.38]
2025-04-22 00:42:27,839 [trainer.py] => NME top5 curve: [37.96, 22.56, 15.43]

2025-04-22 00:42:27,840 [trainer.py] => All params: 15002414
2025-04-22 00:42:27,840 [trainer.py] => Trainable params: 7521966
2025-04-22 00:42:27,980 [der.py] => Learning on 35-45
2025-04-22 00:42:27,981 [der.py] => All params: 15012664
2025-04-22 00:42:27,982 [der.py] => Trainable params: 7532216
2025-04-22 00:42:28,107 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:42:28,108 [der.py] => per cls weights : [1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  0.14198023
 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023
 0.14198023 0.14198023 0.14198023]
2025-04-22 00:58:33,133 [trainer.py] => 实验名称:CIL实验
2025-04-22 00:58:33,134 [trainer.py] => config: ./exps/der.json
2025-04-22 00:58:33,134 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 00:58:33,134 [trainer.py] => prefix: reproduce
2025-04-22 00:58:33,134 [trainer.py] => dataset: xrfdataset
2025-04-22 00:58:33,134 [trainer.py] => memory_size: 1650
2025-04-22 00:58:33,134 [trainer.py] => memory_per_class: 30
2025-04-22 00:58:33,134 [trainer.py] => fixed_memory: True
2025-04-22 00:58:33,134 [trainer.py] => shuffle: True
2025-04-22 00:58:33,134 [trainer.py] => init_cls: 15
2025-04-22 00:58:33,134 [trainer.py] => increment: 10
2025-04-22 00:58:33,134 [trainer.py] => model_name: der
2025-04-22 00:58:33,135 [trainer.py] => compression_epochs: 1
2025-04-22 00:58:33,135 [trainer.py] => compression_lr: 0.1
2025-04-22 00:58:33,135 [trainer.py] => is_student_wa: False
2025-04-22 00:58:33,135 [trainer.py] => wa_value: 1
2025-04-22 00:58:33,135 [trainer.py] => T: 2
2025-04-22 00:58:33,135 [trainer.py] => convnet_type: resnet34
2025-04-22 00:58:33,135 [trainer.py] => device: [device(type='cuda', index=1)]
2025-04-22 00:58:33,135 [trainer.py] => seed: 1993
2025-04-22 00:58:33,151 [data.py] => 加载完毕XRF原始数据集
2025-04-22 00:58:33,157 [data.py] => 加载完毕XRF原始数据集
2025-04-22 00:58:33,158 [trainer.py] => All params: 0
2025-04-22 00:58:33,159 [trainer.py] => Trainable params: 0
2025-04-22 00:58:33,306 [der.py] => Learning on 0-15
2025-04-22 00:58:33,306 [der.py] => All params: 7496351
2025-04-22 00:58:33,307 [der.py] => Trainable params: 7496351
2025-04-22 00:58:42,660 [der.py] => Task 0, Epoch 1/1 => Loss 4.457, Train_accy 6.92, Test_accy 6.85
2025-04-22 00:58:42,661 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:59:03,460 [der.py] => Exemplar size: 450
2025-04-22 00:59:03,460 [trainer.py] => CNN: {'total': 6.85, '0': 0.56, '1': 97.22, '2': 5.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, 'old': 0, 'new': 6.85}
2025-04-22 00:59:03,460 [trainer.py] => NME: {'total': 10.44, '0': 32.78, '1': 36.67, '2': 1.11, '3': 0.0, '4': 0.0, '5': 28.89, '6': 0.0, '7': 12.22, '8': 1.11, '9': 0.0, '10': 1.67, '11': 38.89, '12': 3.33, '13': 0.0, 'old': 0, 'new': 10.44}
2025-04-22 00:59:03,461 [trainer.py] => CNN top1 curve: [6.85]
2025-04-22 00:59:03,461 [trainer.py] => CNN top5 curve: [34.52]
2025-04-22 00:59:03,461 [trainer.py] => NME top1 curve: [10.44]
2025-04-22 00:59:03,461 [trainer.py] => NME top5 curve: [37.96]

2025-04-22 00:59:03,461 [trainer.py] => All params: 7496351
2025-04-22 00:59:03,462 [trainer.py] => Trainable params: 7496351
2025-04-22 00:59:03,597 [der.py] => Learning on 15-25
2025-04-22 00:59:03,598 [der.py] => All params: 14992164
2025-04-22 00:59:03,599 [der.py] => Trainable params: 7511716
2025-04-22 00:59:03,690 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:59:03,691 [der.py] => per cls weights : [1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 0.17661843 0.17661843 0.17661843
 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843
 0.17661843]
2025-04-22 00:59:11,478 [der.py] => Task 1, Epoch 1/1 => Loss 5.008, Loss_clf 2.657, Loss_aux 2.351, Train_accy 11.03, Test_accy 5.00
2025-04-22 00:59:19,667 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 3.050,  Train_accy 11.20, Test_accy 3.73
2025-04-22 00:59:19,668 [der.py] => do not weight align student!
2025-04-22 00:59:22,988 [der.py] => darknet eval: 
2025-04-22 00:59:22,988 [der.py] => CNN top1 curve: 3.73
2025-04-22 00:59:22,988 [der.py] => CNN top5 curve: 20.44
2025-04-22 00:59:22,989 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 00:59:46,671 [der.py] => Exemplar size: 750
2025-04-22 00:59:46,671 [trainer.py] => CNN: {'total': 4.98, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 25.56, '16': 0.0, '17': 0.0, '18': 6.11, '19': 0.0, '20': 0.0, '21': 0.0, '22': 13.33, '23': 4.44, 'old': 0.0, 'new': 12.44}
2025-04-22 00:59:46,671 [trainer.py] => NME: {'total': 4.91, '0': 6.67, '1': 37.22, '2': 4.44, '3': 12.22, '4': 0.0, '5': 0.56, '6': 2.22, '7': 3.89, '8': 2.22, '9': 0.0, '10': 6.67, '11': 2.22, '12': 2.78, '13': 7.78, '14': 11.11, '15': 0.56, '16': 0.56, '17': 0.56, '18': 0.0, '19': 0.56, '20': 0.0, '21': 3.33, '22': 0.0, '23': 1.11, 'old': 6.67, 'new': 2.28}
2025-04-22 00:59:46,671 [trainer.py] => CNN top1 curve: [6.85, 4.98]
2025-04-22 00:59:46,671 [trainer.py] => CNN top5 curve: [34.52, 22.64]
2025-04-22 00:59:46,672 [trainer.py] => NME top1 curve: [10.44, 4.91]
2025-04-22 00:59:46,672 [trainer.py] => NME top5 curve: [37.96, 22.56]

2025-04-22 00:59:46,672 [trainer.py] => All params: 14992164
2025-04-22 00:59:46,673 [trainer.py] => Trainable params: 7511716
2025-04-22 00:59:46,815 [der.py] => Learning on 25-35
2025-04-22 00:59:46,816 [der.py] => All params: 15002414
2025-04-22 00:59:46,817 [der.py] => Trainable params: 7521966
2025-04-22 00:59:46,920 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 00:59:46,920 [der.py] => per cls weights : [1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388
 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388]
2025-04-22 00:59:55,937 [der.py] => Task 2, Epoch 1/1 => Loss 6.655, Loss_clf 4.260, Loss_aux 2.395, Train_accy 9.04, Test_accy 3.25
2025-04-22 01:00:05,546 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.231,  Train_accy 10.51, Test_accy 2.89
2025-04-22 01:00:05,547 [der.py] => do not weight align student!
2025-04-22 01:00:09,562 [der.py] => darknet eval: 
2025-04-22 01:00:09,562 [der.py] => CNN top1 curve: 2.89
2025-04-22 01:00:09,563 [der.py] => CNN top5 curve: 14.68
2025-04-22 01:00:09,563 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:00:38,550 [der.py] => Exemplar size: 1050
2025-04-22 01:00:38,551 [trainer.py] => CNN: {'total': 3.25, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 86.67, '26': 0.0, '27': 6.11, '28': 0.0, '29': 10.0, '30': 0.0, '31': 1.11, '32': 6.67, '33': 3.33, 'old': 0.0, 'new': 11.39}
2025-04-22 01:00:38,551 [trainer.py] => NME: {'total': 3.38, '0': 2.22, '1': 11.11, '2': 0.56, '3': 0.56, '4': 0.56, '5': 0.56, '6': 2.22, '7': 6.67, '8': 0.56, '9': 0.56, '10': 3.33, '11': 1.67, '12': 5.0, '13': 0.0, '14': 13.33, '15': 2.22, '16': 0.0, '17': 0.56, '18': 1.67, '19': 1.11, '20': 15.0, '21': 0.56, '22': 0.0, '23': 0.56, '24': 2.78, '25': 0.0, '26': 0.0, '27': 8.89, '28': 33.89, '29': 0.56, '30': 0.56, '31': 0.0, '32': 0.0, '33': 0.56, 'old': 2.93, 'new': 4.5}
2025-04-22 01:00:38,551 [trainer.py] => CNN top1 curve: [6.85, 4.98, 3.25]
2025-04-22 01:00:38,551 [trainer.py] => CNN top5 curve: [34.52, 22.64, 15.02]
2025-04-22 01:00:38,551 [trainer.py] => NME top1 curve: [10.44, 4.91, 3.38]
2025-04-22 01:00:38,551 [trainer.py] => NME top5 curve: [37.96, 22.56, 15.43]

2025-04-22 01:00:38,552 [trainer.py] => All params: 15002414
2025-04-22 01:00:38,553 [trainer.py] => Trainable params: 7521966
2025-04-22 01:00:38,685 [der.py] => Learning on 35-45
2025-04-22 01:00:38,686 [der.py] => All params: 15012664
2025-04-22 01:00:38,687 [der.py] => Trainable params: 7532216
2025-04-22 01:00:38,803 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 01:00:38,804 [der.py] => per cls weights : [1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  0.14198023
 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023
 0.14198023 0.14198023 0.14198023]
2025-04-22 01:02:15,253 [der.py] => Task 3, Epoch 1/1 => Loss 7.479, Loss_clf 5.109, Loss_aux 2.370, Train_accy 9.56, Test_accy 2.42
2025-04-22 01:02:25,776 [der.py] => SNet: Task 3, Epoch 1/1 => Loss 3.419,  Train_accy 11.12, Test_accy 2.49
2025-04-22 01:02:25,777 [der.py] => do not weight align student!
2025-04-22 01:02:31,462 [der.py] => darknet eval: 
2025-04-22 01:02:31,462 [der.py] => CNN top1 curve: 2.49
2025-04-22 01:02:31,462 [der.py] => CNN top5 curve: 12.28
2025-04-22 01:02:31,463 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:03:08,093 [der.py] => Exemplar size: 1350
2025-04-22 01:03:08,094 [trainer.py] => CNN: {'total': 2.4, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 0.0, '38': 19.44, '39': 7.22, '40': 0.0, '41': 76.67, '42': 3.33, '43': 1.11, 'old': 0.0, 'new': 10.78}
2025-04-22 01:03:08,094 [trainer.py] => NME: {'total': 2.99, '0': 0.56, '1': 12.22, '2': 0.0, '3': 12.78, '4': 1.67, '5': 0.56, '6': 2.78, '7': 5.0, '8': 0.56, '9': 0.0, '10': 5.56, '11': 3.89, '12': 2.22, '13': 1.11, '14': 10.0, '15': 0.56, '16': 8.33, '17': 1.11, '18': 1.11, '19': 1.67, '20': 1.11, '21': 0.0, '22': 0.56, '23': 0.0, '24': 0.56, '25': 1.11, '26': 0.56, '27': 0.0, '28': 27.78, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 1.67, '35': 1.67, '36': 0.0, '37': 0.0, '38': 11.11, '39': 1.11, '40': 1.11, '41': 0.0, '42': 5.56, '43': 8.33, 'old': 3.0, 'new': 2.94}
2025-04-22 01:03:08,094 [trainer.py] => CNN top1 curve: [6.85, 4.98, 3.25, 2.4]
2025-04-22 01:03:08,094 [trainer.py] => CNN top5 curve: [34.52, 22.64, 15.02, 12.33]
2025-04-22 01:03:08,094 [trainer.py] => NME top1 curve: [10.44, 4.91, 3.38, 2.99]
2025-04-22 01:03:08,094 [trainer.py] => NME top5 curve: [37.96, 22.56, 15.43, 12.6]

2025-04-22 01:03:08,095 [trainer.py] => All params: 15012664
2025-04-22 01:03:08,096 [trainer.py] => Trainable params: 7532216
2025-04-22 01:03:08,236 [der.py] => Learning on 45-55
2025-04-22 01:03:08,237 [der.py] => All params: 15022914
2025-04-22 01:03:08,243 [der.py] => Trainable params: 7542466
2025-04-22 01:03:08,374 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 01:03:08,374 [der.py] => per cls weights : [1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 0.13592186 0.13592186 0.13592186
 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186
 0.13592186]
