2024-06-13 22:05:04,756 [trainer.py] => 实验名称:WiFi,打印测试
2024-06-13 22:05:04,758 [trainer.py] => config: ./exps/der.json
2024-06-13 22:05:04,758 [trainer.py] => experiment_name: 实验名称:WiFi,打印测试
2024-06-13 22:05:04,758 [trainer.py] => prefix: reproduce
2024-06-13 22:05:04,758 [trainer.py] => dataset: xrfdataset
2024-06-13 22:05:04,758 [trainer.py] => memory_size: 1650
2024-06-13 22:05:04,758 [trainer.py] => memory_per_class: 30
2024-06-13 22:05:04,758 [trainer.py] => fixed_memory: True
2024-06-13 22:05:04,758 [trainer.py] => shuffle: True
2024-06-13 22:05:04,758 [trainer.py] => init_cls: 15
2024-06-13 22:05:04,758 [trainer.py] => increment: 10
2024-06-13 22:05:04,758 [trainer.py] => model_name: der
2024-06-13 22:05:04,758 [trainer.py] => compression_epochs: 1
2024-06-13 22:05:04,758 [trainer.py] => compression_lr: 0.1
2024-06-13 22:05:04,758 [trainer.py] => T: 2
2024-06-13 22:05:04,758 [trainer.py] => convnet_type: unet
2024-06-13 22:05:04,758 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2024-06-13 22:05:04,758 [trainer.py] => seed: 1993
2024-06-13 22:05:04,783 [data.py] => 加载完毕XRF原始数据集
2024-06-13 22:05:04,806 [data.py] => 加载完毕XRF原始数据集
2024-06-13 22:05:04,807 [trainer.py] => All params: 0
2024-06-13 22:05:04,807 [trainer.py] => Trainable params: 0
2024-06-13 22:05:05,131 [der.py] => Learning on 0-15
2024-06-13 22:05:05,132 [der.py] => All params: 21045611
2024-06-13 22:05:05,132 [der.py] => Trainable params: 21045611
2024-06-13 22:09:01,844 [trainer.py] => 实验名称:WiFi,打印测试
2024-06-13 22:09:01,845 [trainer.py] => config: ./exps/der.json
2024-06-13 22:09:01,845 [trainer.py] => experiment_name: 实验名称:WiFi,打印测试
2024-06-13 22:09:01,845 [trainer.py] => prefix: reproduce
2024-06-13 22:09:01,845 [trainer.py] => dataset: xrfdataset
2024-06-13 22:09:01,846 [trainer.py] => memory_size: 1650
2024-06-13 22:09:01,846 [trainer.py] => memory_per_class: 30
2024-06-13 22:09:01,846 [trainer.py] => fixed_memory: True
2024-06-13 22:09:01,846 [trainer.py] => shuffle: True
2024-06-13 22:09:01,846 [trainer.py] => init_cls: 15
2024-06-13 22:09:01,846 [trainer.py] => increment: 10
2024-06-13 22:09:01,846 [trainer.py] => model_name: der
2024-06-13 22:09:01,846 [trainer.py] => compression_epochs: 1
2024-06-13 22:09:01,846 [trainer.py] => compression_lr: 0.1
2024-06-13 22:09:01,846 [trainer.py] => T: 2
2024-06-13 22:09:01,846 [trainer.py] => convnet_type: unet
2024-06-13 22:09:01,846 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2024-06-13 22:09:01,846 [trainer.py] => seed: 1993
2024-06-13 22:09:01,890 [data.py] => 加载完毕XRF原始数据集
2024-06-13 22:09:01,914 [data.py] => 加载完毕XRF原始数据集
2024-06-13 22:09:01,916 [trainer.py] => All params: 0
2024-06-13 22:09:01,917 [trainer.py] => Trainable params: 0
2024-06-13 22:09:02,115 [der.py] => Learning on 0-15
2024-06-13 22:09:02,116 [der.py] => All params: 21045611
2024-06-13 22:09:02,117 [der.py] => Trainable params: 21045611
2024-06-13 22:10:38,502 [der.py] => Task 0, Epoch 1/1 => Loss 2.564, Train_accy 13.40, Test_accy 12.93
2024-06-13 22:10:38,528 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-13 22:12:53,851 [der.py] => Exemplar size: 450
2024-06-13 22:12:53,852 [trainer.py] => CNN: {'total': 12.93, '0': 58.33, '1': 2.78, '2': 2.78, '3': 6.11, '4': 3.33, '5': 7.78, '6': 4.44, '7': 2.22, '8': 5.0, '9': 11.67, '10': 2.22, '11': 23.89, '12': 0.0, '13': 0.0, 'old': 0, 'new': 12.93}
2024-06-13 22:12:53,852 [trainer.py] => NME: {'total': 13.37, '0': 47.22, '1': 0.0, '2': 0.0, '3': 0.0, '4': 7.22, '5': 12.78, '6': 0.56, '7': 5.56, '8': 4.44, '9': 11.11, '10': 33.33, '11': 9.44, '12': 2.78, '13': 13.33, 'old': 0, 'new': 13.37}
2024-06-13 22:12:53,852 [trainer.py] => CNN top1 curve: [12.93]
2024-06-13 22:12:53,852 [trainer.py] => CNN top5 curve: [49.26]
2024-06-13 22:12:53,852 [trainer.py] => NME top1 curve: [13.37]
2024-06-13 22:12:53,852 [trainer.py] => NME top5 curve: [55.74]

2024-06-13 22:12:53,853 [trainer.py] => All params: 21045611
2024-06-13 22:12:53,853 [trainer.py] => Trainable params: 21045611
2024-06-13 22:12:54,129 [der.py] => Learning on 15-25
2024-06-13 22:12:54,137 [der.py] => All params: 42091068
2024-06-13 22:12:54,140 [der.py] => Trainable params: 21049456
2024-06-13 22:12:54,368 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-13 22:12:54,369 [der.py] => per cls weights : [-0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638
 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638
 -0.10555638 -0.10555638 -0.10555638  2.65833457  2.65833457  2.65833457
  2.65833457  2.65833457  2.65833457  2.65833457  2.65833457  2.65833457
  2.65833457]
2024-06-13 22:16:21,122 [der.py] => Task 1, Epoch 1/1 => Loss 5.745, Loss_clf 3.476, Loss_aux 2.269, Train_accy 14.60, Test_accy 7.69
2024-06-13 22:16:21,152 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-13 22:16:21,154 [der.py] => per cls weights : [-0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677   2.65250155  2.65250155  2.65250155
  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155
  2.65250155]
2024-06-13 22:17:40,002 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.104,  Train_accy 13.66, Test_accy 7.13
2024-06-13 22:17:57,187 [der.py] => darknet eval: 
2024-06-13 22:17:57,187 [der.py] => CNN top1 curve: 7.13
2024-06-13 22:17:57,187 [der.py] => CNN top5 curve: 24.24
2024-06-13 22:17:57,191 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-13 22:20:20,324 [der.py] => Exemplar size: 750
2024-06-13 22:20:20,324 [trainer.py] => CNN: {'total': 7.78, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 4.44, '11': 0.0, '12': 0.56, '13': 0.0, '14': 0.0, '15': 0.0, '16': 2.22, '17': 27.78, '18': 6.11, '19': 0.0, '20': 3.33, '21': 5.56, '22': 55.0, '23': 51.67, 'old': 0.33, 'new': 18.94}
2024-06-13 22:20:20,324 [trainer.py] => NME: {'total': 9.6, '0': 47.22, '1': 0.0, '2': 0.0, '3': 7.78, '4': 3.89, '5': 5.0, '6': 0.56, '7': 16.11, '8': 0.0, '9': 16.67, '10': 30.56, '11': 5.56, '12': 2.78, '13': 5.0, '14': 36.67, '15': 0.0, '16': 3.33, '17': 0.56, '18': 6.67, '19': 37.22, '20': 0.0, '21': 0.0, '22': 8.33, '23': 2.22, 'old': 11.85, 'new': 6.22}
2024-06-13 22:20:20,324 [trainer.py] => CNN top1 curve: [12.93, 7.78]
2024-06-13 22:20:20,324 [trainer.py] => CNN top5 curve: [49.26, 31.02]
2024-06-13 22:20:20,324 [trainer.py] => NME top1 curve: [13.37, 9.6]
2024-06-13 22:20:20,324 [trainer.py] => NME top5 curve: [55.74, 40.8]

2024-06-13 22:20:20,326 [trainer.py] => All params: 42091068
2024-06-13 22:20:20,327 [trainer.py] => Trainable params: 21049456
2024-06-13 22:20:20,764 [der.py] => Learning on 25-35
2024-06-13 22:20:20,767 [der.py] => All params: 63139730
2024-06-13 22:20:20,775 [der.py] => Trainable params: 21056506
2024-06-13 22:20:21,003 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-13 22:20:21,004 [der.py] => per cls weights : [-0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361  3.88573402  3.88573402  3.88573402  3.88573402  3.88573402
  3.88573402  3.88573402  3.88573402  3.88573402  3.88573402]
2024-06-13 22:23:09,663 [der.py] => Task 2, Epoch 1/1 => Loss 5.648, Loss_clf 3.449, Loss_aux 2.200, Train_accy 17.43, Test_accy 6.89
2024-06-13 22:23:09,697 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-13 22:23:09,700 [der.py] => per cls weights : [-0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685   3.87092124  3.87092124  3.87092124  3.87092124  3.87092124
  3.87092124  3.87092124  3.87092124  3.87092124  3.87092124]
2024-06-13 22:24:58,399 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 2.214,  Train_accy 16.00, Test_accy 5.68
2024-06-13 22:25:11,857 [der.py] => darknet eval: 
2024-06-13 22:25:11,857 [der.py] => CNN top1 curve: 5.68
2024-06-13 22:25:11,857 [der.py] => CNN top5 curve: 19.67
2024-06-13 22:25:11,861 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-13 22:28:00,318 [der.py] => Exemplar size: 1050
2024-06-13 22:28:00,319 [trainer.py] => CNN: {'total': 6.9, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 3.33, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 3.89, '18': 3.33, '19': 0.0, '20': 10.0, '21': 3.33, '22': 0.0, '23': 0.0, '24': 0.0, '25': 28.89, '26': 17.78, '27': 70.0, '28': 5.0, '29': 32.22, '30': 15.56, '31': 0.0, '32': 43.89, '33': 3.33, 'old': 0.96, 'new': 21.78}
2024-06-13 22:28:00,319 [trainer.py] => NME: {'total': 8.35, '0': 43.33, '1': 0.0, '2': 5.56, '3': 3.89, '4': 4.44, '5': 2.78, '6': 1.11, '7': 19.44, '8': 0.0, '9': 15.0, '10': 28.33, '11': 12.22, '12': 5.56, '13': 8.33, '14': 28.89, '15': 5.0, '16': 2.22, '17': 0.56, '18': 8.89, '19': 28.33, '20': 0.56, '21': 0.56, '22': 8.89, '23': 0.56, '24': 6.11, '25': 15.56, '26': 0.56, '27': 2.22, '28': 6.67, '29': 0.0, '30': 3.33, '31': 5.0, '32': 12.78, '33': 5.56, 'old': 9.62, 'new': 5.17}
2024-06-13 22:28:00,319 [trainer.py] => CNN top1 curve: [12.93, 7.78, 6.9]
2024-06-13 22:28:00,319 [trainer.py] => CNN top5 curve: [49.26, 31.02, 27.7]
2024-06-13 22:28:00,319 [trainer.py] => NME top1 curve: [13.37, 9.6, 8.35]
2024-06-13 22:28:00,319 [trainer.py] => NME top5 curve: [55.74, 40.8, 32.75]

2024-06-13 22:28:00,320 [trainer.py] => All params: 63139730
2024-06-13 22:28:00,321 [trainer.py] => Trainable params: 21056506
2024-06-13 22:28:00,555 [der.py] => Learning on 35-45
2024-06-13 22:28:00,559 [der.py] => All params: 84190952
2024-06-13 22:28:00,655 [der.py] => Trainable params: 21066116
2024-06-13 22:28:01,027 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-13 22:28:01,028 [der.py] => per cls weights : [-0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605  5.22634117
  5.22634117  5.22634117  5.22634117  5.22634117  5.22634117  5.22634117
  5.22634117  5.22634117  5.22634117]
2024-06-13 22:31:53,671 [trainer.py] => 实验名称:WiFi,打印测试
2024-06-13 22:31:53,709 [trainer.py] => config: ./exps/der.json
2024-06-13 22:31:53,709 [trainer.py] => experiment_name: 实验名称:WiFi,打印测试
2024-06-13 22:31:53,710 [trainer.py] => prefix: reproduce
2024-06-13 22:31:53,710 [trainer.py] => dataset: xrfdataset
2024-06-13 22:31:53,710 [trainer.py] => memory_size: 1650
2024-06-13 22:31:53,710 [trainer.py] => memory_per_class: 30
2024-06-13 22:31:53,710 [trainer.py] => fixed_memory: True
2024-06-13 22:31:53,710 [trainer.py] => shuffle: True
2024-06-13 22:31:53,710 [trainer.py] => init_cls: 15
2024-06-13 22:31:53,711 [trainer.py] => increment: 10
2024-06-13 22:31:53,711 [trainer.py] => model_name: der
2024-06-13 22:31:53,711 [trainer.py] => compression_epochs: 1
2024-06-13 22:31:53,711 [trainer.py] => compression_lr: 0.1
2024-06-13 22:31:53,711 [trainer.py] => T: 2
2024-06-13 22:31:53,711 [trainer.py] => convnet_type: unet
2024-06-13 22:31:53,711 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2024-06-13 22:31:53,711 [trainer.py] => seed: 1993
2024-06-13 22:31:53,745 [data.py] => 加载完毕XRF原始数据集
2024-06-13 22:31:53,767 [data.py] => 加载完毕XRF原始数据集
2024-06-13 22:31:53,768 [trainer.py] => All params: 0
2024-06-13 22:31:53,768 [trainer.py] => Trainable params: 0
2024-06-13 22:31:53,992 [der.py] => Learning on 0-15
2024-06-13 22:31:53,993 [der.py] => All params: 21045611
2024-06-13 22:31:53,993 [der.py] => Trainable params: 21045611
2024-06-13 23:18:52,394 [der.py] => Task 0, Epoch 150/150 => Loss 0.059, Train_accy 98.95
2024-06-13 23:18:52,395 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-13 23:19:58,978 [der.py] => Exemplar size: 450
2024-06-13 23:19:58,979 [trainer.py] => CNN: {'total': 89.7, '0': 100.0, '1': 92.78, '2': 96.67, '3': 83.33, '4': 94.44, '5': 83.89, '6': 82.22, '7': 90.0, '8': 92.78, '9': 59.44, '10': 98.89, '11': 100.0, '12': 89.44, '13': 90.0, 'old': 0, 'new': 89.7}
2024-06-13 23:19:58,979 [trainer.py] => NME: {'total': 89.04, '0': 99.44, '1': 91.11, '2': 94.44, '3': 85.56, '4': 93.33, '5': 80.0, '6': 66.67, '7': 92.22, '8': 93.89, '9': 69.44, '10': 98.33, '11': 100.0, '12': 86.67, '13': 92.22, 'old': 0, 'new': 89.04}
2024-06-13 23:19:58,979 [trainer.py] => CNN top1 curve: [89.7]
2024-06-13 23:19:58,979 [trainer.py] => CNN top5 curve: [99.44]
2024-06-13 23:19:58,980 [trainer.py] => NME top1 curve: [89.04]
2024-06-13 23:19:58,980 [trainer.py] => NME top5 curve: [99.37]

2024-06-13 23:19:58,980 [trainer.py] => All params: 21045611
2024-06-13 23:19:58,981 [trainer.py] => Trainable params: 21045611
2024-06-13 23:19:59,282 [der.py] => Learning on 15-25
2024-06-13 23:19:59,284 [der.py] => All params: 42091068
2024-06-13 23:19:59,285 [der.py] => Trainable params: 21049456
2024-06-13 23:19:59,540 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-13 23:19:59,541 [der.py] => per cls weights : [-0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638
 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638
 -0.10555638 -0.10555638 -0.10555638  2.65833457  2.65833457  2.65833457
  2.65833457  2.65833457  2.65833457  2.65833457  2.65833457  2.65833457
  2.65833457]
2024-06-13 23:22:18,387 [trainer.py] => 实验名称:WiFi,打印测试
2024-06-13 23:22:18,426 [trainer.py] => config: ./exps/der.json
2024-06-13 23:22:18,427 [trainer.py] => experiment_name: 实验名称:WiFi,打印测试
2024-06-13 23:22:18,427 [trainer.py] => prefix: reproduce
2024-06-13 23:22:18,427 [trainer.py] => dataset: xrfdataset
2024-06-13 23:22:18,427 [trainer.py] => memory_size: 1650
2024-06-13 23:22:18,427 [trainer.py] => memory_per_class: 30
2024-06-13 23:22:18,427 [trainer.py] => fixed_memory: True
2024-06-13 23:22:18,427 [trainer.py] => shuffle: True
2024-06-13 23:22:18,427 [trainer.py] => init_cls: 15
2024-06-13 23:22:18,427 [trainer.py] => increment: 10
2024-06-13 23:22:18,427 [trainer.py] => model_name: der
2024-06-13 23:22:18,427 [trainer.py] => compression_epochs: 130
2024-06-13 23:22:18,427 [trainer.py] => compression_lr: 0.1
2024-06-13 23:22:18,427 [trainer.py] => T: 2
2024-06-13 23:22:18,427 [trainer.py] => convnet_type: unet
2024-06-13 23:22:18,427 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2024-06-13 23:22:18,427 [trainer.py] => seed: 1993
2024-06-13 23:22:18,480 [data.py] => 加载完毕XRF原始数据集
2024-06-13 23:22:18,514 [data.py] => 加载完毕XRF原始数据集
2024-06-13 23:22:18,515 [trainer.py] => All params: 0
2024-06-13 23:22:18,515 [trainer.py] => Trainable params: 0
2024-06-13 23:22:18,808 [der.py] => Learning on 0-15
2024-06-13 23:22:18,808 [der.py] => All params: 21045611
2024-06-13 23:22:18,809 [der.py] => Trainable params: 21045611
2024-06-14 00:12:49,198 [der.py] => Task 0, Epoch 150/150 => Loss 0.059, Train_accy 98.95
2024-06-14 00:12:49,200 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-14 00:14:00,508 [der.py] => Exemplar size: 450
2024-06-14 00:14:00,534 [trainer.py] => CNN: {'total': 89.7, '0': 100.0, '1': 92.78, '2': 96.67, '3': 83.33, '4': 94.44, '5': 83.89, '6': 82.22, '7': 90.0, '8': 92.78, '9': 59.44, '10': 98.89, '11': 100.0, '12': 89.44, '13': 90.0, 'old': 0, 'new': 89.7}
2024-06-14 00:14:00,534 [trainer.py] => NME: {'total': 89.04, '0': 99.44, '1': 91.11, '2': 94.44, '3': 85.56, '4': 93.33, '5': 80.0, '6': 66.67, '7': 92.22, '8': 93.89, '9': 69.44, '10': 98.33, '11': 100.0, '12': 86.67, '13': 92.22, 'old': 0, 'new': 89.04}
2024-06-14 00:14:00,534 [trainer.py] => CNN top1 curve: [89.7]
2024-06-14 00:14:00,534 [trainer.py] => CNN top5 curve: [99.44]
2024-06-14 00:14:00,534 [trainer.py] => NME top1 curve: [89.04]
2024-06-14 00:14:00,534 [trainer.py] => NME top5 curve: [99.37]

2024-06-14 00:14:00,535 [trainer.py] => All params: 21045611
2024-06-14 00:14:00,536 [trainer.py] => Trainable params: 21045611
2024-06-14 00:14:00,912 [der.py] => Learning on 15-25
2024-06-14 00:14:00,914 [der.py] => All params: 42091068
2024-06-14 00:14:00,917 [der.py] => Trainable params: 21049456
2024-06-14 00:14:01,283 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 00:14:01,285 [der.py] => per cls weights : [-0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638
 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638 -0.10555638
 -0.10555638 -0.10555638 -0.10555638  2.65833457  2.65833457  2.65833457
  2.65833457  2.65833457  2.65833457  2.65833457  2.65833457  2.65833457
  2.65833457]
2024-06-14 01:12:36,409 [der.py] => Task 1, Epoch 150/150 => Loss 0.021, Loss_clf 0.008, Loss_aux 0.013, Train_accy 99.96
2024-06-14 01:12:36,656 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 01:12:36,658 [der.py] => per cls weights : [-0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677   2.65250155  2.65250155  2.65250155
  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155
  2.65250155]
2024-06-14 01:13:10,021 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 3.574,  Train_accy 11.14, Test_accy 4.04
2024-06-14 01:13:31,799 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 4.688,  Train_accy 9.08
2024-06-14 01:13:50,391 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 3.458,  Train_accy 10.82
2024-06-14 01:14:10,427 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 2.767,  Train_accy 10.09
2024-06-14 01:14:30,667 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.689,  Train_accy 7.53
2024-06-14 01:15:05,292 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.259,  Train_accy 6.45, Test_accy 4.00
2024-06-14 01:15:30,453 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 60.862,  Train_accy 4.60
2024-06-14 01:15:57,990 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 2.969,  Train_accy 6.97
2024-06-14 01:16:23,058 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 3.340,  Train_accy 6.92
2024-06-14 01:16:47,310 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 6.401,  Train_accy 6.45
2024-06-14 01:17:33,523 [der.py] => SNet: Task 1, Epoch 11/130 => Loss -0.931,  Train_accy 6.56, Test_accy 4.00
2024-06-14 01:18:00,733 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 289.320,  Train_accy 7.03
2024-06-14 01:18:27,903 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 94.784,  Train_accy 6.17
2024-06-14 01:18:53,100 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 450.588,  Train_accy 5.10
2024-06-14 01:19:16,958 [der.py] => SNet: Task 1, Epoch 15/130 => Loss -1333.088,  Train_accy 4.24
2024-06-14 01:19:51,923 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 4708.552,  Train_accy 7.27, Test_accy 4.00
2024-06-14 01:20:16,459 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 15699.325,  Train_accy 7.81
2024-06-14 01:20:46,066 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 297844.923,  Train_accy 6.69
2024-06-14 01:21:12,445 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 296.861,  Train_accy 5.66
2024-06-14 01:21:39,905 [der.py] => SNet: Task 1, Epoch 20/130 => Loss -16.717,  Train_accy 2.92
2024-06-14 01:22:20,591 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 6.002,  Train_accy 2.77, Test_accy 3.84
2024-06-14 01:22:47,317 [der.py] => SNet: Task 1, Epoch 22/130 => Loss -113.964,  Train_accy 2.49
2024-06-14 01:23:17,551 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 82.131,  Train_accy 4.86
2024-06-14 01:23:47,162 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 645.723,  Train_accy 6.62
2024-06-14 01:24:16,807 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 55.983,  Train_accy 8.26
2024-06-14 01:25:02,886 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 23.055,  Train_accy 9.05, Test_accy 4.22
2024-06-14 01:25:32,861 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 4.490,  Train_accy 8.90
2024-06-14 01:25:58,423 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 2.344,  Train_accy 8.97
2024-06-14 01:26:21,253 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.551,  Train_accy 8.56
2024-06-14 01:26:43,419 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.497,  Train_accy 3.68
2024-06-14 01:27:19,411 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.383,  Train_accy 1.81, Test_accy 3.87
2024-06-14 01:27:42,522 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.323,  Train_accy 2.13
2024-06-14 01:28:06,643 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.850,  Train_accy 6.58
2024-06-14 01:28:26,389 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.464,  Train_accy 3.18
2024-06-14 01:28:48,446 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.072,  Train_accy 1.61
2024-06-14 01:29:23,952 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.108,  Train_accy 1.83, Test_accy 4.16
2024-06-14 01:29:45,574 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.085,  Train_accy 5.53
2024-06-14 01:30:06,774 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.692,  Train_accy 1.96
2024-06-14 01:30:29,025 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.991,  Train_accy 1.46
2024-06-14 01:30:50,813 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.944,  Train_accy 1.59
2024-06-14 01:31:22,718 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.524,  Train_accy 3.29, Test_accy 4.02
2024-06-14 01:31:41,752 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.706,  Train_accy 4.24
2024-06-14 01:32:03,305 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.866,  Train_accy 3.83
2024-06-14 01:32:24,121 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.353,  Train_accy 1.78
2024-06-14 01:32:45,505 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.739,  Train_accy 1.53
2024-06-14 01:33:17,876 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.626,  Train_accy 1.44, Test_accy 4.02
2024-06-14 01:33:36,536 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.771,  Train_accy 4.77
2024-06-14 01:33:57,344 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.712,  Train_accy 1.66
2024-06-14 01:34:19,028 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.569,  Train_accy 5.53
2024-06-14 01:34:40,627 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.603,  Train_accy 1.46
2024-06-14 01:35:13,915 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.572,  Train_accy 2.73, Test_accy 3.98
2024-06-14 01:35:34,743 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.533,  Train_accy 1.40
2024-06-14 01:35:56,675 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 4.642,  Train_accy 4.95
2024-06-14 01:36:17,831 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.660,  Train_accy 1.46
2024-06-14 01:36:38,859 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.567,  Train_accy 8.95
2024-06-14 01:37:11,781 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.397,  Train_accy 6.99, Test_accy 4.13
2024-06-14 01:37:33,191 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.364,  Train_accy 8.54
2024-06-14 01:37:53,900 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.342,  Train_accy 2.37
2024-06-14 01:38:15,324 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.270,  Train_accy 0.97
2024-06-14 01:38:35,882 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.253,  Train_accy 6.26
2024-06-14 01:39:06,933 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.207,  Train_accy 1.85, Test_accy 4.09
2024-06-14 01:39:27,364 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.194,  Train_accy 0.86
2024-06-14 01:39:51,014 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.159,  Train_accy 7.98
2024-06-14 01:40:12,066 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.126,  Train_accy 4.24
2024-06-14 01:40:33,503 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.101,  Train_accy 1.33
2024-06-14 01:41:05,130 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.069,  Train_accy 0.80, Test_accy 4.13
2024-06-14 01:41:25,879 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.070,  Train_accy 3.85
2024-06-14 01:41:46,314 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.000,  Train_accy 1.98
2024-06-14 01:42:07,565 [der.py] => SNet: Task 1, Epoch 69/130 => Loss -0.016,  Train_accy 0.77
2024-06-14 01:42:27,021 [der.py] => SNet: Task 1, Epoch 70/130 => Loss -0.039,  Train_accy 5.31
2024-06-14 01:42:58,839 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.021,  Train_accy 4.99, Test_accy 4.11
2024-06-14 01:43:20,311 [der.py] => SNet: Task 1, Epoch 72/130 => Loss -0.058,  Train_accy 0.88
2024-06-14 01:43:40,220 [der.py] => SNet: Task 1, Epoch 73/130 => Loss -0.087,  Train_accy 4.00
2024-06-14 01:44:01,798 [der.py] => SNet: Task 1, Epoch 74/130 => Loss -0.119,  Train_accy 2.22
2024-06-14 01:44:22,059 [der.py] => SNet: Task 1, Epoch 75/130 => Loss -0.071,  Train_accy 2.26
2024-06-14 01:44:53,545 [der.py] => SNet: Task 1, Epoch 76/130 => Loss -0.131,  Train_accy 5.14, Test_accy 3.93
2024-06-14 01:45:14,738 [der.py] => SNet: Task 1, Epoch 77/130 => Loss -0.146,  Train_accy 4.04
2024-06-14 01:45:35,220 [der.py] => SNet: Task 1, Epoch 78/130 => Loss -0.208,  Train_accy 1.42
2024-06-14 01:45:56,151 [der.py] => SNet: Task 1, Epoch 79/130 => Loss -0.227,  Train_accy 1.16
2024-06-14 01:46:16,791 [der.py] => SNet: Task 1, Epoch 80/130 => Loss -0.200,  Train_accy 1.08
2024-06-14 01:46:48,747 [der.py] => SNet: Task 1, Epoch 81/130 => Loss -0.147,  Train_accy 5.70, Test_accy 4.04
2024-06-14 01:47:08,731 [der.py] => SNet: Task 1, Epoch 82/130 => Loss -0.243,  Train_accy 5.68
2024-06-14 01:47:29,870 [der.py] => SNet: Task 1, Epoch 83/130 => Loss -0.273,  Train_accy 1.63
2024-06-14 01:47:50,916 [der.py] => SNet: Task 1, Epoch 84/130 => Loss -0.307,  Train_accy 1.31
2024-06-14 01:48:12,058 [der.py] => SNet: Task 1, Epoch 85/130 => Loss -0.312,  Train_accy 1.33
2024-06-14 01:48:43,542 [der.py] => SNet: Task 1, Epoch 86/130 => Loss -0.323,  Train_accy 1.14, Test_accy 3.98
2024-06-14 01:49:05,106 [der.py] => SNet: Task 1, Epoch 87/130 => Loss -0.361,  Train_accy 1.27
2024-06-14 01:49:27,729 [der.py] => SNet: Task 1, Epoch 88/130 => Loss -0.324,  Train_accy 1.44
2024-06-14 01:49:50,947 [der.py] => SNet: Task 1, Epoch 89/130 => Loss -0.372,  Train_accy 1.68
2024-06-14 01:50:18,449 [der.py] => SNet: Task 1, Epoch 90/130 => Loss -0.365,  Train_accy 6.02
2024-06-14 01:50:53,138 [der.py] => SNet: Task 1, Epoch 91/130 => Loss -0.399,  Train_accy 1.55, Test_accy 3.98
2024-06-14 01:51:13,914 [der.py] => SNet: Task 1, Epoch 92/130 => Loss -0.405,  Train_accy 1.40
2024-06-14 01:51:33,908 [der.py] => SNet: Task 1, Epoch 93/130 => Loss -0.391,  Train_accy 1.57
2024-06-14 01:51:54,555 [der.py] => SNet: Task 1, Epoch 94/130 => Loss -0.425,  Train_accy 1.68
2024-06-14 01:52:14,790 [der.py] => SNet: Task 1, Epoch 95/130 => Loss -0.422,  Train_accy 1.66
2024-06-14 01:52:45,442 [der.py] => SNet: Task 1, Epoch 96/130 => Loss -0.449,  Train_accy 1.57, Test_accy 3.96
2024-06-14 01:53:06,302 [der.py] => SNet: Task 1, Epoch 97/130 => Loss -0.432,  Train_accy 1.55
2024-06-14 01:53:26,956 [der.py] => SNet: Task 1, Epoch 98/130 => Loss -0.431,  Train_accy 1.42
2024-06-14 01:53:48,057 [der.py] => SNet: Task 1, Epoch 99/130 => Loss -0.418,  Train_accy 1.68
2024-06-14 01:54:08,963 [der.py] => SNet: Task 1, Epoch 100/130 => Loss -0.418,  Train_accy 1.72
2024-06-14 01:54:38,537 [der.py] => SNet: Task 1, Epoch 101/130 => Loss -0.478,  Train_accy 1.63, Test_accy 3.89
2024-06-14 01:54:58,879 [der.py] => SNet: Task 1, Epoch 102/130 => Loss -0.497,  Train_accy 1.51
2024-06-14 01:55:18,833 [der.py] => SNet: Task 1, Epoch 103/130 => Loss -0.504,  Train_accy 1.63
2024-06-14 01:55:40,183 [der.py] => SNet: Task 1, Epoch 104/130 => Loss -0.502,  Train_accy 1.46
2024-06-14 01:56:00,560 [der.py] => SNet: Task 1, Epoch 105/130 => Loss -0.535,  Train_accy 1.53
2024-06-14 01:56:31,363 [der.py] => SNet: Task 1, Epoch 106/130 => Loss -0.512,  Train_accy 1.53, Test_accy 3.91
2024-06-14 01:56:51,134 [der.py] => SNet: Task 1, Epoch 107/130 => Loss -0.512,  Train_accy 1.53
2024-06-14 01:57:11,929 [der.py] => SNet: Task 1, Epoch 108/130 => Loss -0.522,  Train_accy 1.68
2024-06-14 01:57:32,664 [der.py] => SNet: Task 1, Epoch 109/130 => Loss -0.537,  Train_accy 1.68
2024-06-14 01:57:53,235 [der.py] => SNet: Task 1, Epoch 110/130 => Loss -0.541,  Train_accy 1.72
2024-06-14 01:58:23,850 [der.py] => SNet: Task 1, Epoch 111/130 => Loss -0.535,  Train_accy 1.53, Test_accy 3.84
2024-06-14 01:58:44,206 [der.py] => SNet: Task 1, Epoch 112/130 => Loss -0.430,  Train_accy 1.59
2024-06-14 01:59:02,892 [der.py] => SNet: Task 1, Epoch 113/130 => Loss -0.449,  Train_accy 1.51
2024-06-14 01:59:23,502 [der.py] => SNet: Task 1, Epoch 114/130 => Loss -0.540,  Train_accy 1.83
2024-06-14 01:59:43,236 [der.py] => SNet: Task 1, Epoch 115/130 => Loss -0.450,  Train_accy 1.63
2024-06-14 02:00:13,819 [der.py] => SNet: Task 1, Epoch 116/130 => Loss -0.545,  Train_accy 1.57, Test_accy 3.98
2024-06-14 02:00:33,167 [der.py] => SNet: Task 1, Epoch 117/130 => Loss -0.552,  Train_accy 1.46
2024-06-14 02:00:53,971 [der.py] => SNet: Task 1, Epoch 118/130 => Loss -0.627,  Train_accy 1.72
2024-06-14 02:01:12,705 [der.py] => SNet: Task 1, Epoch 119/130 => Loss -0.560,  Train_accy 1.78
2024-06-14 02:01:33,856 [der.py] => SNet: Task 1, Epoch 120/130 => Loss -0.548,  Train_accy 1.57
2024-06-14 02:02:06,923 [der.py] => SNet: Task 1, Epoch 121/130 => Loss -0.562,  Train_accy 1.57, Test_accy 4.00
2024-06-14 02:02:27,516 [der.py] => SNet: Task 1, Epoch 122/130 => Loss -0.550,  Train_accy 1.59
2024-06-14 02:02:48,328 [der.py] => SNet: Task 1, Epoch 123/130 => Loss -0.532,  Train_accy 1.46
2024-06-14 02:03:09,069 [der.py] => SNet: Task 1, Epoch 124/130 => Loss -0.454,  Train_accy 1.46
2024-06-14 02:03:29,280 [der.py] => SNet: Task 1, Epoch 125/130 => Loss -0.617,  Train_accy 1.70
2024-06-14 02:03:59,236 [der.py] => SNet: Task 1, Epoch 126/130 => Loss -0.546,  Train_accy 1.96, Test_accy 4.00
2024-06-14 02:04:20,152 [der.py] => SNet: Task 1, Epoch 127/130 => Loss -0.550,  Train_accy 1.70
2024-06-14 02:04:39,050 [der.py] => SNet: Task 1, Epoch 128/130 => Loss -0.559,  Train_accy 1.55
2024-06-14 02:05:00,042 [der.py] => SNet: Task 1, Epoch 129/130 => Loss -0.577,  Train_accy 1.59
2024-06-14 02:05:20,006 [der.py] => SNet: Task 1, Epoch 130/130 => Loss -0.560,  Train_accy 1.57
2024-06-14 02:05:28,500 [der.py] => darknet eval: 
2024-06-14 02:05:28,501 [der.py] => CNN top1 curve: 3.93
2024-06-14 02:05:28,501 [der.py] => CNN top5 curve: 20.56
2024-06-14 02:05:28,504 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-14 02:07:09,856 [der.py] => Exemplar size: 750
2024-06-14 02:07:09,856 [trainer.py] => CNN: {'total': 88.69, '0': 92.22, '1': 84.44, '2': 93.33, '3': 82.78, '4': 93.33, '5': 75.0, '6': 76.11, '7': 87.22, '8': 71.67, '9': 58.89, '10': 95.56, '11': 100.0, '12': 86.11, '13': 91.11, '14': 83.33, '15': 97.78, '16': 100.0, '17': 97.78, '18': 97.78, '19': 95.56, '20': 98.33, '21': 88.89, '22': 87.78, '23': 85.0, 'old': 84.74, 'new': 94.61}
2024-06-14 02:07:09,856 [trainer.py] => NME: {'total': 85.33, '0': 86.67, '1': 68.89, '2': 93.33, '3': 82.78, '4': 91.67, '5': 69.44, '6': 60.56, '7': 64.44, '8': 52.22, '9': 67.22, '10': 95.0, '11': 100.0, '12': 79.44, '13': 88.89, '14': 83.33, '15': 96.67, '16': 100.0, '17': 93.89, '18': 96.11, '19': 95.56, '20': 95.0, '21': 91.67, '22': 93.33, '23': 92.22, 'old': 78.93, 'new': 94.94}
2024-06-14 02:07:09,856 [trainer.py] => CNN top1 curve: [89.7, 88.69]
2024-06-14 02:07:09,856 [trainer.py] => CNN top5 curve: [99.44, 99.07]
2024-06-14 02:07:09,856 [trainer.py] => NME top1 curve: [89.04, 85.33]
2024-06-14 02:07:09,856 [trainer.py] => NME top5 curve: [99.37, 98.98]

2024-06-14 02:07:09,857 [trainer.py] => All params: 42091068
2024-06-14 02:07:09,858 [trainer.py] => Trainable params: 21049456
2024-06-14 02:07:10,073 [der.py] => Learning on 25-35
2024-06-14 02:07:10,076 [der.py] => All params: 63139730
2024-06-14 02:07:10,078 [der.py] => Trainable params: 21056506
2024-06-14 02:07:10,463 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 02:07:10,465 [der.py] => per cls weights : [-0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361 -0.15429361
 -0.15429361  3.88573402  3.88573402  3.88573402  3.88573402  3.88573402
  3.88573402  3.88573402  3.88573402  3.88573402  3.88573402]
2024-06-14 03:17:45,389 [der.py] => Task 2, Epoch 150/150 => Loss 0.024, Loss_clf 0.009, Loss_aux 0.015, Train_accy 99.90
2024-06-14 03:17:45,500 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 03:17:45,507 [der.py] => per cls weights : [-0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685   3.87092124  3.87092124  3.87092124  3.87092124  3.87092124
  3.87092124  3.87092124  3.87092124  3.87092124  3.87092124]
2024-06-14 03:18:23,139 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 9.339,  Train_accy 3.52, Test_accy 2.86
2024-06-14 03:18:47,117 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 3.953,  Train_accy 4.81
2024-06-14 03:19:11,336 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 8.155,  Train_accy 4.57
2024-06-14 03:19:35,068 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 112.392,  Train_accy 0.95
2024-06-14 03:19:57,512 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 70.386,  Train_accy 4.55
2024-06-14 03:20:34,736 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 0.286,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:20:57,647 [der.py] => SNet: Task 2, Epoch 7/130 => Loss -4.195,  Train_accy 0.48
2024-06-14 03:21:20,184 [der.py] => SNet: Task 2, Epoch 8/130 => Loss -6.846,  Train_accy 0.65
2024-06-14 03:21:46,878 [der.py] => SNet: Task 2, Epoch 9/130 => Loss -6.736,  Train_accy 0.77
2024-06-14 03:22:11,928 [der.py] => SNet: Task 2, Epoch 10/130 => Loss -7.936,  Train_accy 0.61
2024-06-14 03:22:52,832 [der.py] => SNet: Task 2, Epoch 11/130 => Loss -9.083,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:23:15,894 [der.py] => SNet: Task 2, Epoch 12/130 => Loss -10.481,  Train_accy 0.69
2024-06-14 03:23:40,711 [der.py] => SNet: Task 2, Epoch 13/130 => Loss -10.246,  Train_accy 0.61
2024-06-14 03:24:04,544 [der.py] => SNet: Task 2, Epoch 14/130 => Loss -12.070,  Train_accy 0.63
2024-06-14 03:24:27,237 [der.py] => SNet: Task 2, Epoch 15/130 => Loss -13.011,  Train_accy 0.53
2024-06-14 03:25:06,290 [der.py] => SNet: Task 2, Epoch 16/130 => Loss -14.183,  Train_accy 0.59, Test_accy 2.86
2024-06-14 03:25:30,533 [der.py] => SNet: Task 2, Epoch 17/130 => Loss -14.921,  Train_accy 0.61
2024-06-14 03:25:54,156 [der.py] => SNet: Task 2, Epoch 18/130 => Loss -15.782,  Train_accy 0.65
2024-06-14 03:26:18,049 [der.py] => SNet: Task 2, Epoch 19/130 => Loss -17.145,  Train_accy 0.63
2024-06-14 03:26:41,043 [der.py] => SNet: Task 2, Epoch 20/130 => Loss -18.290,  Train_accy 0.61
2024-06-14 03:27:17,583 [der.py] => SNet: Task 2, Epoch 21/130 => Loss -32.395,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:27:41,242 [der.py] => SNet: Task 2, Epoch 22/130 => Loss -18.043,  Train_accy 0.57
2024-06-14 03:28:05,525 [der.py] => SNet: Task 2, Epoch 23/130 => Loss -20.176,  Train_accy 0.55
2024-06-14 03:28:30,939 [der.py] => SNet: Task 2, Epoch 24/130 => Loss -21.990,  Train_accy 0.53
2024-06-14 03:28:53,991 [der.py] => SNet: Task 2, Epoch 25/130 => Loss -24.363,  Train_accy 0.55
2024-06-14 03:29:29,888 [der.py] => SNet: Task 2, Epoch 26/130 => Loss -23.742,  Train_accy 0.77, Test_accy 2.86
2024-06-14 03:29:51,648 [der.py] => SNet: Task 2, Epoch 27/130 => Loss -24.840,  Train_accy 0.65
2024-06-14 03:30:15,190 [der.py] => SNet: Task 2, Epoch 28/130 => Loss -26.064,  Train_accy 0.44
2024-06-14 03:30:38,310 [der.py] => SNet: Task 2, Epoch 29/130 => Loss -27.266,  Train_accy 0.61
2024-06-14 03:31:02,169 [der.py] => SNet: Task 2, Epoch 30/130 => Loss -28.121,  Train_accy 0.57
2024-06-14 03:31:38,966 [der.py] => SNet: Task 2, Epoch 31/130 => Loss -29.309,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:32:02,613 [der.py] => SNet: Task 2, Epoch 32/130 => Loss -29.569,  Train_accy 0.61
2024-06-14 03:32:26,661 [der.py] => SNet: Task 2, Epoch 33/130 => Loss -30.273,  Train_accy 0.61
2024-06-14 03:32:49,977 [der.py] => SNet: Task 2, Epoch 34/130 => Loss -31.655,  Train_accy 0.67
2024-06-14 03:33:13,078 [der.py] => SNet: Task 2, Epoch 35/130 => Loss -32.083,  Train_accy 0.75
2024-06-14 03:33:51,654 [der.py] => SNet: Task 2, Epoch 36/130 => Loss -32.780,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:34:14,967 [der.py] => SNet: Task 2, Epoch 37/130 => Loss -34.468,  Train_accy 0.63
2024-06-14 03:34:39,295 [der.py] => SNet: Task 2, Epoch 38/130 => Loss -35.052,  Train_accy 0.69
2024-06-14 03:35:03,593 [der.py] => SNet: Task 2, Epoch 39/130 => Loss -35.547,  Train_accy 0.71
2024-06-14 03:35:26,824 [der.py] => SNet: Task 2, Epoch 40/130 => Loss -36.927,  Train_accy 0.61
2024-06-14 03:36:04,100 [der.py] => SNet: Task 2, Epoch 41/130 => Loss -37.228,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:36:27,885 [der.py] => SNet: Task 2, Epoch 42/130 => Loss -37.848,  Train_accy 0.67
2024-06-14 03:36:50,980 [der.py] => SNet: Task 2, Epoch 43/130 => Loss -39.065,  Train_accy 0.61
2024-06-14 03:37:14,544 [der.py] => SNet: Task 2, Epoch 44/130 => Loss -37.344,  Train_accy 0.61
2024-06-14 03:37:37,315 [der.py] => SNet: Task 2, Epoch 45/130 => Loss -40.908,  Train_accy 0.57
2024-06-14 03:38:15,410 [der.py] => SNet: Task 2, Epoch 46/130 => Loss -41.266,  Train_accy 0.59, Test_accy 2.86
2024-06-14 03:38:38,636 [der.py] => SNet: Task 2, Epoch 47/130 => Loss -37.411,  Train_accy 0.57
2024-06-14 03:39:04,175 [der.py] => SNet: Task 2, Epoch 48/130 => Loss -42.540,  Train_accy 0.53
2024-06-14 03:39:30,246 [der.py] => SNet: Task 2, Epoch 49/130 => Loss -43.517,  Train_accy 0.53
2024-06-14 03:39:53,335 [der.py] => SNet: Task 2, Epoch 50/130 => Loss -43.727,  Train_accy 0.61
2024-06-14 03:40:29,019 [der.py] => SNet: Task 2, Epoch 51/130 => Loss -45.387,  Train_accy 0.63, Test_accy 2.86
2024-06-14 03:40:52,441 [der.py] => SNet: Task 2, Epoch 52/130 => Loss -45.336,  Train_accy 0.67
2024-06-14 03:41:16,886 [der.py] => SNet: Task 2, Epoch 53/130 => Loss -46.301,  Train_accy 0.55
2024-06-14 03:41:41,525 [der.py] => SNet: Task 2, Epoch 54/130 => Loss -46.757,  Train_accy 0.55
2024-06-14 03:42:05,036 [der.py] => SNet: Task 2, Epoch 55/130 => Loss -47.686,  Train_accy 0.61
2024-06-14 03:42:44,457 [der.py] => SNet: Task 2, Epoch 56/130 => Loss -47.840,  Train_accy 0.71, Test_accy 2.86
2024-06-14 03:43:11,311 [der.py] => SNet: Task 2, Epoch 57/130 => Loss -48.006,  Train_accy 0.67
2024-06-14 03:43:35,291 [der.py] => SNet: Task 2, Epoch 58/130 => Loss -49.438,  Train_accy 0.51
2024-06-14 03:43:59,278 [der.py] => SNet: Task 2, Epoch 59/130 => Loss -50.338,  Train_accy 0.61
2024-06-14 03:44:24,822 [der.py] => SNet: Task 2, Epoch 60/130 => Loss -50.666,  Train_accy 0.55
2024-06-14 03:45:05,055 [der.py] => SNet: Task 2, Epoch 61/130 => Loss -51.274,  Train_accy 0.65, Test_accy 2.86
2024-06-14 03:45:31,694 [der.py] => SNet: Task 2, Epoch 62/130 => Loss -51.658,  Train_accy 0.61
2024-06-14 03:45:56,863 [der.py] => SNet: Task 2, Epoch 63/130 => Loss -52.519,  Train_accy 0.61
2024-06-14 03:46:22,571 [der.py] => SNet: Task 2, Epoch 64/130 => Loss -52.062,  Train_accy 0.65
2024-06-14 03:46:47,551 [der.py] => SNet: Task 2, Epoch 65/130 => Loss -53.689,  Train_accy 0.53
2024-06-14 03:47:26,920 [der.py] => SNet: Task 2, Epoch 66/130 => Loss -52.328,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:47:51,374 [der.py] => SNet: Task 2, Epoch 67/130 => Loss -54.616,  Train_accy 0.61
2024-06-14 03:48:16,021 [der.py] => SNet: Task 2, Epoch 68/130 => Loss -55.233,  Train_accy 0.61
2024-06-14 03:48:42,090 [der.py] => SNet: Task 2, Epoch 69/130 => Loss -56.137,  Train_accy 0.63
2024-06-14 03:49:07,068 [der.py] => SNet: Task 2, Epoch 70/130 => Loss -56.510,  Train_accy 0.55
2024-06-14 03:49:46,335 [der.py] => SNet: Task 2, Epoch 71/130 => Loss -55.420,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:50:13,226 [der.py] => SNet: Task 2, Epoch 72/130 => Loss -57.260,  Train_accy 0.61
2024-06-14 03:50:40,048 [der.py] => SNet: Task 2, Epoch 73/130 => Loss -57.656,  Train_accy 0.61
2024-06-14 03:51:05,638 [der.py] => SNet: Task 2, Epoch 74/130 => Loss -57.894,  Train_accy 0.69
2024-06-14 03:51:31,613 [der.py] => SNet: Task 2, Epoch 75/130 => Loss -57.809,  Train_accy 0.57
2024-06-14 03:52:09,878 [der.py] => SNet: Task 2, Epoch 76/130 => Loss -58.463,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:52:34,352 [der.py] => SNet: Task 2, Epoch 77/130 => Loss -59.533,  Train_accy 0.61
2024-06-14 03:52:59,803 [der.py] => SNet: Task 2, Epoch 78/130 => Loss -59.639,  Train_accy 0.61
2024-06-14 03:53:25,018 [der.py] => SNet: Task 2, Epoch 79/130 => Loss -59.418,  Train_accy 0.55
2024-06-14 03:53:49,762 [der.py] => SNet: Task 2, Epoch 80/130 => Loss -59.997,  Train_accy 0.63
2024-06-14 03:54:28,081 [der.py] => SNet: Task 2, Epoch 81/130 => Loss -60.642,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:54:53,679 [der.py] => SNet: Task 2, Epoch 82/130 => Loss -60.935,  Train_accy 0.61
2024-06-14 03:55:18,568 [der.py] => SNet: Task 2, Epoch 83/130 => Loss -61.273,  Train_accy 0.61
2024-06-14 03:55:43,255 [der.py] => SNet: Task 2, Epoch 84/130 => Loss -60.967,  Train_accy 0.61
2024-06-14 03:56:07,482 [der.py] => SNet: Task 2, Epoch 85/130 => Loss -61.037,  Train_accy 0.61
2024-06-14 03:56:46,303 [der.py] => SNet: Task 2, Epoch 86/130 => Loss -62.408,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:57:11,162 [der.py] => SNet: Task 2, Epoch 87/130 => Loss -62.659,  Train_accy 0.61
2024-06-14 03:57:36,339 [der.py] => SNet: Task 2, Epoch 88/130 => Loss -62.925,  Train_accy 0.61
2024-06-14 03:58:01,966 [der.py] => SNet: Task 2, Epoch 89/130 => Loss -63.095,  Train_accy 0.61
2024-06-14 03:58:27,280 [der.py] => SNet: Task 2, Epoch 90/130 => Loss -63.313,  Train_accy 0.57
2024-06-14 03:59:06,989 [der.py] => SNet: Task 2, Epoch 91/130 => Loss -62.627,  Train_accy 0.61, Test_accy 2.86
2024-06-14 03:59:31,887 [der.py] => SNet: Task 2, Epoch 92/130 => Loss -63.943,  Train_accy 0.61
2024-06-14 03:59:58,248 [der.py] => SNet: Task 2, Epoch 93/130 => Loss -64.053,  Train_accy 0.63
2024-06-14 04:00:23,684 [der.py] => SNet: Task 2, Epoch 94/130 => Loss -64.245,  Train_accy 0.61
2024-06-14 04:00:48,039 [der.py] => SNet: Task 2, Epoch 95/130 => Loss -64.597,  Train_accy 0.61
2024-06-14 04:01:25,359 [der.py] => SNet: Task 2, Epoch 96/130 => Loss -64.886,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:01:50,666 [der.py] => SNet: Task 2, Epoch 97/130 => Loss -64.956,  Train_accy 0.61
2024-06-14 04:02:15,102 [der.py] => SNet: Task 2, Epoch 98/130 => Loss -65.190,  Train_accy 0.61
2024-06-14 04:02:39,523 [der.py] => SNet: Task 2, Epoch 99/130 => Loss -65.203,  Train_accy 0.61
2024-06-14 04:03:03,382 [der.py] => SNet: Task 2, Epoch 100/130 => Loss -65.496,  Train_accy 0.61
2024-06-14 04:03:42,486 [der.py] => SNet: Task 2, Epoch 101/130 => Loss -65.688,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:04:06,581 [der.py] => SNet: Task 2, Epoch 102/130 => Loss -65.805,  Train_accy 0.61
2024-06-14 04:04:30,912 [der.py] => SNet: Task 2, Epoch 103/130 => Loss -65.845,  Train_accy 0.61
2024-06-14 04:04:55,905 [der.py] => SNet: Task 2, Epoch 104/130 => Loss -66.025,  Train_accy 0.61
2024-06-14 04:05:19,633 [der.py] => SNet: Task 2, Epoch 105/130 => Loss -66.116,  Train_accy 0.61
2024-06-14 04:05:52,779 [der.py] => SNet: Task 2, Epoch 106/130 => Loss -66.902,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:06:12,958 [der.py] => SNet: Task 2, Epoch 107/130 => Loss -66.288,  Train_accy 0.61
2024-06-14 04:06:30,833 [der.py] => SNet: Task 2, Epoch 108/130 => Loss -66.602,  Train_accy 0.61
2024-06-14 04:06:52,379 [der.py] => SNet: Task 2, Epoch 109/130 => Loss -66.590,  Train_accy 0.61
2024-06-14 04:07:16,260 [der.py] => SNet: Task 2, Epoch 110/130 => Loss -66.661,  Train_accy 0.61
2024-06-14 04:07:50,152 [der.py] => SNet: Task 2, Epoch 111/130 => Loss -68.597,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:08:10,574 [der.py] => SNet: Task 2, Epoch 112/130 => Loss -66.629,  Train_accy 0.61
2024-06-14 04:08:32,566 [der.py] => SNet: Task 2, Epoch 113/130 => Loss -66.926,  Train_accy 0.61
2024-06-14 04:08:52,412 [der.py] => SNet: Task 2, Epoch 114/130 => Loss -66.573,  Train_accy 0.61
2024-06-14 04:09:13,804 [der.py] => SNet: Task 2, Epoch 115/130 => Loss -66.919,  Train_accy 0.61
2024-06-14 04:09:47,285 [der.py] => SNet: Task 2, Epoch 116/130 => Loss -67.116,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:10:09,223 [der.py] => SNet: Task 2, Epoch 117/130 => Loss -66.946,  Train_accy 0.61
2024-06-14 04:10:34,041 [der.py] => SNet: Task 2, Epoch 118/130 => Loss -66.998,  Train_accy 0.61
2024-06-14 04:10:56,453 [der.py] => SNet: Task 2, Epoch 119/130 => Loss -67.066,  Train_accy 0.61
2024-06-14 04:11:18,473 [der.py] => SNet: Task 2, Epoch 120/130 => Loss -67.055,  Train_accy 0.61
2024-06-14 04:11:53,986 [der.py] => SNet: Task 2, Epoch 121/130 => Loss -66.938,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:12:16,188 [der.py] => SNet: Task 2, Epoch 122/130 => Loss -67.221,  Train_accy 0.61
2024-06-14 04:12:40,227 [der.py] => SNet: Task 2, Epoch 123/130 => Loss -66.620,  Train_accy 0.61
2024-06-14 04:13:03,234 [der.py] => SNet: Task 2, Epoch 124/130 => Loss -67.149,  Train_accy 0.61
2024-06-14 04:13:25,150 [der.py] => SNet: Task 2, Epoch 125/130 => Loss -66.618,  Train_accy 0.61
2024-06-14 04:13:58,565 [der.py] => SNet: Task 2, Epoch 126/130 => Loss -68.749,  Train_accy 0.61, Test_accy 2.86
2024-06-14 04:14:21,808 [der.py] => SNet: Task 2, Epoch 127/130 => Loss -67.303,  Train_accy 0.61
2024-06-14 04:14:43,946 [der.py] => SNet: Task 2, Epoch 128/130 => Loss -67.235,  Train_accy 0.61
2024-06-14 04:15:06,529 [der.py] => SNet: Task 2, Epoch 129/130 => Loss -67.195,  Train_accy 0.61
2024-06-14 04:15:28,628 [der.py] => SNet: Task 2, Epoch 130/130 => Loss -66.643,  Train_accy 0.61
2024-06-14 04:15:38,596 [der.py] => darknet eval: 
2024-06-14 04:15:38,597 [der.py] => CNN top1 curve: 2.86
2024-06-14 04:15:38,597 [der.py] => CNN top5 curve: 14.29
2024-06-14 04:15:38,602 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-14 04:17:32,500 [der.py] => Exemplar size: 1050
2024-06-14 04:17:32,501 [trainer.py] => CNN: {'total': 82.02, '0': 87.22, '1': 73.33, '2': 92.78, '3': 82.78, '4': 91.11, '5': 62.22, '6': 72.78, '7': 67.78, '8': 49.44, '9': 58.89, '10': 95.56, '11': 98.33, '12': 86.67, '13': 87.78, '14': 77.22, '15': 95.56, '16': 98.89, '17': 95.0, '18': 98.89, '19': 96.11, '20': 98.33, '21': 92.22, '22': 94.44, '23': 92.22, '24': 88.33, '25': 58.89, '26': 77.22, '27': 71.11, '28': 61.11, '29': 69.44, '30': 64.44, '31': 84.44, '32': 88.33, '33': 80.0, 'old': 85.36, 'new': 73.67}
2024-06-14 04:17:32,501 [trainer.py] => NME: {'total': 78.95, '0': 84.44, '1': 57.22, '2': 93.33, '3': 72.22, '4': 85.0, '5': 50.0, '6': 61.11, '7': 62.22, '8': 50.0, '9': 62.78, '10': 90.56, '11': 89.44, '12': 76.11, '13': 83.33, '14': 54.44, '15': 93.89, '16': 98.89, '17': 92.78, '18': 94.44, '19': 92.78, '20': 92.22, '21': 91.67, '22': 87.22, '23': 74.44, '24': 77.78, '25': 80.0, '26': 92.22, '27': 80.56, '28': 69.44, '29': 72.22, '30': 80.56, '31': 83.33, '32': 91.67, '33': 67.78, 'old': 78.73, 'new': 79.5}
2024-06-14 04:17:32,501 [trainer.py] => CNN top1 curve: [89.7, 88.69, 82.02]
2024-06-14 04:17:32,501 [trainer.py] => CNN top5 curve: [99.44, 99.07, 97.65]
2024-06-14 04:17:32,501 [trainer.py] => NME top1 curve: [89.04, 85.33, 78.95]
2024-06-14 04:17:32,501 [trainer.py] => NME top5 curve: [99.37, 98.98, 97.14]

2024-06-14 04:17:32,502 [trainer.py] => All params: 63139730
2024-06-14 04:17:32,503 [trainer.py] => Trainable params: 21056506
2024-06-14 04:17:32,816 [der.py] => Learning on 35-45
2024-06-14 04:17:32,824 [der.py] => All params: 84190952
2024-06-14 04:17:32,830 [der.py] => Trainable params: 21066116
2024-06-14 04:17:33,131 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 04:17:33,133 [der.py] => per cls weights : [-0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605
 -0.20752605 -0.20752605 -0.20752605 -0.20752605 -0.20752605  5.22634117
  5.22634117  5.22634117  5.22634117  5.22634117  5.22634117  5.22634117
  5.22634117  5.22634117  5.22634117]
2024-06-14 05:37:19,859 [der.py] => Task 3, Epoch 150/150 => Loss 0.114, Loss_clf 0.034, Loss_aux 0.080, Train_accy 99.73
2024-06-14 05:37:19,904 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 05:37:19,905 [der.py] => per cls weights : [-0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395  5.19721383
  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383
  5.19721383  5.19721383  5.19721383]
2024-06-14 05:37:59,232 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 3.554,  Train_accy 11.45, Test_accy 2.16
2024-06-14 05:38:22,399 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 8.336,  Train_accy 5.81
2024-06-14 05:38:47,613 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 37.867,  Train_accy 6.51
2024-06-14 05:39:10,393 [der.py] => SNet: Task 3, Epoch 4/130 => Loss -57.364,  Train_accy 5.75
2024-06-14 05:39:33,407 [der.py] => SNet: Task 3, Epoch 5/130 => Loss -0.749,  Train_accy 6.32
2024-06-14 05:40:11,727 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 4109.795,  Train_accy 5.47, Test_accy 2.32
2024-06-14 05:40:34,808 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1610.381,  Train_accy 2.99
2024-06-14 05:40:57,949 [der.py] => SNet: Task 3, Epoch 8/130 => Loss -215.119,  Train_accy 5.60
2024-06-14 05:41:20,898 [der.py] => SNet: Task 3, Epoch 9/130 => Loss -3205.956,  Train_accy 7.14
2024-06-14 05:41:43,932 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 3076.702,  Train_accy 6.19
2024-06-14 05:42:22,181 [der.py] => SNet: Task 3, Epoch 11/130 => Loss -1252.732,  Train_accy 6.38, Test_accy 2.31
2024-06-14 05:42:46,866 [der.py] => SNet: Task 3, Epoch 12/130 => Loss -19399.723,  Train_accy 6.23
2024-06-14 05:43:10,218 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 45497.148,  Train_accy 5.49
2024-06-14 05:43:34,190 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 109656.746,  Train_accy 5.12
2024-06-14 05:43:57,710 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 18207.551,  Train_accy 4.53
2024-06-14 05:44:34,840 [der.py] => SNet: Task 3, Epoch 16/130 => Loss -23.245,  Train_accy 0.59, Test_accy 2.22
2024-06-14 05:44:58,108 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 0.208,  Train_accy 0.59
2024-06-14 05:45:21,970 [der.py] => SNet: Task 3, Epoch 18/130 => Loss -0.623,  Train_accy 3.35
2024-06-14 05:45:45,809 [der.py] => SNet: Task 3, Epoch 19/130 => Loss -0.989,  Train_accy 5.71
2024-06-14 05:46:09,239 [der.py] => SNet: Task 3, Epoch 20/130 => Loss -0.854,  Train_accy 6.10
2024-06-14 05:46:46,517 [der.py] => SNet: Task 3, Epoch 21/130 => Loss -1.317,  Train_accy 1.90, Test_accy 2.22
2024-06-14 05:47:10,016 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 0.650,  Train_accy 0.57
2024-06-14 05:47:33,343 [der.py] => SNet: Task 3, Epoch 23/130 => Loss -1.346,  Train_accy 7.35
2024-06-14 05:47:56,618 [der.py] => SNet: Task 3, Epoch 24/130 => Loss -1.688,  Train_accy 7.90
2024-06-14 05:48:20,247 [der.py] => SNet: Task 3, Epoch 25/130 => Loss -1.848,  Train_accy 4.42
2024-06-14 05:48:57,083 [der.py] => SNet: Task 3, Epoch 26/130 => Loss -1.993,  Train_accy 3.22, Test_accy 2.22
2024-06-14 05:49:19,897 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 9.988,  Train_accy 6.76
2024-06-14 05:49:43,180 [der.py] => SNet: Task 3, Epoch 28/130 => Loss -2.228,  Train_accy 1.28
2024-06-14 05:50:06,888 [der.py] => SNet: Task 3, Epoch 29/130 => Loss -2.406,  Train_accy 1.89
2024-06-14 05:50:29,591 [der.py] => SNet: Task 3, Epoch 30/130 => Loss -2.521,  Train_accy 8.00
2024-06-14 05:51:07,923 [der.py] => SNet: Task 3, Epoch 31/130 => Loss -2.679,  Train_accy 8.00, Test_accy 2.22
2024-06-14 05:51:31,238 [der.py] => SNet: Task 3, Epoch 32/130 => Loss -2.780,  Train_accy 7.45
2024-06-14 05:51:55,141 [der.py] => SNet: Task 3, Epoch 33/130 => Loss -2.918,  Train_accy 0.57
2024-06-14 05:52:18,796 [der.py] => SNet: Task 3, Epoch 34/130 => Loss -3.053,  Train_accy 3.35
2024-06-14 05:52:40,101 [der.py] => SNet: Task 3, Epoch 35/130 => Loss -24.319,  Train_accy 7.35
2024-06-14 05:53:16,295 [der.py] => SNet: Task 3, Epoch 36/130 => Loss -3.397,  Train_accy 0.99, Test_accy 2.22
2024-06-14 05:53:39,527 [der.py] => SNet: Task 3, Epoch 37/130 => Loss -3.833,  Train_accy 0.51
2024-06-14 05:54:02,833 [der.py] => SNet: Task 3, Epoch 38/130 => Loss -3.951,  Train_accy 8.00
2024-06-14 05:54:26,859 [der.py] => SNet: Task 3, Epoch 39/130 => Loss -4.005,  Train_accy 2.36
2024-06-14 05:54:50,101 [der.py] => SNet: Task 3, Epoch 40/130 => Loss -4.205,  Train_accy 2.74
2024-06-14 05:55:27,220 [der.py] => SNet: Task 3, Epoch 41/130 => Loss -4.265,  Train_accy 8.00, Test_accy 2.22
2024-06-14 05:55:50,206 [der.py] => SNet: Task 3, Epoch 42/130 => Loss -4.418,  Train_accy 7.90
2024-06-14 05:56:13,655 [der.py] => SNet: Task 3, Epoch 43/130 => Loss -4.550,  Train_accy 6.44
2024-06-14 05:56:37,251 [der.py] => SNet: Task 3, Epoch 44/130 => Loss -4.590,  Train_accy 4.34
2024-06-14 05:57:01,036 [der.py] => SNet: Task 3, Epoch 45/130 => Loss -4.762,  Train_accy 0.57
2024-06-14 05:57:38,314 [der.py] => SNet: Task 3, Epoch 46/130 => Loss -4.930,  Train_accy 5.50, Test_accy 2.22
2024-06-14 05:58:01,980 [der.py] => SNet: Task 3, Epoch 47/130 => Loss -4.985,  Train_accy 8.00
2024-06-14 05:58:24,952 [der.py] => SNet: Task 3, Epoch 48/130 => Loss -5.085,  Train_accy 3.64
2024-06-14 05:58:47,608 [der.py] => SNet: Task 3, Epoch 49/130 => Loss -5.215,  Train_accy 6.59
2024-06-14 05:59:11,249 [der.py] => SNet: Task 3, Epoch 50/130 => Loss -5.280,  Train_accy 1.96
2024-06-14 05:59:48,350 [der.py] => SNet: Task 3, Epoch 51/130 => Loss -5.418,  Train_accy 2.13, Test_accy 2.22
2024-06-14 06:00:12,528 [der.py] => SNet: Task 3, Epoch 52/130 => Loss -5.523,  Train_accy 5.64
2024-06-14 06:00:36,853 [der.py] => SNet: Task 3, Epoch 53/130 => Loss -5.631,  Train_accy 8.00
2024-06-14 06:01:00,537 [der.py] => SNet: Task 3, Epoch 54/130 => Loss -5.637,  Train_accy 1.52
2024-06-14 06:01:24,064 [der.py] => SNet: Task 3, Epoch 55/130 => Loss -5.821,  Train_accy 1.10
2024-06-14 06:02:02,599 [der.py] => SNet: Task 3, Epoch 56/130 => Loss -5.880,  Train_accy 8.00, Test_accy 2.22
2024-06-14 06:02:26,277 [der.py] => SNet: Task 3, Epoch 57/130 => Loss -7.325,  Train_accy 6.93
2024-06-14 06:02:49,577 [der.py] => SNet: Task 3, Epoch 58/130 => Loss -6.083,  Train_accy 4.21
2024-06-14 06:03:13,349 [der.py] => SNet: Task 3, Epoch 59/130 => Loss -6.160,  Train_accy 0.57
2024-06-14 06:03:36,584 [der.py] => SNet: Task 3, Epoch 60/130 => Loss -6.247,  Train_accy 5.68
2024-06-14 06:04:13,091 [der.py] => SNet: Task 3, Epoch 61/130 => Loss -6.264,  Train_accy 1.26, Test_accy 2.22
2024-06-14 06:04:36,811 [der.py] => SNet: Task 3, Epoch 62/130 => Loss -6.429,  Train_accy 2.74
2024-06-14 06:05:00,649 [der.py] => SNet: Task 3, Epoch 63/130 => Loss -6.504,  Train_accy 8.00
2024-06-14 06:05:25,677 [der.py] => SNet: Task 3, Epoch 64/130 => Loss -6.574,  Train_accy 8.00
2024-06-14 06:05:49,907 [der.py] => SNet: Task 3, Epoch 65/130 => Loss -10.073,  Train_accy 4.69
2024-06-14 06:06:29,348 [der.py] => SNet: Task 3, Epoch 66/130 => Loss -6.775,  Train_accy 0.57, Test_accy 2.22
2024-06-14 06:06:54,343 [der.py] => SNet: Task 3, Epoch 67/130 => Loss -6.680,  Train_accy 0.57
2024-06-14 06:07:19,031 [der.py] => SNet: Task 3, Epoch 68/130 => Loss -6.954,  Train_accy 3.03
2024-06-14 06:07:43,520 [der.py] => SNet: Task 3, Epoch 69/130 => Loss -6.966,  Train_accy 0.57
2024-06-14 06:08:08,393 [der.py] => SNet: Task 3, Epoch 70/130 => Loss -7.051,  Train_accy 7.26
2024-06-14 06:08:46,855 [der.py] => SNet: Task 3, Epoch 71/130 => Loss -7.114,  Train_accy 8.00, Test_accy 2.22
2024-06-14 06:09:11,281 [der.py] => SNet: Task 3, Epoch 72/130 => Loss -7.194,  Train_accy 7.05
2024-06-14 06:09:36,110 [der.py] => SNet: Task 3, Epoch 73/130 => Loss -13.940,  Train_accy 0.57
2024-06-14 06:10:01,477 [der.py] => SNet: Task 3, Epoch 74/130 => Loss -7.341,  Train_accy 0.57
2024-06-14 06:10:26,057 [der.py] => SNet: Task 3, Epoch 75/130 => Loss -7.376,  Train_accy 5.54
2024-06-14 06:11:06,380 [der.py] => SNet: Task 3, Epoch 76/130 => Loss -7.418,  Train_accy 7.30, Test_accy 2.22
2024-06-14 06:11:32,495 [der.py] => SNet: Task 3, Epoch 77/130 => Loss -7.517,  Train_accy 0.57
2024-06-14 06:11:59,102 [der.py] => SNet: Task 3, Epoch 78/130 => Loss -6.337,  Train_accy 5.50
2024-06-14 06:12:24,110 [der.py] => SNet: Task 3, Epoch 79/130 => Loss -7.634,  Train_accy 7.03
2024-06-14 06:12:49,807 [der.py] => SNet: Task 3, Epoch 80/130 => Loss -7.674,  Train_accy 4.78
2024-06-14 06:13:28,088 [der.py] => SNet: Task 3, Epoch 81/130 => Loss -7.678,  Train_accy 5.07, Test_accy 2.22
2024-06-14 06:13:52,069 [der.py] => SNet: Task 3, Epoch 82/130 => Loss -7.769,  Train_accy 0.57
2024-06-14 06:14:16,974 [der.py] => SNet: Task 3, Epoch 83/130 => Loss -7.760,  Train_accy 0.72
2024-06-14 06:14:41,778 [der.py] => SNet: Task 3, Epoch 84/130 => Loss -7.908,  Train_accy 0.57
2024-06-14 06:15:06,591 [der.py] => SNet: Task 3, Epoch 85/130 => Loss -7.868,  Train_accy 4.36
2024-06-14 06:15:47,103 [der.py] => SNet: Task 3, Epoch 86/130 => Loss -7.950,  Train_accy 4.59, Test_accy 2.22
2024-06-14 06:16:12,685 [der.py] => SNet: Task 3, Epoch 87/130 => Loss -8.021,  Train_accy 7.70
2024-06-14 06:16:36,411 [der.py] => SNet: Task 3, Epoch 88/130 => Loss -8.114,  Train_accy 6.95
2024-06-14 06:17:01,972 [der.py] => SNet: Task 3, Epoch 89/130 => Loss -9.067,  Train_accy 8.00
2024-06-14 06:17:28,281 [der.py] => SNet: Task 3, Epoch 90/130 => Loss -8.109,  Train_accy 8.00
2024-06-14 06:18:07,045 [der.py] => SNet: Task 3, Epoch 91/130 => Loss -8.124,  Train_accy 8.00, Test_accy 2.22
2024-06-14 06:18:32,332 [der.py] => SNet: Task 3, Epoch 92/130 => Loss -8.167,  Train_accy 5.33
2024-06-14 06:18:56,676 [der.py] => SNet: Task 3, Epoch 93/130 => Loss -8.204,  Train_accy 8.00
2024-06-14 06:19:23,143 [der.py] => SNet: Task 3, Epoch 94/130 => Loss -6.767,  Train_accy 8.00
2024-06-14 06:19:48,007 [der.py] => SNet: Task 3, Epoch 95/130 => Loss -8.252,  Train_accy 8.00
2024-06-14 06:20:26,436 [der.py] => SNet: Task 3, Epoch 96/130 => Loss -8.273,  Train_accy 8.00, Test_accy 2.22
2024-06-14 06:20:51,317 [der.py] => SNet: Task 3, Epoch 97/130 => Loss -8.275,  Train_accy 1.83
2024-06-14 06:21:16,633 [der.py] => SNet: Task 3, Epoch 98/130 => Loss -8.275,  Train_accy 0.57
2024-06-14 06:21:40,911 [der.py] => SNet: Task 3, Epoch 99/130 => Loss -8.302,  Train_accy 0.69
2024-06-14 06:22:06,334 [der.py] => SNet: Task 3, Epoch 100/130 => Loss -8.306,  Train_accy 2.78
2024-06-14 06:22:47,321 [der.py] => SNet: Task 3, Epoch 101/130 => Loss -8.354,  Train_accy 3.03, Test_accy 2.22
2024-06-14 06:23:12,395 [der.py] => SNet: Task 3, Epoch 102/130 => Loss -8.328,  Train_accy 7.52
2024-06-14 06:23:37,215 [der.py] => SNet: Task 3, Epoch 103/130 => Loss -8.421,  Train_accy 8.00
2024-06-14 06:24:02,550 [der.py] => SNet: Task 3, Epoch 104/130 => Loss -8.368,  Train_accy 1.60
2024-06-14 06:24:27,818 [der.py] => SNet: Task 3, Epoch 105/130 => Loss -8.455,  Train_accy 6.53
2024-06-14 06:25:07,793 [der.py] => SNet: Task 3, Epoch 106/130 => Loss -8.438,  Train_accy 2.90, Test_accy 2.22
2024-06-14 06:25:32,145 [der.py] => SNet: Task 3, Epoch 107/130 => Loss -8.457,  Train_accy 3.81
2024-06-14 06:25:57,277 [der.py] => SNet: Task 3, Epoch 108/130 => Loss -8.507,  Train_accy 7.35
2024-06-14 06:26:22,745 [der.py] => SNet: Task 3, Epoch 109/130 => Loss -8.506,  Train_accy 8.00
2024-06-14 06:26:47,791 [der.py] => SNet: Task 3, Epoch 110/130 => Loss -8.483,  Train_accy 3.30
2024-06-14 06:27:26,911 [der.py] => SNet: Task 3, Epoch 111/130 => Loss -17.120,  Train_accy 0.57, Test_accy 2.22
2024-06-14 06:27:52,300 [der.py] => SNet: Task 3, Epoch 112/130 => Loss -8.542,  Train_accy 1.50
2024-06-14 06:28:16,374 [der.py] => SNet: Task 3, Epoch 113/130 => Loss -8.517,  Train_accy 3.54
2024-06-14 06:28:41,112 [der.py] => SNet: Task 3, Epoch 114/130 => Loss -8.754,  Train_accy 0.57
2024-06-14 06:29:05,421 [der.py] => SNet: Task 3, Epoch 115/130 => Loss -8.518,  Train_accy 0.57
2024-06-14 06:29:43,191 [der.py] => SNet: Task 3, Epoch 116/130 => Loss -8.556,  Train_accy 0.57, Test_accy 2.22
2024-06-14 06:30:07,740 [der.py] => SNet: Task 3, Epoch 117/130 => Loss -8.554,  Train_accy 0.57
2024-06-14 06:30:31,861 [der.py] => SNet: Task 3, Epoch 118/130 => Loss -8.550,  Train_accy 0.59
2024-06-14 06:30:56,287 [der.py] => SNet: Task 3, Epoch 119/130 => Loss -8.578,  Train_accy 0.80
2024-06-14 06:31:20,402 [der.py] => SNet: Task 3, Epoch 120/130 => Loss -8.940,  Train_accy 0.57
2024-06-14 06:31:57,425 [der.py] => SNet: Task 3, Epoch 121/130 => Loss -8.562,  Train_accy 0.57, Test_accy 2.22
2024-06-14 06:32:21,262 [der.py] => SNet: Task 3, Epoch 122/130 => Loss -8.587,  Train_accy 0.57
2024-06-14 06:32:44,202 [der.py] => SNet: Task 3, Epoch 123/130 => Loss -8.588,  Train_accy 0.57
2024-06-14 06:33:05,558 [der.py] => SNet: Task 3, Epoch 124/130 => Loss -8.591,  Train_accy 0.57
2024-06-14 06:33:30,535 [der.py] => SNet: Task 3, Epoch 125/130 => Loss -8.592,  Train_accy 0.59
2024-06-14 06:34:08,087 [der.py] => SNet: Task 3, Epoch 126/130 => Loss -8.582,  Train_accy 0.57, Test_accy 2.22
2024-06-14 06:34:32,175 [der.py] => SNet: Task 3, Epoch 127/130 => Loss -8.550,  Train_accy 0.57
2024-06-14 06:34:56,646 [der.py] => SNet: Task 3, Epoch 128/130 => Loss -8.549,  Train_accy 0.57
2024-06-14 06:35:21,051 [der.py] => SNet: Task 3, Epoch 129/130 => Loss -8.617,  Train_accy 0.57
2024-06-14 06:35:44,783 [der.py] => SNet: Task 3, Epoch 130/130 => Loss -8.590,  Train_accy 0.57
2024-06-14 06:35:56,171 [der.py] => darknet eval: 
2024-06-14 06:35:56,171 [der.py] => CNN top1 curve: 2.22
2024-06-14 06:35:56,171 [der.py] => CNN top5 curve: 11.11
2024-06-14 06:35:56,174 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-14 06:38:09,168 [der.py] => Exemplar size: 1350
2024-06-14 06:38:09,170 [trainer.py] => CNN: {'total': 76.65, '0': 77.22, '1': 62.22, '2': 87.22, '3': 72.22, '4': 93.89, '5': 46.11, '6': 70.56, '7': 62.22, '8': 44.44, '9': 41.11, '10': 91.67, '11': 91.67, '12': 73.33, '13': 86.11, '14': 58.89, '15': 94.44, '16': 97.78, '17': 93.33, '18': 95.56, '19': 96.11, '20': 97.22, '21': 92.22, '22': 76.67, '23': 80.0, '24': 63.33, '25': 86.11, '26': 89.44, '27': 93.33, '28': 75.0, '29': 81.11, '30': 80.56, '31': 93.33, '32': 100.0, '33': 81.67, '34': 85.56, '35': 78.89, '36': 85.56, '37': 38.33, '38': 2.78, '39': 45.0, '40': 65.56, '41': 92.78, '42': 97.22, '43': 97.78, 'old': 80.33, 'new': 63.78}
2024-06-14 06:38:09,170 [trainer.py] => NME: {'total': 77.6, '0': 61.11, '1': 51.67, '2': 91.67, '3': 57.22, '4': 80.56, '5': 47.78, '6': 57.22, '7': 59.44, '8': 46.67, '9': 65.0, '10': 86.67, '11': 83.89, '12': 72.22, '13': 78.89, '14': 53.33, '15': 93.89, '16': 96.11, '17': 93.33, '18': 95.56, '19': 89.44, '20': 90.56, '21': 89.44, '22': 90.0, '23': 71.11, '24': 72.78, '25': 75.56, '26': 91.11, '27': 78.33, '28': 67.78, '29': 72.22, '30': 77.78, '31': 82.78, '32': 90.0, '33': 56.67, '34': 78.33, '35': 90.56, '36': 91.67, '37': 67.78, '38': 91.11, '39': 87.78, '40': 73.89, '41': 89.44, '42': 93.89, '43': 98.33, 'old': 75.6, 'new': 84.61}
2024-06-14 06:38:09,170 [trainer.py] => CNN top1 curve: [89.7, 88.69, 82.02, 76.65]
2024-06-14 06:38:09,170 [trainer.py] => CNN top5 curve: [99.44, 99.07, 97.65, 95.53]
2024-06-14 06:38:09,170 [trainer.py] => NME top1 curve: [89.04, 85.33, 78.95, 77.6]
2024-06-14 06:38:09,171 [trainer.py] => NME top5 curve: [99.37, 98.98, 97.14, 96.49]

2024-06-14 06:38:09,176 [trainer.py] => All params: 84190952
2024-06-14 06:38:09,180 [trainer.py] => Trainable params: 21066116
2024-06-14 06:38:09,598 [der.py] => Learning on 45-55
2024-06-14 06:38:09,605 [der.py] => All params: 105244734
2024-06-14 06:38:09,608 [der.py] => Trainable params: 21078286
2024-06-14 06:38:09,837 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 06:38:09,838 [der.py] => per cls weights : [-0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569 -0.26590569
 -0.26590569 -0.26590569 -0.26590569  6.69657563  6.69657563  6.69657563
  6.69657563  6.69657563  6.69657563  6.69657563  6.69657563  6.69657563
  6.69657563]
2024-06-14 08:15:24,174 [der.py] => Task 4, Epoch 150/150 => Loss 0.034, Loss_clf 0.011, Loss_aux 0.023, Train_accy 100.00
2024-06-14 08:15:24,273 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2024-06-14 08:15:24,275 [der.py] => per cls weights : [-0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859  6.64636865  6.64636865  6.64636865
  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865
  6.64636865]
2024-06-14 08:16:09,008 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.268,  Train_accy 9.93, Test_accy 3.19
2024-06-14 08:16:37,589 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 3.287,  Train_accy 8.47
2024-06-14 08:17:04,421 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.467,  Train_accy 7.12
2024-06-14 08:17:32,105 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.023,  Train_accy 6.67
2024-06-14 08:18:01,093 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 8.492,  Train_accy 6.83
2024-06-14 08:18:59,178 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 8.711,  Train_accy 6.97, Test_accy 1.80
2024-06-14 08:19:25,848 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 21.138,  Train_accy 6.11
2024-06-14 08:19:53,525 [der.py] => SNet: Task 4, Epoch 8/130 => Loss -34.515,  Train_accy 6.95
2024-06-14 08:20:20,098 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 676.455,  Train_accy 8.22
2024-06-14 08:20:47,773 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 13.728,  Train_accy 7.53
2024-06-14 08:21:29,246 [der.py] => SNet: Task 4, Epoch 11/130 => Loss -26.083,  Train_accy 6.52, Test_accy 1.77
2024-06-14 08:21:54,624 [der.py] => SNet: Task 4, Epoch 12/130 => Loss -436.318,  Train_accy 5.51
2024-06-14 08:22:19,900 [der.py] => SNet: Task 4, Epoch 13/130 => Loss -3794.238,  Train_accy 7.46
2024-06-14 08:22:45,581 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 1700.553,  Train_accy 7.59
2024-06-14 08:23:12,168 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 931.116,  Train_accy 6.25
2024-06-14 08:23:53,962 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 188.487,  Train_accy 7.60, Test_accy 1.82
2024-06-14 08:24:21,114 [der.py] => SNet: Task 4, Epoch 17/130 => Loss -591.520,  Train_accy 7.14
2024-06-14 08:24:47,179 [der.py] => SNet: Task 4, Epoch 18/130 => Loss -39.562,  Train_accy 7.17
2024-06-14 08:25:13,983 [der.py] => SNet: Task 4, Epoch 19/130 => Loss -666.194,  Train_accy 7.66
2024-06-14 08:25:40,997 [der.py] => SNet: Task 4, Epoch 20/130 => Loss -1770.423,  Train_accy 7.14
2024-06-14 08:26:23,929 [der.py] => SNet: Task 4, Epoch 21/130 => Loss -3044.745,  Train_accy 7.15, Test_accy 1.83
2024-06-14 08:26:51,241 [der.py] => SNet: Task 4, Epoch 22/130 => Loss -5610.595,  Train_accy 6.85
2024-06-14 08:27:17,780 [der.py] => SNet: Task 4, Epoch 23/130 => Loss -8769.762,  Train_accy 7.53
2024-06-14 08:27:44,549 [der.py] => SNet: Task 4, Epoch 24/130 => Loss -8702.507,  Train_accy 7.28
2024-06-14 08:28:11,508 [der.py] => SNet: Task 4, Epoch 25/130 => Loss -20743.535,  Train_accy 7.73
2024-06-14 08:28:53,346 [der.py] => SNet: Task 4, Epoch 26/130 => Loss -28752.558,  Train_accy 6.85, Test_accy 1.76
2024-06-14 08:29:20,199 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 4938.553,  Train_accy 7.55
2024-06-14 08:29:47,564 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 13319.196,  Train_accy 6.52
2024-06-14 08:30:15,468 [der.py] => SNet: Task 4, Epoch 29/130 => Loss -7677.247,  Train_accy 7.50
2024-06-14 08:30:42,935 [der.py] => SNet: Task 4, Epoch 30/130 => Loss -36734.167,  Train_accy 7.46
2024-06-14 08:31:26,578 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 58547.045,  Train_accy 7.62, Test_accy 1.82
2024-06-14 08:31:53,657 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 158514.711,  Train_accy 6.23
2024-06-14 08:32:21,488 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 7.540,  Train_accy 7.39
2024-06-14 08:32:49,244 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.686,  Train_accy 7.55
2024-06-14 08:33:17,023 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.664,  Train_accy 7.55
2024-06-14 08:34:00,580 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.648,  Train_accy 7.53, Test_accy 1.82
2024-06-14 08:34:28,468 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.605,  Train_accy 7.57
2024-06-14 08:34:56,220 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.608,  Train_accy 7.57
2024-06-14 08:35:23,158 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.584,  Train_accy 7.57
2024-06-14 08:35:50,488 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.569,  Train_accy 7.57
2024-06-14 08:36:36,398 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.542,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:37:03,609 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.543,  Train_accy 7.57
2024-06-14 08:37:31,332 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.533,  Train_accy 7.57
2024-06-14 08:37:59,062 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.515,  Train_accy 7.57
2024-06-14 08:38:26,779 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.496,  Train_accy 7.57
2024-06-14 08:39:09,841 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.490,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:39:34,414 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.484,  Train_accy 7.57
2024-06-14 08:39:59,151 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.459,  Train_accy 7.57
2024-06-14 08:40:24,176 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.456,  Train_accy 7.57
2024-06-14 08:40:50,014 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.480,  Train_accy 7.57
2024-06-14 08:41:31,088 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.441,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:41:57,482 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.423,  Train_accy 7.57
2024-06-14 08:42:23,764 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.410,  Train_accy 7.57
2024-06-14 08:42:49,980 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.427,  Train_accy 7.57
2024-06-14 08:43:16,247 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.390,  Train_accy 7.57
2024-06-14 08:43:57,739 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.386,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:44:23,493 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.385,  Train_accy 7.57
2024-06-14 08:44:49,655 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.386,  Train_accy 7.57
2024-06-14 08:45:15,628 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.363,  Train_accy 7.57
2024-06-14 08:45:41,489 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.353,  Train_accy 7.57
2024-06-14 08:46:28,142 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.338,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:46:54,945 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.421,  Train_accy 7.57
2024-06-14 08:47:23,616 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.343,  Train_accy 7.57
2024-06-14 08:47:52,195 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.338,  Train_accy 7.57
2024-06-14 08:48:19,908 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.318,  Train_accy 7.57
2024-06-14 08:49:05,375 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.293,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:49:35,229 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.295,  Train_accy 7.57
2024-06-14 08:50:03,299 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.306,  Train_accy 7.57
2024-06-14 08:50:30,940 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.279,  Train_accy 7.57
2024-06-14 08:50:57,615 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.270,  Train_accy 7.57
2024-06-14 08:51:42,564 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.223,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:52:09,687 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.259,  Train_accy 7.57
2024-06-14 08:52:35,680 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.261,  Train_accy 7.57
2024-06-14 08:53:02,114 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.237,  Train_accy 7.57
2024-06-14 08:53:28,870 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.256,  Train_accy 7.57
2024-06-14 08:54:16,292 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.243,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:54:43,533 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.228,  Train_accy 7.57
2024-06-14 08:55:10,054 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.217,  Train_accy 7.57
2024-06-14 08:55:38,775 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.222,  Train_accy 7.57
2024-06-14 08:56:06,450 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.210,  Train_accy 7.57
2024-06-14 08:56:52,227 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.206,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:57:19,603 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.216,  Train_accy 7.57
2024-06-14 08:57:46,139 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.205,  Train_accy 7.57
2024-06-14 08:58:13,892 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.187,  Train_accy 7.57
2024-06-14 08:58:42,186 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.210,  Train_accy 7.57
2024-06-14 08:59:26,566 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.186,  Train_accy 7.57, Test_accy 1.82
2024-06-14 08:59:53,731 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.183,  Train_accy 7.57
2024-06-14 09:00:20,912 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.176,  Train_accy 7.57
2024-06-14 09:00:48,166 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.136,  Train_accy 7.57
2024-06-14 09:01:15,931 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.167,  Train_accy 7.57
2024-06-14 09:02:00,746 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.153,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:02:28,033 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.161,  Train_accy 7.57
2024-06-14 09:02:55,124 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.160,  Train_accy 7.57
2024-06-14 09:03:23,288 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.172,  Train_accy 7.57
2024-06-14 09:03:50,709 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.166,  Train_accy 7.57
2024-06-14 09:04:34,802 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.154,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:05:02,160 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.158,  Train_accy 7.57
2024-06-14 09:05:27,942 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.136,  Train_accy 7.57
2024-06-14 09:05:56,387 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.148,  Train_accy 7.57
2024-06-14 09:06:25,371 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.136,  Train_accy 7.57
2024-06-14 09:07:12,759 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.150,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:07:41,767 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.067,  Train_accy 7.57
2024-06-14 09:08:10,788 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.127,  Train_accy 7.57
2024-06-14 09:08:39,885 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.117,  Train_accy 7.57
2024-06-14 09:09:09,749 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.127,  Train_accy 7.57
2024-06-14 09:09:58,051 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.134,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:10:27,146 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.133,  Train_accy 7.57
2024-06-14 09:10:56,618 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.134,  Train_accy 7.57
2024-06-14 09:11:26,621 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.128,  Train_accy 7.57
2024-06-14 09:11:55,958 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.147,  Train_accy 7.57
2024-06-14 09:12:43,043 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.114,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:13:10,879 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.124,  Train_accy 7.57
2024-06-14 09:13:39,852 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.122,  Train_accy 7.57
2024-06-14 09:14:08,910 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.161,  Train_accy 7.57
2024-06-14 09:14:36,921 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.126,  Train_accy 7.57
2024-06-14 09:15:22,526 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.130,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:15:52,334 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.133,  Train_accy 7.57
2024-06-14 09:16:20,081 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.117,  Train_accy 7.57
2024-06-14 09:16:48,923 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.127,  Train_accy 7.57
2024-06-14 09:17:16,264 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.123,  Train_accy 7.57
2024-06-14 09:18:04,682 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.115,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:18:33,016 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.106,  Train_accy 7.57
2024-06-14 09:19:01,828 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.116,  Train_accy 7.57
2024-06-14 09:19:31,578 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.137,  Train_accy 7.57
2024-06-14 09:20:01,939 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.122,  Train_accy 7.57
2024-06-14 09:20:46,810 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.132,  Train_accy 7.57, Test_accy 1.82
2024-06-14 09:21:15,463 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.115,  Train_accy 7.57
2024-06-14 09:21:44,377 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.123,  Train_accy 7.57
2024-06-14 09:22:12,483 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.127,  Train_accy 7.57
2024-06-14 09:22:40,001 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.124,  Train_accy 7.57
2024-06-14 09:22:52,128 [der.py] => darknet eval: 
2024-06-14 09:22:52,129 [der.py] => CNN top1 curve: 1.82
2024-06-14 09:22:52,130 [der.py] => CNN top5 curve: 9.09
2024-06-14 09:22:52,135 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-06-14 09:25:40,380 [der.py] => Exemplar size: 1650
2024-06-14 09:25:40,380 [trainer.py] => CNN: {'total': 76.75, '0': 52.78, '1': 70.0, '2': 91.67, '3': 61.67, '4': 89.44, '5': 49.44, '6': 71.11, '7': 61.11, '8': 47.22, '9': 55.56, '10': 90.0, '11': 77.22, '12': 87.22, '13': 81.11, '14': 58.89, '15': 95.0, '16': 95.0, '17': 93.33, '18': 95.56, '19': 94.44, '20': 98.33, '21': 88.89, '22': 90.0, '23': 73.33, '24': 65.0, '25': 83.33, '26': 92.22, '27': 90.0, '28': 76.11, '29': 85.0, '30': 89.44, '31': 85.56, '32': 90.0, '33': 61.67, '34': 74.44, '35': 98.89, '36': 98.89, '37': 81.67, '38': 96.67, '39': 99.44, '40': 87.78, '41': 99.44, '42': 97.78, '43': 97.78, '44': 83.33, '45': 48.33, '46': 53.89, '47': 47.22, '48': 54.44, '49': 52.22, '50': 57.78, '51': 63.33, '52': 46.67, '53': 55.56, 'old': 82.28, 'new': 51.83}
2024-06-14 09:25:40,381 [trainer.py] => NME: {'total': 73.07, '0': 61.11, '1': 51.11, '2': 88.89, '3': 38.89, '4': 72.78, '5': 50.56, '6': 58.33, '7': 58.33, '8': 42.22, '9': 62.22, '10': 80.0, '11': 82.78, '12': 67.22, '13': 73.89, '14': 52.22, '15': 93.33, '16': 93.33, '17': 92.22, '18': 90.0, '19': 85.0, '20': 88.33, '21': 87.78, '22': 87.22, '23': 66.67, '24': 68.89, '25': 73.89, '26': 85.56, '27': 77.78, '28': 68.33, '29': 70.56, '30': 75.0, '31': 76.67, '32': 86.67, '33': 49.44, '34': 75.0, '35': 91.67, '36': 90.56, '37': 63.89, '38': 89.44, '39': 87.78, '40': 66.67, '41': 91.67, '42': 93.33, '43': 93.89, '44': 52.78, '45': 74.44, '46': 78.33, '47': 65.0, '48': 68.33, '49': 57.22, '50': 62.22, '51': 73.33, '52': 67.22, '53': 58.89, 'old': 74.53, 'new': 66.5}
2024-06-14 09:25:40,381 [trainer.py] => CNN top1 curve: [89.7, 88.69, 82.02, 76.65, 76.75]
2024-06-14 09:25:40,381 [trainer.py] => CNN top5 curve: [99.44, 99.07, 97.65, 95.53, 96.15]
2024-06-14 09:25:40,381 [trainer.py] => NME top1 curve: [89.04, 85.33, 78.95, 77.6, 73.07]
2024-06-14 09:25:40,381 [trainer.py] => NME top5 curve: [99.37, 98.98, 97.14, 96.49, 94.98]

2025-01-10 16:06:05,837 [trainer.py] => 实验名称:BKD与KD对比实验
2025-01-10 16:06:05,874 [trainer.py] => config: ./exps/der.json
2025-01-10 16:06:05,874 [trainer.py] => experiment_name: 实验名称:BKD与KD对比实验
2025-01-10 16:06:05,874 [trainer.py] => prefix: reproduce
2025-01-10 16:06:05,874 [trainer.py] => dataset: xrfdataset
2025-01-10 16:06:05,875 [trainer.py] => memory_size: 1650
2025-01-10 16:06:05,875 [trainer.py] => memory_per_class: 30
2025-01-10 16:06:05,875 [trainer.py] => fixed_memory: True
2025-01-10 16:06:05,875 [trainer.py] => shuffle: True
2025-01-10 16:06:05,875 [trainer.py] => init_cls: 15
2025-01-10 16:06:05,875 [trainer.py] => increment: 10
2025-01-10 16:06:05,875 [trainer.py] => model_name: der
2025-01-10 16:06:05,875 [trainer.py] => compression_epochs: 130
2025-01-10 16:06:05,875 [trainer.py] => compression_lr: 0.1
2025-01-10 16:06:05,875 [trainer.py] => T: 2
2025-01-10 16:06:05,875 [trainer.py] => convnet_type: unet
2025-01-10 16:06:05,875 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-10 16:06:05,875 [trainer.py] => seed: 1993
2025-01-10 16:06:05,993 [data.py] => 加载完毕XRF原始数据集
2025-01-10 16:06:06,015 [data.py] => 加载完毕XRF原始数据集
2025-01-10 16:06:06,016 [trainer.py] => All params: 0
2025-01-10 16:06:06,016 [trainer.py] => Trainable params: 0
2025-01-10 16:06:06,319 [der.py] => Learning on 0-15
2025-01-10 16:06:06,319 [der.py] => All params: 21045611
2025-01-10 16:06:06,320 [der.py] => Trainable params: 21045611
2025-01-10 16:33:24,640 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-10 16:33:24,641 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-10 16:33:47,840 [der.py] => Exemplar size: 450
2025-01-10 16:33:47,840 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-10 16:33:47,840 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-10 16:33:47,840 [trainer.py] => CNN top1 curve: [89.44]
2025-01-10 16:33:47,841 [trainer.py] => CNN top5 curve: [98.93]
2025-01-10 16:33:47,841 [trainer.py] => NME top1 curve: [88.22]
2025-01-10 16:33:47,841 [trainer.py] => NME top5 curve: [98.81]

2025-01-10 16:33:47,841 [trainer.py] => All params: 21045611
2025-01-10 16:33:47,842 [trainer.py] => Trainable params: 21045611
2025-01-10 16:33:48,007 [der.py] => Learning on 15-25
2025-01-10 16:33:48,009 [der.py] => All params: 42091068
2025-01-10 16:33:48,011 [der.py] => Trainable params: 21049456
2025-01-10 16:59:29,549 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-10 16:59:29,631 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-10 16:59:29,632 [der.py] => per cls weights : [-0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677   2.65250155  2.65250155  2.65250155
  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155
  2.65250155]
2025-01-10 16:59:43,592 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.035,  Train_accy 45.59, Test_accy 43.49
2025-01-10 16:59:53,080 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.469,  Train_accy 70.65
2025-01-10 17:00:02,546 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.276,  Train_accy 80.43
2025-01-10 17:00:11,951 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.148,  Train_accy 87.33
2025-01-10 17:00:21,534 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.085,  Train_accy 89.83
2025-01-10 17:00:35,318 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.049,  Train_accy 91.94, Test_accy 71.58
2025-01-10 17:00:44,848 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.025,  Train_accy 93.01
2025-01-10 17:00:54,283 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.984,  Train_accy 95.23
2025-01-10 17:01:03,793 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.968,  Train_accy 95.61
2025-01-10 17:01:13,216 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.965,  Train_accy 95.89
2025-01-10 17:01:26,947 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.945,  Train_accy 96.80, Test_accy 75.18
2025-01-10 17:01:37,111 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.934,  Train_accy 97.44
2025-01-10 17:01:48,651 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.920,  Train_accy 97.96
2025-01-10 17:01:58,343 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.921,  Train_accy 97.70
2025-01-10 17:02:07,984 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.919,  Train_accy 97.81
2025-01-10 17:02:22,176 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.924,  Train_accy 97.72, Test_accy 76.56
2025-01-10 17:02:31,985 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.914,  Train_accy 98.02
2025-01-10 17:02:41,594 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.908,  Train_accy 98.15
2025-01-10 17:02:51,252 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.905,  Train_accy 98.52
2025-01-10 17:03:00,999 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.906,  Train_accy 98.34
2025-01-10 17:03:15,206 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.895,  Train_accy 98.62, Test_accy 78.49
2025-01-10 17:03:24,813 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.893,  Train_accy 98.69
2025-01-10 17:03:34,649 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.888,  Train_accy 98.82
2025-01-10 17:03:44,562 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.888,  Train_accy 98.97
2025-01-10 17:03:54,303 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.884,  Train_accy 98.99
2025-01-10 17:04:08,849 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.882,  Train_accy 98.97, Test_accy 79.53
2025-01-10 17:04:18,667 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.882,  Train_accy 99.14
2025-01-10 17:04:28,338 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.877,  Train_accy 99.05
2025-01-10 17:04:38,076 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.876,  Train_accy 99.01
2025-01-10 17:04:47,830 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.879,  Train_accy 99.08
2025-01-10 17:05:02,142 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.878,  Train_accy 99.05, Test_accy 78.36
2025-01-10 17:05:11,833 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.881,  Train_accy 99.05
2025-01-10 17:05:21,541 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.871,  Train_accy 99.18
2025-01-10 17:05:31,323 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.869,  Train_accy 99.12
2025-01-10 17:05:40,996 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.870,  Train_accy 98.92
2025-01-10 17:05:55,422 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.870,  Train_accy 99.12, Test_accy 79.73
2025-01-10 17:06:05,195 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.868,  Train_accy 98.86
2025-01-10 17:06:14,884 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.871,  Train_accy 99.08
2025-01-10 17:06:24,617 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.870,  Train_accy 98.99
2025-01-10 17:06:34,364 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.867,  Train_accy 99.14
2025-01-10 17:06:48,659 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.865,  Train_accy 99.16, Test_accy 79.91
2025-01-10 17:06:58,463 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.867,  Train_accy 99.14
2025-01-10 17:07:08,252 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.868,  Train_accy 99.23
2025-01-10 17:07:17,929 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.859,  Train_accy 99.46
2025-01-10 17:07:27,635 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.859,  Train_accy 99.40
2025-01-10 17:07:42,009 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.864,  Train_accy 99.31, Test_accy 80.24
2025-01-10 17:07:51,748 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.864,  Train_accy 99.23
2025-01-10 17:08:01,508 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.859,  Train_accy 99.42
2025-01-10 17:08:11,215 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.864,  Train_accy 99.14
2025-01-10 17:08:20,947 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.863,  Train_accy 99.25
2025-01-10 17:08:35,264 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.862,  Train_accy 99.20, Test_accy 79.67
2025-01-10 17:08:45,077 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.862,  Train_accy 99.03
2025-01-10 17:08:54,808 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.860,  Train_accy 99.38
2025-01-10 17:09:04,538 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.862,  Train_accy 99.31
2025-01-10 17:09:14,159 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.861,  Train_accy 99.20
2025-01-10 17:09:28,550 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.855,  Train_accy 99.25, Test_accy 80.80
2025-01-10 17:09:38,314 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.853,  Train_accy 99.59
2025-01-10 17:09:48,084 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.854,  Train_accy 99.38
2025-01-10 17:09:57,840 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.854,  Train_accy 99.35
2025-01-10 17:10:07,644 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.852,  Train_accy 99.46
2025-01-10 17:10:21,936 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.849,  Train_accy 99.46, Test_accy 80.51
2025-01-10 17:10:31,542 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.854,  Train_accy 99.25
2025-01-10 17:10:41,355 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.853,  Train_accy 99.40
2025-01-10 17:10:50,994 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.853,  Train_accy 99.31
2025-01-10 17:11:00,729 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.850,  Train_accy 99.27
2025-01-10 17:11:14,904 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.849,  Train_accy 99.27, Test_accy 80.36
2025-01-10 17:11:24,593 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.850,  Train_accy 99.48
2025-01-10 17:11:34,287 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.852,  Train_accy 99.27
2025-01-10 17:11:44,049 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.852,  Train_accy 99.53
2025-01-10 17:11:53,796 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.852,  Train_accy 99.51
2025-01-10 17:12:08,028 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.851,  Train_accy 99.33, Test_accy 80.27
2025-01-10 17:12:17,814 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.850,  Train_accy 99.38
2025-01-10 17:12:27,543 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.847,  Train_accy 99.51
2025-01-10 17:12:37,256 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.852,  Train_accy 99.29
2025-01-10 17:12:47,099 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.848,  Train_accy 99.35
2025-01-10 17:13:01,572 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.849,  Train_accy 99.31, Test_accy 80.56
2025-01-10 17:13:11,370 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.851,  Train_accy 99.44
2025-01-10 17:13:21,008 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.847,  Train_accy 99.38
2025-01-10 17:13:30,655 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.846,  Train_accy 99.40
2025-01-10 17:13:40,367 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.849,  Train_accy 99.46
2025-01-10 17:13:54,723 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.846,  Train_accy 99.66, Test_accy 80.87
2025-01-10 17:14:04,383 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.850,  Train_accy 99.33
2025-01-10 17:14:13,986 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.848,  Train_accy 99.42
2025-01-10 17:14:23,687 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.845,  Train_accy 99.27
2025-01-10 17:14:33,551 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.845,  Train_accy 99.70
2025-01-10 17:14:47,640 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.842,  Train_accy 99.53, Test_accy 81.56
2025-01-10 17:14:57,315 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.846,  Train_accy 99.51
2025-01-10 17:15:07,001 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.849,  Train_accy 99.31
2025-01-10 17:15:16,793 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.846,  Train_accy 99.42
2025-01-10 17:15:26,814 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.844,  Train_accy 99.46
2025-01-10 17:17:55,885 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.845,  Train_accy 99.18, Test_accy 80.96
2025-01-10 17:20:07,775 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.844,  Train_accy 99.53
2025-01-10 17:21:02,798 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.843,  Train_accy 99.44
2025-01-10 17:21:12,553 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.843,  Train_accy 99.48
2025-01-10 17:21:22,457 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.846,  Train_accy 99.44
2025-01-10 17:23:31,412 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.842,  Train_accy 99.35, Test_accy 80.93
2025-01-10 17:23:40,872 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.844,  Train_accy 99.61
2025-01-10 17:23:50,624 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.843,  Train_accy 99.42
2025-01-10 17:24:00,459 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.842,  Train_accy 99.35
2025-01-10 17:24:10,220 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.847,  Train_accy 99.48
2025-01-10 17:24:24,606 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.844,  Train_accy 99.48, Test_accy 81.33
2025-01-10 17:24:34,297 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.844,  Train_accy 99.51
2025-01-10 17:24:43,935 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.840,  Train_accy 99.59
2025-01-10 17:24:53,709 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.841,  Train_accy 99.61
2025-01-10 17:25:03,476 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.842,  Train_accy 99.48
2025-01-10 17:25:17,769 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.839,  Train_accy 99.51, Test_accy 80.84
2025-01-10 17:25:27,431 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.839,  Train_accy 99.57
2025-01-10 17:25:37,122 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.845,  Train_accy 99.46
2025-01-10 17:25:46,925 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.839,  Train_accy 99.35
2025-01-10 17:25:56,686 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.843,  Train_accy 99.38
2025-01-10 17:26:11,130 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.11
2025-01-10 17:26:20,900 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.841,  Train_accy 99.61
2025-01-10 17:26:30,637 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.841,  Train_accy 99.57
2025-01-10 17:26:40,293 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.842,  Train_accy 99.59
2025-01-10 17:26:49,985 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.841,  Train_accy 99.57
2025-01-10 17:27:04,225 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.841,  Train_accy 99.44, Test_accy 81.33
2025-01-10 17:27:13,927 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.839,  Train_accy 99.57
2025-01-10 17:27:23,599 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.840,  Train_accy 99.44
2025-01-10 17:27:33,310 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.843,  Train_accy 99.59
2025-01-10 17:27:42,961 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.842,  Train_accy 99.46
2025-01-10 17:27:57,520 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.47
2025-01-10 17:28:07,437 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.843,  Train_accy 99.48
2025-01-10 17:28:17,228 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.841,  Train_accy 99.53
2025-01-10 17:28:26,888 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.839,  Train_accy 99.53
2025-01-10 17:28:36,593 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.839,  Train_accy 99.57
2025-01-10 17:28:50,795 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.838,  Train_accy 99.53, Test_accy 81.62
2025-01-10 17:29:00,493 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.842,  Train_accy 99.51
2025-01-10 17:29:10,268 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.843,  Train_accy 99.48
2025-01-10 17:29:19,950 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.838,  Train_accy 99.59
2025-01-10 17:29:29,659 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.838,  Train_accy 99.48
2025-01-10 17:29:34,530 [der.py] => darknet eval: 
2025-01-10 17:29:34,531 [der.py] => CNN top1 curve: 81.18
2025-01-10 17:29:34,531 [der.py] => CNN top5 curve: 97.73
2025-01-10 17:29:34,541 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-10 17:30:04,478 [der.py] => Exemplar size: 750
2025-01-10 17:30:04,478 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-10 17:30:04,478 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-10 17:30:04,478 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-10 17:30:04,478 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-10 17:30:04,478 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-10 17:30:04,478 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-10 17:30:04,479 [trainer.py] => All params: 42091068
2025-01-10 17:30:04,480 [trainer.py] => Trainable params: 21049456
2025-01-10 17:30:04,735 [der.py] => Learning on 25-35
2025-01-10 17:30:04,737 [der.py] => All params: 63139730
2025-01-10 17:30:04,738 [der.py] => Trainable params: 21056506
2025-01-10 18:04:11,874 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-10 18:04:12,129 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-10 18:04:12,141 [der.py] => per cls weights : [-0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685   3.87092124  3.87092124  3.87092124  3.87092124  3.87092124
  3.87092124  3.87092124  3.87092124  3.87092124  3.87092124]
2025-01-10 18:04:30,318 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.588,  Train_accy 36.85, Test_accy 39.98
2025-01-10 18:04:42,035 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.191,  Train_accy 59.35
2025-01-10 18:04:53,686 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 2.021,  Train_accy 67.94
2025-01-10 18:05:05,474 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.919,  Train_accy 73.39
2025-01-10 18:05:17,078 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.851,  Train_accy 77.17
2025-01-10 18:05:34,922 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.800,  Train_accy 80.12, Test_accy 54.38
2025-01-10 18:05:46,665 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.785,  Train_accy 81.47
2025-01-10 18:05:58,396 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.748,  Train_accy 82.91
2025-01-10 18:06:10,080 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.726,  Train_accy 84.40
2025-01-10 18:06:21,692 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.703,  Train_accy 86.10
2025-01-10 18:06:39,571 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.677,  Train_accy 87.33, Test_accy 59.14
2025-01-10 18:06:51,257 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.666,  Train_accy 87.56
2025-01-10 18:07:02,944 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.651,  Train_accy 88.93
2025-01-10 18:07:14,651 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.639,  Train_accy 89.19
2025-01-10 18:07:26,422 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.633,  Train_accy 89.82
2025-01-10 18:07:44,238 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.627,  Train_accy 89.29, Test_accy 63.97
2025-01-10 18:07:56,088 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.618,  Train_accy 90.71
2025-01-10 18:08:07,800 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.601,  Train_accy 91.01
2025-01-10 18:08:19,605 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.595,  Train_accy 91.09
2025-01-10 18:08:31,307 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.589,  Train_accy 91.58
2025-01-10 18:08:49,180 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.584,  Train_accy 92.42, Test_accy 64.16
2025-01-10 18:09:00,865 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.576,  Train_accy 92.24
2025-01-10 18:09:12,576 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.565,  Train_accy 93.25
2025-01-10 18:09:24,331 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.569,  Train_accy 93.64
2025-01-10 18:09:36,058 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.566,  Train_accy 92.91
2025-01-10 18:09:54,027 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.556,  Train_accy 93.52, Test_accy 68.05
2025-01-10 18:10:05,845 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.548,  Train_accy 93.86
2025-01-10 18:10:17,580 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.547,  Train_accy 93.94
2025-01-10 18:10:29,229 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.542,  Train_accy 93.96
2025-01-10 18:10:40,937 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.542,  Train_accy 93.88
2025-01-10 18:10:58,754 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.536,  Train_accy 94.36, Test_accy 69.16
2025-01-10 18:11:10,467 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.528,  Train_accy 94.59
2025-01-10 18:11:22,327 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.534,  Train_accy 94.71
2025-01-10 18:11:34,396 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.531,  Train_accy 94.89
2025-01-10 18:11:46,189 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.525,  Train_accy 94.81
2025-01-10 18:12:04,190 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.525,  Train_accy 94.63, Test_accy 67.49
2025-01-10 18:12:15,888 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.525,  Train_accy 94.83
2025-01-10 18:12:27,566 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.522,  Train_accy 94.69
2025-01-10 18:12:39,314 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.513,  Train_accy 95.45
2025-01-10 18:12:50,909 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.514,  Train_accy 95.05
2025-01-10 18:13:08,688 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.513,  Train_accy 95.39, Test_accy 68.73
2025-01-10 18:13:20,348 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.512,  Train_accy 95.35
2025-01-10 18:13:32,111 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.513,  Train_accy 94.71
2025-01-10 18:13:43,813 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.507,  Train_accy 95.33
2025-01-10 18:13:55,727 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.504,  Train_accy 95.29
2025-01-10 18:14:13,663 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.504,  Train_accy 95.27, Test_accy 69.43
2025-01-10 18:14:25,354 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.500,  Train_accy 95.58
2025-01-10 18:14:37,004 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.499,  Train_accy 95.68
2025-01-10 18:14:48,733 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.498,  Train_accy 95.94
2025-01-10 18:15:00,729 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.499,  Train_accy 95.15
2025-01-10 18:15:18,576 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.494,  Train_accy 95.56, Test_accy 70.37
2025-01-10 18:15:30,291 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.492,  Train_accy 96.16
2025-01-10 18:15:42,103 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.493,  Train_accy 95.62
2025-01-10 18:15:53,723 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.492,  Train_accy 95.54
2025-01-10 18:16:05,475 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.490,  Train_accy 96.18
2025-01-10 18:16:23,444 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.487,  Train_accy 96.12, Test_accy 70.08
2025-01-10 18:16:35,206 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.488,  Train_accy 95.76
2025-01-10 18:16:46,954 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.485,  Train_accy 95.78
2025-01-10 18:16:58,693 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.485,  Train_accy 96.14
2025-01-10 18:17:10,367 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.484,  Train_accy 95.98
2025-01-10 18:17:28,113 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.483,  Train_accy 96.22, Test_accy 70.33
2025-01-10 18:17:39,826 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.488,  Train_accy 95.92
2025-01-10 18:17:51,548 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.480,  Train_accy 95.94
2025-01-10 18:18:03,140 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.483,  Train_accy 96.26
2025-01-10 18:18:14,876 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.479,  Train_accy 96.04
2025-01-10 18:18:32,885 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.480,  Train_accy 95.92, Test_accy 69.95
2025-01-10 18:18:44,647 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.481,  Train_accy 96.18
2025-01-10 18:18:56,264 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.475,  Train_accy 96.24
2025-01-10 18:19:07,948 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.476,  Train_accy 96.02
2025-01-10 18:19:19,626 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.477,  Train_accy 96.12
2025-01-10 18:19:37,507 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.476,  Train_accy 96.14, Test_accy 70.73
2025-01-10 18:19:49,140 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.475,  Train_accy 96.32
2025-01-10 18:20:00,790 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.475,  Train_accy 96.06
2025-01-10 18:20:12,568 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.473,  Train_accy 96.40
2025-01-10 18:20:24,289 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.476,  Train_accy 96.59
2025-01-10 18:20:42,233 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.473,  Train_accy 95.84, Test_accy 71.11
2025-01-10 18:20:53,931 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.471,  Train_accy 96.63
2025-01-10 18:21:05,636 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.471,  Train_accy 96.08
2025-01-10 18:21:17,673 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.472,  Train_accy 96.61
2025-01-10 18:21:29,466 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.473,  Train_accy 96.22
2025-01-10 18:21:47,264 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.471,  Train_accy 96.32, Test_accy 71.43
2025-01-10 18:21:58,960 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.469,  Train_accy 96.36
2025-01-10 18:22:10,760 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.466,  Train_accy 96.26
2025-01-10 18:22:22,428 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.469,  Train_accy 96.38
2025-01-10 18:22:34,149 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.466,  Train_accy 96.65
2025-01-10 18:22:52,017 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.468,  Train_accy 96.71, Test_accy 71.00
2025-01-10 18:23:03,720 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.465,  Train_accy 96.34
2025-01-10 18:23:15,549 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.467,  Train_accy 96.16
2025-01-10 18:23:27,343 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.463,  Train_accy 96.48
2025-01-10 18:23:39,135 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.464,  Train_accy 96.14
2025-01-10 18:23:56,896 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.463,  Train_accy 96.44, Test_accy 71.44
2025-01-10 18:24:08,600 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.462,  Train_accy 96.71
2025-01-10 18:24:20,209 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.464,  Train_accy 96.10
2025-01-10 18:24:32,019 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.464,  Train_accy 96.48
2025-01-10 18:24:43,746 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.463,  Train_accy 96.73
2025-01-10 18:25:01,558 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.466,  Train_accy 96.44, Test_accy 71.40
2025-01-10 18:25:13,221 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.462,  Train_accy 96.30
2025-01-10 18:25:24,882 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.464,  Train_accy 96.67
2025-01-10 18:25:36,544 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.463,  Train_accy 96.57
2025-01-10 18:25:48,343 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.462,  Train_accy 96.57
2025-01-10 18:26:06,424 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.464,  Train_accy 96.20, Test_accy 71.76
2025-01-10 18:26:18,223 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.461,  Train_accy 96.46
2025-01-10 18:26:29,874 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.461,  Train_accy 96.61
2025-01-10 18:26:41,579 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.463,  Train_accy 96.59
2025-01-10 18:26:53,270 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.460,  Train_accy 96.71
2025-01-10 18:27:11,151 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.459,  Train_accy 96.75, Test_accy 71.33
2025-01-10 18:27:22,856 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.462,  Train_accy 96.55
2025-01-10 18:27:34,472 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.460,  Train_accy 96.79
2025-01-10 18:27:46,130 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.460,  Train_accy 96.75
2025-01-10 18:27:57,922 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.458,  Train_accy 96.38
2025-01-10 18:28:15,861 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.458,  Train_accy 96.57, Test_accy 71.51
2025-01-10 18:28:27,706 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.460,  Train_accy 96.61
2025-01-10 18:28:39,381 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.454,  Train_accy 96.99
2025-01-10 18:28:51,037 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.459,  Train_accy 96.46
2025-01-10 18:29:02,674 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.461,  Train_accy 96.16
2025-01-10 18:29:20,587 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.459,  Train_accy 96.55, Test_accy 71.41
2025-01-10 18:29:32,310 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.459,  Train_accy 96.61
2025-01-10 18:29:44,136 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.457,  Train_accy 96.81
2025-01-10 18:29:55,813 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.461,  Train_accy 96.34
2025-01-10 18:30:07,546 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.459,  Train_accy 96.32
2025-01-10 18:30:25,383 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.460,  Train_accy 96.28, Test_accy 71.57
2025-01-10 18:30:37,048 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.458,  Train_accy 96.36
2025-01-10 18:30:48,716 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.459,  Train_accy 96.69
2025-01-10 18:31:00,582 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.458,  Train_accy 96.79
2025-01-10 18:31:12,293 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.455,  Train_accy 96.89
2025-01-10 18:31:30,723 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.455,  Train_accy 96.65, Test_accy 71.32
2025-01-10 18:31:42,461 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.460,  Train_accy 96.36
2025-01-10 18:31:54,128 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.458,  Train_accy 97.09
2025-01-10 18:32:05,776 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.458,  Train_accy 96.71
2025-01-10 18:32:17,522 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.460,  Train_accy 96.46
2025-01-10 18:32:23,232 [der.py] => darknet eval: 
2025-01-10 18:32:23,233 [der.py] => CNN top1 curve: 71.41
2025-01-10 18:32:23,233 [der.py] => CNN top5 curve: 96.33
2025-01-10 18:32:23,234 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-10 18:33:07,290 [der.py] => Exemplar size: 1050
2025-01-10 18:33:07,291 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-10 18:33:07,291 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-10 18:33:07,291 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-10 18:33:07,291 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-10 18:33:07,291 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-10 18:33:07,291 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-10 18:33:07,292 [trainer.py] => All params: 63139730
2025-01-10 18:33:07,292 [trainer.py] => Trainable params: 21056506
2025-01-10 18:33:07,431 [der.py] => Learning on 35-45
2025-01-10 18:33:07,433 [der.py] => All params: 84190952
2025-01-10 18:33:07,433 [der.py] => Trainable params: 21066116
2025-01-10 19:19:27,798 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-10 19:19:27,829 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-10 19:19:27,839 [der.py] => per cls weights : [-0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395  5.19721383
  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383
  5.19721383  5.19721383  5.19721383]
2025-01-10 19:19:49,135 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.607,  Train_accy 27.92, Test_accy 28.06
2025-01-10 19:20:02,817 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.033,  Train_accy 44.70
2025-01-10 19:20:16,360 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.856,  Train_accy 49.37
2025-01-10 19:20:30,014 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.775,  Train_accy 52.78
2025-01-10 19:20:43,584 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.708,  Train_accy 55.20
2025-01-10 19:21:43,680 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.610,  Train_accy 57.92, Test_accy 32.85
2025-01-10 19:22:00,133 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.558,  Train_accy 58.76
2025-01-10 19:22:14,108 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.511,  Train_accy 61.31
2025-01-10 19:22:28,204 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.471,  Train_accy 62.91
2025-01-10 19:22:42,529 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.438,  Train_accy 63.30
2025-01-10 19:24:14,557 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.420,  Train_accy 64.91, Test_accy 38.54
2025-01-10 19:24:34,715 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.405,  Train_accy 64.29
2025-01-10 19:24:48,296 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.378,  Train_accy 65.62
2025-01-10 19:25:02,145 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.403,  Train_accy 66.59
2025-01-10 19:25:17,657 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.396,  Train_accy 67.52
2025-01-10 19:27:10,254 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.393,  Train_accy 65.54, Test_accy 41.41
2025-01-10 19:27:23,889 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.336,  Train_accy 67.50
2025-01-10 19:27:37,446 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.306,  Train_accy 69.31
2025-01-10 19:27:51,126 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.295,  Train_accy 68.38
2025-01-10 19:28:04,748 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.323,  Train_accy 67.18
2025-01-10 19:28:25,754 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.281,  Train_accy 70.34, Test_accy 48.26
2025-01-10 19:28:39,356 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.266,  Train_accy 70.17
2025-01-10 19:28:53,032 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.274,  Train_accy 69.83
2025-01-10 19:29:06,915 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.243,  Train_accy 71.52
2025-01-10 19:29:20,747 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.239,  Train_accy 70.97
2025-01-10 19:30:39,527 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.224,  Train_accy 71.18, Test_accy 51.59
2025-01-10 19:30:53,166 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.244,  Train_accy 72.91
2025-01-10 19:31:06,846 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.192,  Train_accy 73.18
2025-01-10 19:31:20,664 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.197,  Train_accy 72.36
2025-01-10 19:31:34,567 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.194,  Train_accy 72.84
2025-01-10 19:31:55,576 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.177,  Train_accy 73.70, Test_accy 54.56
2025-01-10 19:32:09,177 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.176,  Train_accy 74.11
2025-01-10 19:32:22,956 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.146,  Train_accy 74.38
2025-01-10 19:32:36,763 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.137,  Train_accy 74.11
2025-01-10 19:32:50,528 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.163,  Train_accy 74.27
2025-01-10 19:33:42,753 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.134,  Train_accy 74.88, Test_accy 54.99
2025-01-10 19:33:56,723 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.149,  Train_accy 73.45
2025-01-10 19:34:10,300 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.141,  Train_accy 74.78
2025-01-10 19:34:24,114 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.115,  Train_accy 74.91
2025-01-10 19:34:38,028 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.116,  Train_accy 74.70
2025-01-10 19:34:59,520 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.139,  Train_accy 75.60, Test_accy 54.36
2025-01-10 19:35:13,209 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.112,  Train_accy 73.71
2025-01-10 19:35:26,838 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.110,  Train_accy 75.35
2025-01-10 19:35:40,755 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.124,  Train_accy 75.60
2025-01-10 19:35:54,596 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.092,  Train_accy 75.24
2025-01-10 19:36:31,915 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.069,  Train_accy 76.04, Test_accy 54.15
2025-01-10 19:36:47,075 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.112,  Train_accy 75.09
2025-01-10 19:37:00,642 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.101,  Train_accy 75.81
2025-01-10 19:37:14,244 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.101,  Train_accy 75.68
2025-01-10 19:37:27,901 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.104,  Train_accy 75.10
2025-01-10 19:38:09,144 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.080,  Train_accy 75.92, Test_accy 58.16
2025-01-10 19:38:22,742 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.073,  Train_accy 76.27
2025-01-10 19:38:36,347 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.064,  Train_accy 76.17
2025-01-10 19:38:50,092 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.070,  Train_accy 76.17
2025-01-10 19:39:03,871 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.071,  Train_accy 76.21
2025-01-10 19:39:24,830 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.093,  Train_accy 76.15, Test_accy 53.70
2025-01-10 19:39:38,403 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.066,  Train_accy 76.40
2025-01-10 19:39:52,163 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.066,  Train_accy 76.13
2025-01-10 19:40:05,859 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.049,  Train_accy 76.40
2025-01-10 19:40:19,799 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.072,  Train_accy 76.29
2025-01-10 19:41:09,074 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.049,  Train_accy 76.36, Test_accy 54.84
2025-01-10 19:41:22,699 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.059,  Train_accy 76.48
2025-01-10 19:41:36,238 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.058,  Train_accy 76.53
2025-01-10 19:41:49,806 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.048,  Train_accy 76.57
2025-01-10 19:42:03,489 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.025,  Train_accy 76.46
2025-01-10 19:42:24,981 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.058,  Train_accy 76.00, Test_accy 59.36
2025-01-10 19:42:38,769 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.040,  Train_accy 76.72
2025-01-10 19:42:52,567 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.031,  Train_accy 76.36
2025-01-10 19:43:06,492 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.025,  Train_accy 76.61
2025-01-10 19:43:20,306 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.010,  Train_accy 76.50
2025-01-10 19:43:41,810 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.036,  Train_accy 76.61, Test_accy 60.73
2025-01-10 19:43:55,857 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.057,  Train_accy 77.26
2025-01-10 19:44:09,900 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.037,  Train_accy 76.51
2025-01-10 19:44:23,939 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.031,  Train_accy 76.40
2025-01-10 19:44:37,740 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.031,  Train_accy 76.86
2025-01-10 19:44:59,890 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.050,  Train_accy 75.89, Test_accy 59.10
2025-01-10 19:45:13,292 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.033,  Train_accy 76.95
2025-01-10 19:45:26,638 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.039,  Train_accy 76.55
2025-01-10 19:45:40,206 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.021,  Train_accy 76.32
2025-01-10 19:45:54,166 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.029,  Train_accy 76.55
2025-01-10 19:46:16,349 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.011,  Train_accy 76.65, Test_accy 59.58
2025-01-10 19:46:29,867 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.039,  Train_accy 76.48
2025-01-10 19:46:43,244 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.030,  Train_accy 76.91
2025-01-10 19:46:56,694 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.034,  Train_accy 76.59
2025-01-10 19:47:10,120 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.006,  Train_accy 76.59
2025-01-10 19:47:31,746 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.985,  Train_accy 76.93, Test_accy 58.09
2025-01-10 19:47:45,073 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.028,  Train_accy 76.84
2025-01-10 19:47:58,594 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.030,  Train_accy 76.82
2025-01-10 19:48:12,035 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.031,  Train_accy 76.99
2025-01-10 19:48:25,343 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.027,  Train_accy 76.76
2025-01-10 19:48:45,514 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.017,  Train_accy 77.45, Test_accy 60.28
2025-01-10 19:48:58,770 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.998,  Train_accy 77.30
2025-01-10 19:49:12,483 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.015,  Train_accy 76.78
2025-01-10 19:49:26,922 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.020,  Train_accy 77.35
2025-01-10 19:49:40,743 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.991,  Train_accy 76.99
2025-01-10 19:50:02,447 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.980,  Train_accy 77.09, Test_accy 60.06
2025-01-10 19:50:16,323 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.044,  Train_accy 76.91
2025-01-10 19:50:30,077 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.040,  Train_accy 76.93
2025-01-10 19:50:43,878 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.017,  Train_accy 76.91
2025-01-10 19:50:57,733 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.018,  Train_accy 76.95
2025-01-10 19:51:19,332 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.021,  Train_accy 77.18, Test_accy 60.96
2025-01-10 19:51:33,194 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.009,  Train_accy 77.28
2025-01-10 19:51:47,121 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.999,  Train_accy 77.43
2025-01-10 19:52:00,768 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.024,  Train_accy 77.07
2025-01-10 19:52:14,801 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.999,  Train_accy 76.72
2025-01-10 19:52:36,380 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.006,  Train_accy 77.07, Test_accy 60.54
2025-01-10 19:52:50,174 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.000,  Train_accy 76.90
2025-01-10 19:53:04,008 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.015,  Train_accy 76.95
2025-01-10 19:53:17,956 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.017,  Train_accy 77.22
2025-01-10 19:53:31,569 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.038,  Train_accy 77.52
2025-01-10 19:53:51,980 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.012,  Train_accy 76.74, Test_accy 57.72
2025-01-10 19:54:05,758 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.999,  Train_accy 76.59
2025-01-10 19:54:19,371 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.018,  Train_accy 77.39
2025-01-10 19:54:33,127 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.013,  Train_accy 77.43
2025-01-10 19:54:47,027 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.014,  Train_accy 77.10
2025-01-10 19:55:08,859 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.982,  Train_accy 77.22, Test_accy 60.14
2025-01-10 19:55:22,032 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.020,  Train_accy 77.09
2025-01-10 19:55:35,390 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.005,  Train_accy 77.35
2025-01-10 19:55:48,931 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.986,  Train_accy 77.35
2025-01-10 19:56:03,005 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.997,  Train_accy 77.75
2025-01-10 19:56:24,935 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.998,  Train_accy 77.30, Test_accy 60.31
2025-01-10 19:56:38,964 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.004,  Train_accy 77.28
2025-01-10 19:56:53,012 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.970,  Train_accy 76.70
2025-01-10 19:57:06,887 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.998,  Train_accy 76.93
2025-01-10 19:57:20,472 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.009,  Train_accy 77.18
2025-01-10 19:57:41,465 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.003,  Train_accy 77.30, Test_accy 59.90
2025-01-10 19:57:55,144 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.005,  Train_accy 77.09
2025-01-10 19:58:08,905 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.007,  Train_accy 76.97
2025-01-10 19:58:22,638 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.016,  Train_accy 77.43
2025-01-10 19:58:36,370 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.996,  Train_accy 77.14
2025-01-10 19:58:43,319 [der.py] => darknet eval: 
2025-01-10 19:58:43,320 [der.py] => CNN top1 curve: 62.12
2025-01-10 19:58:43,320 [der.py] => CNN top5 curve: 91.57
2025-01-10 19:58:43,322 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-10 19:59:43,225 [der.py] => Exemplar size: 1350
2025-01-10 19:59:43,226 [trainer.py] => CNN: {'total': 76.41, '0': 63.89, '1': 72.22, '2': 91.67, '3': 66.67, '4': 82.78, '5': 40.56, '6': 75.56, '7': 58.89, '8': 42.22, '9': 56.11, '10': 92.22, '11': 95.0, '12': 83.33, '13': 79.44, '14': 56.11, '15': 96.67, '16': 93.89, '17': 95.0, '18': 92.78, '19': 93.89, '20': 96.11, '21': 91.67, '22': 73.33, '23': 71.11, '24': 62.22, '25': 88.33, '26': 93.33, '27': 93.33, '28': 69.44, '29': 79.44, '30': 94.44, '31': 83.33, '32': 98.89, '33': 83.33, '34': 81.67, '35': 90.0, '36': 87.78, '37': 22.78, '38': 4.44, '39': 40.56, '40': 73.89, '41': 96.11, '42': 97.22, '43': 96.11, 'old': 79.68, 'new': 64.94}
2025-01-10 19:59:43,226 [trainer.py] => NME: {'total': 78.53, '0': 66.11, '1': 64.44, '2': 85.56, '3': 52.78, '4': 85.0, '5': 45.0, '6': 65.56, '7': 55.0, '8': 47.78, '9': 59.44, '10': 91.67, '11': 83.33, '12': 82.22, '13': 76.67, '14': 56.67, '15': 89.44, '16': 90.0, '17': 93.89, '18': 89.44, '19': 93.33, '20': 92.22, '21': 88.33, '22': 86.11, '23': 62.78, '24': 75.56, '25': 78.89, '26': 91.67, '27': 85.0, '28': 63.33, '29': 76.67, '30': 76.11, '31': 83.33, '32': 91.67, '33': 62.78, '34': 81.67, '35': 97.22, '36': 89.44, '37': 66.67, '38': 89.44, '39': 85.0, '40': 84.44, '41': 91.11, '42': 97.22, '43': 94.44, 'old': 76.27, 'new': 86.44}
2025-01-10 19:59:43,226 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41]
2025-01-10 19:59:43,226 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35]
2025-01-10 19:59:43,226 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53]
2025-01-10 19:59:43,226 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06]

2025-01-10 19:59:43,227 [trainer.py] => All params: 84190952
2025-01-10 19:59:43,228 [trainer.py] => Trainable params: 21066116
2025-01-10 19:59:43,402 [der.py] => Learning on 45-55
2025-01-10 19:59:43,406 [der.py] => All params: 105244734
2025-01-10 19:59:43,407 [der.py] => Trainable params: 21078286
2025-01-10 21:22:14,363 [der.py] => Task 4, Epoch 150/150 => Loss 0.016, Loss_clf 0.007, Loss_aux 0.008, Train_accy 100.00
2025-01-10 21:22:14,731 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-10 21:22:14,741 [der.py] => per cls weights : [-0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859  6.64636865  6.64636865  6.64636865
  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865
  6.64636865]
2025-01-10 21:22:39,824 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.471,  Train_accy 11.42, Test_accy 26.07
2025-01-10 21:22:55,733 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 3.286,  Train_accy 17.08
2025-01-10 21:23:11,560 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 3.185,  Train_accy 23.05
2025-01-10 21:23:27,440 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 3.102,  Train_accy 28.58
2025-01-10 21:23:43,307 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 3.029,  Train_accy 34.92
2025-01-10 21:24:08,454 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.981,  Train_accy 39.17, Test_accy 38.40
2025-01-10 21:24:24,464 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.923,  Train_accy 44.13
2025-01-10 21:24:40,361 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.877,  Train_accy 48.70
2025-01-10 21:24:56,243 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.860,  Train_accy 51.08
2025-01-10 21:25:12,127 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.822,  Train_accy 54.27
2025-01-10 21:25:37,612 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.797,  Train_accy 55.48, Test_accy 43.93
2025-01-10 21:25:53,620 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.772,  Train_accy 58.40
2025-01-10 21:26:09,495 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.757,  Train_accy 60.20
2025-01-10 21:26:25,432 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.728,  Train_accy 62.09
2025-01-10 21:26:41,425 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.715,  Train_accy 63.62
2025-01-10 21:27:06,403 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.709,  Train_accy 63.41, Test_accy 46.99
2025-01-10 21:27:22,534 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.692,  Train_accy 64.85
2025-01-10 21:27:38,542 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.678,  Train_accy 65.57
2025-01-10 21:27:54,541 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.665,  Train_accy 67.68
2025-01-10 21:28:10,481 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.651,  Train_accy 68.76
2025-01-10 21:28:35,257 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.647,  Train_accy 69.55, Test_accy 53.18
2025-01-10 21:28:51,241 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.637,  Train_accy 70.18
2025-01-10 21:29:07,229 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.630,  Train_accy 69.46
2025-01-10 21:29:23,215 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.619,  Train_accy 72.05
2025-01-10 21:29:39,246 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.609,  Train_accy 71.50
2025-01-10 21:30:04,251 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.599,  Train_accy 72.94, Test_accy 52.15
2025-01-10 21:30:20,130 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.593,  Train_accy 73.48
2025-01-10 21:30:36,013 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.579,  Train_accy 73.75
2025-01-10 21:30:51,947 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.584,  Train_accy 72.86
2025-01-10 21:31:07,834 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.575,  Train_accy 73.77
2025-01-10 21:31:33,055 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.578,  Train_accy 73.08, Test_accy 55.93
2025-01-10 21:31:48,994 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.566,  Train_accy 74.25
2025-01-10 21:32:04,877 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.560,  Train_accy 75.55
2025-01-10 21:32:20,834 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.550,  Train_accy 75.42
2025-01-10 21:32:36,953 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.540,  Train_accy 76.22
2025-01-10 21:33:02,371 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.544,  Train_accy 76.76, Test_accy 56.27
2025-01-10 21:33:18,518 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.545,  Train_accy 76.38
2025-01-10 21:33:34,542 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.545,  Train_accy 76.85
2025-01-10 21:33:50,537 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.539,  Train_accy 76.65
2025-01-10 21:34:06,483 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.532,  Train_accy 76.83
2025-01-10 21:34:31,717 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.536,  Train_accy 76.70, Test_accy 58.33
2025-01-10 21:34:47,639 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.522,  Train_accy 77.60
2025-01-10 21:35:03,651 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.516,  Train_accy 78.47
2025-01-10 21:35:19,626 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.515,  Train_accy 78.18
2025-01-10 21:35:35,584 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.520,  Train_accy 77.60
2025-01-10 21:36:00,792 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.514,  Train_accy 78.29, Test_accy 58.66
2025-01-10 21:36:17,084 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.517,  Train_accy 78.07
2025-01-10 21:36:33,485 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.507,  Train_accy 79.51
2025-01-10 21:36:49,360 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.504,  Train_accy 78.77
2025-01-10 21:37:05,399 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.499,  Train_accy 79.15
2025-01-10 21:37:30,662 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.502,  Train_accy 78.56, Test_accy 59.56
2025-01-10 21:37:46,725 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.500,  Train_accy 78.99
2025-01-10 21:38:02,619 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.495,  Train_accy 79.59
2025-01-10 21:38:18,662 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.488,  Train_accy 80.45
2025-01-10 21:38:34,695 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.487,  Train_accy 80.31
2025-01-10 21:38:59,601 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.490,  Train_accy 80.11, Test_accy 59.99
2025-01-10 21:39:15,502 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.482,  Train_accy 80.16
2025-01-10 21:39:31,411 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.483,  Train_accy 80.02
2025-01-10 21:39:47,530 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.483,  Train_accy 79.64
2025-01-10 21:40:03,429 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.477,  Train_accy 80.97
2025-01-10 21:40:28,365 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.486,  Train_accy 80.31, Test_accy 61.53
2025-01-10 21:40:44,293 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.474,  Train_accy 80.74
2025-01-10 21:41:00,241 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.482,  Train_accy 80.20
2025-01-10 21:41:16,200 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.476,  Train_accy 80.20
2025-01-10 21:41:32,121 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.472,  Train_accy 80.70
2025-01-10 21:41:57,145 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.471,  Train_accy 80.94, Test_accy 61.66
2025-01-10 21:42:13,019 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.469,  Train_accy 81.15
2025-01-10 21:42:28,926 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.468,  Train_accy 81.03
2025-01-10 21:42:44,901 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.468,  Train_accy 80.68
2025-01-10 21:43:00,981 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.467,  Train_accy 80.86
2025-01-10 21:43:25,840 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.461,  Train_accy 82.09, Test_accy 61.56
2025-01-10 21:43:41,827 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.467,  Train_accy 80.86
2025-01-10 21:43:57,810 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.463,  Train_accy 81.41
2025-01-10 21:44:13,711 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.458,  Train_accy 81.35
2025-01-10 21:44:29,621 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.461,  Train_accy 81.51
2025-01-10 21:46:16,610 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.454,  Train_accy 81.68, Test_accy 62.39
2025-01-10 21:46:34,178 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.457,  Train_accy 82.29
2025-01-10 21:46:50,511 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.459,  Train_accy 81.68
2025-01-10 21:47:06,856 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.456,  Train_accy 82.41
2025-01-10 21:47:22,901 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.454,  Train_accy 82.58
2025-01-10 21:48:01,747 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.452,  Train_accy 82.14, Test_accy 62.30
2025-01-10 21:48:18,339 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.447,  Train_accy 82.59
2025-01-10 21:48:34,502 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.451,  Train_accy 82.09
2025-01-10 21:48:50,574 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.455,  Train_accy 82.14
2025-01-10 21:49:06,519 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.454,  Train_accy 81.84
2025-01-10 21:49:49,084 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.450,  Train_accy 82.97, Test_accy 62.53
2025-01-10 21:50:05,508 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.446,  Train_accy 82.18
2025-01-10 21:50:21,311 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.446,  Train_accy 82.72
2025-01-10 21:50:37,387 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.445,  Train_accy 82.99
2025-01-10 21:50:53,471 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.451,  Train_accy 82.02
2025-01-10 21:51:23,628 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.446,  Train_accy 82.92, Test_accy 62.78
2025-01-10 21:51:39,621 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.446,  Train_accy 82.88
2025-01-10 21:51:55,519 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.445,  Train_accy 82.70
2025-01-10 21:52:11,602 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.444,  Train_accy 82.36
2025-01-10 21:52:27,398 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.441,  Train_accy 83.28
2025-01-10 21:53:13,509 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.440,  Train_accy 82.58, Test_accy 63.42
2025-01-10 21:53:29,349 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.443,  Train_accy 82.40
2025-01-10 21:53:45,188 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.447,  Train_accy 83.23
2025-01-10 21:54:00,964 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.439,  Train_accy 82.92
2025-01-10 21:54:16,805 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.440,  Train_accy 83.12
2025-01-10 21:55:12,475 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.437,  Train_accy 83.51, Test_accy 63.59
2025-01-10 21:55:28,169 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.440,  Train_accy 82.67
2025-01-10 21:55:44,073 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.440,  Train_accy 83.06
2025-01-10 21:55:59,932 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.437,  Train_accy 82.81
2025-01-10 21:56:15,836 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.438,  Train_accy 82.97
2025-01-10 21:56:49,042 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.439,  Train_accy 82.47, Test_accy 63.76
2025-01-10 21:57:04,869 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.439,  Train_accy 83.35
2025-01-10 21:57:20,661 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.442,  Train_accy 82.97
2025-01-10 21:57:36,499 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.437,  Train_accy 82.74
2025-01-10 21:57:52,341 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.434,  Train_accy 83.08
2025-01-10 21:58:18,485 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.438,  Train_accy 82.86, Test_accy 63.74
2025-01-10 21:58:34,463 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.439,  Train_accy 83.46
2025-01-10 21:58:50,255 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.439,  Train_accy 82.67
2025-01-10 21:59:06,075 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.436,  Train_accy 83.42
2025-01-10 21:59:21,923 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.437,  Train_accy 82.65
2025-01-10 21:59:46,841 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.439,  Train_accy 83.01, Test_accy 63.23
2025-01-10 22:00:02,695 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.436,  Train_accy 83.28
2025-01-10 22:00:18,576 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.436,  Train_accy 83.06
2025-01-10 22:00:34,455 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.438,  Train_accy 83.96
2025-01-10 22:00:50,245 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.433,  Train_accy 83.21
2025-01-10 22:01:15,189 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.438,  Train_accy 82.22, Test_accy 63.86
2025-01-10 22:01:31,115 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.436,  Train_accy 82.59
2025-01-10 22:01:47,086 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.434,  Train_accy 82.58
2025-01-10 22:02:02,949 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.438,  Train_accy 83.14
2025-01-10 22:02:18,879 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.434,  Train_accy 83.64
2025-01-10 22:02:44,301 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.431,  Train_accy 83.69, Test_accy 64.11
2025-01-10 22:03:00,165 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.437,  Train_accy 84.05
2025-01-10 22:03:16,197 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.436,  Train_accy 83.71
2025-01-10 22:03:32,067 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.431,  Train_accy 83.82
2025-01-10 22:03:47,895 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.438,  Train_accy 83.21
2025-01-10 22:03:56,435 [der.py] => darknet eval: 
2025-01-10 22:03:56,436 [der.py] => CNN top1 curve: 63.74
2025-01-10 22:03:56,436 [der.py] => CNN top5 curve: 92.02
2025-01-10 22:03:56,438 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-10 22:05:14,454 [der.py] => Exemplar size: 1650
2025-01-10 22:05:14,455 [trainer.py] => CNN: {'total': 77.15, '0': 60.56, '1': 74.44, '2': 92.22, '3': 49.44, '4': 87.22, '5': 47.78, '6': 71.67, '7': 57.22, '8': 52.78, '9': 60.0, '10': 91.67, '11': 78.89, '12': 85.56, '13': 83.33, '14': 60.0, '15': 93.89, '16': 95.56, '17': 96.11, '18': 91.67, '19': 95.56, '20': 96.67, '21': 90.0, '22': 83.33, '23': 63.33, '24': 66.11, '25': 82.78, '26': 90.0, '27': 92.22, '28': 75.56, '29': 80.56, '30': 91.11, '31': 83.33, '32': 95.56, '33': 68.33, '34': 77.22, '35': 96.67, '36': 96.67, '37': 81.67, '38': 97.78, '39': 95.0, '40': 90.0, '41': 97.22, '42': 99.44, '43': 97.22, '44': 87.22, '45': 52.78, '46': 70.0, '47': 46.67, '48': 57.22, '49': 51.67, '50': 51.67, '51': 60.56, '52': 55.0, '53': 55.56, 'old': 82.23, 'new': 54.28}
2025-01-10 22:05:14,455 [trainer.py] => NME: {'total': 73.45, '0': 70.0, '1': 59.44, '2': 78.89, '3': 33.33, '4': 83.33, '5': 43.33, '6': 59.44, '7': 51.67, '8': 45.56, '9': 51.11, '10': 90.0, '11': 81.11, '12': 77.22, '13': 65.56, '14': 55.0, '15': 88.89, '16': 88.89, '17': 92.78, '18': 90.0, '19': 91.11, '20': 88.89, '21': 87.22, '22': 83.33, '23': 61.67, '24': 72.78, '25': 76.11, '26': 88.33, '27': 82.78, '28': 60.56, '29': 73.33, '30': 76.67, '31': 79.44, '32': 90.56, '33': 60.0, '34': 81.67, '35': 96.67, '36': 87.78, '37': 63.33, '38': 92.78, '39': 85.56, '40': 75.56, '41': 90.56, '42': 97.22, '43': 95.56, '44': 53.89, '45': 78.33, '46': 80.56, '47': 63.89, '48': 61.67, '49': 61.67, '50': 52.22, '51': 65.0, '52': 60.0, '53': 57.78, 'old': 75.53, 'new': 64.11}
2025-01-10 22:05:14,455 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41, 77.15]
2025-01-10 22:05:14,455 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35, 96.05]
2025-01-10 22:05:14,455 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53, 73.45]
2025-01-10 22:05:14,455 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06, 94.92]

2025-01-10 23:04:30,051 [trainer.py] => 实验名称:BKD与KD*lambda对比实验
2025-01-10 23:04:30,096 [trainer.py] => config: ./exps/der.json
2025-01-10 23:04:30,096 [trainer.py] => experiment_name: 实验名称:BKD与KD*lambda对比实验
2025-01-10 23:04:30,096 [trainer.py] => prefix: reproduce
2025-01-10 23:04:30,096 [trainer.py] => dataset: xrfdataset
2025-01-10 23:04:30,096 [trainer.py] => memory_size: 1650
2025-01-10 23:04:30,096 [trainer.py] => memory_per_class: 30
2025-01-10 23:04:30,096 [trainer.py] => fixed_memory: True
2025-01-10 23:04:30,096 [trainer.py] => shuffle: True
2025-01-10 23:04:30,096 [trainer.py] => init_cls: 15
2025-01-10 23:04:30,096 [trainer.py] => increment: 10
2025-01-10 23:04:30,096 [trainer.py] => model_name: der
2025-01-10 23:04:30,096 [trainer.py] => compression_epochs: 130
2025-01-10 23:04:30,096 [trainer.py] => compression_lr: 0.1
2025-01-10 23:04:30,097 [trainer.py] => T: 2
2025-01-10 23:04:30,097 [trainer.py] => convnet_type: unet
2025-01-10 23:04:30,097 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-10 23:04:30,097 [trainer.py] => seed: 1993
2025-01-10 23:04:30,182 [data.py] => 加载完毕XRF原始数据集
2025-01-10 23:04:30,206 [data.py] => 加载完毕XRF原始数据集
2025-01-10 23:04:30,207 [trainer.py] => All params: 0
2025-01-10 23:04:30,208 [trainer.py] => Trainable params: 0
2025-01-10 23:04:30,410 [der.py] => Learning on 0-15
2025-01-10 23:04:30,411 [der.py] => All params: 21045611
2025-01-10 23:04:30,411 [der.py] => Trainable params: 21045611
2025-01-10 23:31:44,502 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-10 23:31:44,532 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-10 23:32:09,981 [der.py] => Exemplar size: 450
2025-01-10 23:32:09,981 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-10 23:32:09,982 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-10 23:32:09,982 [trainer.py] => CNN top1 curve: [89.44]
2025-01-10 23:32:09,982 [trainer.py] => CNN top5 curve: [98.93]
2025-01-10 23:32:09,982 [trainer.py] => NME top1 curve: [88.22]
2025-01-10 23:32:09,982 [trainer.py] => NME top5 curve: [98.81]

2025-01-10 23:32:09,982 [trainer.py] => All params: 21045611
2025-01-10 23:32:09,983 [trainer.py] => Trainable params: 21045611
2025-01-10 23:32:10,213 [der.py] => Learning on 15-25
2025-01-10 23:32:10,215 [der.py] => All params: 42091068
2025-01-10 23:32:10,217 [der.py] => Trainable params: 21049456
2025-01-10 23:59:05,475 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-10 23:59:06,150 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-10 23:59:06,161 [der.py] => per cls weights : [-0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677   2.65250155  2.65250155  2.65250155
  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155
  2.65250155]
2025-01-10 23:59:20,025 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 1.272,  Train_accy 43.23, Test_accy 44.69
2025-01-10 23:59:29,489 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 0.942,  Train_accy 68.75
2025-01-10 23:59:38,989 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 0.806,  Train_accy 78.80
2025-01-10 23:59:48,503 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 0.720,  Train_accy 85.81
2025-01-10 23:59:57,980 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 0.675,  Train_accy 88.60
2025-01-11 00:00:11,809 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.645,  Train_accy 91.55, Test_accy 71.47
2025-01-11 00:00:21,378 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 0.621,  Train_accy 93.25
2025-01-11 00:00:30,869 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.600,  Train_accy 94.88
2025-01-11 00:00:40,665 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.593,  Train_accy 95.12
2025-01-11 00:00:50,174 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.591,  Train_accy 95.33
2025-01-11 00:01:04,204 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.574,  Train_accy 96.90, Test_accy 76.42
2025-01-11 00:01:13,779 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.568,  Train_accy 96.82
2025-01-11 00:01:23,288 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.561,  Train_accy 97.44
2025-01-11 00:01:32,731 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.558,  Train_accy 97.35
2025-01-11 00:01:42,302 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.558,  Train_accy 97.38
2025-01-11 00:01:56,206 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.561,  Train_accy 97.29, Test_accy 78.27
2025-01-11 00:02:05,814 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.553,  Train_accy 97.81
2025-01-11 00:02:15,444 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.551,  Train_accy 97.98
2025-01-11 00:02:24,854 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.548,  Train_accy 98.28
2025-01-11 00:02:34,471 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.549,  Train_accy 98.37
2025-01-11 00:02:48,422 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.542,  Train_accy 98.67, Test_accy 78.96
2025-01-11 00:02:57,925 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.540,  Train_accy 98.60
2025-01-11 00:03:07,356 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.537,  Train_accy 98.88
2025-01-11 00:03:16,866 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.538,  Train_accy 98.84
2025-01-11 00:03:26,361 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.536,  Train_accy 99.10
2025-01-11 00:03:40,192 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.534,  Train_accy 98.65, Test_accy 79.22
2025-01-11 00:03:49,701 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.533,  Train_accy 99.14
2025-01-11 00:03:59,155 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.531,  Train_accy 99.03
2025-01-11 00:04:08,672 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.530,  Train_accy 99.03
2025-01-11 00:04:18,231 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.532,  Train_accy 98.99
2025-01-11 00:04:32,172 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.530,  Train_accy 98.95, Test_accy 79.78
2025-01-11 00:04:41,586 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.533,  Train_accy 98.77
2025-01-11 00:04:51,032 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.527,  Train_accy 99.10
2025-01-11 00:05:00,575 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.526,  Train_accy 98.86
2025-01-11 00:05:10,011 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.525,  Train_accy 98.99
2025-01-11 00:05:23,877 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.525,  Train_accy 99.10, Test_accy 80.07
2025-01-11 00:05:33,968 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.524,  Train_accy 99.03
2025-01-11 00:05:44,179 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.526,  Train_accy 99.01
2025-01-11 00:05:54,327 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.527,  Train_accy 99.08
2025-01-11 00:06:04,337 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.523,  Train_accy 99.05
2025-01-11 00:06:19,120 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.523,  Train_accy 99.18, Test_accy 80.04
2025-01-11 00:06:29,149 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.524,  Train_accy 99.20
2025-01-11 00:06:39,180 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.524,  Train_accy 99.14
2025-01-11 00:06:49,215 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.519,  Train_accy 99.40
2025-01-11 00:06:59,127 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.519,  Train_accy 99.33
2025-01-11 00:07:13,897 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.523,  Train_accy 99.18, Test_accy 80.47
2025-01-11 00:07:23,772 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.522,  Train_accy 98.99
2025-01-11 00:07:33,748 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.519,  Train_accy 99.25
2025-01-11 00:07:43,623 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.522,  Train_accy 99.14
2025-01-11 00:07:53,485 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.521,  Train_accy 99.14
2025-01-11 00:08:08,221 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.521,  Train_accy 99.08, Test_accy 80.20
2025-01-11 00:08:18,233 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.520,  Train_accy 99.12
2025-01-11 00:08:28,390 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.519,  Train_accy 99.38
2025-01-11 00:08:38,074 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.521,  Train_accy 99.25
2025-01-11 00:08:47,690 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.520,  Train_accy 99.27
2025-01-11 00:09:02,609 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.517,  Train_accy 99.18, Test_accy 80.58
2025-01-11 00:09:12,037 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.516,  Train_accy 99.53
2025-01-11 00:09:21,507 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.516,  Train_accy 99.42
2025-01-11 00:09:30,817 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.516,  Train_accy 99.31
2025-01-11 00:09:40,253 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.514,  Train_accy 99.40
2025-01-11 00:10:00,759 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.512,  Train_accy 99.40, Test_accy 80.38
2025-01-11 00:10:10,437 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.516,  Train_accy 99.16
2025-01-11 00:10:20,108 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.515,  Train_accy 99.31
2025-01-11 00:10:29,515 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.515,  Train_accy 99.31
2025-01-11 00:10:39,127 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.513,  Train_accy 99.35
2025-01-11 00:10:52,878 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.512,  Train_accy 99.38, Test_accy 80.29
2025-01-11 00:11:02,320 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.514,  Train_accy 99.46
2025-01-11 00:11:11,796 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.514,  Train_accy 99.25
2025-01-11 00:11:21,225 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.515,  Train_accy 99.40
2025-01-11 00:11:30,717 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.515,  Train_accy 99.44
2025-01-11 00:11:44,331 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.514,  Train_accy 99.31, Test_accy 80.84
2025-01-11 00:11:53,725 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.513,  Train_accy 99.38
2025-01-11 00:12:03,077 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.512,  Train_accy 99.44
2025-01-11 00:12:12,360 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.514,  Train_accy 99.33
2025-01-11 00:12:21,681 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.512,  Train_accy 99.42
2025-01-11 00:12:35,389 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.513,  Train_accy 99.33, Test_accy 80.78
2025-01-11 00:12:44,841 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.514,  Train_accy 99.42
2025-01-11 00:12:54,357 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.511,  Train_accy 99.27
2025-01-11 00:13:03,837 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.511,  Train_accy 99.46
2025-01-11 00:13:13,336 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.513,  Train_accy 99.27
2025-01-11 00:13:27,379 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.511,  Train_accy 99.57, Test_accy 80.80
2025-01-11 00:13:36,982 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.513,  Train_accy 99.29
2025-01-11 00:13:46,292 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.512,  Train_accy 99.38
2025-01-11 00:13:55,685 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.510,  Train_accy 99.25
2025-01-11 00:14:05,214 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.510,  Train_accy 99.53
2025-01-11 00:14:18,963 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.508,  Train_accy 99.42, Test_accy 81.38
2025-01-11 00:14:28,420 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.511,  Train_accy 99.53
2025-01-11 00:14:37,700 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.512,  Train_accy 99.35
2025-01-11 00:14:47,028 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.511,  Train_accy 99.44
2025-01-11 00:14:56,499 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.510,  Train_accy 99.38
2025-01-11 00:15:10,067 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.510,  Train_accy 99.33, Test_accy 81.16
2025-01-11 00:15:19,364 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.510,  Train_accy 99.33
2025-01-11 00:15:28,631 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.509,  Train_accy 99.40
2025-01-11 00:15:38,037 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.509,  Train_accy 99.44
2025-01-11 00:15:47,479 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.511,  Train_accy 99.35
2025-01-11 00:16:01,245 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.508,  Train_accy 99.31, Test_accy 81.27
2025-01-11 00:16:10,787 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.510,  Train_accy 99.55
2025-01-11 00:16:20,266 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.509,  Train_accy 99.40
2025-01-11 00:16:29,782 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.508,  Train_accy 99.42
2025-01-11 00:16:39,222 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.512,  Train_accy 99.46
2025-01-11 00:16:53,071 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.509,  Train_accy 99.53, Test_accy 81.27
2025-01-11 00:17:02,636 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.510,  Train_accy 99.44
2025-01-11 00:17:11,970 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.507,  Train_accy 99.48
2025-01-11 00:17:21,260 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.508,  Train_accy 99.51
2025-01-11 00:17:30,840 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.509,  Train_accy 99.44
2025-01-11 00:17:44,809 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.507,  Train_accy 99.55, Test_accy 81.24
2025-01-11 00:17:54,078 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.507,  Train_accy 99.53
2025-01-11 00:18:03,693 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.510,  Train_accy 99.42
2025-01-11 00:18:15,089 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.507,  Train_accy 99.33
2025-01-11 00:18:24,346 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.509,  Train_accy 99.42
2025-01-11 00:18:38,921 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.509,  Train_accy 99.27, Test_accy 80.89
2025-01-11 00:18:48,275 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.508,  Train_accy 99.53
2025-01-11 00:18:57,633 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.508,  Train_accy 99.48
2025-01-11 00:19:07,110 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.508,  Train_accy 99.53
2025-01-11 00:19:16,456 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.508,  Train_accy 99.40
2025-01-11 00:19:30,327 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.508,  Train_accy 99.40, Test_accy 81.47
2025-01-11 00:19:39,789 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.507,  Train_accy 99.48
2025-01-11 00:19:49,332 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.507,  Train_accy 99.51
2025-01-11 00:19:58,663 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.509,  Train_accy 99.55
2025-01-11 00:20:08,213 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.509,  Train_accy 99.44
2025-01-11 00:20:41,477 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.509,  Train_accy 99.51, Test_accy 81.78
2025-01-11 00:20:50,829 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.509,  Train_accy 99.38
2025-01-11 00:21:00,216 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.508,  Train_accy 99.46
2025-01-11 00:21:09,632 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.507,  Train_accy 99.48
2025-01-11 00:21:18,975 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.507,  Train_accy 99.55
2025-01-11 00:21:32,658 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.506,  Train_accy 99.48, Test_accy 81.69
2025-01-11 00:21:42,060 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.509,  Train_accy 99.55
2025-01-11 00:21:51,419 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.509,  Train_accy 99.31
2025-01-11 00:22:00,881 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.506,  Train_accy 99.55
2025-01-11 00:22:10,288 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.506,  Train_accy 99.46
2025-01-11 00:22:14,899 [der.py] => darknet eval: 
2025-01-11 00:22:14,899 [der.py] => CNN top1 curve: 81.04
2025-01-11 00:22:14,899 [der.py] => CNN top5 curve: 97.93
2025-01-11 00:22:14,901 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 00:22:45,748 [der.py] => Exemplar size: 750
2025-01-11 00:22:45,748 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-11 00:22:45,748 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-11 00:22:45,748 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-11 00:22:45,748 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-11 00:22:45,748 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-11 00:22:45,748 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-11 00:22:45,749 [trainer.py] => All params: 42091068
2025-01-11 00:22:45,749 [trainer.py] => Trainable params: 21049456
2025-01-11 00:22:45,922 [der.py] => Learning on 25-35
2025-01-11 00:22:45,926 [der.py] => All params: 63139730
2025-01-11 00:22:45,928 [der.py] => Trainable params: 21056506
2025-01-11 01:01:07,060 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-11 01:01:07,431 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 01:01:07,440 [der.py] => per cls weights : [-0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685   3.87092124  3.87092124  3.87092124  3.87092124  3.87092124
  3.87092124  3.87092124  3.87092124  3.87092124  3.87092124]
2025-01-11 01:01:24,340 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 1.875,  Train_accy 35.23, Test_accy 39.05
2025-01-11 01:01:35,570 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.608,  Train_accy 56.73
2025-01-11 01:01:46,678 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.477,  Train_accy 66.24
2025-01-11 01:01:57,768 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.404,  Train_accy 71.98
2025-01-11 01:02:09,067 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.352,  Train_accy 75.07
2025-01-11 01:02:26,277 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.308,  Train_accy 79.19, Test_accy 53.11
2025-01-11 01:02:37,591 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.289,  Train_accy 80.51
2025-01-11 01:02:48,798 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.262,  Train_accy 82.02
2025-01-11 01:02:59,962 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.247,  Train_accy 83.68
2025-01-11 01:03:11,281 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.230,  Train_accy 84.63
2025-01-11 01:03:33,391 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.212,  Train_accy 86.65, Test_accy 57.17
2025-01-11 01:03:44,673 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.205,  Train_accy 86.95
2025-01-11 01:03:56,261 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.189,  Train_accy 88.67
2025-01-11 01:04:07,559 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.182,  Train_accy 88.57
2025-01-11 01:04:18,786 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.177,  Train_accy 89.25
2025-01-11 01:04:35,505 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.173,  Train_accy 89.37, Test_accy 61.19
2025-01-11 01:04:46,741 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.165,  Train_accy 90.89
2025-01-11 01:04:57,994 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.157,  Train_accy 90.61
2025-01-11 01:05:09,167 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.153,  Train_accy 90.69
2025-01-11 01:05:20,355 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.145,  Train_accy 91.49
2025-01-11 01:05:37,055 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.141,  Train_accy 92.08, Test_accy 64.17
2025-01-11 01:05:48,410 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.133,  Train_accy 92.08
2025-01-11 01:05:59,749 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.127,  Train_accy 92.55
2025-01-11 01:06:11,246 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.129,  Train_accy 93.07
2025-01-11 01:06:22,563 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.127,  Train_accy 92.75
2025-01-11 01:06:39,664 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.119,  Train_accy 93.68, Test_accy 68.73
2025-01-11 01:06:50,889 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.115,  Train_accy 93.43
2025-01-11 01:07:02,128 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.115,  Train_accy 93.33
2025-01-11 01:07:13,385 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.110,  Train_accy 93.56
2025-01-11 01:07:24,608 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.110,  Train_accy 93.88
2025-01-11 01:07:42,058 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.106,  Train_accy 93.92, Test_accy 68.67
2025-01-11 01:07:53,419 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.099,  Train_accy 94.67
2025-01-11 01:08:04,631 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.104,  Train_accy 94.51
2025-01-11 01:08:15,936 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.101,  Train_accy 94.55
2025-01-11 01:08:27,180 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.097,  Train_accy 94.44
2025-01-11 01:08:44,026 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.097,  Train_accy 94.38, Test_accy 68.79
2025-01-11 01:08:55,322 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.096,  Train_accy 94.71
2025-01-11 01:09:06,484 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.095,  Train_accy 94.55
2025-01-11 01:09:17,729 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.089,  Train_accy 94.89
2025-01-11 01:09:28,912 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.090,  Train_accy 94.48
2025-01-11 01:09:45,663 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.088,  Train_accy 94.63, Test_accy 69.51
2025-01-11 01:09:56,902 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.087,  Train_accy 94.89
2025-01-11 01:10:08,078 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.087,  Train_accy 94.53
2025-01-11 01:10:19,525 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.083,  Train_accy 95.39
2025-01-11 01:10:30,680 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.081,  Train_accy 94.97
2025-01-11 01:10:48,049 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.082,  Train_accy 95.07, Test_accy 69.62
2025-01-11 01:10:59,312 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.078,  Train_accy 95.70
2025-01-11 01:11:10,623 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.077,  Train_accy 95.23
2025-01-11 01:11:21,822 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.076,  Train_accy 95.58
2025-01-11 01:11:33,093 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.077,  Train_accy 95.19
2025-01-11 01:11:50,093 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.073,  Train_accy 95.86, Test_accy 70.13
2025-01-11 01:12:01,473 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.072,  Train_accy 95.72
2025-01-11 01:12:12,841 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.073,  Train_accy 95.54
2025-01-11 01:12:24,417 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.073,  Train_accy 95.23
2025-01-11 01:12:35,621 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.071,  Train_accy 95.84
2025-01-11 01:12:52,785 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.068,  Train_accy 95.82, Test_accy 69.98
2025-01-11 01:13:04,190 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.070,  Train_accy 95.70
2025-01-11 01:13:15,398 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.067,  Train_accy 95.27
2025-01-11 01:13:26,766 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.066,  Train_accy 96.00
2025-01-11 01:13:38,035 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.067,  Train_accy 95.78
2025-01-11 01:13:55,116 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.065,  Train_accy 96.02, Test_accy 70.67
2025-01-11 01:14:06,420 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.068,  Train_accy 95.74
2025-01-11 01:14:17,664 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.062,  Train_accy 95.94
2025-01-11 01:14:28,985 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.065,  Train_accy 96.10
2025-01-11 01:14:40,105 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.062,  Train_accy 95.88
2025-01-11 01:14:56,946 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.063,  Train_accy 96.08, Test_accy 71.10
2025-01-11 01:15:08,188 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.064,  Train_accy 96.22
2025-01-11 01:15:19,483 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.060,  Train_accy 96.04
2025-01-11 01:15:30,633 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.061,  Train_accy 95.90
2025-01-11 01:15:41,911 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.062,  Train_accy 95.86
2025-01-11 01:16:09,433 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.060,  Train_accy 95.86, Test_accy 70.51
2025-01-11 01:17:32,974 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.059,  Train_accy 96.38
2025-01-11 01:17:45,249 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.058,  Train_accy 95.92
2025-01-11 01:17:56,408 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.058,  Train_accy 96.36
2025-01-11 01:18:07,554 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.060,  Train_accy 96.10
2025-01-11 01:20:38,885 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.058,  Train_accy 95.86, Test_accy 71.35
2025-01-11 01:22:26,832 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.057,  Train_accy 96.57
2025-01-11 01:22:39,788 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.057,  Train_accy 95.80
2025-01-11 01:22:50,977 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.057,  Train_accy 96.40
2025-01-11 01:23:02,079 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.058,  Train_accy 96.04
2025-01-11 01:25:05,969 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.056,  Train_accy 96.22, Test_accy 71.49
2025-01-11 01:25:17,163 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.055,  Train_accy 96.00
2025-01-11 01:25:28,372 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.053,  Train_accy 96.24
2025-01-11 01:25:39,570 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.055,  Train_accy 96.18
2025-01-11 01:25:50,659 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.052,  Train_accy 96.46
2025-01-11 01:28:38,756 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.053,  Train_accy 96.32, Test_accy 71.22
2025-01-11 01:28:49,997 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.051,  Train_accy 96.06
2025-01-11 01:29:01,145 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.052,  Train_accy 95.84
2025-01-11 01:29:12,171 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.050,  Train_accy 96.63
2025-01-11 01:29:23,247 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.051,  Train_accy 96.08
2025-01-11 01:30:14,932 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.050,  Train_accy 96.42, Test_accy 71.70
2025-01-11 01:30:25,973 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.049,  Train_accy 96.57
2025-01-11 01:30:37,169 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.051,  Train_accy 96.30
2025-01-11 01:30:48,256 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.051,  Train_accy 96.44
2025-01-11 01:30:59,274 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.050,  Train_accy 96.48
2025-01-11 01:31:19,027 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.053,  Train_accy 96.46, Test_accy 71.14
2025-01-11 01:31:30,998 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.049,  Train_accy 96.44
2025-01-11 01:31:42,031 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.051,  Train_accy 96.55
2025-01-11 01:31:53,084 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.050,  Train_accy 96.48
2025-01-11 01:32:04,196 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.050,  Train_accy 96.40
2025-01-11 01:32:21,056 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.051,  Train_accy 96.24, Test_accy 71.75
2025-01-11 01:32:32,467 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.049,  Train_accy 96.26
2025-01-11 01:32:43,663 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.048,  Train_accy 96.57
2025-01-11 01:32:54,998 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.050,  Train_accy 96.34
2025-01-11 01:33:06,260 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.048,  Train_accy 96.46
2025-01-11 01:33:24,355 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.047,  Train_accy 96.67, Test_accy 71.35
2025-01-11 01:33:35,442 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.049,  Train_accy 96.55
2025-01-11 01:33:46,561 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.048,  Train_accy 96.59
2025-01-11 01:33:57,790 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.047,  Train_accy 96.55
2025-01-11 01:34:08,944 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.047,  Train_accy 96.71
2025-01-11 01:34:30,800 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.046,  Train_accy 96.61, Test_accy 71.79
2025-01-11 01:34:42,045 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.048,  Train_accy 96.61
2025-01-11 01:34:53,145 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.043,  Train_accy 96.75
2025-01-11 01:35:04,290 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.047,  Train_accy 96.28
2025-01-11 01:35:15,412 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.049,  Train_accy 96.02
2025-01-11 01:35:47,492 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.047,  Train_accy 96.20, Test_accy 71.68
2025-01-11 01:35:58,606 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.048,  Train_accy 96.36
2025-01-11 01:36:09,769 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.046,  Train_accy 96.63
2025-01-11 01:36:20,819 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.049,  Train_accy 96.28
2025-01-11 01:36:31,974 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.047,  Train_accy 96.20
2025-01-11 01:36:48,476 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.047,  Train_accy 96.59, Test_accy 71.78
2025-01-11 01:36:59,572 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.046,  Train_accy 96.24
2025-01-11 01:37:10,614 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.047,  Train_accy 96.57
2025-01-11 01:37:21,697 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.047,  Train_accy 96.83
2025-01-11 01:37:32,826 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.044,  Train_accy 96.79
2025-01-11 01:37:49,373 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.044,  Train_accy 96.53, Test_accy 71.90
2025-01-11 01:38:00,538 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.048,  Train_accy 96.40
2025-01-11 01:38:11,677 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.046,  Train_accy 96.79
2025-01-11 01:38:22,757 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.046,  Train_accy 96.81
2025-01-11 01:38:33,815 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.048,  Train_accy 96.48
2025-01-11 01:38:39,556 [der.py] => darknet eval: 
2025-01-11 01:38:39,556 [der.py] => CNN top1 curve: 71.6
2025-01-11 01:38:39,556 [der.py] => CNN top5 curve: 96.46
2025-01-11 01:38:39,558 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 01:39:22,360 [der.py] => Exemplar size: 1050
2025-01-11 01:39:22,360 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-11 01:39:22,360 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-11 01:39:22,360 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-11 01:39:22,360 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-11 01:39:22,360 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-11 01:39:22,360 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-11 01:39:22,361 [trainer.py] => All params: 63139730
2025-01-11 01:39:22,362 [trainer.py] => Trainable params: 21056506
2025-01-11 01:39:22,636 [der.py] => Learning on 35-45
2025-01-11 01:39:22,637 [der.py] => All params: 84190952
2025-01-11 01:39:22,638 [der.py] => Trainable params: 21066116
2025-01-11 02:20:26,525 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-11 02:20:26,814 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 02:20:26,828 [der.py] => per cls weights : [-0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395  5.19721383
  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383
  5.19721383  5.19721383  5.19721383]
2025-01-11 02:20:47,434 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.042,  Train_accy 26.99, Test_accy 29.09
2025-01-11 02:21:00,708 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.585,  Train_accy 44.67
2025-01-11 02:21:14,138 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.431,  Train_accy 50.84
2025-01-11 02:21:27,448 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.365,  Train_accy 52.86
2025-01-11 02:21:40,689 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.321,  Train_accy 56.00
2025-01-11 02:22:01,007 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.245,  Train_accy 58.11, Test_accy 36.69
2025-01-11 02:22:14,263 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.208,  Train_accy 59.01
2025-01-11 02:22:27,353 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.176,  Train_accy 61.39
2025-01-11 02:22:40,624 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.144,  Train_accy 63.01
2025-01-11 02:22:53,867 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.117,  Train_accy 63.62
2025-01-11 02:23:13,893 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.102,  Train_accy 65.09, Test_accy 41.67
2025-01-11 02:23:26,964 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.094,  Train_accy 64.59
2025-01-11 02:23:40,193 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.077,  Train_accy 65.31
2025-01-11 02:23:53,381 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.101,  Train_accy 65.66
2025-01-11 02:24:06,475 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.080,  Train_accy 67.31
2025-01-11 02:24:26,273 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.070,  Train_accy 65.85, Test_accy 46.11
2025-01-11 02:24:39,546 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.026,  Train_accy 68.25
2025-01-11 02:24:52,761 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.015,  Train_accy 69.52
2025-01-11 02:25:05,919 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.000,  Train_accy 69.26
2025-01-11 02:25:19,073 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.017,  Train_accy 68.25
2025-01-11 02:25:38,867 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 0.985,  Train_accy 70.88, Test_accy 45.67
2025-01-11 02:25:52,013 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 0.972,  Train_accy 70.59
2025-01-11 02:26:05,167 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 0.980,  Train_accy 70.50
2025-01-11 02:26:18,443 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 0.961,  Train_accy 71.33
2025-01-11 02:26:31,561 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 0.964,  Train_accy 71.41
2025-01-11 02:26:51,748 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 0.955,  Train_accy 71.62, Test_accy 51.56
2025-01-11 02:27:04,936 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 0.963,  Train_accy 73.12
2025-01-11 02:27:18,173 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 0.936,  Train_accy 72.23
2025-01-11 02:27:31,369 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 0.928,  Train_accy 72.30
2025-01-11 02:27:44,717 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 0.925,  Train_accy 73.14
2025-01-11 02:28:04,720 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 0.912,  Train_accy 73.96, Test_accy 53.42
2025-01-11 02:28:17,899 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 0.920,  Train_accy 74.04
2025-01-11 02:28:31,046 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 0.895,  Train_accy 74.11
2025-01-11 02:28:44,185 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 0.883,  Train_accy 74.46
2025-01-11 02:28:57,419 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 0.897,  Train_accy 74.72
2025-01-11 02:29:18,018 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 0.885,  Train_accy 75.20, Test_accy 51.85
2025-01-11 02:29:31,238 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 0.897,  Train_accy 73.52
2025-01-11 02:29:44,384 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 0.890,  Train_accy 74.51
2025-01-11 02:29:57,591 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 0.875,  Train_accy 74.88
2025-01-11 02:30:10,763 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 0.874,  Train_accy 74.44
2025-01-11 02:30:30,792 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 0.890,  Train_accy 75.66, Test_accy 52.86
2025-01-11 02:30:44,041 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 0.867,  Train_accy 74.19
2025-01-11 02:30:57,553 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 0.871,  Train_accy 75.16
2025-01-11 02:31:11,006 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 0.874,  Train_accy 75.64
2025-01-11 02:31:24,342 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 0.857,  Train_accy 75.31
2025-01-11 02:31:44,322 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 0.839,  Train_accy 75.81, Test_accy 51.91
2025-01-11 02:31:57,537 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 0.869,  Train_accy 75.18
2025-01-11 02:32:10,782 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 0.860,  Train_accy 75.22
2025-01-11 02:32:24,067 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 0.870,  Train_accy 75.30
2025-01-11 02:32:37,203 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 0.858,  Train_accy 75.47
2025-01-11 02:32:56,867 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 0.840,  Train_accy 75.77, Test_accy 56.43
2025-01-11 02:33:09,985 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 0.837,  Train_accy 76.38
2025-01-11 02:33:23,075 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 0.832,  Train_accy 76.19
2025-01-11 02:33:36,244 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 0.838,  Train_accy 76.08
2025-01-11 02:33:49,385 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 0.847,  Train_accy 76.06
2025-01-11 02:34:09,188 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 0.849,  Train_accy 75.94, Test_accy 51.49
2025-01-11 02:34:22,296 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 0.835,  Train_accy 76.34
2025-01-11 02:34:35,450 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 0.835,  Train_accy 75.73
2025-01-11 02:34:49,045 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 0.826,  Train_accy 76.04
2025-01-11 02:35:02,207 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 0.842,  Train_accy 76.17
2025-01-11 02:35:21,954 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 0.818,  Train_accy 76.40, Test_accy 51.25
2025-01-11 02:35:35,200 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 0.831,  Train_accy 76.53
2025-01-11 02:35:48,363 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 0.830,  Train_accy 76.19
2025-01-11 02:36:01,563 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 0.823,  Train_accy 76.11
2025-01-11 02:36:14,756 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 0.803,  Train_accy 76.78
2025-01-11 02:36:34,625 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 0.826,  Train_accy 76.23, Test_accy 57.17
2025-01-11 02:36:47,869 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 0.815,  Train_accy 76.55
2025-01-11 02:37:01,042 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 0.809,  Train_accy 76.13
2025-01-11 02:37:14,176 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 0.801,  Train_accy 76.29
2025-01-11 02:37:27,378 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 0.792,  Train_accy 76.02
2025-01-11 02:37:47,512 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 0.810,  Train_accy 76.93, Test_accy 58.88
2025-01-11 02:38:00,668 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 0.828,  Train_accy 77.05
2025-01-11 02:38:13,800 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 0.811,  Train_accy 76.90
2025-01-11 02:38:26,939 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 0.809,  Train_accy 76.50
2025-01-11 02:38:40,142 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 0.806,  Train_accy 76.44
2025-01-11 02:39:00,026 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 0.823,  Train_accy 76.40, Test_accy 54.85
2025-01-11 02:39:13,265 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 0.804,  Train_accy 76.69
2025-01-11 02:39:27,612 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 0.810,  Train_accy 76.51
2025-01-11 02:39:41,468 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 0.800,  Train_accy 76.19
2025-01-11 02:39:54,895 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 0.805,  Train_accy 76.61
2025-01-11 02:40:27,542 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 0.795,  Train_accy 77.01, Test_accy 58.51
2025-01-11 02:40:40,956 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 0.808,  Train_accy 76.80
2025-01-11 02:40:54,399 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 0.806,  Train_accy 77.03
2025-01-11 02:41:07,819 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 0.808,  Train_accy 76.93
2025-01-11 02:41:21,128 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 0.788,  Train_accy 76.50
2025-01-11 02:41:41,298 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.771,  Train_accy 76.91, Test_accy 54.72
2025-01-11 02:41:54,592 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 0.800,  Train_accy 77.10
2025-01-11 02:42:08,050 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 0.806,  Train_accy 76.69
2025-01-11 02:42:21,485 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 0.805,  Train_accy 77.03
2025-01-11 02:42:34,923 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 0.804,  Train_accy 76.84
2025-01-11 02:42:55,339 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 0.794,  Train_accy 77.45, Test_accy 58.84
2025-01-11 02:43:08,706 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.783,  Train_accy 77.39
2025-01-11 02:43:22,005 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 0.795,  Train_accy 76.90
2025-01-11 02:43:35,469 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 0.798,  Train_accy 77.07
2025-01-11 02:43:48,830 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.774,  Train_accy 76.76
2025-01-11 02:44:11,437 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.765,  Train_accy 77.12, Test_accy 56.48
2025-01-11 02:44:24,742 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 0.814,  Train_accy 77.18
2025-01-11 02:44:38,040 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 0.814,  Train_accy 77.10
2025-01-11 02:44:51,640 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 0.794,  Train_accy 77.26
2025-01-11 02:45:05,442 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 0.794,  Train_accy 76.51
2025-01-11 02:45:26,215 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 0.797,  Train_accy 77.22, Test_accy 58.86
2025-01-11 02:45:39,600 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 0.788,  Train_accy 77.33
2025-01-11 02:45:52,845 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.782,  Train_accy 77.64
2025-01-11 02:46:06,058 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 0.797,  Train_accy 77.16
2025-01-11 02:46:19,501 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.781,  Train_accy 77.18
2025-01-11 02:46:46,404 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 0.785,  Train_accy 76.76, Test_accy 55.04
2025-01-11 02:46:59,722 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 0.781,  Train_accy 76.69
2025-01-11 02:47:12,996 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 0.792,  Train_accy 76.99
2025-01-11 02:47:26,327 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 0.794,  Train_accy 77.58
2025-01-11 02:47:39,602 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 0.811,  Train_accy 77.35
2025-01-11 02:48:08,501 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 0.794,  Train_accy 76.50, Test_accy 52.96
2025-01-11 02:48:21,807 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.780,  Train_accy 76.86
2025-01-11 02:48:35,100 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 0.795,  Train_accy 77.39
2025-01-11 02:48:48,404 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 0.789,  Train_accy 77.26
2025-01-11 02:49:01,587 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.794,  Train_accy 77.30
2025-01-11 02:49:21,886 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.770,  Train_accy 77.10, Test_accy 55.42
2025-01-11 02:49:35,194 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 0.798,  Train_accy 77.14
2025-01-11 02:49:48,484 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 0.784,  Train_accy 77.33
2025-01-11 02:50:01,776 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.771,  Train_accy 77.30
2025-01-11 02:50:15,030 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.776,  Train_accy 77.33
2025-01-11 02:50:35,203 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.777,  Train_accy 77.31, Test_accy 60.46
2025-01-11 02:50:48,470 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 0.786,  Train_accy 77.07
2025-01-11 02:51:01,925 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.762,  Train_accy 77.05
2025-01-11 02:51:15,196 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.781,  Train_accy 77.14
2025-01-11 02:51:28,517 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 0.786,  Train_accy 77.30
2025-01-11 02:51:50,891 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 0.783,  Train_accy 77.28, Test_accy 57.77
2025-01-11 02:52:04,176 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 0.781,  Train_accy 76.70
2025-01-11 02:52:17,494 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.788,  Train_accy 77.05
2025-01-11 02:52:30,823 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 0.794,  Train_accy 76.70
2025-01-11 02:52:44,115 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.780,  Train_accy 77.12
2025-01-11 02:52:50,350 [der.py] => darknet eval: 
2025-01-11 02:52:50,351 [der.py] => CNN top1 curve: 60.91
2025-01-11 02:52:50,351 [der.py] => CNN top5 curve: 90.98
2025-01-11 02:52:50,353 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 02:53:48,196 [der.py] => Exemplar size: 1350
2025-01-11 02:53:48,196 [trainer.py] => CNN: {'total': 76.41, '0': 63.89, '1': 72.22, '2': 91.67, '3': 66.67, '4': 82.78, '5': 40.56, '6': 75.56, '7': 58.89, '8': 42.22, '9': 56.11, '10': 92.22, '11': 95.0, '12': 83.33, '13': 79.44, '14': 56.11, '15': 96.67, '16': 93.89, '17': 95.0, '18': 92.78, '19': 93.89, '20': 96.11, '21': 91.67, '22': 73.33, '23': 71.11, '24': 62.22, '25': 88.33, '26': 93.33, '27': 93.33, '28': 69.44, '29': 79.44, '30': 94.44, '31': 83.33, '32': 98.89, '33': 83.33, '34': 81.67, '35': 90.0, '36': 87.78, '37': 22.78, '38': 4.44, '39': 40.56, '40': 73.89, '41': 96.11, '42': 97.22, '43': 96.11, 'old': 79.68, 'new': 64.94}
2025-01-11 02:53:48,197 [trainer.py] => NME: {'total': 78.53, '0': 66.11, '1': 64.44, '2': 85.56, '3': 52.78, '4': 85.0, '5': 45.0, '6': 65.56, '7': 55.0, '8': 47.78, '9': 59.44, '10': 91.67, '11': 83.33, '12': 82.22, '13': 76.67, '14': 56.67, '15': 89.44, '16': 90.0, '17': 93.89, '18': 89.44, '19': 93.33, '20': 92.22, '21': 88.33, '22': 86.11, '23': 62.78, '24': 75.56, '25': 78.89, '26': 91.67, '27': 85.0, '28': 63.33, '29': 76.67, '30': 76.11, '31': 83.33, '32': 91.67, '33': 62.78, '34': 81.67, '35': 97.22, '36': 89.44, '37': 66.67, '38': 89.44, '39': 85.0, '40': 84.44, '41': 91.11, '42': 97.22, '43': 94.44, 'old': 76.27, 'new': 86.44}
2025-01-11 02:53:48,197 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41]
2025-01-11 02:53:48,197 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35]
2025-01-11 02:53:48,197 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53]
2025-01-11 02:53:48,197 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06]

2025-01-11 02:53:48,198 [trainer.py] => All params: 84190952
2025-01-11 02:53:48,199 [trainer.py] => Trainable params: 21066116
2025-01-11 02:53:48,363 [der.py] => Learning on 45-55
2025-01-11 02:53:48,366 [der.py] => All params: 105244734
2025-01-11 02:53:48,368 [der.py] => Trainable params: 21078286
2025-01-11 03:44:12,379 [der.py] => Task 4, Epoch 150/150 => Loss 0.016, Loss_clf 0.007, Loss_aux 0.008, Train_accy 100.00
2025-01-11 03:44:12,644 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 03:44:12,651 [der.py] => per cls weights : [-0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859  6.64636865  6.64636865  6.64636865
  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865
  6.64636865]
2025-01-11 03:44:36,263 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.847,  Train_accy 11.01, Test_accy 26.21
2025-01-11 03:44:51,913 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.705,  Train_accy 16.18
2025-01-11 03:45:07,244 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.628,  Train_accy 21.33
2025-01-11 03:45:22,617 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.563,  Train_accy 25.93
2025-01-11 03:45:37,999 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.506,  Train_accy 31.66
2025-01-11 03:46:01,854 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.466,  Train_accy 35.80, Test_accy 38.53
2025-01-11 03:46:17,232 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.418,  Train_accy 40.83
2025-01-11 03:46:32,620 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.380,  Train_accy 46.50
2025-01-11 03:46:47,961 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.360,  Train_accy 49.41
2025-01-11 03:47:03,343 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.328,  Train_accy 50.99
2025-01-11 03:47:27,098 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.305,  Train_accy 53.60, Test_accy 44.21
2025-01-11 03:47:42,788 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.286,  Train_accy 56.05
2025-01-11 03:47:58,259 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.272,  Train_accy 58.31
2025-01-11 03:48:13,672 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.250,  Train_accy 60.40
2025-01-11 03:48:29,099 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.235,  Train_accy 62.38
2025-01-11 03:48:52,599 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.227,  Train_accy 63.14, Test_accy 48.34
2025-01-11 03:49:07,977 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.215,  Train_accy 63.26
2025-01-11 03:49:23,511 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.202,  Train_accy 64.13
2025-01-11 03:49:39,583 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.193,  Train_accy 66.45
2025-01-11 03:49:55,064 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.179,  Train_accy 67.35
2025-01-11 03:50:18,527 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.179,  Train_accy 68.18, Test_accy 52.94
2025-01-11 03:50:33,915 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.168,  Train_accy 69.59
2025-01-11 03:50:49,250 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.166,  Train_accy 68.34
2025-01-11 03:51:04,629 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.154,  Train_accy 70.86
2025-01-11 03:51:20,220 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.146,  Train_accy 70.07
2025-01-11 03:51:44,131 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.139,  Train_accy 71.69, Test_accy 52.02
2025-01-11 03:51:59,493 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.134,  Train_accy 72.49
2025-01-11 03:52:14,862 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.122,  Train_accy 72.79
2025-01-11 03:52:30,239 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.123,  Train_accy 72.72
2025-01-11 03:52:45,576 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.117,  Train_accy 73.15
2025-01-11 03:53:08,886 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.117,  Train_accy 73.35, Test_accy 54.86
2025-01-11 03:53:24,218 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.107,  Train_accy 74.20
2025-01-11 03:53:39,571 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.104,  Train_accy 74.77
2025-01-11 03:53:54,852 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.098,  Train_accy 74.56
2025-01-11 03:54:10,199 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.089,  Train_accy 75.84
2025-01-11 03:54:33,485 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.091,  Train_accy 75.80, Test_accy 55.68
2025-01-11 03:54:48,800 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.091,  Train_accy 75.64
2025-01-11 03:55:04,202 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.091,  Train_accy 76.14
2025-01-11 03:55:19,569 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.086,  Train_accy 76.88
2025-01-11 03:55:34,969 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.079,  Train_accy 76.07
2025-01-11 03:55:58,363 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.080,  Train_accy 76.58, Test_accy 58.04
2025-01-11 03:56:13,749 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.072,  Train_accy 77.39
2025-01-11 03:56:29,128 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.067,  Train_accy 77.12
2025-01-11 03:56:44,524 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.065,  Train_accy 78.00
2025-01-11 03:56:59,811 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.071,  Train_accy 77.21
2025-01-11 03:57:23,166 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.064,  Train_accy 77.69, Test_accy 59.14
2025-01-11 03:57:38,578 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.070,  Train_accy 77.69
2025-01-11 03:57:54,010 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.059,  Train_accy 78.61
2025-01-11 03:58:09,303 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.056,  Train_accy 78.25
2025-01-11 03:58:24,613 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.051,  Train_accy 78.49
2025-01-11 03:58:48,008 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.052,  Train_accy 78.52, Test_accy 59.78
2025-01-11 03:59:03,420 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.052,  Train_accy 78.81
2025-01-11 03:59:18,744 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.049,  Train_accy 79.23
2025-01-11 03:59:34,099 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.042,  Train_accy 79.98
2025-01-11 03:59:49,385 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.041,  Train_accy 79.68
2025-01-11 04:00:12,813 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.044,  Train_accy 79.51, Test_accy 59.87
2025-01-11 04:00:28,146 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.037,  Train_accy 79.93
2025-01-11 04:00:43,754 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.040,  Train_accy 79.19
2025-01-11 04:00:59,516 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.039,  Train_accy 79.23
2025-01-11 04:01:14,958 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.035,  Train_accy 80.97
2025-01-11 04:01:38,560 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.041,  Train_accy 79.82, Test_accy 61.89
2025-01-11 04:01:53,996 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.029,  Train_accy 80.25
2025-01-11 04:02:09,345 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.033,  Train_accy 79.96
2025-01-11 04:02:24,730 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.031,  Train_accy 80.05
2025-01-11 04:02:40,041 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.027,  Train_accy 80.61
2025-01-11 04:03:03,449 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.026,  Train_accy 80.67, Test_accy 61.13
2025-01-11 04:03:18,807 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.024,  Train_accy 81.01
2025-01-11 04:03:34,195 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.024,  Train_accy 80.56
2025-01-11 04:03:49,566 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.025,  Train_accy 80.83
2025-01-11 04:04:04,887 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.024,  Train_accy 80.85
2025-01-11 04:04:28,238 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.020,  Train_accy 81.32, Test_accy 61.10
2025-01-11 04:04:43,544 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.024,  Train_accy 80.05
2025-01-11 04:04:58,920 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.021,  Train_accy 81.35
2025-01-11 04:05:14,264 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.017,  Train_accy 81.15
2025-01-11 04:05:29,603 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.019,  Train_accy 81.44
2025-01-11 04:05:52,932 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.013,  Train_accy 81.69, Test_accy 62.25
2025-01-11 04:06:08,314 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.016,  Train_accy 82.38
2025-01-11 04:06:23,591 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.017,  Train_accy 81.03
2025-01-11 04:06:38,969 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.015,  Train_accy 82.22
2025-01-11 04:06:54,332 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.014,  Train_accy 82.22
2025-01-11 04:07:17,702 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.012,  Train_accy 81.62, Test_accy 62.09
2025-01-11 04:07:33,080 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.008,  Train_accy 82.36
2025-01-11 04:07:48,368 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.011,  Train_accy 81.44
2025-01-11 04:08:03,849 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.014,  Train_accy 81.46
2025-01-11 04:08:19,166 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.013,  Train_accy 81.60
2025-01-11 04:08:43,273 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.010,  Train_accy 82.40, Test_accy 62.36
2025-01-11 04:08:58,624 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.006,  Train_accy 82.29
2025-01-11 04:09:14,049 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.007,  Train_accy 82.49
2025-01-11 04:09:29,496 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.005,  Train_accy 82.25
2025-01-11 04:09:44,809 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.011,  Train_accy 81.82
2025-01-11 04:10:08,319 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.006,  Train_accy 82.54, Test_accy 62.95
2025-01-11 04:10:23,674 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.008,  Train_accy 82.50
2025-01-11 04:10:39,222 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.005,  Train_accy 82.49
2025-01-11 04:10:54,484 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.004,  Train_accy 82.13
2025-01-11 04:11:09,816 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.002,  Train_accy 83.01
2025-01-11 04:11:53,343 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.002,  Train_accy 82.32, Test_accy 63.28
2025-01-11 04:12:09,426 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.004,  Train_accy 82.11
2025-01-11 04:12:25,300 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.007,  Train_accy 82.76
2025-01-11 04:12:41,182 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.001,  Train_accy 82.49
2025-01-11 04:12:57,013 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.001,  Train_accy 82.83
2025-01-11 04:13:21,743 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 1.999,  Train_accy 83.37, Test_accy 63.21
2025-01-11 04:13:37,462 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.002,  Train_accy 82.20
2025-01-11 04:13:53,215 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.002,  Train_accy 82.94
2025-01-11 04:14:08,947 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 1.998,  Train_accy 82.63
2025-01-11 04:14:24,626 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.000,  Train_accy 82.49
2025-01-11 04:14:48,515 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.001,  Train_accy 82.27, Test_accy 63.48
2025-01-11 04:15:03,978 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.000,  Train_accy 82.67
2025-01-11 04:15:19,800 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.002,  Train_accy 82.90
2025-01-11 04:15:35,360 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 1.999,  Train_accy 82.29
2025-01-11 04:15:50,725 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 1.997,  Train_accy 82.54
2025-01-11 04:16:14,063 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.000,  Train_accy 82.85, Test_accy 63.67
2025-01-11 04:16:29,474 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.001,  Train_accy 82.97
2025-01-11 04:16:44,950 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.001,  Train_accy 82.20
2025-01-11 04:17:00,428 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 1.999,  Train_accy 83.06
2025-01-11 04:17:15,812 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 1.999,  Train_accy 82.99
2025-01-11 04:17:39,440 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.001,  Train_accy 83.14, Test_accy 63.06
2025-01-11 04:17:54,826 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 1.999,  Train_accy 82.97
2025-01-11 04:18:10,190 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 1.998,  Train_accy 82.70
2025-01-11 04:18:26,314 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 1.999,  Train_accy 83.59
2025-01-11 04:18:41,685 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 1.995,  Train_accy 83.10
2025-01-11 04:19:11,772 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.000,  Train_accy 82.43, Test_accy 63.73
2025-01-11 04:19:27,091 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 1.998,  Train_accy 82.32
2025-01-11 04:19:42,494 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 1.996,  Train_accy 82.36
2025-01-11 04:19:57,856 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.000,  Train_accy 82.88
2025-01-11 04:20:13,188 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 1.996,  Train_accy 83.26
2025-01-11 04:20:36,771 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 1.994,  Train_accy 82.97, Test_accy 63.72
2025-01-11 04:20:52,080 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 1.999,  Train_accy 83.62
2025-01-11 04:21:07,427 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 1.998,  Train_accy 83.10
2025-01-11 04:21:22,716 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 1.994,  Train_accy 83.44
2025-01-11 04:21:38,130 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.000,  Train_accy 82.94
2025-01-11 04:21:45,420 [der.py] => darknet eval: 
2025-01-11 04:21:45,421 [der.py] => CNN top1 curve: 63.45
2025-01-11 04:21:45,421 [der.py] => CNN top5 curve: 92.33
2025-01-11 04:21:45,422 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 04:22:59,310 [der.py] => Exemplar size: 1650
2025-01-11 04:22:59,311 [trainer.py] => CNN: {'total': 77.15, '0': 60.56, '1': 74.44, '2': 92.22, '3': 49.44, '4': 87.22, '5': 47.78, '6': 71.67, '7': 57.22, '8': 52.78, '9': 60.0, '10': 91.67, '11': 78.89, '12': 85.56, '13': 83.33, '14': 60.0, '15': 93.89, '16': 95.56, '17': 96.11, '18': 91.67, '19': 95.56, '20': 96.67, '21': 90.0, '22': 83.33, '23': 63.33, '24': 66.11, '25': 82.78, '26': 90.0, '27': 92.22, '28': 75.56, '29': 80.56, '30': 91.11, '31': 83.33, '32': 95.56, '33': 68.33, '34': 77.22, '35': 96.67, '36': 96.67, '37': 81.67, '38': 97.78, '39': 95.0, '40': 90.0, '41': 97.22, '42': 99.44, '43': 97.22, '44': 87.22, '45': 52.78, '46': 70.0, '47': 46.67, '48': 57.22, '49': 51.67, '50': 51.67, '51': 60.56, '52': 55.0, '53': 55.56, 'old': 82.23, 'new': 54.28}
2025-01-11 04:22:59,319 [trainer.py] => NME: {'total': 73.45, '0': 70.0, '1': 59.44, '2': 78.89, '3': 33.33, '4': 83.33, '5': 43.33, '6': 59.44, '7': 51.67, '8': 45.56, '9': 51.11, '10': 90.0, '11': 81.11, '12': 77.22, '13': 65.56, '14': 55.0, '15': 88.89, '16': 88.89, '17': 92.78, '18': 90.0, '19': 91.11, '20': 88.89, '21': 87.22, '22': 83.33, '23': 61.67, '24': 72.78, '25': 76.11, '26': 88.33, '27': 82.78, '28': 60.56, '29': 73.33, '30': 76.67, '31': 79.44, '32': 90.56, '33': 60.0, '34': 81.67, '35': 96.67, '36': 87.78, '37': 63.33, '38': 92.78, '39': 85.56, '40': 75.56, '41': 90.56, '42': 97.22, '43': 95.56, '44': 53.89, '45': 78.33, '46': 80.56, '47': 63.89, '48': 61.67, '49': 61.67, '50': 52.22, '51': 65.0, '52': 60.0, '53': 57.78, 'old': 75.53, 'new': 64.11}
2025-01-11 04:22:59,319 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41, 77.15]
2025-01-11 04:22:59,319 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35, 96.05]
2025-01-11 04:22:59,319 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53, 73.45]
2025-01-11 04:22:59,320 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06, 94.92]

2025-01-11 11:47:51,219 [trainer.py] => 实验名称:only der对比实验
2025-01-11 11:47:51,261 [trainer.py] => config: ./exps/der.json
2025-01-11 11:47:51,261 [trainer.py] => experiment_name: 实验名称:only der对比实验
2025-01-11 11:47:51,261 [trainer.py] => prefix: reproduce
2025-01-11 11:47:51,261 [trainer.py] => dataset: xrfdataset
2025-01-11 11:47:51,261 [trainer.py] => memory_size: 1650
2025-01-11 11:47:51,261 [trainer.py] => memory_per_class: 30
2025-01-11 11:47:51,261 [trainer.py] => fixed_memory: True
2025-01-11 11:47:51,261 [trainer.py] => shuffle: True
2025-01-11 11:47:51,261 [trainer.py] => init_cls: 15
2025-01-11 11:47:51,261 [trainer.py] => increment: 10
2025-01-11 11:47:51,262 [trainer.py] => model_name: der
2025-01-11 11:47:51,262 [trainer.py] => compression_epochs: 1
2025-01-11 11:47:51,262 [trainer.py] => compression_lr: 0.1
2025-01-11 11:47:51,262 [trainer.py] => T: 2
2025-01-11 11:47:51,262 [trainer.py] => convnet_type: unet
2025-01-11 11:47:51,262 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-11 11:47:51,262 [trainer.py] => seed: 1993
2025-01-11 11:47:51,316 [data.py] => 加载完毕XRF原始数据集
2025-01-11 11:47:51,338 [data.py] => 加载完毕XRF原始数据集
2025-01-11 11:47:51,340 [trainer.py] => All params: 0
2025-01-11 11:47:51,340 [trainer.py] => Trainable params: 0
2025-01-11 11:47:51,533 [der.py] => Learning on 0-15
2025-01-11 11:47:51,533 [der.py] => All params: 21045611
2025-01-11 11:47:51,534 [der.py] => Trainable params: 21045611
2025-01-11 12:16:13,873 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-11 12:16:13,891 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 12:16:37,383 [der.py] => Exemplar size: 450
2025-01-11 12:16:37,383 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-11 12:16:37,383 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-11 12:16:37,383 [trainer.py] => CNN top1 curve: [89.44]
2025-01-11 12:16:37,383 [trainer.py] => CNN top5 curve: [98.93]
2025-01-11 12:16:37,383 [trainer.py] => NME top1 curve: [88.22]
2025-01-11 12:16:37,383 [trainer.py] => NME top5 curve: [98.81]

2025-01-11 12:16:37,384 [trainer.py] => All params: 21045611
2025-01-11 12:16:37,384 [trainer.py] => Trainable params: 21045611
2025-01-11 12:16:37,564 [der.py] => Learning on 15-25
2025-01-11 12:16:37,565 [der.py] => All params: 42091068
2025-01-11 12:16:37,565 [der.py] => Trainable params: 21049456
2025-01-11 12:46:05,832 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-11 12:46:05,975 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 12:46:05,977 [der.py] => per cls weights : [-0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677  -0.1016677
 -0.1016677  -0.1016677  -0.1016677   2.65250155  2.65250155  2.65250155
  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155  2.65250155
  2.65250155]
2025-01-11 12:46:05,977 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 12:46:38,139 [der.py] => Exemplar size: 750
2025-01-11 12:46:38,139 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-11 12:46:38,139 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-11 12:46:38,139 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-11 12:46:38,139 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-11 12:46:38,139 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-11 12:46:38,139 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-11 12:46:38,140 [trainer.py] => All params: 42091068
2025-01-11 12:46:38,140 [trainer.py] => Trainable params: 21049456
2025-01-11 12:46:38,288 [der.py] => Learning on 25-35
2025-01-11 12:46:38,289 [der.py] => All params: 63139730
2025-01-11 12:46:38,290 [der.py] => Trainable params: 21056506
2025-01-11 13:21:57,611 [der.py] => Task 2, Epoch 150/150 => Loss 0.015, Loss_clf 0.006, Loss_aux 0.008, Train_accy 99.98
2025-01-11 13:21:57,647 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 13:21:57,648 [der.py] => per cls weights : [-0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685  -0.1483685
 -0.1483685   3.87092124  3.87092124  3.87092124  3.87092124  3.87092124
  3.87092124  3.87092124  3.87092124  3.87092124  3.87092124]
2025-01-11 13:21:57,649 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 13:22:43,616 [der.py] => Exemplar size: 1050
2025-01-11 13:22:43,617 [trainer.py] => CNN: {'total': 81.52, '0': 87.78, '1': 75.0, '2': 92.78, '3': 81.67, '4': 92.78, '5': 56.67, '6': 75.56, '7': 62.22, '8': 47.78, '9': 61.67, '10': 96.11, '11': 98.89, '12': 88.33, '13': 88.89, '14': 69.44, '15': 95.56, '16': 98.33, '17': 97.22, '18': 96.67, '19': 96.11, '20': 98.33, '21': 90.0, '22': 92.78, '23': 85.0, '24': 89.44, '25': 64.44, '26': 73.89, '27': 71.67, '28': 56.67, '29': 70.56, '30': 76.67, '31': 78.89, '32': 83.89, '33': 77.78, 'old': 84.6, 'new': 73.83}
2025-01-11 13:22:43,617 [trainer.py] => NME: {'total': 79.17, '0': 81.67, '1': 61.11, '2': 90.56, '3': 73.89, '4': 90.0, '5': 45.0, '6': 69.44, '7': 57.22, '8': 47.78, '9': 62.22, '10': 93.89, '11': 97.78, '12': 85.56, '13': 79.44, '14': 57.78, '15': 91.11, '16': 97.22, '17': 93.89, '18': 87.78, '19': 94.44, '20': 95.0, '21': 93.89, '22': 83.33, '23': 72.78, '24': 76.11, '25': 79.44, '26': 91.11, '27': 82.78, '28': 61.67, '29': 72.22, '30': 76.67, '31': 81.11, '32': 97.22, '33': 68.33, 'old': 79.16, 'new': 79.22}
2025-01-11 13:22:43,617 [trainer.py] => CNN top1 curve: [89.44, 88.07, 81.52]
2025-01-11 13:22:43,617 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.79]
2025-01-11 13:22:43,617 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.17]
2025-01-11 13:22:43,617 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.48]

2025-01-11 13:22:43,618 [trainer.py] => All params: 63139730
2025-01-11 13:22:43,618 [trainer.py] => Trainable params: 21056506
2025-01-11 13:22:43,757 [der.py] => Learning on 35-45
2025-01-11 13:22:43,758 [der.py] => All params: 84190952
2025-01-11 13:22:43,759 [der.py] => Trainable params: 21066116
2025-01-11 14:11:13,550 [der.py] => Task 3, Epoch 150/150 => Loss 0.079, Loss_clf 0.022, Loss_aux 0.056, Train_accy 99.85
2025-01-11 14:11:13,616 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 14:11:13,616 [der.py] => per cls weights : [-0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395
 -0.19920395 -0.19920395 -0.19920395 -0.19920395 -0.19920395  5.19721383
  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383  5.19721383
  5.19721383  5.19721383  5.19721383]
2025-01-11 14:11:13,617 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 14:12:16,025 [der.py] => Exemplar size: 1350
2025-01-11 14:12:16,026 [trainer.py] => CNN: {'total': 76.88, '0': 86.67, '1': 63.33, '2': 92.22, '3': 67.78, '4': 85.0, '5': 45.56, '6': 69.44, '7': 61.67, '8': 52.22, '9': 56.11, '10': 87.22, '11': 96.67, '12': 86.67, '13': 83.33, '14': 56.11, '15': 95.56, '16': 95.0, '17': 94.44, '18': 93.33, '19': 94.44, '20': 95.56, '21': 85.56, '22': 80.0, '23': 76.67, '24': 72.78, '25': 81.11, '26': 90.56, '27': 85.56, '28': 71.11, '29': 83.33, '30': 89.44, '31': 78.33, '32': 96.11, '33': 83.33, '34': 79.44, '35': 79.44, '36': 91.11, '37': 35.56, '38': 4.44, '39': 62.22, '40': 58.33, '41': 81.67, '42': 98.89, '43': 98.33, 'old': 80.33, 'new': 64.78}
2025-01-11 14:12:16,026 [trainer.py] => NME: {'total': 77.8, '0': 63.89, '1': 60.0, '2': 82.22, '3': 55.56, '4': 84.44, '5': 44.44, '6': 66.67, '7': 58.33, '8': 44.44, '9': 53.33, '10': 93.33, '11': 92.22, '12': 80.56, '13': 71.67, '14': 56.67, '15': 91.67, '16': 91.67, '17': 93.89, '18': 87.78, '19': 91.67, '20': 93.33, '21': 90.0, '22': 83.33, '23': 71.11, '24': 75.0, '25': 78.89, '26': 88.89, '27': 80.56, '28': 62.22, '29': 69.44, '30': 75.56, '31': 82.22, '32': 90.0, '33': 56.67, '34': 80.0, '35': 96.11, '36': 91.11, '37': 67.22, '38': 89.44, '39': 85.0, '40': 80.0, '41': 90.0, '42': 97.22, '43': 95.56, 'old': 75.48, 'new': 85.94}
2025-01-11 14:12:16,026 [trainer.py] => CNN top1 curve: [89.44, 88.07, 81.52, 76.88]
2025-01-11 14:12:16,026 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.79, 96.25]
2025-01-11 14:12:16,026 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.17, 77.8]
2025-01-11 14:12:16,026 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.48, 97.11]

2025-01-11 14:12:16,027 [trainer.py] => All params: 84190952
2025-01-11 14:12:16,028 [trainer.py] => Trainable params: 21066116
2025-01-11 14:12:16,192 [der.py] => Learning on 45-55
2025-01-11 14:12:16,194 [der.py] => All params: 105244734
2025-01-11 14:12:16,195 [der.py] => Trainable params: 21078286
2025-01-11 15:13:54,604 [der.py] => Task 4, Epoch 150/150 => Loss 0.018, Loss_clf 0.008, Loss_aux 0.010, Train_accy 100.00
2025-01-11 15:13:54,956 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2025-01-11 15:13:54,968 [der.py] => per cls weights : [-0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859 -0.25474859
 -0.25474859 -0.25474859 -0.25474859  6.64636865  6.64636865  6.64636865
  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865  6.64636865
  6.64636865]
2025-01-11 15:13:54,968 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 15:15:17,777 [der.py] => Exemplar size: 1650
2025-01-11 15:15:17,778 [trainer.py] => CNN: {'total': 76.6, '0': 60.0, '1': 66.67, '2': 90.56, '3': 48.89, '4': 92.22, '5': 45.0, '6': 66.11, '7': 57.78, '8': 46.11, '9': 61.67, '10': 93.89, '11': 77.78, '12': 85.56, '13': 82.22, '14': 55.56, '15': 95.56, '16': 93.89, '17': 95.56, '18': 94.44, '19': 93.89, '20': 96.11, '21': 90.0, '22': 87.22, '23': 70.56, '24': 69.44, '25': 75.56, '26': 87.78, '27': 87.22, '28': 69.44, '29': 79.44, '30': 89.44, '31': 82.22, '32': 93.33, '33': 68.33, '34': 81.11, '35': 97.22, '36': 97.22, '37': 76.67, '38': 97.22, '39': 93.89, '40': 88.89, '41': 98.33, '42': 99.44, '43': 98.33, '44': 86.11, '45': 45.56, '46': 62.78, '47': 58.33, '48': 54.44, '49': 57.78, '50': 54.44, '51': 59.44, '52': 55.0, '53': 52.78, 'old': 81.42, 'new': 54.89}
2025-01-11 15:15:17,778 [trainer.py] => NME: {'total': 72.55, '0': 65.56, '1': 58.33, '2': 74.44, '3': 31.67, '4': 78.33, '5': 40.0, '6': 61.11, '7': 53.89, '8': 43.89, '9': 47.22, '10': 88.33, '11': 86.11, '12': 76.67, '13': 65.0, '14': 54.44, '15': 85.56, '16': 89.44, '17': 92.78, '18': 88.89, '19': 89.44, '20': 91.67, '21': 88.33, '22': 78.33, '23': 62.78, '24': 75.0, '25': 76.11, '26': 83.89, '27': 80.56, '28': 58.33, '29': 69.44, '30': 72.78, '31': 78.33, '32': 85.56, '33': 56.11, '34': 85.0, '35': 95.0, '36': 90.0, '37': 61.67, '38': 92.22, '39': 86.11, '40': 70.56, '41': 90.56, '42': 96.11, '43': 93.89, '44': 54.44, '45': 71.67, '46': 77.78, '47': 70.56, '48': 61.11, '49': 56.11, '50': 52.22, '51': 67.22, '52': 59.44, '53': 66.11, 'old': 74.31, 'new': 64.61}
2025-01-11 15:15:17,778 [trainer.py] => CNN top1 curve: [89.44, 88.07, 81.52, 76.88, 76.6]
2025-01-11 15:15:17,778 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.79, 96.25, 96.01]
2025-01-11 15:15:17,778 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.17, 77.8, 72.55]
2025-01-11 15:15:17,778 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.48, 97.11, 95.28]

2025-01-11 16:58:20,083 [trainer.py] => 实验名称:msekd*lambda对比实验
2025-01-11 16:58:20,105 [trainer.py] => config: ./exps/der.json
2025-01-11 16:58:20,105 [trainer.py] => experiment_name: 实验名称:msekd*lambda对比实验
2025-01-11 16:58:20,106 [trainer.py] => prefix: reproduce
2025-01-11 16:58:20,106 [trainer.py] => dataset: xrfdataset
2025-01-11 16:58:20,106 [trainer.py] => memory_size: 1650
2025-01-11 16:58:20,106 [trainer.py] => memory_per_class: 30
2025-01-11 16:58:20,106 [trainer.py] => fixed_memory: True
2025-01-11 16:58:20,106 [trainer.py] => shuffle: True
2025-01-11 16:58:20,106 [trainer.py] => init_cls: 15
2025-01-11 16:58:20,106 [trainer.py] => increment: 10
2025-01-11 16:58:20,106 [trainer.py] => model_name: der
2025-01-11 16:58:20,106 [trainer.py] => compression_epochs: 130
2025-01-11 16:58:20,106 [trainer.py] => compression_lr: 0.1
2025-01-11 16:58:20,106 [trainer.py] => T: 2
2025-01-11 16:58:20,106 [trainer.py] => convnet_type: unet
2025-01-11 16:58:20,106 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-11 16:58:20,106 [trainer.py] => seed: 1993
2025-01-11 16:58:20,142 [data.py] => 加载完毕XRF原始数据集
2025-01-11 16:58:20,167 [data.py] => 加载完毕XRF原始数据集
2025-01-11 16:58:20,169 [trainer.py] => All params: 0
2025-01-11 16:58:20,169 [trainer.py] => Trainable params: 0
2025-01-11 16:58:20,337 [der.py] => Learning on 0-15
2025-01-11 16:58:20,337 [der.py] => All params: 21045611
2025-01-11 16:58:20,338 [der.py] => Trainable params: 21045611
2025-01-11 16:59:21,251 [trainer.py] => 实验名称:msekd_without_lambda对比实验
2025-01-11 16:59:21,276 [trainer.py] => config: ./exps/der.json
2025-01-11 16:59:21,276 [trainer.py] => experiment_name: 实验名称:msekd_without_lambda对比实验
2025-01-11 16:59:21,276 [trainer.py] => prefix: reproduce
2025-01-11 16:59:21,276 [trainer.py] => dataset: xrfdataset
2025-01-11 16:59:21,276 [trainer.py] => memory_size: 1650
2025-01-11 16:59:21,276 [trainer.py] => memory_per_class: 30
2025-01-11 16:59:21,276 [trainer.py] => fixed_memory: True
2025-01-11 16:59:21,276 [trainer.py] => shuffle: True
2025-01-11 16:59:21,276 [trainer.py] => init_cls: 15
2025-01-11 16:59:21,276 [trainer.py] => increment: 10
2025-01-11 16:59:21,276 [trainer.py] => model_name: der
2025-01-11 16:59:21,276 [trainer.py] => compression_epochs: 130
2025-01-11 16:59:21,276 [trainer.py] => compression_lr: 0.1
2025-01-11 16:59:21,276 [trainer.py] => T: 2
2025-01-11 16:59:21,276 [trainer.py] => convnet_type: unet
2025-01-11 16:59:21,276 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-11 16:59:21,277 [trainer.py] => seed: 1993
2025-01-11 16:59:21,299 [data.py] => 加载完毕XRF原始数据集
2025-01-11 16:59:21,305 [data.py] => 加载完毕XRF原始数据集
2025-01-11 16:59:21,306 [trainer.py] => All params: 0
2025-01-11 16:59:21,306 [trainer.py] => Trainable params: 0
2025-01-11 16:59:21,468 [der.py] => Learning on 0-15
2025-01-11 16:59:21,468 [der.py] => All params: 21045611
2025-01-11 16:59:21,468 [der.py] => Trainable params: 21045611
2025-01-11 17:36:27,802 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-11 17:36:27,819 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 17:36:54,562 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-11 17:36:54,562 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 17:36:54,860 [der.py] => Exemplar size: 450
2025-01-11 17:36:54,860 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-11 17:36:54,860 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-11 17:36:54,861 [trainer.py] => CNN top1 curve: [89.44]
2025-01-11 17:36:54,861 [trainer.py] => CNN top5 curve: [98.93]
2025-01-11 17:36:54,861 [trainer.py] => NME top1 curve: [88.22]
2025-01-11 17:36:54,861 [trainer.py] => NME top5 curve: [98.81]

2025-01-11 17:36:54,862 [trainer.py] => All params: 21045611
2025-01-11 17:36:54,862 [trainer.py] => Trainable params: 21045611
2025-01-11 17:36:55,144 [der.py] => Learning on 15-25
2025-01-11 17:36:55,145 [der.py] => All params: 42091068
2025-01-11 17:36:55,146 [der.py] => Trainable params: 21049456
2025-01-11 17:37:21,271 [der.py] => Exemplar size: 450
2025-01-11 17:37:21,271 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-11 17:37:21,271 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-11 17:37:21,271 [trainer.py] => CNN top1 curve: [89.44]
2025-01-11 17:37:21,272 [trainer.py] => CNN top5 curve: [98.93]
2025-01-11 17:37:21,272 [trainer.py] => NME top1 curve: [88.22]
2025-01-11 17:37:21,272 [trainer.py] => NME top5 curve: [98.81]

2025-01-11 17:37:21,272 [trainer.py] => All params: 21045611
2025-01-11 17:37:21,273 [trainer.py] => Trainable params: 21045611
2025-01-11 17:37:21,431 [der.py] => Learning on 15-25
2025-01-11 17:37:21,432 [der.py] => All params: 42091068
2025-01-11 17:37:21,432 [der.py] => Trainable params: 21049456
2025-01-11 18:29:27,506 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-11 18:29:33,583 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-11 18:29:48,408 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 0.100,  Train_accy 11.14, Test_accy 53.13
2025-01-11 18:29:53,414 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 0.062,  Train_accy 10.99, Test_accy 52.47
2025-01-11 18:30:01,855 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 0.085,  Train_accy 13.91
2025-01-11 18:30:08,407 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 0.054,  Train_accy 12.26
2025-01-11 18:30:16,366 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 0.079,  Train_accy 16.71
2025-01-11 18:30:23,117 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 0.050,  Train_accy 13.68
2025-01-11 18:30:30,955 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 0.074,  Train_accy 19.81
2025-01-11 18:30:37,761 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 0.048,  Train_accy 16.02
2025-01-11 18:30:44,915 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 0.071,  Train_accy 22.71
2025-01-11 18:30:52,349 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 0.047,  Train_accy 16.92
2025-01-11 18:31:05,472 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.067,  Train_accy 26.45, Test_accy 59.07
2025-01-11 18:31:11,686 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.045,  Train_accy 19.33, Test_accy 55.84
2025-01-11 18:31:18,757 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 0.064,  Train_accy 29.61
2025-01-11 18:31:26,532 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 0.043,  Train_accy 21.42
2025-01-11 18:31:33,242 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.062,  Train_accy 33.94
2025-01-11 18:31:41,413 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.042,  Train_accy 24.52
2025-01-11 18:31:47,763 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.059,  Train_accy 37.66
2025-01-11 18:31:55,793 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.041,  Train_accy 26.02
2025-01-11 18:32:02,126 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.057,  Train_accy 40.02
2025-01-11 18:32:10,797 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.040,  Train_accy 27.14
2025-01-11 18:32:22,726 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.054,  Train_accy 42.99, Test_accy 64.98
2025-01-11 18:32:29,936 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.039,  Train_accy 29.51, Test_accy 60.07
2025-01-11 18:32:35,885 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.053,  Train_accy 46.67
2025-01-11 18:32:44,808 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.038,  Train_accy 31.89
2025-01-11 18:32:50,348 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.051,  Train_accy 48.69
2025-01-11 18:32:59,606 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.037,  Train_accy 33.33
2025-01-11 18:33:04,764 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.050,  Train_accy 50.75
2025-01-11 18:33:14,325 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.036,  Train_accy 35.89
2025-01-11 18:33:19,147 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.048,  Train_accy 52.41
2025-01-11 18:33:28,988 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.035,  Train_accy 38.28
2025-01-11 18:33:38,870 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.047,  Train_accy 53.87, Test_accy 68.16
2025-01-11 18:33:48,177 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.034,  Train_accy 40.47, Test_accy 64.38
2025-01-11 18:33:51,691 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.046,  Train_accy 55.81
2025-01-11 18:34:02,708 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.034,  Train_accy 41.85
2025-01-11 18:34:05,888 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.045,  Train_accy 56.88
2025-01-11 18:34:17,688 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.033,  Train_accy 44.04
2025-01-11 18:34:20,556 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.044,  Train_accy 58.97
2025-01-11 18:34:31,940 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.032,  Train_accy 45.78
2025-01-11 18:34:34,651 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.044,  Train_accy 59.14
2025-01-11 18:34:46,999 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.032,  Train_accy 47.18
2025-01-11 18:34:55,207 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.043,  Train_accy 60.58, Test_accy 68.40
2025-01-11 18:35:06,128 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.031,  Train_accy 48.26, Test_accy 66.24
2025-01-11 18:35:07,921 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.042,  Train_accy 61.05
2025-01-11 18:35:20,398 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.030,  Train_accy 50.30
2025-01-11 18:35:22,071 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.041,  Train_accy 62.67
2025-01-11 18:35:35,541 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.029,  Train_accy 51.42
2025-01-11 18:35:36,870 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.040,  Train_accy 63.05
2025-01-11 18:35:50,701 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.029,  Train_accy 52.30
2025-01-11 18:35:51,620 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.039,  Train_accy 64.65
2025-01-11 18:36:05,096 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.029,  Train_accy 53.10
2025-01-11 18:36:11,848 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.039,  Train_accy 65.12, Test_accy 69.64
2025-01-11 18:36:24,321 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.028,  Train_accy 54.39, Test_accy 68.13
2025-01-11 18:36:24,844 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.039,  Train_accy 65.61
2025-01-11 18:36:39,069 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.028,  Train_accy 55.59
2025-01-11 18:36:39,418 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.038,  Train_accy 65.91
2025-01-11 18:36:54,052 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.027,  Train_accy 55.96
2025-01-11 18:36:54,089 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.037,  Train_accy 66.88
2025-01-11 18:37:09,130 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.037,  Train_accy 67.48
2025-01-11 18:37:09,355 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.027,  Train_accy 57.16
2025-01-11 18:37:24,082 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.027,  Train_accy 57.46
2025-01-11 18:37:29,000 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.037,  Train_accy 66.90, Test_accy 70.53
2025-01-11 18:37:42,860 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.037,  Train_accy 67.76
2025-01-11 18:37:43,610 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.027,  Train_accy 57.18, Test_accy 67.91
2025-01-11 18:37:57,440 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.036,  Train_accy 68.95
2025-01-11 18:37:58,784 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.027,  Train_accy 58.11
2025-01-11 18:38:11,490 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.035,  Train_accy 70.15
2025-01-11 18:38:13,154 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.026,  Train_accy 59.68
2025-01-11 18:38:26,325 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.035,  Train_accy 70.04
2025-01-11 18:38:28,250 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.026,  Train_accy 59.68
2025-01-11 18:38:42,445 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.025,  Train_accy 60.84
2025-01-11 18:39:22,964 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.025,  Train_accy 60.90, Test_accy 68.67
2025-01-11 18:39:22,969 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.035,  Train_accy 70.84, Test_accy 71.16
2025-01-11 18:39:38,002 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.034,  Train_accy 71.14
2025-01-11 18:39:38,225 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.025,  Train_accy 61.48
2025-01-11 18:39:52,185 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.034,  Train_accy 71.57
2025-01-11 18:39:52,843 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.025,  Train_accy 62.11
2025-01-11 18:40:06,314 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.034,  Train_accy 72.45
2025-01-11 18:40:07,287 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.025,  Train_accy 62.56
2025-01-11 18:40:21,015 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.033,  Train_accy 73.01
2025-01-11 18:40:22,397 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.024,  Train_accy 63.10
2025-01-11 18:40:52,557 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.033,  Train_accy 72.95, Test_accy 71.87
2025-01-11 18:40:52,580 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.024,  Train_accy 63.23, Test_accy 69.20
2025-01-11 18:41:07,814 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.033,  Train_accy 74.39
2025-01-11 18:41:07,842 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.024,  Train_accy 63.85
2025-01-11 18:41:22,860 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.032,  Train_accy 74.45
2025-01-11 18:41:23,360 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.024,  Train_accy 63.76
2025-01-11 18:41:37,359 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.032,  Train_accy 74.30
2025-01-11 18:41:37,985 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.024,  Train_accy 63.78
2025-01-11 18:41:52,153 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.032,  Train_accy 75.72
2025-01-11 18:41:52,954 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.023,  Train_accy 65.51
2025-01-11 18:42:35,424 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.032,  Train_accy 74.69, Test_accy 73.02
2025-01-11 18:42:35,471 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.024,  Train_accy 63.74, Test_accy 69.56
2025-01-11 18:42:49,893 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.031,  Train_accy 74.90
2025-01-11 18:42:50,262 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.023,  Train_accy 64.97
2025-01-11 18:43:04,180 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.031,  Train_accy 76.19
2025-01-11 18:43:04,989 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.023,  Train_accy 65.81
2025-01-11 18:43:19,311 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.031,  Train_accy 76.28
2025-01-11 18:43:20,143 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.023,  Train_accy 66.41
2025-01-11 18:43:34,556 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.031,  Train_accy 77.16
2025-01-11 18:43:35,431 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.023,  Train_accy 66.09
2025-01-11 18:44:24,707 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.030,  Train_accy 77.44, Test_accy 73.22
2025-01-11 18:44:24,799 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.023,  Train_accy 66.39, Test_accy 70.33
2025-01-11 18:44:39,826 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.030,  Train_accy 77.14
2025-01-11 18:44:40,142 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.023,  Train_accy 66.28
2025-01-11 18:44:54,388 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.030,  Train_accy 78.69
2025-01-11 18:44:55,092 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.022,  Train_accy 67.81
2025-01-11 18:45:08,627 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.030,  Train_accy 78.28
2025-01-11 18:45:09,757 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.022,  Train_accy 67.68
2025-01-11 18:45:22,813 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.029,  Train_accy 78.95
2025-01-11 18:45:24,099 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.022,  Train_accy 67.91
2025-01-11 18:45:42,784 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.029,  Train_accy 79.10, Test_accy 73.96
2025-01-11 18:45:44,805 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.022,  Train_accy 68.32, Test_accy 70.60
2025-01-11 18:45:56,739 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.029,  Train_accy 79.46
2025-01-11 18:45:59,404 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.022,  Train_accy 68.49
2025-01-11 18:46:11,227 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.029,  Train_accy 79.66
2025-01-11 18:46:14,363 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.022,  Train_accy 68.06
2025-01-11 18:46:25,575 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.029,  Train_accy 80.11
2025-01-11 18:46:29,063 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.022,  Train_accy 69.59
2025-01-11 18:46:39,606 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.028,  Train_accy 80.17
2025-01-11 18:46:43,850 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.021,  Train_accy 68.92
2025-01-11 18:46:59,177 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.028,  Train_accy 80.24, Test_accy 74.56
2025-01-11 18:47:04,597 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.021,  Train_accy 70.26, Test_accy 71.20
2025-01-11 18:47:12,571 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.028,  Train_accy 81.33
2025-01-11 18:47:19,108 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.022,  Train_accy 69.35
2025-01-11 18:47:28,512 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.028,  Train_accy 80.97
2025-01-11 18:48:29,810 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.021,  Train_accy 70.47
2025-01-11 18:50:05,244 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.021,  Train_accy 69.70
2025-01-11 18:50:05,244 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.028,  Train_accy 80.86
2025-01-11 18:51:05,359 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.027,  Train_accy 81.70
2025-01-11 18:51:05,418 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.021,  Train_accy 70.39
2025-01-11 18:54:11,306 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.027,  Train_accy 82.24, Test_accy 74.96
2025-01-11 18:54:11,326 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.021,  Train_accy 70.97, Test_accy 71.29
2025-01-11 18:56:12,552 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.027,  Train_accy 81.72
2025-01-11 18:56:12,601 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.021,  Train_accy 69.51
2025-01-11 18:57:01,268 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.027,  Train_accy 82.34
2025-01-11 18:57:01,303 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.021,  Train_accy 70.69
2025-01-11 18:57:40,659 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.027,  Train_accy 82.69
2025-01-11 18:57:40,728 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.021,  Train_accy 70.62
2025-01-11 18:59:09,307 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.021,  Train_accy 71.44
2025-01-11 18:59:09,312 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.027,  Train_accy 82.80
2025-01-11 19:02:18,413 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.027,  Train_accy 82.67, Test_accy 75.07
2025-01-11 19:02:18,420 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.021,  Train_accy 70.73, Test_accy 71.18
2025-01-11 19:03:53,598 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.027,  Train_accy 82.65
2025-01-11 19:03:53,598 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.021,  Train_accy 70.86
2025-01-11 19:04:14,418 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.026,  Train_accy 82.69
2025-01-11 19:04:14,955 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.020,  Train_accy 72.22
2025-01-11 19:04:45,001 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.027,  Train_accy 82.84
2025-01-11 19:04:45,103 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.021,  Train_accy 71.57
2025-01-11 19:05:02,033 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.026,  Train_accy 83.53
2025-01-11 19:05:02,166 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.020,  Train_accy 72.30
2025-01-11 19:07:12,335 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.020,  Train_accy 70.88, Test_accy 71.53
2025-01-11 19:07:12,335 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.026,  Train_accy 83.48, Test_accy 75.07
2025-01-11 19:09:26,777 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.020,  Train_accy 72.60
2025-01-11 19:09:26,779 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.026,  Train_accy 84.09
2025-01-11 19:10:31,981 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.026,  Train_accy 83.78
2025-01-11 19:10:34,532 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.020,  Train_accy 72.19
2025-01-11 19:10:46,746 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.026,  Train_accy 84.22
2025-01-11 19:10:48,861 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.020,  Train_accy 72.24
2025-01-11 19:11:00,848 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.026,  Train_accy 83.68
2025-01-11 19:11:03,514 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.020,  Train_accy 71.91
2025-01-11 19:13:17,692 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.020,  Train_accy 72.95, Test_accy 71.62
2025-01-11 19:13:17,699 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.026,  Train_accy 84.49, Test_accy 75.27
2025-01-11 19:13:32,654 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.026,  Train_accy 83.94
2025-01-11 19:13:33,232 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.020,  Train_accy 72.88
2025-01-11 19:13:46,949 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.026,  Train_accy 84.69
2025-01-11 19:13:48,047 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.020,  Train_accy 72.82
2025-01-11 19:14:01,167 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.025,  Train_accy 84.90
2025-01-11 19:14:02,705 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.020,  Train_accy 73.33
2025-01-11 19:14:15,426 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.025,  Train_accy 84.77
2025-01-11 19:14:17,520 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.020,  Train_accy 73.05
2025-01-11 19:14:35,056 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.025,  Train_accy 84.37, Test_accy 75.47
2025-01-11 19:14:37,382 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.019,  Train_accy 73.81, Test_accy 71.89
2025-01-11 19:14:48,785 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.025,  Train_accy 85.20
2025-01-11 19:14:51,690 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.020,  Train_accy 72.41
2025-01-11 19:15:02,780 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.026,  Train_accy 84.26
2025-01-11 19:15:06,107 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.020,  Train_accy 72.84
2025-01-11 19:15:16,750 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.025,  Train_accy 85.01
2025-01-11 19:15:20,411 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.020,  Train_accy 73.14
2025-01-11 19:15:30,759 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.025,  Train_accy 85.78
2025-01-11 19:15:34,821 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.019,  Train_accy 74.19
2025-01-11 19:15:50,396 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.025,  Train_accy 85.23, Test_accy 75.93
2025-01-11 19:15:54,718 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.020,  Train_accy 73.27, Test_accy 72.42
2025-01-11 19:16:04,137 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.025,  Train_accy 85.78
2025-01-11 19:16:09,683 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.020,  Train_accy 74.84
2025-01-11 19:16:18,642 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.025,  Train_accy 86.24
2025-01-11 19:16:24,610 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.019,  Train_accy 74.69
2025-01-11 19:16:32,843 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.025,  Train_accy 85.33
2025-01-11 19:16:39,227 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.020,  Train_accy 73.81
2025-01-11 19:16:46,998 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.025,  Train_accy 85.48
2025-01-11 19:16:53,769 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.020,  Train_accy 73.72
2025-01-11 19:17:06,704 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.025,  Train_accy 85.48, Test_accy 75.64
2025-01-11 19:17:13,367 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.019,  Train_accy 74.52, Test_accy 72.36
2025-01-11 19:17:19,310 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.025,  Train_accy 85.16
2025-01-11 19:17:27,954 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.020,  Train_accy 74.06
2025-01-11 19:17:33,491 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.025,  Train_accy 86.22
2025-01-11 19:17:43,003 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.019,  Train_accy 74.88
2025-01-11 19:17:47,826 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.025,  Train_accy 86.19
2025-01-11 19:17:57,977 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.019,  Train_accy 73.85
2025-01-11 19:18:02,213 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.025,  Train_accy 85.89
2025-01-11 19:18:12,154 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.020,  Train_accy 74.17
2025-01-11 19:18:21,633 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.025,  Train_accy 85.85, Test_accy 75.33
2025-01-11 19:18:31,876 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.019,  Train_accy 74.41, Test_accy 71.73
2025-01-11 19:18:33,995 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.025,  Train_accy 85.89
2025-01-11 19:18:46,865 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.020,  Train_accy 73.66
2025-01-11 19:18:48,728 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.025,  Train_accy 85.89
2025-01-11 19:19:01,955 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.019,  Train_accy 75.18
2025-01-11 19:19:03,273 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.024,  Train_accy 86.02
2025-01-11 19:19:16,349 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.019,  Train_accy 74.41
2025-01-11 19:19:17,174 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.024,  Train_accy 85.98
2025-01-11 19:19:30,743 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.019,  Train_accy 74.37
2025-01-11 19:19:36,858 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.024,  Train_accy 86.37, Test_accy 75.60
2025-01-11 19:19:50,189 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.024,  Train_accy 85.96
2025-01-11 19:19:50,607 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.019,  Train_accy 75.48, Test_accy 72.49
2025-01-11 19:20:05,001 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.025,  Train_accy 86.13
2025-01-11 19:20:05,781 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.019,  Train_accy 74.84
2025-01-11 19:20:19,286 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.025,  Train_accy 85.81
2025-01-11 19:20:20,846 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.019,  Train_accy 75.05
2025-01-11 19:20:33,011 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.025,  Train_accy 86.30
2025-01-11 19:20:35,583 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.019,  Train_accy 74.86
2025-01-11 19:20:50,296 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.019,  Train_accy 74.54
2025-01-11 19:20:52,802 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.024,  Train_accy 86.45, Test_accy 76.44
2025-01-11 19:21:06,791 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.024,  Train_accy 86.04
2025-01-11 19:21:10,778 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.019,  Train_accy 74.26, Test_accy 72.51
2025-01-11 19:21:20,093 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.024,  Train_accy 86.58
2025-01-11 19:21:25,396 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.019,  Train_accy 74.75
2025-01-11 19:21:34,501 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.024,  Train_accy 85.91
2025-01-11 19:21:40,567 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.019,  Train_accy 74.41
2025-01-11 19:21:48,743 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.024,  Train_accy 86.26
2025-01-11 19:21:55,506 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.019,  Train_accy 74.37
2025-01-11 19:22:08,621 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.024,  Train_accy 86.41, Test_accy 75.91
2025-01-11 19:22:09,230 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.019,  Train_accy 74.82
2025-01-11 19:22:22,977 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.024,  Train_accy 86.06
2025-01-11 19:22:30,555 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.019,  Train_accy 75.72, Test_accy 72.40
2025-01-11 19:22:35,399 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.024,  Train_accy 86.82
2025-01-11 19:22:45,174 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.019,  Train_accy 74.62
2025-01-11 19:22:49,447 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.024,  Train_accy 86.52
2025-01-11 19:22:59,990 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.019,  Train_accy 75.16
2025-01-11 19:23:03,931 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.024,  Train_accy 86.52
2025-01-11 19:23:14,824 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.019,  Train_accy 74.71
2025-01-11 19:23:23,792 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.024,  Train_accy 86.02, Test_accy 76.38
2025-01-11 19:23:28,344 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.019,  Train_accy 74.54
2025-01-11 19:23:38,133 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.024,  Train_accy 85.72
2025-01-11 19:23:49,347 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.019,  Train_accy 75.18, Test_accy 72.93
2025-01-11 19:23:50,486 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.024,  Train_accy 86.65
2025-01-11 19:24:03,510 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.019,  Train_accy 75.33
2025-01-11 19:24:04,326 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.024,  Train_accy 86.02
2025-01-11 19:24:17,732 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.019,  Train_accy 75.31
2025-01-11 19:24:18,318 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.024,  Train_accy 86.41
2025-01-11 19:24:32,878 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.019,  Train_accy 74.80
2025-01-11 19:24:38,898 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.024,  Train_accy 86.39, Test_accy 76.02
2025-01-11 19:24:46,805 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.019,  Train_accy 75.10
2025-01-11 19:24:53,349 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.024,  Train_accy 86.34
2025-01-11 19:25:06,414 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.024,  Train_accy 86.13
2025-01-11 19:25:07,266 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.019,  Train_accy 75.74, Test_accy 72.29
2025-01-11 19:25:20,495 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.024,  Train_accy 85.78
2025-01-11 19:25:22,114 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.019,  Train_accy 74.65
2025-01-11 19:25:34,787 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.024,  Train_accy 85.96
2025-01-11 19:25:36,769 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.019,  Train_accy 74.65
2025-01-11 19:25:39,815 [der.py] => darknet eval: 
2025-01-11 19:25:39,815 [der.py] => CNN top1 curve: 75.96
2025-01-11 19:25:39,815 [der.py] => CNN top5 curve: 98.04
2025-01-11 19:25:39,818 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 19:25:47,455 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.019,  Train_accy 75.20
2025-01-11 19:25:58,988 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.019,  Train_accy 74.95
2025-01-11 19:26:03,942 [der.py] => darknet eval: 
2025-01-11 19:26:03,942 [der.py] => CNN top1 curve: 72.36
2025-01-11 19:26:03,942 [der.py] => CNN top5 curve: 97.8
2025-01-11 19:26:03,943 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 19:26:08,373 [der.py] => Exemplar size: 750
2025-01-11 19:26:08,373 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-11 19:26:08,373 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-11 19:26:08,373 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-11 19:26:08,373 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-11 19:26:08,374 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-11 19:26:08,374 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-11 19:26:08,374 [trainer.py] => All params: 42091068
2025-01-11 19:26:08,375 [trainer.py] => Trainable params: 21049456
2025-01-11 19:26:08,585 [der.py] => Learning on 25-35
2025-01-11 19:26:08,586 [der.py] => All params: 63139730
2025-01-11 19:26:08,587 [der.py] => Trainable params: 21056506
2025-01-11 19:26:33,522 [der.py] => Exemplar size: 750
2025-01-11 19:26:33,522 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-11 19:26:33,522 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-11 19:26:33,523 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-11 19:26:33,523 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-11 19:26:33,523 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-11 19:26:33,523 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-11 19:26:33,523 [trainer.py] => All params: 42091068
2025-01-11 19:26:33,524 [trainer.py] => Trainable params: 21049456
2025-01-11 19:26:33,665 [der.py] => Learning on 25-35
2025-01-11 19:26:33,666 [der.py] => All params: 63139730
2025-01-11 19:26:33,666 [der.py] => Trainable params: 21056506
2025-01-11 20:20:31,703 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-11 20:20:36,484 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-11 20:20:57,098 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 0.101,  Train_accy 9.15, Test_accy 36.92
2025-01-11 20:21:01,502 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 0.073,  Train_accy 9.03, Test_accy 36.60
2025-01-11 20:21:14,160 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 0.087,  Train_accy 9.76
2025-01-11 20:21:19,943 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 0.065,  Train_accy 9.47
2025-01-11 20:21:31,784 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 0.080,  Train_accy 10.30
2025-01-11 20:21:37,763 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 0.060,  Train_accy 9.80
2025-01-11 20:21:49,855 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 0.076,  Train_accy 11.15
2025-01-11 20:21:56,188 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 0.057,  Train_accy 10.46
2025-01-11 20:22:07,693 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 0.072,  Train_accy 11.60
2025-01-11 20:22:14,116 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 0.055,  Train_accy 10.73
2025-01-11 20:22:32,923 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 0.070,  Train_accy 13.45, Test_accy 37.86
2025-01-11 20:22:38,064 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 0.053,  Train_accy 11.49, Test_accy 37.54
2025-01-11 20:22:49,702 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 0.067,  Train_accy 14.34
2025-01-11 20:22:56,527 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 0.051,  Train_accy 12.38
2025-01-11 20:23:07,772 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 0.065,  Train_accy 15.70
2025-01-11 20:23:14,426 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 0.050,  Train_accy 13.15
2025-01-11 20:23:25,495 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 0.063,  Train_accy 16.24
2025-01-11 20:23:32,663 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 0.049,  Train_accy 13.52
2025-01-11 20:23:43,487 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 0.062,  Train_accy 18.12
2025-01-11 20:23:50,584 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 0.048,  Train_accy 14.59
2025-01-11 20:24:09,281 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 0.061,  Train_accy 19.21, Test_accy 40.27
2025-01-11 20:24:14,545 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 0.047,  Train_accy 15.82, Test_accy 38.98
2025-01-11 20:24:26,160 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 0.060,  Train_accy 20.32
2025-01-11 20:24:32,383 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 0.046,  Train_accy 16.02
2025-01-11 20:24:44,056 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 0.058,  Train_accy 21.92
2025-01-11 20:24:50,256 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 0.045,  Train_accy 17.43
2025-01-11 20:25:02,245 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 0.057,  Train_accy 22.55
2025-01-11 20:25:08,161 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 0.044,  Train_accy 18.14
2025-01-11 20:25:20,162 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 0.056,  Train_accy 24.00
2025-01-11 20:25:26,491 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 0.043,  Train_accy 19.27
2025-01-11 20:25:45,656 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 0.055,  Train_accy 24.59, Test_accy 41.30
2025-01-11 20:25:50,312 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 0.043,  Train_accy 19.80, Test_accy 39.84
2025-01-11 20:26:02,584 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 0.055,  Train_accy 27.13
2025-01-11 20:26:08,195 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 0.042,  Train_accy 21.15
2025-01-11 20:26:20,753 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 0.053,  Train_accy 26.93
2025-01-11 20:26:26,184 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 0.041,  Train_accy 21.72
2025-01-11 20:26:39,325 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 0.053,  Train_accy 27.60
2025-01-11 20:26:44,278 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 0.041,  Train_accy 22.24
2025-01-11 20:26:57,059 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 0.052,  Train_accy 28.42
2025-01-11 20:27:02,426 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 0.040,  Train_accy 23.25
2025-01-11 20:27:21,877 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 0.052,  Train_accy 29.60, Test_accy 43.16
2025-01-11 20:27:27,181 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 0.040,  Train_accy 23.94, Test_accy 41.27
2025-01-11 20:27:38,693 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 0.051,  Train_accy 30.75
2025-01-11 20:27:46,035 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 0.039,  Train_accy 25.01
2025-01-11 20:27:56,469 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 0.050,  Train_accy 30.24
2025-01-11 20:28:04,595 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 0.039,  Train_accy 24.99
2025-01-11 20:28:14,233 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 0.050,  Train_accy 32.00
2025-01-11 20:28:23,174 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 0.039,  Train_accy 26.22
2025-01-11 20:28:31,884 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 0.049,  Train_accy 31.72
2025-01-11 20:28:41,303 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 0.038,  Train_accy 26.34
2025-01-11 20:28:57,124 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 0.048,  Train_accy 32.73, Test_accy 44.11
2025-01-11 20:29:05,392 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 0.038,  Train_accy 27.58, Test_accy 42.43
2025-01-11 20:29:12,657 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 0.048,  Train_accy 33.62
2025-01-11 20:29:23,519 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 0.038,  Train_accy 28.30
2025-01-11 20:29:30,465 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 0.048,  Train_accy 32.99
2025-01-11 20:29:41,689 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 0.037,  Train_accy 27.80
2025-01-11 20:29:48,254 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 0.047,  Train_accy 34.18
2025-01-11 20:29:59,940 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 0.037,  Train_accy 29.49
2025-01-11 20:30:05,913 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 0.046,  Train_accy 35.17
2025-01-11 20:30:17,970 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 0.036,  Train_accy 29.66
2025-01-11 20:30:31,076 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 0.046,  Train_accy 35.11, Test_accy 45.22
2025-01-11 20:30:42,110 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 0.036,  Train_accy 29.86, Test_accy 43.44
2025-01-11 20:30:45,957 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 0.045,  Train_accy 35.60
2025-01-11 20:31:00,215 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 0.036,  Train_accy 30.14
2025-01-11 20:31:03,396 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 0.046,  Train_accy 35.66
2025-01-11 20:31:18,345 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 0.036,  Train_accy 30.81
2025-01-11 20:31:21,108 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 0.045,  Train_accy 36.18
2025-01-11 20:31:36,419 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 0.036,  Train_accy 31.21
2025-01-11 20:31:38,689 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 0.045,  Train_accy 36.77
2025-01-11 20:31:54,280 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 0.035,  Train_accy 31.11
2025-01-11 20:32:03,850 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 0.044,  Train_accy 37.43, Test_accy 46.51
2025-01-11 20:32:18,653 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 0.035,  Train_accy 31.78, Test_accy 44.32
2025-01-11 20:32:19,293 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 0.044,  Train_accy 37.86
2025-01-11 20:32:36,882 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 0.035,  Train_accy 32.10
2025-01-11 20:32:37,272 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 0.044,  Train_accy 36.91
2025-01-11 20:32:55,666 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 0.035,  Train_accy 32.24
2025-01-11 20:32:55,966 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 0.044,  Train_accy 38.40
2025-01-11 20:33:14,537 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 0.035,  Train_accy 33.45
2025-01-11 20:33:14,541 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 0.043,  Train_accy 38.75
2025-01-11 20:33:33,568 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 0.034,  Train_accy 33.27
2025-01-11 20:33:40,993 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 0.043,  Train_accy 38.95, Test_accy 46.92
2025-01-11 20:33:57,084 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 0.042,  Train_accy 39.25
2025-01-11 20:33:58,257 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 0.034,  Train_accy 33.37, Test_accy 44.92
2025-01-11 20:34:14,515 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 0.042,  Train_accy 39.68
2025-01-11 20:34:16,219 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 0.034,  Train_accy 33.88
2025-01-11 20:34:32,044 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 0.041,  Train_accy 40.36
2025-01-11 20:34:34,204 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 0.034,  Train_accy 34.53
2025-01-11 20:34:49,545 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 0.041,  Train_accy 41.37
2025-01-11 20:34:52,133 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 0.033,  Train_accy 34.95
2025-01-11 20:35:10,041 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 0.033,  Train_accy 35.39
2025-01-11 20:35:14,756 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 0.041,  Train_accy 39.54, Test_accy 47.67
2025-01-11 20:35:31,913 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 0.041,  Train_accy 41.19
2025-01-11 20:35:35,639 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 0.033,  Train_accy 35.05, Test_accy 45.56
2025-01-11 20:35:48,836 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 0.041,  Train_accy 41.74
2025-01-11 20:35:53,790 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 0.033,  Train_accy 35.58
2025-01-11 20:36:06,528 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 0.041,  Train_accy 41.33
2025-01-11 20:36:11,955 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 0.033,  Train_accy 36.06
2025-01-11 20:36:24,248 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 0.040,  Train_accy 42.42
2025-01-11 20:36:30,094 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 0.032,  Train_accy 36.14
2025-01-11 20:36:47,449 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 0.032,  Train_accy 36.12
2025-01-11 20:36:49,835 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 0.040,  Train_accy 42.32, Test_accy 48.02
2025-01-11 20:37:07,164 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 0.039,  Train_accy 42.55
2025-01-11 20:37:13,169 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 0.032,  Train_accy 36.57, Test_accy 45.52
2025-01-11 20:37:23,710 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 0.039,  Train_accy 42.95
2025-01-11 20:37:31,242 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 0.032,  Train_accy 36.75
2025-01-11 20:37:41,170 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 0.039,  Train_accy 42.71
2025-01-11 20:37:49,317 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 0.032,  Train_accy 37.27
2025-01-11 20:37:58,693 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 0.039,  Train_accy 43.15
2025-01-11 20:38:07,835 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 0.032,  Train_accy 37.58
2025-01-11 20:38:24,435 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 0.038,  Train_accy 44.04, Test_accy 48.40
2025-01-11 20:38:24,569 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 0.032,  Train_accy 37.07
2025-01-11 20:38:42,481 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 0.039,  Train_accy 44.36
2025-01-11 20:38:51,005 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 0.031,  Train_accy 37.66, Test_accy 46.35
2025-01-11 20:38:57,863 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 0.038,  Train_accy 44.67
2025-01-11 20:39:09,238 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 0.031,  Train_accy 37.92
2025-01-11 20:39:16,080 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 0.038,  Train_accy 44.30
2025-01-11 20:39:27,878 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 0.031,  Train_accy 38.20
2025-01-11 20:39:33,722 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 0.038,  Train_accy 44.91
2025-01-11 20:39:46,022 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 0.031,  Train_accy 38.22
2025-01-11 20:39:59,390 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 0.037,  Train_accy 44.36, Test_accy 49.60
2025-01-11 20:40:02,338 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 0.031,  Train_accy 38.63
2025-01-11 20:40:17,357 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 0.038,  Train_accy 44.85
2025-01-11 20:40:28,810 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 0.030,  Train_accy 38.89, Test_accy 47.03
2025-01-11 20:40:32,529 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 0.037,  Train_accy 45.33
2025-01-11 20:40:47,047 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 0.031,  Train_accy 38.28
2025-01-11 20:40:50,295 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 0.038,  Train_accy 45.52
2025-01-11 20:41:05,122 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 0.030,  Train_accy 39.15
2025-01-11 20:41:08,047 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 0.037,  Train_accy 46.10
2025-01-11 20:41:23,177 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 0.031,  Train_accy 38.97
2025-01-11 20:41:33,883 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 0.037,  Train_accy 46.42, Test_accy 50.02
2025-01-11 20:41:38,834 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 0.030,  Train_accy 39.88
2025-01-11 20:41:51,421 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 0.037,  Train_accy 46.46
2025-01-11 20:42:04,653 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 0.030,  Train_accy 39.80, Test_accy 47.25
2025-01-11 20:42:07,033 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 0.036,  Train_accy 47.19
2025-01-11 20:42:22,651 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 0.030,  Train_accy 39.43
2025-01-11 20:42:25,115 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 0.037,  Train_accy 46.20
2025-01-11 20:42:40,744 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 0.030,  Train_accy 39.94
2025-01-11 20:42:43,092 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 0.037,  Train_accy 46.91
2025-01-11 20:42:58,582 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 0.030,  Train_accy 39.60
2025-01-11 20:43:09,075 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 0.036,  Train_accy 47.27, Test_accy 50.75
2025-01-11 20:43:14,540 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 0.030,  Train_accy 39.98
2025-01-11 20:43:27,016 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 0.036,  Train_accy 47.94
2025-01-11 20:43:40,881 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 0.030,  Train_accy 40.51, Test_accy 47.79
2025-01-11 20:43:42,531 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 0.036,  Train_accy 47.33
2025-01-11 20:43:58,971 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 0.029,  Train_accy 41.03
2025-01-11 20:44:00,405 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 0.036,  Train_accy 48.48
2025-01-11 20:44:16,988 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 0.029,  Train_accy 40.32
2025-01-11 20:44:17,927 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 0.036,  Train_accy 46.93
2025-01-11 20:44:35,155 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 0.029,  Train_accy 41.62
2025-01-11 20:44:43,739 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 0.036,  Train_accy 47.43, Test_accy 50.94
2025-01-11 20:44:51,004 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 0.030,  Train_accy 40.12
2025-01-11 20:45:01,404 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 0.036,  Train_accy 48.18
2025-01-11 20:45:17,322 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 0.029,  Train_accy 40.40, Test_accy 47.62
2025-01-11 20:45:17,483 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 0.036,  Train_accy 48.46
2025-01-11 20:45:36,299 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 0.036,  Train_accy 49.21
2025-01-11 20:45:36,439 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 0.029,  Train_accy 40.89
2025-01-11 20:45:54,321 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 0.036,  Train_accy 48.75
2025-01-11 20:45:54,717 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 0.029,  Train_accy 41.19
2025-01-11 20:46:12,665 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 0.029,  Train_accy 41.29
2025-01-11 20:46:19,564 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 0.036,  Train_accy 49.37, Test_accy 50.90
2025-01-11 20:46:29,462 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 0.029,  Train_accy 41.07
2025-01-11 20:46:37,081 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 0.035,  Train_accy 49.11
2025-01-11 20:46:53,656 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 0.035,  Train_accy 49.13
2025-01-11 20:46:55,077 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 0.029,  Train_accy 41.66, Test_accy 47.81
2025-01-11 20:47:11,232 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 0.035,  Train_accy 49.47
2025-01-11 20:47:13,363 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 0.029,  Train_accy 41.70
2025-01-11 20:47:28,934 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 0.035,  Train_accy 49.39
2025-01-11 20:47:31,542 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 0.029,  Train_accy 41.45
2025-01-11 20:47:49,183 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 0.029,  Train_accy 42.10
2025-01-11 20:47:54,226 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 0.035,  Train_accy 49.49, Test_accy 51.05
2025-01-11 20:48:06,225 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 0.029,  Train_accy 41.64
2025-01-11 20:48:11,759 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 0.035,  Train_accy 50.36
2025-01-11 20:48:28,652 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 0.035,  Train_accy 50.26
2025-01-11 20:48:31,873 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 0.029,  Train_accy 41.35, Test_accy 47.98
2025-01-11 20:48:46,168 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 0.034,  Train_accy 51.43
2025-01-11 20:48:50,217 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 0.028,  Train_accy 42.34
2025-01-11 20:49:04,185 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 0.034,  Train_accy 50.38
2025-01-11 20:49:08,671 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 0.029,  Train_accy 41.96
2025-01-11 20:49:25,919 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 0.028,  Train_accy 43.03
2025-01-11 20:49:29,765 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 0.034,  Train_accy 50.20, Test_accy 50.90
2025-01-11 20:49:43,292 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 0.028,  Train_accy 42.55
2025-01-11 20:49:47,414 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 0.034,  Train_accy 51.15
2025-01-11 20:50:04,225 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 0.035,  Train_accy 50.04
2025-01-11 20:50:08,964 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 0.028,  Train_accy 42.20, Test_accy 48.06
2025-01-11 20:50:21,042 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 0.034,  Train_accy 50.51
2025-01-11 20:50:27,210 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 0.028,  Train_accy 42.97
2025-01-11 20:50:39,004 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 0.034,  Train_accy 50.46
2025-01-11 20:50:45,201 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 0.028,  Train_accy 42.40
2025-01-11 20:51:01,967 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 0.028,  Train_accy 42.57
2025-01-11 20:51:03,928 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 0.035,  Train_accy 50.59, Test_accy 51.49
2025-01-11 20:51:19,544 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 0.028,  Train_accy 42.77
2025-01-11 20:51:21,576 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 0.034,  Train_accy 51.43
2025-01-11 20:51:39,606 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 0.035,  Train_accy 50.81
2025-01-11 20:51:45,868 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 0.029,  Train_accy 42.65, Test_accy 48.25
2025-01-11 20:51:55,832 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 0.034,  Train_accy 50.12
2025-01-11 20:52:03,915 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 0.028,  Train_accy 43.01
2025-01-11 20:52:13,503 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 0.034,  Train_accy 51.03
2025-01-11 20:52:22,129 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 0.028,  Train_accy 43.11
2025-01-11 20:52:38,269 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 0.028,  Train_accy 42.55
2025-01-11 20:52:38,706 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 0.034,  Train_accy 50.73, Test_accy 51.86
2025-01-11 20:52:56,665 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 0.028,  Train_accy 42.00
2025-01-11 20:52:57,056 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 0.034,  Train_accy 50.59
2025-01-11 20:53:15,300 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 0.034,  Train_accy 51.15
2025-01-11 20:53:23,337 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 0.028,  Train_accy 42.79, Test_accy 48.49
2025-01-11 20:53:31,420 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 0.035,  Train_accy 49.86
2025-01-11 20:53:41,920 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 0.028,  Train_accy 42.81
2025-01-11 20:53:49,325 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 0.033,  Train_accy 51.07
2025-01-11 20:54:00,288 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 0.028,  Train_accy 43.19
2025-01-11 20:54:15,330 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 0.034,  Train_accy 51.29, Test_accy 51.70
2025-01-11 20:54:16,206 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 0.028,  Train_accy 41.78
2025-01-11 20:54:33,468 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 0.034,  Train_accy 51.54
2025-01-11 20:54:34,752 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 0.028,  Train_accy 43.25
2025-01-11 20:54:51,167 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 0.034,  Train_accy 51.31
2025-01-11 20:55:00,861 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 0.028,  Train_accy 42.87, Test_accy 48.29
2025-01-11 20:55:06,402 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 0.034,  Train_accy 50.42
2025-01-11 20:55:18,871 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 0.028,  Train_accy 42.71
2025-01-11 20:55:24,263 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 0.034,  Train_accy 51.29
2025-01-11 20:55:36,754 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 0.028,  Train_accy 42.91
2025-01-11 20:55:49,679 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 0.034,  Train_accy 51.78, Test_accy 52.38
2025-01-11 20:55:52,803 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 0.028,  Train_accy 42.55
2025-01-11 20:56:07,048 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 0.034,  Train_accy 52.26
2025-01-11 20:56:11,019 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 0.028,  Train_accy 43.54
2025-01-11 20:56:25,085 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 0.033,  Train_accy 51.68
2025-01-11 20:56:37,558 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 0.028,  Train_accy 43.43, Test_accy 48.86
2025-01-11 20:56:40,311 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 0.034,  Train_accy 51.05
2025-01-11 20:56:55,705 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 0.028,  Train_accy 43.74
2025-01-11 20:56:58,041 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 0.034,  Train_accy 50.93
2025-01-11 20:57:13,514 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 0.028,  Train_accy 43.09
2025-01-11 20:57:23,432 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 0.034,  Train_accy 51.19, Test_accy 51.83
2025-01-11 20:57:29,229 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 0.028,  Train_accy 42.77
2025-01-11 20:57:41,394 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 0.034,  Train_accy 51.43
2025-01-11 20:57:47,739 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 0.028,  Train_accy 42.93
2025-01-11 20:57:59,162 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 0.034,  Train_accy 51.01
2025-01-11 20:58:13,939 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 0.028,  Train_accy 42.73, Test_accy 48.54
2025-01-11 20:58:14,737 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 0.034,  Train_accy 52.24
2025-01-11 20:58:32,059 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 0.028,  Train_accy 42.65
2025-01-11 20:58:32,707 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 0.033,  Train_accy 51.45
2025-01-11 20:58:50,701 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 0.028,  Train_accy 43.05
2025-01-11 20:58:58,919 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 0.034,  Train_accy 52.18, Test_accy 51.92
2025-01-11 20:59:07,184 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 0.028,  Train_accy 43.23
2025-01-11 20:59:16,668 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 0.034,  Train_accy 51.15
2025-01-11 20:59:25,014 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 0.028,  Train_accy 42.91
2025-01-11 20:59:34,519 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 0.034,  Train_accy 51.88
2025-01-11 20:59:50,784 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 0.033,  Train_accy 52.57
2025-01-11 20:59:50,949 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 0.028,  Train_accy 43.56, Test_accy 48.63
2025-01-11 21:00:08,669 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 0.034,  Train_accy 52.16
2025-01-11 21:00:09,098 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 0.028,  Train_accy 43.43
2025-01-11 21:00:27,383 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 0.028,  Train_accy 42.99
2025-01-11 21:00:34,108 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 0.034,  Train_accy 51.56, Test_accy 52.13
2025-01-11 21:00:44,435 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 0.028,  Train_accy 43.68
2025-01-11 21:00:51,974 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 0.034,  Train_accy 50.61
2025-01-11 21:01:03,087 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 0.028,  Train_accy 43.43
2025-01-11 21:01:10,067 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 0.034,  Train_accy 52.00
2025-01-11 21:01:25,703 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 0.034,  Train_accy 51.47
2025-01-11 21:01:37,155 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 0.034,  Train_accy 50.91
2025-01-11 21:03:35,167 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 0.028,  Train_accy 43.13, Test_accy 48.78
2025-01-11 21:04:31,353 [der.py] => darknet eval: 
2025-01-11 21:04:31,354 [der.py] => CNN top1 curve: 51.79
2025-01-11 21:04:31,354 [der.py] => CNN top5 curve: 91.06
2025-01-11 21:04:31,356 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 21:04:45,774 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 0.028,  Train_accy 42.46
2025-01-11 21:05:00,001 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 0.028,  Train_accy 43.68
2025-01-11 21:05:11,597 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 0.028,  Train_accy 42.89
2025-01-11 21:05:26,358 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 0.028,  Train_accy 42.85
2025-01-11 21:05:33,019 [der.py] => darknet eval: 
2025-01-11 21:05:33,019 [der.py] => CNN top1 curve: 48.4
2025-01-11 21:05:33,019 [der.py] => CNN top5 curve: 88.38
2025-01-11 21:05:33,021 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 21:05:38,288 [der.py] => Exemplar size: 1050
2025-01-11 21:05:38,288 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-11 21:05:38,289 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-11 21:05:38,289 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-11 21:05:38,289 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-11 21:05:38,289 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-11 21:05:38,289 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-11 21:05:38,290 [trainer.py] => All params: 63139730
2025-01-11 21:05:38,291 [trainer.py] => Trainable params: 21056506
2025-01-11 21:05:38,545 [der.py] => Learning on 35-45
2025-01-11 21:05:38,549 [der.py] => All params: 84190952
2025-01-11 21:05:38,550 [der.py] => Trainable params: 21066116
2025-01-11 21:06:15,915 [der.py] => Exemplar size: 1050
2025-01-11 21:06:15,915 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-11 21:06:15,915 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-11 21:06:15,915 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-11 21:06:15,915 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-11 21:06:15,915 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-11 21:06:15,915 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-11 21:06:15,916 [trainer.py] => All params: 63139730
2025-01-11 21:06:15,917 [trainer.py] => Trainable params: 21056506
2025-01-11 21:06:16,046 [der.py] => Learning on 35-45
2025-01-11 21:06:16,048 [der.py] => All params: 84190952
2025-01-11 21:06:16,049 [der.py] => Trainable params: 21066116
2025-01-11 22:34:02,578 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-11 22:34:03,429 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-11 22:34:33,775 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 0.333,  Train_accy 8.80, Test_accy 27.93
2025-01-11 22:34:35,145 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 0.264,  Train_accy 8.69, Test_accy 27.93
2025-01-11 22:34:55,780 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 0.259,  Train_accy 8.90
2025-01-11 22:34:57,373 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 0.211,  Train_accy 8.91
2025-01-11 22:35:17,889 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 0.233,  Train_accy 9.43
2025-01-11 22:35:19,524 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 0.191,  Train_accy 9.16
2025-01-11 22:35:40,293 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 0.219,  Train_accy 10.67
2025-01-11 22:35:41,719 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 0.180,  Train_accy 9.68
2025-01-11 22:36:02,503 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 0.203,  Train_accy 11.70
2025-01-11 22:36:04,431 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 0.167,  Train_accy 10.69
2025-01-11 22:36:34,275 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 0.188,  Train_accy 13.81, Test_accy 26.54
2025-01-11 22:36:35,701 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 0.156,  Train_accy 12.00, Test_accy 25.85
2025-01-11 22:36:56,196 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 0.184,  Train_accy 14.72
2025-01-11 22:36:58,074 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 0.152,  Train_accy 13.10
2025-01-11 22:37:18,914 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 0.182,  Train_accy 15.90
2025-01-11 22:37:20,502 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 0.151,  Train_accy 14.30
2025-01-11 22:37:41,141 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 0.173,  Train_accy 17.26
2025-01-11 22:37:42,795 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 0.143,  Train_accy 15.03
2025-01-11 22:38:03,584 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 0.163,  Train_accy 18.32
2025-01-11 22:38:04,732 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 0.136,  Train_accy 16.00
2025-01-11 22:38:35,201 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 0.167,  Train_accy 19.77, Test_accy 29.64
2025-01-11 22:38:36,156 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 0.138,  Train_accy 17.14, Test_accy 29.22
2025-01-11 22:38:57,485 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 0.154,  Train_accy 20.27
2025-01-11 22:38:58,590 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 0.128,  Train_accy 17.85
2025-01-11 22:39:19,648 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 0.166,  Train_accy 21.50
2025-01-11 22:39:21,366 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 0.137,  Train_accy 18.57
2025-01-11 22:39:41,897 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 0.152,  Train_accy 22.69
2025-01-11 22:39:43,644 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 0.127,  Train_accy 19.62
2025-01-11 22:40:04,229 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 0.149,  Train_accy 24.04
2025-01-11 22:40:05,991 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 0.125,  Train_accy 20.50
2025-01-11 22:40:36,264 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 0.143,  Train_accy 25.41, Test_accy 31.64
2025-01-11 22:40:37,184 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 0.120,  Train_accy 21.66, Test_accy 29.65
2025-01-11 22:40:58,207 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 0.137,  Train_accy 25.90
2025-01-11 22:40:59,403 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 0.115,  Train_accy 21.96
2025-01-11 22:41:20,405 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 0.135,  Train_accy 27.50
2025-01-11 22:41:21,570 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 0.114,  Train_accy 23.30
2025-01-11 22:41:42,706 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 0.135,  Train_accy 28.76
2025-01-11 22:41:43,999 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 0.114,  Train_accy 24.27
2025-01-11 22:42:05,182 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 0.129,  Train_accy 29.01
2025-01-11 22:42:06,438 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 0.110,  Train_accy 24.95
2025-01-11 22:42:37,302 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 0.126,  Train_accy 29.73, Test_accy 31.77
2025-01-11 22:42:37,566 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 0.107,  Train_accy 25.71, Test_accy 30.26
2025-01-11 22:43:00,181 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 0.124,  Train_accy 30.59
2025-01-11 22:43:00,516 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 0.106,  Train_accy 26.36
2025-01-11 22:43:23,030 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 0.129,  Train_accy 31.62
2025-01-11 22:43:23,738 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 0.110,  Train_accy 27.41
2025-01-11 22:43:45,222 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 0.121,  Train_accy 32.29
2025-01-11 22:43:46,371 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 0.104,  Train_accy 27.98
2025-01-11 22:44:07,822 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 0.122,  Train_accy 32.84
2025-01-11 22:44:09,041 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 0.104,  Train_accy 28.32
2025-01-11 22:44:39,647 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 0.116,  Train_accy 33.98, Test_accy 35.99
2025-01-11 22:44:40,234 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 0.100,  Train_accy 29.77, Test_accy 34.21
2025-01-11 22:45:02,426 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 0.133,  Train_accy 33.94
2025-01-11 22:45:03,134 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 0.113,  Train_accy 30.38
2025-01-11 22:45:24,898 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 0.109,  Train_accy 34.88
2025-01-11 22:45:25,628 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 0.094,  Train_accy 31.05
2025-01-11 22:45:47,219 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 0.113,  Train_accy 34.74
2025-01-11 22:45:48,111 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 0.097,  Train_accy 31.22
2025-01-11 22:46:09,680 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 0.106,  Train_accy 35.70
2025-01-11 22:46:10,572 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 0.092,  Train_accy 32.21
2025-01-11 22:46:41,281 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 0.107,  Train_accy 36.48, Test_accy 37.33
2025-01-11 22:46:42,191 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 0.092,  Train_accy 32.38, Test_accy 35.75
2025-01-11 22:47:03,266 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 0.107,  Train_accy 35.81
2025-01-11 22:47:04,403 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 0.092,  Train_accy 32.57
2025-01-11 22:47:26,091 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 0.104,  Train_accy 36.72
2025-01-11 22:47:27,131 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 0.090,  Train_accy 33.43
2025-01-11 22:47:48,264 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 0.111,  Train_accy 37.50
2025-01-11 22:47:49,235 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 0.095,  Train_accy 34.00
2025-01-11 22:48:10,862 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 0.112,  Train_accy 37.56
2025-01-11 22:48:11,576 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 0.096,  Train_accy 34.55
2025-01-11 22:48:43,442 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 0.106,  Train_accy 37.41, Test_accy 38.10
2025-01-11 22:48:43,909 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 0.091,  Train_accy 34.38, Test_accy 36.37
2025-01-11 22:49:06,312 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 0.099,  Train_accy 38.23
2025-01-11 22:49:07,004 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 0.086,  Train_accy 34.76
2025-01-11 22:49:28,907 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 0.096,  Train_accy 38.55
2025-01-11 22:49:29,822 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 0.083,  Train_accy 35.24
2025-01-11 22:49:51,734 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 0.100,  Train_accy 38.99
2025-01-11 22:49:52,946 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 0.086,  Train_accy 35.75
2025-01-11 22:50:14,057 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 0.095,  Train_accy 38.88
2025-01-11 22:50:15,205 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 0.083,  Train_accy 35.62
2025-01-11 22:50:45,291 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 0.098,  Train_accy 39.28, Test_accy 38.59
2025-01-11 22:50:46,096 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 0.085,  Train_accy 36.91, Test_accy 36.83
2025-01-11 22:51:07,675 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 0.096,  Train_accy 39.60
2025-01-11 22:51:08,384 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 0.083,  Train_accy 36.86
2025-01-11 22:51:29,623 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 0.090,  Train_accy 39.43
2025-01-11 22:51:30,782 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 0.078,  Train_accy 36.53
2025-01-11 22:51:51,927 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 0.094,  Train_accy 40.27
2025-01-11 22:51:53,376 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 0.081,  Train_accy 37.54
2025-01-11 22:52:14,097 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 0.093,  Train_accy 39.89
2025-01-11 22:52:15,899 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 0.081,  Train_accy 37.31
2025-01-11 22:55:42,747 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 0.104,  Train_accy 40.97, Test_accy 40.21
2025-01-11 22:55:42,747 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 0.089,  Train_accy 37.94, Test_accy 38.04
2025-01-11 22:58:06,195 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 0.089,  Train_accy 40.57
2025-01-11 22:58:06,272 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 0.078,  Train_accy 38.06
2025-01-11 22:58:28,407 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 0.087,  Train_accy 41.22
2025-01-11 22:58:28,831 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 0.075,  Train_accy 38.19
2025-01-11 22:58:50,584 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 0.088,  Train_accy 40.82
2025-01-11 22:58:51,404 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 0.076,  Train_accy 37.54
2025-01-11 22:59:12,754 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 0.086,  Train_accy 40.88
2025-01-11 22:59:13,914 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 0.074,  Train_accy 38.02
2025-01-11 23:00:38,179 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 0.075,  Train_accy 38.91, Test_accy 38.93
2025-01-11 23:00:38,278 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 0.087,  Train_accy 41.50, Test_accy 41.22
2025-01-11 23:01:00,761 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 0.083,  Train_accy 42.40
2025-01-11 23:01:00,949 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 0.072,  Train_accy 38.72
2025-01-11 23:01:23,502 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 0.085,  Train_accy 41.98
2025-01-11 23:01:23,866 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 0.074,  Train_accy 39.10
2025-01-11 23:01:45,873 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 0.084,  Train_accy 41.96
2025-01-11 23:01:46,661 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 0.073,  Train_accy 39.39
2025-01-11 23:02:08,137 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 0.089,  Train_accy 42.30
2025-01-11 23:02:09,319 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 0.077,  Train_accy 39.22
2025-01-11 23:04:43,868 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 0.087,  Train_accy 42.44, Test_accy 38.38
2025-01-11 23:04:43,904 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 0.076,  Train_accy 40.10, Test_accy 36.86
2025-01-11 23:05:07,951 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 0.078,  Train_accy 40.10
2025-01-11 23:05:08,062 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 0.091,  Train_accy 42.90
2025-01-11 23:05:30,672 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 0.092,  Train_accy 42.30
2025-01-11 23:05:30,799 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 0.078,  Train_accy 39.22
2025-01-11 23:05:53,132 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 0.084,  Train_accy 41.62
2025-01-11 23:05:53,620 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 0.072,  Train_accy 39.35
2025-01-11 23:06:15,197 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 0.079,  Train_accy 42.86
2025-01-11 23:06:15,986 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 0.069,  Train_accy 39.31
2025-01-11 23:07:39,606 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 0.081,  Train_accy 42.02, Test_accy 38.74
2025-01-11 23:07:39,739 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 0.070,  Train_accy 39.89, Test_accy 37.26
2025-01-11 23:08:01,850 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 0.081,  Train_accy 43.37
2025-01-11 23:08:02,335 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 0.070,  Train_accy 40.02
2025-01-11 23:08:24,086 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 0.078,  Train_accy 43.49
2025-01-11 23:08:24,835 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 0.068,  Train_accy 40.99
2025-01-11 23:08:46,806 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 0.081,  Train_accy 43.41
2025-01-11 23:08:47,269 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 0.070,  Train_accy 41.20
2025-01-11 23:09:09,583 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 0.108,  Train_accy 43.89
2025-01-11 23:09:10,008 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 0.092,  Train_accy 40.97
2025-01-11 23:10:11,169 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 0.078,  Train_accy 42.67, Test_accy 41.49
2025-01-11 23:10:11,191 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 0.067,  Train_accy 40.40, Test_accy 39.74
2025-01-11 23:10:36,000 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 0.077,  Train_accy 43.71
2025-01-11 23:10:36,164 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 0.067,  Train_accy 41.14
2025-01-11 23:10:58,443 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 0.091,  Train_accy 43.79
2025-01-11 23:10:59,005 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 0.078,  Train_accy 41.07
2025-01-11 23:11:20,726 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 0.080,  Train_accy 43.94
2025-01-11 23:11:21,418 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 0.069,  Train_accy 41.16
2025-01-11 23:11:43,259 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 0.079,  Train_accy 44.51
2025-01-11 23:11:44,085 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 0.069,  Train_accy 42.10
2025-01-11 23:12:24,923 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 0.077,  Train_accy 44.25, Test_accy 40.86
2025-01-11 23:12:25,011 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 0.067,  Train_accy 41.45, Test_accy 39.94
2025-01-11 23:12:47,764 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 0.082,  Train_accy 44.63
2025-01-11 23:12:48,412 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 0.071,  Train_accy 41.98
2025-01-11 23:13:09,909 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 0.081,  Train_accy 44.32
2025-01-11 23:13:11,175 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 0.070,  Train_accy 41.75
2025-01-11 23:13:31,950 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 0.077,  Train_accy 44.30
2025-01-11 23:13:33,379 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 0.067,  Train_accy 41.31
2025-01-11 23:13:54,651 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 0.078,  Train_accy 44.72
2025-01-11 23:13:55,755 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 0.067,  Train_accy 41.87
2025-01-11 23:14:29,886 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 0.068,  Train_accy 42.80, Test_accy 40.31
2025-01-11 23:14:30,302 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 0.078,  Train_accy 45.43, Test_accy 41.21
2025-01-11 23:14:52,364 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 0.068,  Train_accy 41.64
2025-01-11 23:14:52,880 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 0.079,  Train_accy 43.98
2025-01-11 23:15:15,394 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 0.068,  Train_accy 41.68
2025-01-11 23:15:15,990 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 0.079,  Train_accy 45.03
2025-01-11 23:15:37,681 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 0.069,  Train_accy 41.64
2025-01-11 23:15:38,511 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 0.080,  Train_accy 44.46
2025-01-11 23:16:00,113 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 0.068,  Train_accy 42.34
2025-01-11 23:16:00,983 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 0.078,  Train_accy 45.22
2025-01-11 23:16:30,978 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 0.069,  Train_accy 42.53, Test_accy 39.65
2025-01-11 23:16:32,331 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 0.080,  Train_accy 45.49, Test_accy 41.72
2025-01-11 23:16:53,269 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 0.069,  Train_accy 42.82
2025-01-11 23:16:54,317 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 0.080,  Train_accy 45.26
2025-01-11 23:17:15,783 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 0.064,  Train_accy 42.46
2025-01-11 23:17:16,488 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 0.073,  Train_accy 44.61
2025-01-11 23:17:38,453 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 0.067,  Train_accy 42.32
2025-01-11 23:17:39,169 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 0.077,  Train_accy 44.84
2025-01-11 23:18:01,114 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 0.065,  Train_accy 42.19
2025-01-11 23:18:01,826 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 0.075,  Train_accy 44.57
2025-01-11 23:18:31,704 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.066,  Train_accy 42.17, Test_accy 37.58
2025-01-11 23:18:32,355 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.077,  Train_accy 45.60, Test_accy 38.84
2025-01-11 23:18:54,125 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 0.069,  Train_accy 42.59
2025-01-11 23:18:54,822 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 0.080,  Train_accy 45.22
2025-01-11 23:19:16,534 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 0.072,  Train_accy 41.90
2025-01-11 23:19:17,221 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 0.083,  Train_accy 44.63
2025-01-11 23:19:38,845 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 0.070,  Train_accy 42.44
2025-01-11 23:19:39,631 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 0.082,  Train_accy 45.39
2025-01-11 23:20:01,074 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 0.064,  Train_accy 43.05
2025-01-11 23:20:01,971 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 0.073,  Train_accy 45.30
2025-01-11 23:20:32,067 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 0.060,  Train_accy 42.72, Test_accy 41.12
2025-01-11 23:20:33,014 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 0.069,  Train_accy 45.45, Test_accy 42.68
2025-01-11 23:20:54,183 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.070,  Train_accy 43.20
2025-01-11 23:20:55,359 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.081,  Train_accy 46.15
2025-01-11 23:21:16,473 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 0.064,  Train_accy 43.01
2025-01-11 23:21:17,531 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 0.073,  Train_accy 45.87
2025-01-11 23:21:38,582 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 0.064,  Train_accy 43.10
2025-01-11 23:21:39,733 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 0.074,  Train_accy 46.08
2025-01-11 23:22:00,688 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.072,  Train_accy 42.36
2025-01-11 23:22:01,739 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.084,  Train_accy 45.54
2025-01-11 23:24:02,185 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.069,  Train_accy 43.33, Test_accy 41.12
2025-01-11 23:24:02,191 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.080,  Train_accy 46.61, Test_accy 42.64
2025-01-11 23:24:24,824 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 0.077,  Train_accy 46.13
2025-01-11 23:24:24,946 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 0.067,  Train_accy 43.18
2025-01-11 23:24:47,688 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 0.074,  Train_accy 45.87
2025-01-11 23:24:47,793 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 0.064,  Train_accy 43.07
2025-01-11 23:25:10,508 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 0.088,  Train_accy 46.17
2025-01-11 23:25:10,625 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 0.075,  Train_accy 42.97
2025-01-11 23:25:33,380 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 0.068,  Train_accy 45.52
2025-01-11 23:25:33,443 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 0.060,  Train_accy 42.76
2025-01-11 23:26:05,995 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 0.071,  Train_accy 44.93, Test_accy 42.12
2025-01-11 23:26:06,002 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 0.062,  Train_accy 42.51, Test_accy 41.22
2025-01-11 23:26:29,329 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 0.063,  Train_accy 43.37
2025-01-11 23:26:29,598 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 0.073,  Train_accy 45.90
2025-01-11 23:26:52,307 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.061,  Train_accy 43.50
2025-01-11 23:26:52,496 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.070,  Train_accy 46.04
2025-01-11 23:27:19,748 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 0.066,  Train_accy 43.10
2025-01-11 23:27:19,864 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 0.076,  Train_accy 45.47
2025-01-11 23:27:42,392 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.066,  Train_accy 42.90
2025-01-11 23:27:42,534 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.076,  Train_accy 45.83
2025-01-11 23:28:47,867 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 0.083,  Train_accy 45.62, Test_accy 42.48
2025-01-11 23:28:47,917 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 0.071,  Train_accy 42.44, Test_accy 41.30
2025-01-11 23:29:10,268 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 0.069,  Train_accy 45.73
2025-01-11 23:29:10,762 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 0.061,  Train_accy 43.26
2025-01-11 23:29:32,346 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 0.070,  Train_accy 45.73
2025-01-11 23:29:33,148 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 0.061,  Train_accy 42.48
2025-01-11 23:29:54,767 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 0.074,  Train_accy 45.79
2025-01-11 23:29:55,642 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 0.064,  Train_accy 43.07
2025-01-11 23:30:17,360 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 0.073,  Train_accy 45.81
2025-01-11 23:30:18,313 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 0.063,  Train_accy 43.16
2025-01-11 23:30:48,536 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 0.082,  Train_accy 46.10, Test_accy 39.95
2025-01-11 23:30:50,134 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 0.070,  Train_accy 43.20, Test_accy 38.85
2025-01-11 23:31:10,554 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.072,  Train_accy 46.23
2025-01-11 23:31:12,328 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.063,  Train_accy 43.70
2025-01-11 23:31:32,793 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 0.071,  Train_accy 45.79
2025-01-11 23:31:34,843 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 0.062,  Train_accy 43.05
2025-01-11 23:31:54,969 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 0.090,  Train_accy 45.92
2025-01-11 23:31:57,236 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 0.077,  Train_accy 42.80
2025-01-11 23:32:16,888 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.079,  Train_accy 46.02
2025-01-11 23:32:19,391 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.068,  Train_accy 43.60
2025-01-11 23:33:00,658 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.075,  Train_accy 45.18, Test_accy 41.95
2025-01-11 23:33:00,697 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.065,  Train_accy 42.86, Test_accy 40.65
2025-01-11 23:33:23,098 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 0.073,  Train_accy 46.29
2025-01-11 23:33:23,591 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 0.064,  Train_accy 43.50
2025-01-11 23:33:45,264 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 0.075,  Train_accy 46.19
2025-01-11 23:33:46,088 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 0.065,  Train_accy 43.31
2025-01-11 23:34:07,138 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.076,  Train_accy 45.77
2025-01-11 23:34:08,114 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.066,  Train_accy 43.20
2025-01-11 23:34:28,986 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.076,  Train_accy 45.56
2025-01-11 23:34:30,334 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.066,  Train_accy 42.93
2025-01-11 23:35:01,304 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.071,  Train_accy 46.08, Test_accy 43.49
2025-01-11 23:35:02,741 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.062,  Train_accy 43.16, Test_accy 41.86
2025-01-11 23:35:23,178 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 0.071,  Train_accy 45.94
2025-01-11 23:35:25,054 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 0.062,  Train_accy 43.39
2025-01-11 23:35:45,201 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.075,  Train_accy 45.54
2025-01-11 23:35:46,912 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.065,  Train_accy 43.07
2025-01-11 23:36:07,270 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.074,  Train_accy 45.31
2025-01-11 23:36:09,149 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.064,  Train_accy 43.37
2025-01-11 23:36:21,901 [trainer.py] => 实验名称:kd_without_lambda对比实验
2025-01-11 23:36:21,933 [trainer.py] => config: ./exps/der.json
2025-01-11 23:36:21,933 [trainer.py] => experiment_name: 实验名称:kd_without_lambda对比实验
2025-01-11 23:36:21,933 [trainer.py] => prefix: reproduce
2025-01-11 23:36:21,933 [trainer.py] => dataset: xrfdataset
2025-01-11 23:36:21,933 [trainer.py] => memory_size: 1650
2025-01-11 23:36:21,933 [trainer.py] => memory_per_class: 30
2025-01-11 23:36:21,933 [trainer.py] => fixed_memory: True
2025-01-11 23:36:21,933 [trainer.py] => shuffle: True
2025-01-11 23:36:21,933 [trainer.py] => init_cls: 15
2025-01-11 23:36:21,933 [trainer.py] => increment: 10
2025-01-11 23:36:21,934 [trainer.py] => model_name: der
2025-01-11 23:36:21,934 [trainer.py] => compression_epochs: 130
2025-01-11 23:36:21,934 [trainer.py] => compression_lr: 0.1
2025-01-11 23:36:21,934 [trainer.py] => T: 2
2025-01-11 23:36:21,934 [trainer.py] => convnet_type: unet
2025-01-11 23:36:21,934 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-01-11 23:36:21,934 [trainer.py] => seed: 1993
2025-01-11 23:36:21,984 [data.py] => 加载完毕XRF原始数据集
2025-01-11 23:36:22,001 [data.py] => 加载完毕XRF原始数据集
2025-01-11 23:36:22,002 [trainer.py] => All params: 0
2025-01-11 23:36:22,002 [trainer.py] => Trainable params: 0
2025-01-11 23:36:22,261 [der.py] => Learning on 0-15
2025-01-11 23:36:22,262 [der.py] => All params: 21045611
2025-01-11 23:36:22,262 [der.py] => Trainable params: 21045611
2025-01-11 23:36:29,457 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 0.075,  Train_accy 46.23
2025-01-11 23:36:31,310 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 0.065,  Train_accy 43.43
2025-01-11 23:37:01,018 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 0.074,  Train_accy 45.90, Test_accy 42.16
2025-01-11 23:37:03,431 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 0.064,  Train_accy 43.68, Test_accy 40.48
2025-01-11 23:37:22,719 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 0.070,  Train_accy 46.27
2025-01-11 23:37:25,691 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 0.061,  Train_accy 43.58
2025-01-11 23:37:45,045 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.070,  Train_accy 46.44
2025-01-11 23:37:47,849 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.061,  Train_accy 43.10
2025-01-11 23:38:07,461 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 0.073,  Train_accy 46.90
2025-01-11 23:38:10,444 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 0.064,  Train_accy 43.79
2025-01-11 23:38:29,582 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.073,  Train_accy 45.89
2025-01-11 23:38:31,649 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.063,  Train_accy 42.88
2025-01-11 23:41:42,175 [der.py] => darknet eval: 
2025-01-11 23:41:42,187 [der.py] => darknet eval: 
2025-01-11 23:41:42,822 [der.py] => CNN top1 curve: 42.23
2025-01-11 23:41:42,822 [der.py] => CNN top1 curve: 43.58
2025-01-11 23:41:42,822 [der.py] => CNN top5 curve: 83.83
2025-01-11 23:41:42,822 [der.py] => CNN top5 curve: 85.44
2025-01-11 23:41:42,825 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 23:41:42,826 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 23:46:44,753 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-11 23:46:44,792 [trainer.py] => config: ./exps/der.json
2025-01-11 23:46:44,793 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-11 23:46:44,793 [trainer.py] => prefix: reproduce
2025-01-11 23:46:44,793 [trainer.py] => dataset: xrfdataset
2025-01-11 23:46:44,793 [trainer.py] => memory_size: 1650
2025-01-11 23:46:44,793 [trainer.py] => memory_per_class: 30
2025-01-11 23:46:44,793 [trainer.py] => fixed_memory: True
2025-01-11 23:46:44,793 [trainer.py] => shuffle: True
2025-01-11 23:46:44,793 [trainer.py] => init_cls: 15
2025-01-11 23:46:44,793 [trainer.py] => increment: 10
2025-01-11 23:46:44,793 [trainer.py] => model_name: der
2025-01-11 23:46:44,793 [trainer.py] => compression_epochs: 1
2025-01-11 23:46:44,793 [trainer.py] => compression_lr: 0.1
2025-01-11 23:46:44,793 [trainer.py] => is_student_wa: True
2025-01-11 23:46:44,793 [trainer.py] => T: 2
2025-01-11 23:46:44,794 [trainer.py] => convnet_type: unet
2025-01-11 23:46:44,794 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-11 23:46:44,794 [trainer.py] => seed: 1993
2025-01-11 23:46:44,845 [data.py] => 加载完毕XRF原始数据集
2025-01-11 23:46:44,869 [data.py] => 加载完毕XRF原始数据集
2025-01-11 23:46:44,871 [trainer.py] => All params: 0
2025-01-11 23:46:44,871 [trainer.py] => Trainable params: 0
2025-01-11 23:46:45,051 [der.py] => Learning on 0-15
2025-01-11 23:46:45,052 [der.py] => All params: 21045611
2025-01-11 23:46:45,052 [der.py] => Trainable params: 21045611
2025-01-11 23:46:47,605 [der.py] => Exemplar size: 1350
2025-01-11 23:46:47,605 [trainer.py] => CNN: {'total': 76.41, '0': 63.89, '1': 72.22, '2': 91.67, '3': 66.67, '4': 82.78, '5': 40.56, '6': 75.56, '7': 58.89, '8': 42.22, '9': 56.11, '10': 92.22, '11': 95.0, '12': 83.33, '13': 79.44, '14': 56.11, '15': 96.67, '16': 93.89, '17': 95.0, '18': 92.78, '19': 93.89, '20': 96.11, '21': 91.67, '22': 73.33, '23': 71.11, '24': 62.22, '25': 88.33, '26': 93.33, '27': 93.33, '28': 69.44, '29': 79.44, '30': 94.44, '31': 83.33, '32': 98.89, '33': 83.33, '34': 81.67, '35': 90.0, '36': 87.78, '37': 22.78, '38': 4.44, '39': 40.56, '40': 73.89, '41': 96.11, '42': 97.22, '43': 96.11, 'old': 79.68, 'new': 64.94}
2025-01-11 23:46:47,605 [trainer.py] => NME: {'total': 78.53, '0': 66.11, '1': 64.44, '2': 85.56, '3': 52.78, '4': 85.0, '5': 45.0, '6': 65.56, '7': 55.0, '8': 47.78, '9': 59.44, '10': 91.67, '11': 83.33, '12': 82.22, '13': 76.67, '14': 56.67, '15': 89.44, '16': 90.0, '17': 93.89, '18': 89.44, '19': 93.33, '20': 92.22, '21': 88.33, '22': 86.11, '23': 62.78, '24': 75.56, '25': 78.89, '26': 91.67, '27': 85.0, '28': 63.33, '29': 76.67, '30': 76.11, '31': 83.33, '32': 91.67, '33': 62.78, '34': 81.67, '35': 97.22, '36': 89.44, '37': 66.67, '38': 89.44, '39': 85.0, '40': 84.44, '41': 91.11, '42': 97.22, '43': 94.44, 'old': 76.27, 'new': 86.44}
2025-01-11 23:46:47,605 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41]
2025-01-11 23:46:47,605 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35]
2025-01-11 23:46:47,605 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53]
2025-01-11 23:46:47,605 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06]

2025-01-11 23:46:47,606 [trainer.py] => All params: 84190952
2025-01-11 23:46:47,607 [trainer.py] => Trainable params: 21066116
2025-01-11 23:46:47,742 [der.py] => Exemplar size: 1350
2025-01-11 23:46:47,742 [trainer.py] => CNN: {'total': 76.41, '0': 63.89, '1': 72.22, '2': 91.67, '3': 66.67, '4': 82.78, '5': 40.56, '6': 75.56, '7': 58.89, '8': 42.22, '9': 56.11, '10': 92.22, '11': 95.0, '12': 83.33, '13': 79.44, '14': 56.11, '15': 96.67, '16': 93.89, '17': 95.0, '18': 92.78, '19': 93.89, '20': 96.11, '21': 91.67, '22': 73.33, '23': 71.11, '24': 62.22, '25': 88.33, '26': 93.33, '27': 93.33, '28': 69.44, '29': 79.44, '30': 94.44, '31': 83.33, '32': 98.89, '33': 83.33, '34': 81.67, '35': 90.0, '36': 87.78, '37': 22.78, '38': 4.44, '39': 40.56, '40': 73.89, '41': 96.11, '42': 97.22, '43': 96.11, 'old': 79.68, 'new': 64.94}
2025-01-11 23:46:47,743 [trainer.py] => NME: {'total': 78.53, '0': 66.11, '1': 64.44, '2': 85.56, '3': 52.78, '4': 85.0, '5': 45.0, '6': 65.56, '7': 55.0, '8': 47.78, '9': 59.44, '10': 91.67, '11': 83.33, '12': 82.22, '13': 76.67, '14': 56.67, '15': 89.44, '16': 90.0, '17': 93.89, '18': 89.44, '19': 93.33, '20': 92.22, '21': 88.33, '22': 86.11, '23': 62.78, '24': 75.56, '25': 78.89, '26': 91.67, '27': 85.0, '28': 63.33, '29': 76.67, '30': 76.11, '31': 83.33, '32': 91.67, '33': 62.78, '34': 81.67, '35': 97.22, '36': 89.44, '37': 66.67, '38': 89.44, '39': 85.0, '40': 84.44, '41': 91.11, '42': 97.22, '43': 94.44, 'old': 76.27, 'new': 86.44}
2025-01-11 23:46:47,743 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41]
2025-01-11 23:46:47,743 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35]
2025-01-11 23:46:47,743 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53]
2025-01-11 23:46:47,743 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06]

2025-01-11 23:46:47,744 [trainer.py] => All params: 84190952
2025-01-11 23:46:47,745 [trainer.py] => Trainable params: 21066116
2025-01-11 23:46:47,810 [der.py] => Learning on 45-55
2025-01-11 23:46:47,814 [der.py] => All params: 105244734
2025-01-11 23:46:47,816 [der.py] => Trainable params: 21078286
2025-01-11 23:46:47,894 [der.py] => Learning on 45-55
2025-01-11 23:46:47,896 [der.py] => All params: 105244734
2025-01-11 23:46:47,897 [der.py] => Trainable params: 21078286
2025-01-11 23:50:57,595 [der.py] => Task 0, Epoch 1/1 => Loss 2.508, Train_accy 14.60, Test_accy 14.74
2025-01-11 23:50:58,051 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-11 23:51:21,637 [der.py] => Exemplar size: 450
2025-01-11 23:51:21,637 [trainer.py] => CNN: {'total': 14.74, '0': 41.67, '1': 3.89, '2': 0.56, '3': 0.0, '4': 6.67, '5': 15.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 1.11, '10': 61.11, '11': 41.67, '12': 0.0, '13': 0.56, 'old': 0, 'new': 14.74}
2025-01-11 23:51:21,637 [trainer.py] => NME: {'total': 15.89, '0': 41.11, '1': 2.22, '2': 1.67, '3': 2.78, '4': 5.56, '5': 5.0, '6': 2.22, '7': 17.22, '8': 34.44, '9': 29.44, '10': 14.44, '11': 26.67, '12': 15.0, '13': 5.56, 'old': 0, 'new': 15.89}
2025-01-11 23:51:21,637 [trainer.py] => CNN top1 curve: [14.74]
2025-01-11 23:51:21,638 [trainer.py] => CNN top5 curve: [56.04]
2025-01-11 23:51:21,638 [trainer.py] => NME top1 curve: [15.89]
2025-01-11 23:51:21,638 [trainer.py] => NME top5 curve: [61.67]

2025-01-11 23:51:21,638 [trainer.py] => All params: 21045611
2025-01-11 23:51:21,639 [trainer.py] => Trainable params: 21045611
2025-01-11 23:51:22,241 [der.py] => Learning on 15-25
2025-01-11 23:51:22,242 [der.py] => All params: 42091068
2025-01-11 23:51:22,242 [der.py] => Trainable params: 21049456
2025-01-11 23:56:52,482 [der.py] => Task 1, Epoch 1/1 => Loss 5.234, Loss_clf 3.036, Loss_aux 2.199, Train_accy 17.31, Test_accy 8.98
2025-01-12 00:00:07,470 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.703,  Train_accy 12.30, Test_accy 6.56
2025-01-12 00:04:38,522 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 00:04:38,575 [trainer.py] => config: ./exps/der.json
2025-01-12 00:04:38,575 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 00:04:38,575 [trainer.py] => prefix: reproduce
2025-01-12 00:04:38,576 [trainer.py] => dataset: xrfdataset
2025-01-12 00:04:38,576 [trainer.py] => memory_size: 1650
2025-01-12 00:04:38,576 [trainer.py] => memory_per_class: 30
2025-01-12 00:04:38,576 [trainer.py] => fixed_memory: True
2025-01-12 00:04:38,576 [trainer.py] => shuffle: True
2025-01-12 00:04:38,576 [trainer.py] => init_cls: 15
2025-01-12 00:04:38,576 [trainer.py] => increment: 10
2025-01-12 00:04:38,576 [trainer.py] => model_name: der
2025-01-12 00:04:38,576 [trainer.py] => compression_epochs: 1
2025-01-12 00:04:38,576 [trainer.py] => compression_lr: 0.1
2025-01-12 00:04:38,576 [trainer.py] => is_student_wa: True
2025-01-12 00:04:38,576 [trainer.py] => T: 2
2025-01-12 00:04:38,576 [trainer.py] => convnet_type: unet
2025-01-12 00:04:38,576 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-12 00:04:38,576 [trainer.py] => seed: 1993
2025-01-12 00:04:38,628 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:04:38,663 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:04:38,664 [trainer.py] => All params: 0
2025-01-12 00:04:38,665 [trainer.py] => Trainable params: 0
2025-01-12 00:04:38,836 [der.py] => Learning on 0-15
2025-01-12 00:04:38,836 [der.py] => All params: 21045611
2025-01-12 00:04:38,836 [der.py] => Trainable params: 21045611
2025-01-12 00:05:23,169 [der.py] => Task 0, Epoch 1/1 => Loss 2.508, Train_accy 14.60, Test_accy 14.74
2025-01-12 00:05:23,170 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 00:05:55,034 [der.py] => Exemplar size: 450
2025-01-12 00:05:55,035 [trainer.py] => CNN: {'total': 14.74, '0': 41.67, '1': 3.89, '2': 0.56, '3': 0.0, '4': 6.67, '5': 15.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 1.11, '10': 61.11, '11': 41.67, '12': 0.0, '13': 0.56, 'old': 0, 'new': 14.74}
2025-01-12 00:05:55,035 [trainer.py] => NME: {'total': 15.89, '0': 41.11, '1': 2.22, '2': 1.67, '3': 2.78, '4': 5.56, '5': 5.0, '6': 2.22, '7': 17.22, '8': 34.44, '9': 29.44, '10': 14.44, '11': 26.67, '12': 15.0, '13': 5.56, 'old': 0, 'new': 15.89}
2025-01-12 00:05:55,035 [trainer.py] => CNN top1 curve: [14.74]
2025-01-12 00:05:55,035 [trainer.py] => CNN top5 curve: [56.04]
2025-01-12 00:05:55,035 [trainer.py] => NME top1 curve: [15.89]
2025-01-12 00:05:55,035 [trainer.py] => NME top5 curve: [61.67]

2025-01-12 00:05:55,036 [trainer.py] => All params: 21045611
2025-01-12 00:05:55,036 [trainer.py] => Trainable params: 21045611
2025-01-12 00:05:55,206 [der.py] => Learning on 15-25
2025-01-12 00:05:55,207 [der.py] => All params: 42091068
2025-01-12 00:05:55,208 [der.py] => Trainable params: 21049456
2025-01-12 00:10:06,549 [der.py] => Task 1, Epoch 1/1 => Loss 5.234, Loss_clf 3.036, Loss_aux 2.199, Train_accy 17.31, Test_accy 8.98
2025-01-12 00:11:36,036 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-12 00:11:36,321 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 00:12:05,007 [der.py] => Exemplar size: 450
2025-01-12 00:12:05,008 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-12 00:12:05,008 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-12 00:12:05,008 [trainer.py] => CNN top1 curve: [89.44]
2025-01-12 00:12:05,008 [trainer.py] => CNN top5 curve: [98.93]
2025-01-12 00:12:05,008 [trainer.py] => NME top1 curve: [88.22]
2025-01-12 00:12:05,008 [trainer.py] => NME top5 curve: [98.81]

2025-01-12 00:12:05,009 [trainer.py] => All params: 21045611
2025-01-12 00:12:05,009 [trainer.py] => Trainable params: 21045611
2025-01-12 00:12:06,951 [der.py] => Learning on 15-25
2025-01-12 00:12:06,952 [der.py] => All params: 42091068
2025-01-12 00:12:06,952 [der.py] => Trainable params: 21049456
2025-01-12 00:12:25,100 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.703,  Train_accy 12.30, Test_accy 6.56
2025-01-12 00:12:25,101 [der.py] => weight align student!
2025-01-12 00:17:57,290 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 00:17:57,377 [trainer.py] => config: ./exps/der.json
2025-01-12 00:17:57,377 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 00:17:57,377 [trainer.py] => prefix: reproduce
2025-01-12 00:17:57,377 [trainer.py] => dataset: xrfdataset
2025-01-12 00:17:57,377 [trainer.py] => memory_size: 1650
2025-01-12 00:17:57,377 [trainer.py] => memory_per_class: 30
2025-01-12 00:17:57,377 [trainer.py] => fixed_memory: True
2025-01-12 00:17:57,378 [trainer.py] => shuffle: True
2025-01-12 00:17:57,378 [trainer.py] => init_cls: 15
2025-01-12 00:17:57,378 [trainer.py] => increment: 10
2025-01-12 00:17:57,378 [trainer.py] => model_name: der
2025-01-12 00:17:57,378 [trainer.py] => compression_epochs: 130
2025-01-12 00:17:57,378 [trainer.py] => compression_lr: 0.1
2025-01-12 00:17:57,378 [trainer.py] => is_student_wa: True
2025-01-12 00:17:57,378 [trainer.py] => wa_value: 1
2025-01-12 00:17:57,378 [trainer.py] => T: 2
2025-01-12 00:17:57,378 [trainer.py] => convnet_type: unet
2025-01-12 00:17:57,378 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-12 00:17:57,378 [trainer.py] => seed: 1993
2025-01-12 00:17:57,476 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:17:57,609 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:17:57,611 [trainer.py] => All params: 0
2025-01-12 00:17:57,611 [trainer.py] => Trainable params: 0
2025-01-12 00:17:57,780 [der.py] => Learning on 0-15
2025-01-12 00:17:57,781 [der.py] => All params: 21045611
2025-01-12 00:17:57,781 [der.py] => Trainable params: 21045611
2025-01-12 00:27:29,842 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 00:27:32,607 [trainer.py] => config: ./exps/der.json
2025-01-12 00:27:32,608 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 00:27:32,608 [trainer.py] => prefix: reproduce
2025-01-12 00:27:32,608 [trainer.py] => dataset: xrfdataset
2025-01-12 00:27:32,608 [trainer.py] => memory_size: 1650
2025-01-12 00:27:32,608 [trainer.py] => memory_per_class: 30
2025-01-12 00:27:32,608 [trainer.py] => fixed_memory: True
2025-01-12 00:27:32,608 [trainer.py] => shuffle: True
2025-01-12 00:27:32,608 [trainer.py] => init_cls: 15
2025-01-12 00:27:32,608 [trainer.py] => increment: 10
2025-01-12 00:27:32,608 [trainer.py] => model_name: der
2025-01-12 00:27:32,609 [trainer.py] => compression_epochs: 1
2025-01-12 00:27:32,609 [trainer.py] => compression_lr: 0.1
2025-01-12 00:27:32,609 [trainer.py] => is_student_wa: True
2025-01-12 00:27:32,609 [trainer.py] => wa_value: 1
2025-01-12 00:27:32,609 [trainer.py] => T: 2
2025-01-12 00:27:32,609 [trainer.py] => convnet_type: unet
2025-01-12 00:27:32,609 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-12 00:27:32,609 [trainer.py] => seed: 1993
2025-01-12 00:27:33,321 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:27:33,490 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:27:33,492 [trainer.py] => All params: 0
2025-01-12 00:27:33,492 [trainer.py] => Trainable params: 0
2025-01-12 00:27:35,584 [der.py] => Learning on 0-15
2025-01-12 00:27:35,584 [der.py] => All params: 21045611
2025-01-12 00:27:35,584 [der.py] => Trainable params: 21045611
2025-01-12 00:31:38,369 [der.py] => Task 0, Epoch 1/1 => Loss 2.508, Train_accy 14.60, Test_accy 14.74
2025-01-12 00:31:38,393 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 00:34:19,567 [der.py] => Exemplar size: 450
2025-01-12 00:34:20,380 [trainer.py] => CNN: {'total': 14.74, '0': 41.67, '1': 3.89, '2': 0.56, '3': 0.0, '4': 6.67, '5': 15.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 1.11, '10': 61.11, '11': 41.67, '12': 0.0, '13': 0.56, 'old': 0, 'new': 14.74}
2025-01-12 00:34:20,380 [trainer.py] => NME: {'total': 15.89, '0': 41.11, '1': 2.22, '2': 1.67, '3': 2.78, '4': 5.56, '5': 5.0, '6': 2.22, '7': 17.22, '8': 34.44, '9': 29.44, '10': 14.44, '11': 26.67, '12': 15.0, '13': 5.56, 'old': 0, 'new': 15.89}
2025-01-12 00:34:20,380 [trainer.py] => CNN top1 curve: [14.74]
2025-01-12 00:34:20,381 [trainer.py] => CNN top5 curve: [56.04]
2025-01-12 00:34:20,381 [trainer.py] => NME top1 curve: [15.89]
2025-01-12 00:34:20,381 [trainer.py] => NME top5 curve: [61.67]

2025-01-12 00:34:20,382 [trainer.py] => All params: 21045611
2025-01-12 00:34:20,382 [trainer.py] => Trainable params: 21045611
2025-01-12 00:34:20,712 [der.py] => Learning on 15-25
2025-01-12 00:34:20,713 [der.py] => All params: 42091068
2025-01-12 00:34:20,714 [der.py] => Trainable params: 21049456
2025-01-12 00:34:41,406 [der.py] => Task 1, Epoch 1/1 => Loss 5.234, Loss_clf 3.036, Loss_aux 2.199, Train_accy 17.31, Test_accy 8.98
2025-01-12 00:35:04,155 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.703,  Train_accy 12.30, Test_accy 6.56
2025-01-12 00:35:04,156 [der.py] => weight align student!
2025-01-12 00:39:30,533 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-12 00:39:31,914 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 00:39:31,972 [trainer.py] => config: ./exps/der.json
2025-01-12 00:39:31,972 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 00:39:31,973 [trainer.py] => prefix: reproduce
2025-01-12 00:39:31,973 [trainer.py] => dataset: xrfdataset
2025-01-12 00:39:31,973 [trainer.py] => memory_size: 1650
2025-01-12 00:39:31,973 [trainer.py] => memory_per_class: 30
2025-01-12 00:39:31,973 [trainer.py] => fixed_memory: True
2025-01-12 00:39:31,973 [trainer.py] => shuffle: True
2025-01-12 00:39:31,973 [trainer.py] => init_cls: 15
2025-01-12 00:39:31,973 [trainer.py] => increment: 10
2025-01-12 00:39:31,973 [trainer.py] => model_name: der
2025-01-12 00:39:31,973 [trainer.py] => compression_epochs: 1
2025-01-12 00:39:31,973 [trainer.py] => compression_lr: 0.1
2025-01-12 00:39:31,973 [trainer.py] => is_student_wa: True
2025-01-12 00:39:31,973 [trainer.py] => wa_value: 1
2025-01-12 00:39:31,973 [trainer.py] => T: 2
2025-01-12 00:39:31,974 [trainer.py] => convnet_type: unet
2025-01-12 00:39:31,974 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-12 00:39:31,974 [trainer.py] => seed: 1993
2025-01-12 00:39:32,139 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:39:32,207 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:39:32,209 [trainer.py] => All params: 0
2025-01-12 00:39:32,210 [trainer.py] => Trainable params: 0
2025-01-12 00:39:32,388 [der.py] => Learning on 0-15
2025-01-12 00:39:32,388 [der.py] => All params: 21045611
2025-01-12 00:39:32,388 [der.py] => Trainable params: 21045611
2025-01-12 00:39:44,565 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.035,  Train_accy 45.59, Test_accy 43.49
2025-01-12 00:39:53,462 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.469,  Train_accy 70.65
2025-01-12 00:40:02,984 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.276,  Train_accy 80.43
2025-01-12 00:40:11,512 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.148,  Train_accy 87.33
2025-01-12 00:40:20,495 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.085,  Train_accy 89.83
2025-01-12 00:40:44,240 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.049,  Train_accy 91.94, Test_accy 71.58
2025-01-12 00:40:52,988 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.025,  Train_accy 93.01
2025-01-12 00:41:01,599 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.984,  Train_accy 95.23
2025-01-12 00:41:10,418 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.968,  Train_accy 95.61
2025-01-12 00:41:18,968 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.965,  Train_accy 95.89
2025-01-12 00:41:32,089 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.945,  Train_accy 96.80, Test_accy 75.18
2025-01-12 00:41:40,714 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.934,  Train_accy 97.44
2025-01-12 00:41:49,156 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.920,  Train_accy 97.96
2025-01-12 00:41:58,014 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.921,  Train_accy 97.70
2025-01-12 00:42:06,835 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.919,  Train_accy 97.81
2025-01-12 00:42:19,686 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.924,  Train_accy 97.72, Test_accy 76.56
2025-01-12 00:42:28,389 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.914,  Train_accy 98.02
2025-01-12 00:42:36,925 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.908,  Train_accy 98.15
2025-01-12 00:42:45,434 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.905,  Train_accy 98.52
2025-01-12 00:42:53,956 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.906,  Train_accy 98.34
2025-01-12 00:43:06,703 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.895,  Train_accy 98.62, Test_accy 78.49
2025-01-12 00:43:15,156 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.893,  Train_accy 98.69
2025-01-12 00:43:23,621 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.888,  Train_accy 98.82
2025-01-12 00:43:32,002 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.888,  Train_accy 98.97
2025-01-12 00:43:40,431 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.884,  Train_accy 98.99
2025-01-12 00:43:53,070 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.882,  Train_accy 98.97, Test_accy 79.53
2025-01-12 00:44:01,500 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.882,  Train_accy 99.14
2025-01-12 00:44:10,022 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.877,  Train_accy 99.05
2025-01-12 00:44:18,489 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.876,  Train_accy 99.01
2025-01-12 00:44:26,810 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.879,  Train_accy 99.08
2025-01-12 00:44:35,260 [der.py] => Task 0, Epoch 1/1 => Loss 2.508, Train_accy 14.60, Test_accy 14.74
2025-01-12 00:44:35,261 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 00:44:39,598 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.878,  Train_accy 99.05, Test_accy 78.36
2025-01-12 00:44:50,685 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.881,  Train_accy 99.05
2025-01-12 00:45:01,870 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.871,  Train_accy 99.18
2025-01-12 00:45:12,743 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.869,  Train_accy 99.12
2025-01-12 00:45:23,208 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.870,  Train_accy 98.92
2025-01-12 00:45:44,835 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.870,  Train_accy 99.12, Test_accy 79.73
2025-01-12 00:45:55,625 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.868,  Train_accy 98.86
2025-01-12 00:46:04,278 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.871,  Train_accy 99.08
2025-01-12 00:46:12,815 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.870,  Train_accy 98.99
2025-01-12 00:46:21,343 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.867,  Train_accy 99.14
2025-01-12 00:46:49,632 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.865,  Train_accy 99.16, Test_accy 79.91
2025-01-12 00:46:51,524 [der.py] => Exemplar size: 450
2025-01-12 00:46:51,525 [trainer.py] => CNN: {'total': 14.74, '0': 41.67, '1': 3.89, '2': 0.56, '3': 0.0, '4': 6.67, '5': 15.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 1.11, '10': 61.11, '11': 41.67, '12': 0.0, '13': 0.56, 'old': 0, 'new': 14.74}
2025-01-12 00:46:51,525 [trainer.py] => NME: {'total': 15.89, '0': 41.11, '1': 2.22, '2': 1.67, '3': 2.78, '4': 5.56, '5': 5.0, '6': 2.22, '7': 17.22, '8': 34.44, '9': 29.44, '10': 14.44, '11': 26.67, '12': 15.0, '13': 5.56, 'old': 0, 'new': 15.89}
2025-01-12 00:46:51,525 [trainer.py] => CNN top1 curve: [14.74]
2025-01-12 00:46:51,525 [trainer.py] => CNN top5 curve: [56.04]
2025-01-12 00:46:51,525 [trainer.py] => NME top1 curve: [15.89]
2025-01-12 00:46:51,525 [trainer.py] => NME top5 curve: [61.67]

2025-01-12 00:46:51,526 [trainer.py] => All params: 21045611
2025-01-12 00:46:51,527 [trainer.py] => Trainable params: 21045611
2025-01-12 00:46:51,732 [der.py] => Learning on 15-25
2025-01-12 00:46:51,734 [der.py] => All params: 42091068
2025-01-12 00:46:51,734 [der.py] => Trainable params: 21049456
2025-01-12 00:46:58,549 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.867,  Train_accy 99.14
2025-01-12 00:47:07,123 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.868,  Train_accy 99.23
2025-01-12 00:47:15,697 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.859,  Train_accy 99.46
2025-01-12 00:47:24,345 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.859,  Train_accy 99.40
2025-01-12 00:47:26,291 [der.py] => Task 1, Epoch 1/1 => Loss 5.234, Loss_clf 3.036, Loss_aux 2.199, Train_accy 17.31, Test_accy 8.98
2025-01-12 00:47:38,069 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.864,  Train_accy 99.31, Test_accy 80.24
2025-01-12 00:47:46,763 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.864,  Train_accy 99.23
2025-01-12 00:47:54,302 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.703,  Train_accy 12.30, Test_accy 6.56
2025-01-12 00:47:54,509 [der.py] => weight align student!
2025-01-12 00:47:55,391 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.859,  Train_accy 99.42
2025-01-12 00:48:03,990 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.864,  Train_accy 99.14
2025-01-12 00:48:12,675 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.863,  Train_accy 99.25
2025-01-12 00:48:25,955 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.862,  Train_accy 99.20, Test_accy 79.67
2025-01-12 00:48:34,307 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.862,  Train_accy 99.03
2025-01-12 00:48:42,775 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.860,  Train_accy 99.38
2025-01-12 00:48:51,263 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.862,  Train_accy 99.31
2025-01-12 00:48:59,802 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.861,  Train_accy 99.20
2025-01-12 00:49:15,184 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.855,  Train_accy 99.25, Test_accy 80.80
2025-01-12 00:49:26,046 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.853,  Train_accy 99.59
2025-01-12 00:49:36,821 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.854,  Train_accy 99.38
2025-01-12 00:49:46,920 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.854,  Train_accy 99.35
2025-01-12 00:49:55,653 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.852,  Train_accy 99.46
2025-01-12 00:50:08,465 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.849,  Train_accy 99.46, Test_accy 80.51
2025-01-12 00:50:17,257 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.854,  Train_accy 99.25
2025-01-12 00:50:25,824 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.853,  Train_accy 99.40
2025-01-12 00:50:34,572 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.853,  Train_accy 99.31
2025-01-12 00:50:43,388 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.850,  Train_accy 99.27
2025-01-12 00:50:58,369 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.849,  Train_accy 99.27, Test_accy 80.36
2025-01-12 00:51:06,924 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.850,  Train_accy 99.48
2025-01-12 00:51:15,869 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.852,  Train_accy 99.27
2025-01-12 00:51:24,501 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.852,  Train_accy 99.53
2025-01-12 00:51:33,003 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.852,  Train_accy 99.51
2025-01-12 00:51:46,658 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.851,  Train_accy 99.33, Test_accy 80.27
2025-01-12 00:51:55,378 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.850,  Train_accy 99.38
2025-01-12 00:52:04,020 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.847,  Train_accy 99.51
2025-01-12 00:52:12,502 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.852,  Train_accy 99.29
2025-01-12 00:52:20,967 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.848,  Train_accy 99.35
2025-01-12 00:52:34,010 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.849,  Train_accy 99.31, Test_accy 80.56
2025-01-12 00:52:43,382 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.851,  Train_accy 99.44
2025-01-12 00:52:50,132 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 00:52:50,174 [trainer.py] => config: ./exps/der.json
2025-01-12 00:52:50,174 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 00:52:50,174 [trainer.py] => prefix: reproduce
2025-01-12 00:52:50,174 [trainer.py] => dataset: xrfdataset
2025-01-12 00:52:50,174 [trainer.py] => memory_size: 1650
2025-01-12 00:52:50,174 [trainer.py] => memory_per_class: 30
2025-01-12 00:52:50,174 [trainer.py] => fixed_memory: True
2025-01-12 00:52:50,174 [trainer.py] => shuffle: True
2025-01-12 00:52:50,175 [trainer.py] => init_cls: 15
2025-01-12 00:52:50,175 [trainer.py] => increment: 10
2025-01-12 00:52:50,175 [trainer.py] => model_name: der
2025-01-12 00:52:50,175 [trainer.py] => compression_epochs: 1
2025-01-12 00:52:50,175 [trainer.py] => compression_lr: 0.1
2025-01-12 00:52:50,175 [trainer.py] => is_student_wa: True
2025-01-12 00:52:50,175 [trainer.py] => wa_value: 1
2025-01-12 00:52:50,175 [trainer.py] => T: 2
2025-01-12 00:52:50,175 [trainer.py] => convnet_type: unet
2025-01-12 00:52:50,175 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-12 00:52:50,175 [trainer.py] => seed: 1993
2025-01-12 00:52:50,239 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:52:50,259 [data.py] => 加载完毕XRF原始数据集
2025-01-12 00:52:50,260 [trainer.py] => All params: 0
2025-01-12 00:52:50,260 [trainer.py] => Trainable params: 0
2025-01-12 00:52:50,421 [der.py] => Learning on 0-15
2025-01-12 00:52:50,421 [der.py] => All params: 21045611
2025-01-12 00:52:50,421 [der.py] => Trainable params: 21045611
2025-01-12 00:52:54,554 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.847,  Train_accy 99.38
2025-01-12 00:53:05,658 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.846,  Train_accy 99.40
2025-01-12 00:53:16,796 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.849,  Train_accy 99.46
2025-01-12 00:53:31,323 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.846,  Train_accy 99.66, Test_accy 80.87
2025-01-12 00:53:40,167 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.850,  Train_accy 99.33
2025-01-12 00:53:49,162 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.848,  Train_accy 99.42
2025-01-12 00:53:57,885 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.845,  Train_accy 99.27
2025-01-12 00:54:07,497 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.845,  Train_accy 99.70
2025-01-12 00:56:18,867 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.842,  Train_accy 99.53, Test_accy 81.56
2025-01-12 00:56:27,680 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.846,  Train_accy 99.51
2025-01-12 00:56:36,370 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.849,  Train_accy 99.31
2025-01-12 00:56:46,346 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.846,  Train_accy 99.42
2025-01-12 00:56:46,370 [der.py] => Task 0, Epoch 1/1 => Loss 2.508, Train_accy 14.60, Test_accy 14.74
2025-01-12 00:56:46,371 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 00:56:57,744 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.844,  Train_accy 99.46
2025-01-12 00:57:13,805 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.845,  Train_accy 99.18, Test_accy 80.96
2025-01-12 00:57:24,241 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.844,  Train_accy 99.53
2025-01-12 00:57:32,651 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.843,  Train_accy 99.44
2025-01-12 00:57:41,110 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.843,  Train_accy 99.48
2025-01-12 00:57:49,490 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.846,  Train_accy 99.44
2025-01-12 00:58:01,476 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.842,  Train_accy 99.35, Test_accy 80.93
2025-01-12 00:58:09,617 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.844,  Train_accy 99.61
2025-01-12 00:58:18,474 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.843,  Train_accy 99.42
2025-01-12 00:58:26,570 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.842,  Train_accy 99.35
2025-01-12 00:58:34,773 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.847,  Train_accy 99.48
2025-01-12 01:00:58,557 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.844,  Train_accy 99.48, Test_accy 81.33
2025-01-12 01:01:08,163 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.844,  Train_accy 99.51
2025-01-12 01:01:18,569 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.840,  Train_accy 99.59
2025-01-12 01:01:29,471 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.841,  Train_accy 99.61
2025-01-12 01:01:40,359 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.842,  Train_accy 99.48
2025-01-12 01:01:56,555 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.839,  Train_accy 99.51, Test_accy 80.84
2025-01-12 01:02:05,295 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.839,  Train_accy 99.57
2025-01-12 01:02:13,481 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.845,  Train_accy 99.46
2025-01-12 01:02:23,010 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.839,  Train_accy 99.35
2025-01-12 01:02:31,467 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.843,  Train_accy 99.38
2025-01-12 01:02:44,601 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.11
2025-01-12 01:02:45,195 [der.py] => Exemplar size: 450
2025-01-12 01:02:45,195 [trainer.py] => CNN: {'total': 14.74, '0': 41.67, '1': 3.89, '2': 0.56, '3': 0.0, '4': 6.67, '5': 15.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 1.11, '10': 61.11, '11': 41.67, '12': 0.0, '13': 0.56, 'old': 0, 'new': 14.74}
2025-01-12 01:02:45,195 [trainer.py] => NME: {'total': 15.89, '0': 41.11, '1': 2.22, '2': 1.67, '3': 2.78, '4': 5.56, '5': 5.0, '6': 2.22, '7': 17.22, '8': 34.44, '9': 29.44, '10': 14.44, '11': 26.67, '12': 15.0, '13': 5.56, 'old': 0, 'new': 15.89}
2025-01-12 01:02:45,195 [trainer.py] => CNN top1 curve: [14.74]
2025-01-12 01:02:45,195 [trainer.py] => CNN top5 curve: [56.04]
2025-01-12 01:02:45,195 [trainer.py] => NME top1 curve: [15.89]
2025-01-12 01:02:45,196 [trainer.py] => NME top5 curve: [61.67]

2025-01-12 01:02:45,196 [trainer.py] => All params: 21045611
2025-01-12 01:02:45,197 [trainer.py] => Trainable params: 21045611
2025-01-12 01:02:45,411 [der.py] => Learning on 15-25
2025-01-12 01:02:45,412 [der.py] => All params: 42091068
2025-01-12 01:02:45,413 [der.py] => Trainable params: 21049456
2025-01-12 01:02:53,463 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.841,  Train_accy 99.61
2025-01-12 01:03:01,887 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.841,  Train_accy 99.57
2025-01-12 01:03:10,286 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.842,  Train_accy 99.59
2025-01-12 01:03:16,522 [der.py] => Task 1, Epoch 1/1 => Loss 5.234, Loss_clf 3.036, Loss_aux 2.199, Train_accy 17.31, Test_accy 8.98
2025-01-12 01:03:18,772 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.841,  Train_accy 99.57
2025-01-12 01:03:31,303 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.841,  Train_accy 99.44, Test_accy 81.33
2025-01-12 01:03:40,411 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.839,  Train_accy 99.57
2025-01-12 01:03:47,130 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.703,  Train_accy 12.30, Test_accy 6.56
2025-01-12 01:03:47,131 [der.py] => weight align student!
2025-01-12 01:03:49,251 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.840,  Train_accy 99.44
2025-01-12 01:03:53,833 [der.py] => darknet eval: 
2025-01-12 01:03:53,833 [der.py] => CNN top1 curve: 6.62
2025-01-12 01:03:53,833 [der.py] => CNN top5 curve: 30.04
2025-01-12 01:03:53,834 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 01:03:57,781 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.843,  Train_accy 99.59
2025-01-12 01:04:06,277 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.842,  Train_accy 99.46
2025-01-12 01:04:19,368 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.47
2025-01-12 01:04:27,974 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.843,  Train_accy 99.48
2025-01-12 01:04:36,434 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.841,  Train_accy 99.53
2025-01-12 01:04:42,535 [der.py] => Exemplar size: 750
2025-01-12 01:04:42,535 [trainer.py] => CNN: {'total': 9.13, '0': 1.11, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 12.22, '10': 6.11, '11': 12.22, '12': 0.0, '13': 0.0, '14': 0.0, '15': 13.33, '16': 7.78, '17': 55.56, '18': 11.11, '19': 0.0, '20': 0.0, '21': 0.0, '22': 22.78, '23': 21.11, 'old': 2.11, 'new': 19.67}
2025-01-12 01:04:42,535 [trainer.py] => NME: {'total': 13.2, '0': 46.11, '1': 0.56, '2': 4.44, '3': 5.0, '4': 8.89, '5': 9.44, '6': 0.56, '7': 5.56, '8': 17.78, '9': 23.33, '10': 36.67, '11': 32.22, '12': 5.56, '13': 12.78, '14': 20.56, '15': 1.67, '16': 16.11, '17': 16.11, '18': 21.11, '19': 24.44, '20': 0.0, '21': 0.0, '22': 3.89, '23': 7.22, 'old': 15.3, 'new': 10.06}
2025-01-12 01:04:42,535 [trainer.py] => CNN top1 curve: [14.74, 9.13]
2025-01-12 01:04:42,535 [trainer.py] => CNN top5 curve: [56.04, 35.4]
2025-01-12 01:04:42,535 [trainer.py] => NME top1 curve: [15.89, 13.2]
2025-01-12 01:04:42,535 [trainer.py] => NME top5 curve: [61.67, 47.27]

2025-01-12 01:04:42,536 [trainer.py] => All params: 42091068
2025-01-12 01:04:42,536 [trainer.py] => Trainable params: 21049456
2025-01-12 01:04:42,690 [der.py] => Learning on 25-35
2025-01-12 01:04:42,691 [der.py] => All params: 63139730
2025-01-12 01:04:42,692 [der.py] => Trainable params: 21056506
2025-01-12 01:04:45,029 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.839,  Train_accy 99.53
2025-01-12 01:04:53,546 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.839,  Train_accy 99.57
2025-01-12 01:05:05,994 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.838,  Train_accy 99.53, Test_accy 81.62
2025-01-12 01:05:14,460 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.842,  Train_accy 99.51
2025-01-12 01:05:22,887 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.843,  Train_accy 99.48
2025-01-12 01:05:31,049 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.838,  Train_accy 99.59
2025-01-12 01:05:39,550 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.838,  Train_accy 99.48
2025-01-12 01:05:43,975 [der.py] => darknet eval: 
2025-01-12 01:05:43,976 [der.py] => CNN top1 curve: 81.18
2025-01-12 01:05:43,976 [der.py] => CNN top5 curve: 97.73
2025-01-12 01:05:43,979 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 01:06:19,916 [der.py] => Exemplar size: 750
2025-01-12 01:06:19,917 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-12 01:06:19,917 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-12 01:06:19,917 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-12 01:06:19,917 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-12 01:06:19,917 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-12 01:06:19,917 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-12 01:06:19,918 [trainer.py] => All params: 42091068
2025-01-12 01:06:19,918 [trainer.py] => Trainable params: 21049456
2025-01-12 01:06:20,066 [der.py] => Learning on 25-35
2025-01-12 01:06:20,067 [der.py] => All params: 63139730
2025-01-12 01:06:20,068 [der.py] => Trainable params: 21056506
2025-01-12 01:07:39,815 [der.py] => Task 2, Epoch 1/1 => Loss 5.428, Loss_clf 3.242, Loss_aux 2.186, Train_accy 17.31, Test_accy 8.44
2025-01-12 01:11:20,165 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 3.088,  Train_accy 16.14, Test_accy 5.62
2025-01-12 01:11:22,776 [der.py] => weight align student!
2025-01-12 01:11:35,684 [der.py] => darknet eval: 
2025-01-12 01:11:35,684 [der.py] => CNN top1 curve: 5.65
2025-01-12 01:11:35,684 [der.py] => CNN top5 curve: 25.11
2025-01-12 01:11:35,685 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 01:15:02,347 [der.py] => Exemplar size: 1050
2025-01-12 01:15:03,181 [trainer.py] => CNN: {'total': 8.54, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 3.33, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 10.0, '17': 21.11, '18': 8.89, '19': 0.56, '20': 5.56, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 33.33, '26': 15.0, '27': 73.89, '28': 25.0, '29': 11.11, '30': 20.0, '31': 9.44, '32': 25.56, '33': 26.67, 'old': 1.98, 'new': 24.94}
2025-01-12 01:15:03,181 [trainer.py] => NME: {'total': 10.7, '0': 42.22, '1': 0.0, '2': 3.33, '3': 4.44, '4': 5.0, '5': 4.44, '6': 10.56, '7': 12.22, '8': 28.33, '9': 20.0, '10': 33.89, '11': 30.56, '12': 4.44, '13': 11.67, '14': 11.67, '15': 2.78, '16': 10.56, '17': 11.11, '18': 17.78, '19': 28.33, '20': 1.67, '21': 3.89, '22': 3.33, '23': 5.56, '24': 10.56, '25': 16.11, '26': 2.78, '27': 4.44, '28': 3.89, '29': 0.56, '30': 10.56, '31': 0.0, '32': 14.44, '33': 2.22, 'old': 12.73, 'new': 5.61}
2025-01-12 01:15:03,181 [trainer.py] => CNN top1 curve: [14.74, 9.13, 8.54]
2025-01-12 01:15:03,181 [trainer.py] => CNN top5 curve: [56.04, 35.4, 32.51]
2025-01-12 01:15:03,181 [trainer.py] => NME top1 curve: [15.89, 13.2, 10.7]
2025-01-12 01:15:03,181 [trainer.py] => NME top5 curve: [61.67, 47.27, 39.0]

2025-01-12 01:15:03,183 [trainer.py] => All params: 63139730
2025-01-12 01:15:03,185 [trainer.py] => Trainable params: 21056506
2025-01-12 01:15:05,389 [der.py] => Learning on 35-45
2025-01-12 01:15:05,391 [der.py] => All params: 84190952
2025-01-12 01:15:05,391 [der.py] => Trainable params: 21066116
2025-01-12 01:20:07,108 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 01:20:07,142 [trainer.py] => config: ./exps/der.json
2025-01-12 01:20:07,142 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 01:20:07,142 [trainer.py] => prefix: reproduce
2025-01-12 01:20:07,142 [trainer.py] => dataset: xrfdataset
2025-01-12 01:20:07,142 [trainer.py] => memory_size: 1650
2025-01-12 01:20:07,142 [trainer.py] => memory_per_class: 30
2025-01-12 01:20:07,142 [trainer.py] => fixed_memory: True
2025-01-12 01:20:07,142 [trainer.py] => shuffle: True
2025-01-12 01:20:07,142 [trainer.py] => init_cls: 15
2025-01-12 01:20:07,142 [trainer.py] => increment: 10
2025-01-12 01:20:07,143 [trainer.py] => model_name: der
2025-01-12 01:20:07,143 [trainer.py] => compression_epochs: 130
2025-01-12 01:20:07,143 [trainer.py] => compression_lr: 0.1
2025-01-12 01:20:07,143 [trainer.py] => is_student_wa: True
2025-01-12 01:20:07,143 [trainer.py] => wa_value: 1
2025-01-12 01:20:07,143 [trainer.py] => T: 2
2025-01-12 01:20:07,143 [trainer.py] => convnet_type: unet
2025-01-12 01:20:07,143 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-12 01:20:07,143 [trainer.py] => seed: 1993
2025-01-12 01:20:07,194 [data.py] => 加载完毕XRF原始数据集
2025-01-12 01:20:07,218 [data.py] => 加载完毕XRF原始数据集
2025-01-12 01:20:07,220 [trainer.py] => All params: 0
2025-01-12 01:20:07,220 [trainer.py] => Trainable params: 0
2025-01-12 01:20:07,424 [der.py] => Learning on 0-15
2025-01-12 01:20:07,425 [der.py] => All params: 21045611
2025-01-12 01:20:07,425 [der.py] => Trainable params: 21045611
2025-01-12 02:01:51,477 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-12 02:02:07,891 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.588,  Train_accy 36.85, Test_accy 39.98
2025-01-12 02:02:17,887 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.191,  Train_accy 59.35
2025-01-12 02:02:27,989 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 2.021,  Train_accy 67.94
2025-01-12 02:02:38,066 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.919,  Train_accy 73.39
2025-01-12 02:02:47,947 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.851,  Train_accy 77.17
2025-01-12 02:03:03,586 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.800,  Train_accy 80.12, Test_accy 54.38
2025-01-12 02:03:13,624 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.785,  Train_accy 81.47
2025-01-12 02:03:23,560 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.748,  Train_accy 82.91
2025-01-12 02:03:33,526 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.726,  Train_accy 84.40
2025-01-12 02:03:43,511 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.703,  Train_accy 86.10
2025-01-12 02:03:59,211 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.677,  Train_accy 87.33, Test_accy 59.14
2025-01-12 02:04:09,072 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.666,  Train_accy 87.56
2025-01-12 02:04:19,221 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.651,  Train_accy 88.93
2025-01-12 02:04:29,197 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.639,  Train_accy 89.19
2025-01-12 02:04:39,200 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.633,  Train_accy 89.82
2025-01-12 02:04:54,467 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.627,  Train_accy 89.29, Test_accy 63.97
2025-01-12 02:05:04,578 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.618,  Train_accy 90.71
2025-01-12 02:05:14,664 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.601,  Train_accy 91.01
2025-01-12 02:05:24,821 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.595,  Train_accy 91.09
2025-01-12 02:05:34,833 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.589,  Train_accy 91.58
2025-01-12 02:05:50,795 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.584,  Train_accy 92.42, Test_accy 64.16
2025-01-12 02:06:00,684 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.576,  Train_accy 92.24
2025-01-12 02:06:10,593 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.565,  Train_accy 93.25
2025-01-12 02:06:20,668 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.569,  Train_accy 93.64
2025-01-12 02:06:30,697 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.566,  Train_accy 92.91
2025-01-12 02:06:46,311 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.556,  Train_accy 93.52, Test_accy 68.05
2025-01-12 02:06:56,358 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.548,  Train_accy 93.86
2025-01-12 02:07:06,399 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.547,  Train_accy 93.94
2025-01-12 02:07:16,637 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.542,  Train_accy 93.96
2025-01-12 02:07:26,527 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.542,  Train_accy 93.88
2025-01-12 02:07:42,343 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.536,  Train_accy 94.36, Test_accy 69.16
2025-01-12 02:07:52,277 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.528,  Train_accy 94.59
2025-01-12 02:08:02,204 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.534,  Train_accy 94.71
2025-01-12 02:08:12,076 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.531,  Train_accy 94.89
2025-01-12 02:08:22,345 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.525,  Train_accy 94.81
2025-01-12 02:08:37,787 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.525,  Train_accy 94.63, Test_accy 67.49
2025-01-12 02:08:47,667 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.525,  Train_accy 94.83
2025-01-12 02:08:57,637 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.522,  Train_accy 94.69
2025-01-12 02:09:07,824 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.513,  Train_accy 95.45
2025-01-12 02:09:17,923 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.514,  Train_accy 95.05
2025-01-12 02:09:33,525 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.513,  Train_accy 95.39, Test_accy 68.73
2025-01-12 02:09:43,793 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.512,  Train_accy 95.35
2025-01-12 02:09:53,744 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.513,  Train_accy 94.71
2025-01-12 02:10:03,869 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.507,  Train_accy 95.33
2025-01-12 02:10:13,829 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.504,  Train_accy 95.29
2025-01-12 02:10:29,689 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.504,  Train_accy 95.27, Test_accy 69.43
2025-01-12 02:10:39,660 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.500,  Train_accy 95.58
2025-01-12 02:10:49,693 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.499,  Train_accy 95.68
2025-01-12 02:10:59,957 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.498,  Train_accy 95.94
2025-01-12 02:11:10,601 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.499,  Train_accy 95.15
2025-01-12 02:11:25,795 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.494,  Train_accy 95.56, Test_accy 70.37
2025-01-12 02:11:36,013 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.492,  Train_accy 96.16
2025-01-12 02:11:46,191 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.493,  Train_accy 95.62
2025-01-12 02:11:56,408 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.492,  Train_accy 95.54
2025-01-12 02:12:06,254 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.490,  Train_accy 96.18
2025-01-12 02:13:14,832 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.487,  Train_accy 96.12, Test_accy 70.08
2025-01-12 02:17:34,356 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.488,  Train_accy 95.76
2025-01-12 02:17:44,980 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.485,  Train_accy 95.78
2025-01-12 02:17:55,034 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.485,  Train_accy 96.14
2025-01-12 02:18:05,004 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.484,  Train_accy 95.98
2025-01-12 02:19:49,855 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.483,  Train_accy 96.22, Test_accy 70.33
2025-01-12 02:19:59,900 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.488,  Train_accy 95.92
2025-01-12 02:20:09,893 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.480,  Train_accy 95.94
2025-01-12 02:20:19,907 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.483,  Train_accy 96.26
2025-01-12 02:20:30,078 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.479,  Train_accy 96.04
2025-01-12 02:21:50,542 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.480,  Train_accy 95.92, Test_accy 69.95
2025-01-12 02:22:23,609 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.481,  Train_accy 96.18
2025-01-12 02:22:33,521 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.475,  Train_accy 96.24
2025-01-12 02:22:43,385 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.476,  Train_accy 96.02
2025-01-12 02:22:53,434 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.477,  Train_accy 96.12
2025-01-12 02:24:44,306 [der.py] => Task 0, Epoch 150/150 => Loss 0.042, Train_accy 99.10
2025-01-12 02:24:46,030 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 02:24:54,284 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.476,  Train_accy 96.14, Test_accy 70.73
2025-01-12 02:25:17,213 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.475,  Train_accy 96.32
2025-01-12 02:25:27,570 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.475,  Train_accy 96.06
2025-01-12 02:25:37,889 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.473,  Train_accy 96.40
2025-01-12 02:25:46,487 [der.py] => Exemplar size: 450
2025-01-12 02:25:46,488 [trainer.py] => CNN: {'total': 85.93, '0': 98.89, '1': 92.78, '2': 94.44, '3': 78.89, '4': 86.67, '5': 76.67, '6': 56.67, '7': 92.78, '8': 90.56, '9': 63.33, '10': 94.44, '11': 98.89, '12': 87.78, '13': 86.67, 'old': 0, 'new': 85.93}
2025-01-12 02:25:46,488 [trainer.py] => NME: {'total': 85.48, '0': 98.89, '1': 91.67, '2': 93.89, '3': 75.56, '4': 87.22, '5': 78.33, '6': 50.56, '7': 91.67, '8': 85.0, '9': 67.22, '10': 95.56, '11': 99.44, '12': 87.78, '13': 87.78, 'old': 0, 'new': 85.48}
2025-01-12 02:25:46,488 [trainer.py] => CNN top1 curve: [85.93]
2025-01-12 02:25:46,488 [trainer.py] => CNN top5 curve: [97.59]
2025-01-12 02:25:46,488 [trainer.py] => NME top1 curve: [85.48]
2025-01-12 02:25:46,488 [trainer.py] => NME top5 curve: [98.52]

2025-01-12 02:25:46,489 [trainer.py] => All params: 21045611
2025-01-12 02:25:46,489 [trainer.py] => Trainable params: 21045611
2025-01-12 02:25:48,075 [der.py] => Learning on 15-25
2025-01-12 02:25:48,077 [der.py] => All params: 42091068
2025-01-12 02:25:48,078 [der.py] => Trainable params: 21049456
2025-01-12 02:25:48,237 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.476,  Train_accy 96.59
2025-01-12 02:29:00,388 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.473,  Train_accy 95.84, Test_accy 71.11
2025-01-12 02:29:46,635 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.471,  Train_accy 96.63
2025-01-12 02:29:56,479 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.471,  Train_accy 96.08
2025-01-12 02:30:06,503 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.472,  Train_accy 96.61
2025-01-12 02:30:16,472 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.473,  Train_accy 96.22
2025-01-12 02:31:01,129 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.471,  Train_accy 96.32, Test_accy 71.43
2025-01-12 02:31:13,690 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.469,  Train_accy 96.36
2025-01-12 02:31:23,329 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.466,  Train_accy 96.26
2025-01-12 02:31:33,136 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.469,  Train_accy 96.38
2025-01-12 02:31:42,801 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.466,  Train_accy 96.65
2025-01-12 02:32:01,085 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.468,  Train_accy 96.71, Test_accy 71.00
2025-01-12 02:32:10,854 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.465,  Train_accy 96.34
2025-01-12 02:32:20,919 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.467,  Train_accy 96.16
2025-01-12 02:32:30,777 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.463,  Train_accy 96.48
2025-01-12 02:32:40,511 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.464,  Train_accy 96.14
2025-01-12 02:33:02,947 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.463,  Train_accy 96.44, Test_accy 71.44
2025-01-12 02:33:12,894 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.462,  Train_accy 96.71
2025-01-12 02:33:24,235 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.464,  Train_accy 96.10
2025-01-12 02:33:34,049 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.464,  Train_accy 96.48
2025-01-12 02:33:44,345 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.463,  Train_accy 96.73
2025-01-12 02:36:04,598 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.466,  Train_accy 96.44, Test_accy 71.40
2025-01-12 02:38:56,579 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.462,  Train_accy 96.30
2025-01-12 02:42:52,000 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.464,  Train_accy 96.67
2025-01-12 02:44:06,248 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.463,  Train_accy 96.57
2025-01-12 02:44:19,106 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.462,  Train_accy 96.57
2025-01-12 02:45:36,161 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.464,  Train_accy 96.20, Test_accy 71.76
2025-01-12 02:46:47,032 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.461,  Train_accy 96.46
2025-01-12 02:49:00,338 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.461,  Train_accy 96.61
2025-01-12 02:50:55,809 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.463,  Train_accy 96.59
2025-01-12 02:51:08,114 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.460,  Train_accy 96.71
2025-01-12 02:51:48,165 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.459,  Train_accy 96.75, Test_accy 71.33
2025-01-12 02:52:01,201 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.462,  Train_accy 96.55
2025-01-12 02:52:11,837 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.460,  Train_accy 96.79
2025-01-12 02:52:23,628 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.460,  Train_accy 96.75
2025-01-12 02:52:37,176 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.458,  Train_accy 96.38
2025-01-12 02:52:56,512 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.458,  Train_accy 96.57, Test_accy 71.51
2025-01-12 02:53:06,909 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.460,  Train_accy 96.61
2025-01-12 02:53:16,931 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.454,  Train_accy 96.99
2025-01-12 02:53:29,874 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.459,  Train_accy 96.46
2025-01-12 02:54:47,127 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.461,  Train_accy 96.16
2025-01-12 02:57:13,397 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.459,  Train_accy 96.55, Test_accy 71.41
2025-01-12 02:58:05,562 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.459,  Train_accy 96.61
2025-01-12 02:58:19,025 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.457,  Train_accy 96.81
2025-01-12 02:58:32,076 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.461,  Train_accy 96.34
2025-01-12 02:58:45,048 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.459,  Train_accy 96.32
2025-01-12 02:59:02,891 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.460,  Train_accy 96.28, Test_accy 71.57
2025-01-12 02:59:16,275 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.458,  Train_accy 96.36
2025-01-12 02:59:29,070 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.459,  Train_accy 96.69
2025-01-12 02:59:42,371 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.458,  Train_accy 96.79
2025-01-12 02:59:52,518 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.455,  Train_accy 96.89
2025-01-12 03:00:07,565 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.455,  Train_accy 96.65, Test_accy 71.32
2025-01-12 03:00:48,849 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.460,  Train_accy 96.36
2025-01-12 03:02:30,804 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.458,  Train_accy 97.09
2025-01-12 03:04:02,815 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.458,  Train_accy 96.71
2025-01-12 03:04:15,153 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.460,  Train_accy 96.46
2025-01-12 03:04:29,057 [der.py] => darknet eval: 
2025-01-12 03:04:29,057 [der.py] => CNN top1 curve: 71.41
2025-01-12 03:04:29,057 [der.py] => CNN top5 curve: 96.33
2025-01-12 03:04:29,060 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 03:05:14,139 [der.py] => Exemplar size: 1050
2025-01-12 03:05:14,140 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-12 03:05:14,140 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-12 03:05:14,140 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-12 03:05:14,140 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-12 03:05:14,140 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-12 03:05:14,140 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-12 03:05:14,141 [trainer.py] => All params: 63139730
2025-01-12 03:05:14,142 [trainer.py] => Trainable params: 21056506
2025-01-12 03:05:14,493 [der.py] => Learning on 35-45
2025-01-12 03:05:14,496 [der.py] => All params: 84190952
2025-01-12 03:05:14,497 [der.py] => Trainable params: 21066116
2025-01-12 03:12:35,185 [der.py] => Task 4, Epoch 150/150 => Loss 0.016, Loss_clf 0.007, Loss_aux 0.008, Train_accy 100.00
2025-01-12 03:12:35,885 [der.py] => Task 4, Epoch 150/150 => Loss 0.016, Loss_clf 0.007, Loss_aux 0.008, Train_accy 100.00
2025-01-12 03:16:07,019 [der.py] => Task 1, Epoch 150/150 => Loss 0.007, Loss_clf 0.004, Loss_aux 0.002, Train_accy 100.00
2025-01-12 03:16:36,941 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 0.083,  Train_accy 7.68, Test_accy 22.62
2025-01-12 03:16:36,981 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 0.068,  Train_accy 7.68, Test_accy 22.44
2025-01-12 03:16:58,203 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.100,  Train_accy 41.38, Test_accy 40.13
2025-01-12 03:17:14,090 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 0.076,  Train_accy 7.96
2025-01-12 03:17:14,381 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 0.063,  Train_accy 7.91
2025-01-12 03:17:20,366 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.557,  Train_accy 65.38
2025-01-12 03:17:44,083 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.319,  Train_accy 75.25
2025-01-12 03:17:51,772 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 0.072,  Train_accy 7.95
2025-01-12 03:17:52,073 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 0.060,  Train_accy 7.91
2025-01-12 03:18:07,319 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.179,  Train_accy 81.98
2025-01-12 03:18:30,595 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.097,  Train_accy 85.72
2025-01-12 03:18:30,626 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 0.070,  Train_accy 8.02
2025-01-12 03:18:30,772 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 0.058,  Train_accy 8.02
2025-01-12 03:19:05,722 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 0.068,  Train_accy 8.00
2025-01-12 03:19:05,930 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 0.057,  Train_accy 8.00
2025-01-12 03:19:44,554 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.047,  Train_accy 88.45, Test_accy 59.51
2025-01-12 03:19:54,057 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.011,  Train_accy 89.72
2025-01-12 03:20:03,903 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.982,  Train_accy 91.66
2025-01-12 03:20:13,558 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.946,  Train_accy 93.46
2025-01-12 03:20:23,163 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.923,  Train_accy 94.26
2025-01-12 03:20:36,967 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.895,  Train_accy 96.17, Test_accy 63.09
2025-01-12 03:20:46,629 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.890,  Train_accy 95.81
2025-01-12 03:20:56,185 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.871,  Train_accy 97.27
2025-01-12 03:21:06,133 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.862,  Train_accy 97.40
2025-01-12 03:21:15,719 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.846,  Train_accy 97.94
2025-01-12 03:21:29,555 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.856,  Train_accy 97.91, Test_accy 72.09
2025-01-12 03:21:35,660 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 0.067,  Train_accy 7.95, Test_accy 23.46
2025-01-12 03:21:35,686 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 0.056,  Train_accy 7.95, Test_accy 23.40
2025-01-12 03:21:43,284 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.840,  Train_accy 98.47
2025-01-12 03:22:06,691 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.832,  Train_accy 98.73
2025-01-12 03:22:15,807 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 0.066,  Train_accy 8.04
2025-01-12 03:22:16,074 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 0.055,  Train_accy 8.05
2025-01-12 03:22:28,688 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.832,  Train_accy 98.69
2025-01-12 03:22:52,329 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.837,  Train_accy 98.67
2025-01-12 03:22:54,246 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 0.064,  Train_accy 8.00
2025-01-12 03:22:54,623 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 0.054,  Train_accy 8.02
2025-01-12 03:23:22,135 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.832,  Train_accy 98.75, Test_accy 72.84
2025-01-12 03:23:31,328 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 0.064,  Train_accy 7.96
2025-01-12 03:23:32,147 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 0.053,  Train_accy 7.96
2025-01-12 03:23:44,866 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.820,  Train_accy 99.23
2025-01-12 03:24:08,393 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.815,  Train_accy 99.10
2025-01-12 03:24:09,618 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 0.063,  Train_accy 8.07
2025-01-12 03:24:10,200 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 0.053,  Train_accy 8.05
2025-01-12 03:24:40,667 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.814,  Train_accy 99.29
2025-01-12 03:25:00,152 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.814,  Train_accy 99.33
2025-01-12 03:25:15,175 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.806,  Train_accy 99.55, Test_accy 74.18
2025-01-12 03:25:24,706 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.805,  Train_accy 99.46
2025-01-12 03:25:35,280 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.800,  Train_accy 99.53
2025-01-12 03:25:44,696 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.808,  Train_accy 99.38
2025-01-12 03:25:45,780 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 0.062,  Train_accy 8.02, Test_accy 23.51
2025-01-12 03:25:45,794 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 0.052,  Train_accy 8.05, Test_accy 23.55
2025-01-12 03:26:03,330 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.808,  Train_accy 99.40
2025-01-12 03:26:26,863 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 0.051,  Train_accy 8.14
2025-01-12 03:26:26,984 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 0.061,  Train_accy 8.18
2025-01-12 03:26:34,083 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.804,  Train_accy 99.46, Test_accy 75.07
2025-01-12 03:26:57,203 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.805,  Train_accy 99.55
2025-01-12 03:27:04,739 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 0.051,  Train_accy 8.02
2025-01-12 03:27:04,978 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 0.060,  Train_accy 8.05
2025-01-12 03:27:19,330 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.802,  Train_accy 99.55
2025-01-12 03:27:42,821 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.794,  Train_accy 99.68
2025-01-12 03:27:43,422 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 0.050,  Train_accy 8.07
2025-01-12 03:27:43,555 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 0.059,  Train_accy 8.11
2025-01-12 03:28:05,392 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.797,  Train_accy 99.42
2025-01-12 03:28:22,453 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 0.059,  Train_accy 8.04
2025-01-12 03:28:22,745 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 0.050,  Train_accy 7.96
2025-01-12 03:28:34,619 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.799,  Train_accy 99.42, Test_accy 74.98
2025-01-12 03:28:58,235 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.793,  Train_accy 99.74
2025-01-12 03:29:12,206 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.794,  Train_accy 99.53
2025-01-12 03:29:24,663 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.794,  Train_accy 99.55
2025-01-12 03:29:32,895 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 0.049,  Train_accy 8.13, Test_accy 23.59
2025-01-12 03:29:32,927 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 0.058,  Train_accy 8.20, Test_accy 23.60
2025-01-12 03:29:36,260 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.793,  Train_accy 99.66
2025-01-12 03:30:50,578 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 0.057,  Train_accy 8.18
2025-01-12 03:30:50,616 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 0.049,  Train_accy 8.05
2025-01-12 03:31:18,318 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 0.057,  Train_accy 8.20
2025-01-12 03:31:18,640 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 0.048,  Train_accy 8.14
2025-01-12 03:31:19,103 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.787,  Train_accy 99.74, Test_accy 75.44
2025-01-12 03:31:43,322 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.789,  Train_accy 99.66
2025-01-12 03:31:58,684 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 0.048,  Train_accy 8.18
2025-01-12 03:31:58,929 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 0.056,  Train_accy 8.47
2025-01-12 03:32:01,866 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.791,  Train_accy 99.68
2025-01-12 03:32:23,135 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.783,  Train_accy 99.68
2025-01-12 03:32:42,132 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 0.047,  Train_accy 8.20
2025-01-12 03:32:42,421 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 0.055,  Train_accy 8.50
2025-01-12 03:32:45,535 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.787,  Train_accy 99.76
2025-01-12 03:34:28,853 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.787,  Train_accy 99.76, Test_accy 76.00
2025-01-12 03:34:38,927 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.786,  Train_accy 99.63
2025-01-12 03:34:48,863 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.781,  Train_accy 99.70
2025-01-12 03:34:58,388 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.787,  Train_accy 99.61
2025-01-12 03:35:07,850 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.782,  Train_accy 99.78
2025-01-12 03:35:22,048 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.786,  Train_accy 99.74, Test_accy 76.47
2025-01-12 03:35:31,807 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.786,  Train_accy 99.70
2025-01-12 03:35:41,828 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.784,  Train_accy 99.74
2025-01-12 03:35:51,259 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.783,  Train_accy 99.81
2025-01-12 03:36:00,884 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.783,  Train_accy 99.85
2025-01-12 03:36:16,178 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.777,  Train_accy 99.85, Test_accy 77.22
2025-01-12 03:36:26,196 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.781,  Train_accy 99.61
2025-01-12 03:36:35,792 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.781,  Train_accy 99.74
2025-01-12 03:36:44,149 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 0.047,  Train_accy 8.11, Test_accy 23.59
2025-01-12 03:36:44,191 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 0.055,  Train_accy 8.45, Test_accy 23.72
2025-01-12 03:36:45,603 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.779,  Train_accy 99.83
2025-01-12 03:36:55,568 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.779,  Train_accy 99.78
2025-01-12 03:37:14,150 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.776,  Train_accy 99.83, Test_accy 76.51
2025-01-12 03:37:28,536 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.782,  Train_accy 99.76
2025-01-12 03:37:42,803 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.777,  Train_accy 99.70
2025-01-12 03:37:52,314 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.778,  Train_accy 99.68
2025-01-12 03:38:01,824 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.777,  Train_accy 99.83
2025-01-12 03:38:20,084 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.776,  Train_accy 99.83, Test_accy 77.04
2025-01-12 03:38:30,012 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.775,  Train_accy 99.72
2025-01-12 03:38:40,904 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.776,  Train_accy 99.81
2025-01-12 03:38:53,318 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.774,  Train_accy 99.85
2025-01-12 03:39:03,584 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 0.054,  Train_accy 8.63
2025-01-12 03:39:03,618 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 0.046,  Train_accy 8.40
2025-01-12 03:39:04,850 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.773,  Train_accy 99.83
2025-01-12 03:39:32,663 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.775,  Train_accy 99.83, Test_accy 77.13
2025-01-12 03:39:44,518 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 0.054,  Train_accy 8.70
2025-01-12 03:39:44,780 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 0.046,  Train_accy 8.31
2025-01-12 03:39:52,138 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.776,  Train_accy 99.81
2025-01-12 03:40:15,661 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.771,  Train_accy 99.87
2025-01-12 03:40:25,046 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 0.053,  Train_accy 8.76
2025-01-12 03:40:25,290 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 0.045,  Train_accy 8.52
2025-01-12 03:40:37,986 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.772,  Train_accy 99.85
2025-01-12 03:41:01,391 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.771,  Train_accy 99.91
2025-01-12 03:41:03,093 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 0.052,  Train_accy 8.72
2025-01-12 03:41:03,429 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 0.045,  Train_accy 8.47
2025-01-12 03:41:46,606 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.774,  Train_accy 99.81, Test_accy 77.11
2025-01-12 03:41:58,301 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.771,  Train_accy 99.85
2025-01-12 03:42:08,649 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.772,  Train_accy 99.87
2025-01-12 03:42:18,620 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.773,  Train_accy 99.85
2025-01-12 03:42:28,579 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.771,  Train_accy 99.87
2025-01-12 03:42:42,791 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.773,  Train_accy 99.83, Test_accy 77.80
2025-01-12 03:42:53,067 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.772,  Train_accy 99.81
2025-01-12 03:43:03,005 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.774,  Train_accy 99.85
2025-01-12 03:43:13,217 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.770,  Train_accy 99.89
2025-01-12 03:43:21,138 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 0.045,  Train_accy 8.56, Test_accy 23.95
2025-01-12 03:43:21,154 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 0.052,  Train_accy 8.86, Test_accy 24.65
2025-01-12 03:43:23,467 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.771,  Train_accy 99.78
2025-01-12 03:43:48,068 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.767,  Train_accy 99.87, Test_accy 77.51
2025-01-12 03:44:05,900 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 0.044,  Train_accy 8.56
2025-01-12 03:44:05,913 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 0.052,  Train_accy 9.14
2025-01-12 03:44:09,759 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.768,  Train_accy 99.96
2025-01-12 03:44:33,192 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.773,  Train_accy 99.91
2025-01-12 03:44:44,374 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 0.051,  Train_accy 9.23
2025-01-12 03:44:44,678 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 0.044,  Train_accy 8.65
2025-01-12 03:44:55,471 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.770,  Train_accy 99.83
2025-01-12 03:45:19,003 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.771,  Train_accy 99.83
2025-01-12 03:45:23,428 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 0.051,  Train_accy 9.44
2025-01-12 03:45:23,660 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 0.044,  Train_accy 8.68
2025-01-12 03:45:55,929 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 0.050,  Train_accy 9.53
2025-01-12 03:45:56,123 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 0.043,  Train_accy 8.77
2025-01-12 03:46:33,741 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.771,  Train_accy 99.78, Test_accy 77.36
2025-01-12 03:46:43,572 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.770,  Train_accy 99.76
2025-01-12 03:46:53,879 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.769,  Train_accy 99.85
2025-01-12 03:47:03,775 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.771,  Train_accy 99.91
2025-01-12 03:47:13,884 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.770,  Train_accy 99.89
2025-01-12 03:47:27,736 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.769,  Train_accy 99.94, Test_accy 78.04
2025-01-12 03:47:37,782 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.768,  Train_accy 99.85
2025-01-12 03:47:47,416 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.769,  Train_accy 99.87
2025-01-12 03:47:57,451 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.766,  Train_accy 99.94
2025-01-12 03:48:06,969 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.769,  Train_accy 99.91
2025-01-12 03:48:20,321 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.770,  Train_accy 99.91, Test_accy 77.56
2025-01-12 03:48:30,275 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.769,  Train_accy 99.91
2025-01-12 03:48:39,839 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.765,  Train_accy 99.81
2025-01-12 03:48:49,302 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.768,  Train_accy 99.83
2025-01-12 03:48:58,770 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.770,  Train_accy 99.85
2025-01-12 03:48:59,979 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 0.050,  Train_accy 9.55, Test_accy 25.78
2025-01-12 03:48:59,981 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 0.043,  Train_accy 9.06, Test_accy 24.56
2025-01-12 03:49:25,431 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.766,  Train_accy 99.87, Test_accy 77.84
2025-01-12 03:49:39,666 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 0.043,  Train_accy 8.90
2025-01-12 03:49:39,946 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 0.049,  Train_accy 9.53
2025-01-12 03:49:47,961 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.766,  Train_accy 99.83
2025-01-12 03:50:11,423 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.769,  Train_accy 99.96
2025-01-12 03:50:17,925 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 0.042,  Train_accy 9.05
2025-01-12 03:50:18,140 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 0.049,  Train_accy 9.98
2025-01-12 03:50:33,805 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.765,  Train_accy 99.91
2025-01-12 03:50:56,516 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 0.042,  Train_accy 8.95
2025-01-12 03:50:56,697 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 0.049,  Train_accy 9.78
2025-01-12 03:50:56,970 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.767,  Train_accy 99.87
2025-01-12 03:51:32,163 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.768,  Train_accy 99.85, Test_accy 77.67
2025-01-12 03:51:36,998 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 0.048,  Train_accy 10.07
2025-01-12 03:51:37,027 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 0.041,  Train_accy 9.19
2025-01-12 03:51:53,190 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.766,  Train_accy 99.89
2025-01-12 03:52:16,144 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.767,  Train_accy 99.94
2025-01-12 03:52:27,382 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.766,  Train_accy 99.87
2025-01-12 03:52:38,388 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.766,  Train_accy 99.85
2025-01-12 03:52:53,668 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.767,  Train_accy 99.87, Test_accy 77.96
2025-01-12 03:53:03,683 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.766,  Train_accy 99.83
2025-01-12 03:53:13,283 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.765,  Train_accy 99.87
2025-01-12 03:53:23,418 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.769,  Train_accy 99.91
2025-01-12 03:53:32,925 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.769,  Train_accy 99.91
2025-01-12 03:53:46,687 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.768,  Train_accy 99.94, Test_accy 77.93
2025-01-12 03:53:56,120 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.767,  Train_accy 99.85
2025-01-12 03:54:05,659 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.766,  Train_accy 99.81
2025-01-12 03:54:15,509 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.768,  Train_accy 99.83
2025-01-12 03:54:24,943 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.766,  Train_accy 99.89
2025-01-12 03:54:38,070 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.763,  Train_accy 99.81, Test_accy 78.02
2025-01-12 03:54:47,327 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.767,  Train_accy 99.89
2025-01-12 03:54:57,386 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.766,  Train_accy 99.94
2025-01-12 03:55:06,863 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.765,  Train_accy 99.81
2025-01-12 03:55:16,488 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.766,  Train_accy 99.89
2025-01-12 03:55:16,489 [der.py] => weight align student!
2025-01-12 03:55:24,371 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 0.042,  Train_accy 9.24, Test_accy 24.91
2025-01-12 03:55:24,394 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 0.048,  Train_accy 10.13, Test_accy 26.22
2025-01-12 03:56:05,469 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 0.048,  Train_accy 10.36
2025-01-12 03:56:05,602 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 0.041,  Train_accy 9.30
2025-01-12 03:56:13,847 [der.py] => darknet eval: 
2025-01-12 03:56:13,847 [der.py] => CNN top1 curve: 79.49
2025-01-12 03:56:13,848 [der.py] => CNN top5 curve: 96.73
2025-01-12 03:56:13,849 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 03:56:37,502 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 0.041,  Train_accy 9.53
2025-01-12 03:56:37,589 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 0.047,  Train_accy 10.56
2025-01-12 03:57:01,530 [der.py] => Exemplar size: 750
2025-01-12 03:57:01,531 [trainer.py] => CNN: {'total': 85.16, '0': 91.67, '1': 83.33, '2': 91.67, '3': 76.67, '4': 82.22, '5': 61.11, '6': 57.22, '7': 72.22, '8': 74.44, '9': 62.22, '10': 94.44, '11': 97.22, '12': 81.67, '13': 88.89, '14': 80.0, '15': 95.0, '16': 97.22, '17': 97.22, '18': 90.56, '19': 96.11, '20': 97.22, '21': 90.0, '22': 86.11, '23': 90.0, 'old': 79.67, 'new': 93.39}
2025-01-12 03:57:01,531 [trainer.py] => NME: {'total': 82.44, '0': 91.11, '1': 76.67, '2': 89.44, '3': 71.67, '4': 83.33, '5': 56.67, '6': 42.78, '7': 64.44, '8': 58.89, '9': 63.89, '10': 93.33, '11': 99.44, '12': 80.0, '13': 79.44, '14': 73.89, '15': 94.44, '16': 98.33, '17': 95.56, '18': 89.44, '19': 93.89, '20': 95.56, '21': 92.78, '22': 90.56, '23': 91.11, 'old': 75.0, 'new': 93.61}
2025-01-12 03:57:01,531 [trainer.py] => CNN top1 curve: [85.93, 85.16]
2025-01-12 03:57:01,531 [trainer.py] => CNN top5 curve: [97.59, 97.89]
2025-01-12 03:57:01,531 [trainer.py] => NME top1 curve: [85.48, 82.44]
2025-01-12 03:57:01,531 [trainer.py] => NME top5 curve: [98.52, 97.89]

2025-01-12 03:57:01,532 [trainer.py] => All params: 42091068
2025-01-12 03:57:01,532 [trainer.py] => Trainable params: 21049456
2025-01-12 03:57:07,352 [der.py] => Learning on 25-35
2025-01-12 03:57:07,354 [der.py] => All params: 63139730
2025-01-12 03:57:07,356 [der.py] => Trainable params: 21056506
2025-01-12 03:57:10,259 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 0.047,  Train_accy 10.45
2025-01-12 03:57:10,484 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 0.041,  Train_accy 9.50
2025-01-12 03:57:37,290 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 0.046,  Train_accy 10.43
2025-01-12 03:57:37,781 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 0.040,  Train_accy 9.51
2025-01-12 04:01:45,690 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 0.046,  Train_accy 10.72, Test_accy 27.22
2025-01-12 04:01:45,702 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 0.040,  Train_accy 9.75, Test_accy 25.90
2025-01-12 04:02:26,283 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 0.040,  Train_accy 9.89
2025-01-12 04:02:26,430 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 0.046,  Train_accy 10.43
2025-01-12 04:02:56,267 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 0.040,  Train_accy 9.87
2025-01-12 04:02:56,424 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 0.045,  Train_accy 10.85
2025-01-12 04:03:26,257 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 0.039,  Train_accy 9.95
2025-01-12 04:03:26,399 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 0.045,  Train_accy 11.26
2025-01-12 04:03:55,253 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 0.039,  Train_accy 9.82
2025-01-12 04:03:55,403 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 0.045,  Train_accy 10.72
2025-01-12 04:07:01,143 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 0.045,  Train_accy 11.08, Test_accy 27.60
2025-01-12 04:07:01,155 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 0.039,  Train_accy 10.13, Test_accy 26.43
2025-01-12 04:07:39,618 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 0.045,  Train_accy 11.23
2025-01-12 04:07:39,843 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 0.039,  Train_accy 10.49
2025-01-12 04:08:17,401 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 0.044,  Train_accy 11.10
2025-01-12 04:08:17,817 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 0.038,  Train_accy 10.25
2025-01-12 04:08:55,618 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 0.044,  Train_accy 11.10
2025-01-12 04:08:56,547 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 0.038,  Train_accy 10.09
2025-01-12 04:09:33,175 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 0.044,  Train_accy 11.32
2025-01-12 04:09:33,975 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 0.038,  Train_accy 10.47
2025-01-12 04:10:29,631 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 0.043,  Train_accy 11.44, Test_accy 27.81
2025-01-12 04:10:29,715 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 0.038,  Train_accy 10.68, Test_accy 26.75
2025-01-12 04:11:08,384 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 0.038,  Train_accy 10.45
2025-01-12 04:11:08,551 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 0.043,  Train_accy 11.19
2025-01-12 04:11:46,251 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 0.038,  Train_accy 10.63
2025-01-12 04:11:46,515 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 0.043,  Train_accy 11.46
2025-01-12 04:12:24,504 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 0.037,  Train_accy 10.63
2025-01-12 04:12:24,686 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 0.043,  Train_accy 11.55
2025-01-12 04:13:05,732 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 0.037,  Train_accy 10.90
2025-01-12 04:13:06,003 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 0.043,  Train_accy 11.80
2025-01-12 04:15:59,224 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 0.037,  Train_accy 10.83, Test_accy 27.46
2025-01-12 04:15:59,229 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 0.043,  Train_accy 11.44, Test_accy 28.37
2025-01-12 04:16:37,330 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 0.037,  Train_accy 10.81
2025-01-12 04:16:37,643 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 0.042,  Train_accy 11.60
2025-01-12 04:17:16,146 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 0.037,  Train_accy 10.85
2025-01-12 04:17:16,387 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 0.042,  Train_accy 11.55
2025-01-12 04:18:04,844 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 0.042,  Train_accy 11.69
2025-01-12 04:18:05,108 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 0.037,  Train_accy 11.01
2025-01-12 04:18:35,583 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 0.042,  Train_accy 11.57
2025-01-12 04:18:35,752 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 0.036,  Train_accy 10.74
2025-01-12 04:20:20,975 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 0.042,  Train_accy 11.87, Test_accy 28.90
2025-01-12 04:20:21,037 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 0.037,  Train_accy 11.23, Test_accy 27.62
2025-01-12 04:20:59,187 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 0.041,  Train_accy 11.86
2025-01-12 04:20:59,518 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 0.036,  Train_accy 11.23
2025-01-12 04:21:37,260 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 0.041,  Train_accy 11.93
2025-01-12 04:21:37,535 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 0.036,  Train_accy 11.24
2025-01-12 04:22:26,648 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 0.036,  Train_accy 11.21
2025-01-12 04:22:26,650 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 0.041,  Train_accy 11.86
2025-01-12 04:22:56,593 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 0.041,  Train_accy 12.05
2025-01-12 04:22:56,822 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 0.036,  Train_accy 11.26
2025-01-12 04:25:03,236 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 0.041,  Train_accy 12.02, Test_accy 28.97
2025-01-12 04:25:03,284 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 0.036,  Train_accy 11.23, Test_accy 27.66
2025-01-12 04:25:42,821 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 0.041,  Train_accy 11.89
2025-01-12 04:25:43,122 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 0.036,  Train_accy 11.23
2025-01-12 04:26:20,944 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 0.041,  Train_accy 12.25
2025-01-12 04:26:21,222 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 0.036,  Train_accy 11.48
2025-01-12 04:26:59,643 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 0.041,  Train_accy 12.32
2025-01-12 04:26:59,871 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 0.035,  Train_accy 11.57
2025-01-12 04:27:36,930 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 0.040,  Train_accy 12.45
2025-01-12 04:27:37,837 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 0.035,  Train_accy 11.53
2025-01-12 04:30:31,665 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 0.035,  Train_accy 11.33, Test_accy 28.15
2025-01-12 04:30:31,706 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 0.040,  Train_accy 12.34, Test_accy 29.76
2025-01-12 04:31:09,926 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 0.041,  Train_accy 12.20
2025-01-12 04:31:10,011 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 0.035,  Train_accy 11.39
2025-01-12 04:31:48,820 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 0.040,  Train_accy 11.86
2025-01-12 04:31:49,171 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 0.035,  Train_accy 11.17
2025-01-12 04:32:27,397 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 0.040,  Train_accy 12.49
2025-01-12 04:32:27,615 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 0.035,  Train_accy 11.51
2025-01-12 04:33:05,330 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 0.040,  Train_accy 12.29
2025-01-12 04:33:05,594 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 0.035,  Train_accy 11.48
2025-01-12 04:33:57,629 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 0.040,  Train_accy 12.27, Test_accy 29.79
2025-01-12 04:33:58,585 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 0.035,  Train_accy 11.50, Test_accy 28.27
2025-01-12 04:34:36,077 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 0.040,  Train_accy 12.38
2025-01-12 04:34:36,930 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 0.035,  Train_accy 11.69
2025-01-12 04:35:14,107 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 0.039,  Train_accy 12.25
2025-01-12 04:35:15,036 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 0.035,  Train_accy 11.59
2025-01-12 04:35:52,212 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 0.040,  Train_accy 12.07
2025-01-12 04:35:53,130 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 0.035,  Train_accy 11.14
2025-01-12 04:36:29,900 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 0.039,  Train_accy 12.43
2025-01-12 04:36:30,814 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 0.034,  Train_accy 11.30
2025-01-12 04:37:22,174 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 0.039,  Train_accy 12.20, Test_accy 29.85
2025-01-12 04:37:22,844 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 0.035,  Train_accy 11.60, Test_accy 28.33
2025-01-12 04:37:57,907 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 0.039,  Train_accy 12.67
2025-01-12 04:37:58,030 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 0.034,  Train_accy 11.75
2025-01-12 04:38:34,252 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 0.034,  Train_accy 11.75
2025-01-12 04:38:34,499 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 0.039,  Train_accy 12.54
2025-01-12 04:39:12,905 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 0.034,  Train_accy 11.41
2025-01-12 04:39:13,162 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 0.039,  Train_accy 12.16
2025-01-12 04:39:54,713 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 0.039,  Train_accy 12.47
2025-01-12 04:39:55,047 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 0.034,  Train_accy 11.59
2025-01-12 04:41:38,430 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 0.034,  Train_accy 11.80, Test_accy 29.00
2025-01-12 04:41:38,602 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 0.039,  Train_accy 12.56, Test_accy 30.59
2025-01-12 04:42:16,200 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 0.034,  Train_accy 11.80
2025-01-12 04:42:16,448 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 0.039,  Train_accy 12.38
2025-01-12 04:42:28,822 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-12 04:42:51,925 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.607,  Train_accy 27.92, Test_accy 28.06
2025-01-12 04:42:53,530 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 0.034,  Train_accy 12.04
2025-01-12 04:42:54,364 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 0.039,  Train_accy 12.95
2025-01-12 04:43:07,478 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.033,  Train_accy 44.70
2025-01-12 04:43:20,397 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.856,  Train_accy 49.37
2025-01-12 04:43:31,764 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 0.034,  Train_accy 11.86
2025-01-12 04:43:32,619 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 0.039,  Train_accy 12.95
2025-01-12 04:43:34,691 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.775,  Train_accy 52.78
2025-01-12 04:43:50,173 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.708,  Train_accy 55.20
2025-01-12 04:44:09,411 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 0.034,  Train_accy 12.04
2025-01-12 04:44:10,351 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 0.039,  Train_accy 12.83
2025-01-12 04:44:12,242 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.610,  Train_accy 57.92, Test_accy 32.85
2025-01-12 04:44:23,974 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.558,  Train_accy 58.76
2025-01-12 04:44:35,280 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.511,  Train_accy 61.31
2025-01-12 04:44:47,840 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.471,  Train_accy 62.91
2025-01-12 04:46:05,712 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.438,  Train_accy 63.30
2025-01-12 04:48:09,969 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.420,  Train_accy 64.91, Test_accy 38.54
2025-01-12 04:48:18,275 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 0.039,  Train_accy 12.85, Test_accy 30.48
2025-01-12 04:48:18,383 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 0.034,  Train_accy 12.11, Test_accy 28.97
2025-01-12 04:48:25,482 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.405,  Train_accy 64.29
2025-01-12 04:48:37,539 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.378,  Train_accy 65.62
2025-01-12 04:48:48,862 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.403,  Train_accy 66.59
2025-01-12 04:49:00,221 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.396,  Train_accy 67.52
2025-01-12 04:49:05,974 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 0.039,  Train_accy 12.85
2025-01-12 04:49:06,266 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 0.034,  Train_accy 11.95
2025-01-12 04:49:18,102 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.393,  Train_accy 65.54, Test_accy 41.41
2025-01-12 04:51:20,694 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 0.039,  Train_accy 12.86
2025-01-12 04:51:20,704 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 0.034,  Train_accy 11.98
2025-01-12 04:51:46,274 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.336,  Train_accy 67.50
2025-01-12 04:52:03,696 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 0.038,  Train_accy 13.01
2025-01-12 04:52:03,986 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 0.034,  Train_accy 11.75
2025-01-12 04:52:07,483 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.306,  Train_accy 69.31
2025-01-12 04:52:22,790 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.295,  Train_accy 68.38
2025-01-12 04:52:37,662 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.323,  Train_accy 67.18
2025-01-12 04:52:41,508 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 0.039,  Train_accy 13.15
2025-01-12 04:52:41,740 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 0.034,  Train_accy 12.36
2025-01-12 04:53:35,233 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.281,  Train_accy 70.34, Test_accy 48.26
2025-01-12 04:53:47,032 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.266,  Train_accy 70.17
2025-01-12 04:53:57,529 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 0.039,  Train_accy 12.61, Test_accy 30.34
2025-01-12 04:53:57,548 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 0.034,  Train_accy 11.75, Test_accy 28.86
2025-01-12 04:54:02,623 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.274,  Train_accy 69.83
2025-01-12 04:54:18,004 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.243,  Train_accy 71.52
2025-01-12 04:54:32,314 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.239,  Train_accy 70.97
2025-01-12 04:54:36,032 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 0.038,  Train_accy 12.65
2025-01-12 04:54:36,371 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 0.034,  Train_accy 11.78
2025-01-12 04:54:52,443 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.224,  Train_accy 71.18, Test_accy 51.59
2025-01-12 04:55:07,760 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.244,  Train_accy 72.91
2025-01-12 04:55:13,791 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 0.039,  Train_accy 12.97
2025-01-12 04:55:14,007 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 0.034,  Train_accy 12.02
2025-01-12 04:55:22,878 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.192,  Train_accy 73.18
2025-01-12 04:55:34,634 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.197,  Train_accy 72.36
2025-01-12 04:55:50,049 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.194,  Train_accy 72.84
2025-01-12 04:55:52,097 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 0.038,  Train_accy 12.92
2025-01-12 04:55:52,387 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 0.033,  Train_accy 11.98
2025-01-12 04:56:12,974 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.177,  Train_accy 73.70, Test_accy 54.56
2025-01-12 04:56:25,347 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.176,  Train_accy 74.11
2025-01-12 04:56:30,902 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 0.038,  Train_accy 12.85
2025-01-12 04:56:31,105 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 0.033,  Train_accy 11.62
2025-01-12 04:56:39,918 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.146,  Train_accy 74.38
2025-01-12 04:56:55,317 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.137,  Train_accy 74.11
2025-01-12 04:57:11,006 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.163,  Train_accy 74.27
2025-01-12 04:57:21,960 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 0.038,  Train_accy 13.12, Test_accy 30.56
2025-01-12 04:57:22,603 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 0.033,  Train_accy 12.16, Test_accy 28.84
2025-01-12 04:57:30,794 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.134,  Train_accy 74.88, Test_accy 54.99
2025-01-12 04:57:46,341 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.149,  Train_accy 73.45
2025-01-12 04:57:48,449 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 0.038,  Train_accy 12.79
2025-01-12 04:57:49,204 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 0.034,  Train_accy 12.20
2025-01-12 04:58:02,285 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.141,  Train_accy 74.78
2025-01-12 04:58:15,136 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 0.038,  Train_accy 12.79
2025-01-12 04:58:15,432 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.115,  Train_accy 74.91
2025-01-12 04:58:16,160 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 0.034,  Train_accy 12.02
2025-01-12 04:58:31,526 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.116,  Train_accy 74.70
2025-01-12 04:58:41,353 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 0.038,  Train_accy 13.06
2025-01-12 04:58:42,838 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 0.033,  Train_accy 12.09
2025-01-12 04:58:55,974 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.139,  Train_accy 75.60, Test_accy 54.36
2025-01-12 04:59:07,916 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 0.038,  Train_accy 12.95
2025-01-12 04:59:08,457 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.112,  Train_accy 73.71
2025-01-12 04:59:09,376 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 0.034,  Train_accy 12.07
2025-01-12 04:59:24,448 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.110,  Train_accy 75.35
2025-01-12 04:59:40,660 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.124,  Train_accy 75.60
2025-01-12 04:59:46,262 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 0.038,  Train_accy 12.70, Test_accy 30.99
2025-01-12 04:59:48,170 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 0.033,  Train_accy 11.89, Test_accy 29.37
2025-01-12 04:59:55,206 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.092,  Train_accy 75.24
2025-01-12 05:00:12,227 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 0.038,  Train_accy 13.30
2025-01-12 05:00:14,245 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 0.033,  Train_accy 12.25
2025-01-12 05:00:18,270 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.069,  Train_accy 76.04, Test_accy 54.15
2025-01-12 05:00:34,297 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.112,  Train_accy 75.09
2025-01-12 05:00:38,765 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 0.038,  Train_accy 13.05
2025-01-12 05:00:41,069 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 0.033,  Train_accy 12.09
2025-01-12 05:00:48,168 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.101,  Train_accy 75.81
2025-01-12 05:01:02,970 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.101,  Train_accy 75.68
2025-01-12 05:01:05,318 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 0.038,  Train_accy 13.42
2025-01-12 05:01:07,476 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 0.033,  Train_accy 11.89
2025-01-12 05:01:19,149 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.104,  Train_accy 75.10
2025-01-12 05:01:31,925 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 0.038,  Train_accy 13.06
2025-01-12 05:01:34,177 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 0.033,  Train_accy 12.04
2025-01-12 05:01:42,244 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.080,  Train_accy 75.92, Test_accy 58.16
2025-01-12 05:01:54,092 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.073,  Train_accy 76.27
2025-01-12 05:02:06,280 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.064,  Train_accy 76.17
2025-01-12 05:02:09,350 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 0.038,  Train_accy 13.08, Test_accy 30.86
2025-01-12 05:02:12,054 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 0.033,  Train_accy 11.78, Test_accy 29.43
2025-01-12 05:02:53,101 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.070,  Train_accy 76.17
2025-01-12 05:04:09,586 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 0.033,  Train_accy 12.09
2025-01-12 05:04:09,608 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 0.038,  Train_accy 12.95
2025-01-12 05:04:25,158 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.071,  Train_accy 76.21
2025-01-12 05:04:37,285 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 0.033,  Train_accy 12.00
2025-01-12 05:04:37,420 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 0.038,  Train_accy 12.99
2025-01-12 05:05:04,140 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 0.033,  Train_accy 11.75
2025-01-12 05:05:04,342 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 0.038,  Train_accy 12.74
2025-01-12 05:05:15,621 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.093,  Train_accy 76.15, Test_accy 53.70
2025-01-12 05:05:31,181 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 0.033,  Train_accy 11.93
2025-01-12 05:05:31,341 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 0.038,  Train_accy 12.74
2025-01-12 05:05:31,754 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.066,  Train_accy 76.40
2025-01-12 05:05:47,587 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.066,  Train_accy 76.13
2025-01-12 05:06:01,960 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.049,  Train_accy 76.40
2025-01-12 05:06:10,887 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 0.033,  Train_accy 11.78, Test_accy 29.35
2025-01-12 05:06:11,099 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 0.038,  Train_accy 12.85, Test_accy 30.82
2025-01-12 05:06:16,559 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.072,  Train_accy 76.29
2025-01-12 05:06:38,270 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 0.033,  Train_accy 11.95
2025-01-12 05:06:38,328 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 0.038,  Train_accy 13.05
2025-01-12 05:06:41,015 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.049,  Train_accy 76.36, Test_accy 54.84
2025-01-12 05:06:55,263 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.059,  Train_accy 76.48
2025-01-12 05:07:05,768 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 0.033,  Train_accy 12.18
2025-01-12 05:07:05,993 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 0.038,  Train_accy 13.32
2025-01-12 05:07:07,556 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.058,  Train_accy 76.53
2025-01-12 05:07:19,322 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.048,  Train_accy 76.57
2025-01-12 05:07:32,463 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.025,  Train_accy 76.46
2025-01-12 05:07:32,904 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 0.033,  Train_accy 12.16
2025-01-12 05:07:33,377 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 0.038,  Train_accy 13.17
2025-01-12 05:08:21,962 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 0.033,  Train_accy 11.98
2025-01-12 05:08:22,034 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 0.038,  Train_accy 13.05
2025-01-12 05:08:45,197 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.058,  Train_accy 76.00, Test_accy 59.36
2025-01-12 05:08:58,766 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.040,  Train_accy 76.72
2025-01-12 05:09:10,579 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.031,  Train_accy 76.36
2025-01-12 05:09:19,344 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 0.038,  Train_accy 12.99, Test_accy 30.83
2025-01-12 05:09:19,350 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 0.034,  Train_accy 12.20, Test_accy 29.33
2025-01-12 05:09:22,506 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.025,  Train_accy 76.61
2025-01-12 05:09:36,579 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.010,  Train_accy 76.50
2025-01-12 05:09:46,550 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 0.038,  Train_accy 13.10
2025-01-12 05:09:46,714 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 0.033,  Train_accy 12.13
2025-01-12 05:10:00,810 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.036,  Train_accy 76.61, Test_accy 60.73
2025-01-12 05:10:13,858 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 0.038,  Train_accy 13.06
2025-01-12 05:10:14,023 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 0.033,  Train_accy 11.95
2025-01-12 05:10:14,607 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.057,  Train_accy 77.26
2025-01-12 05:10:29,753 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.037,  Train_accy 76.51
2025-01-12 05:10:40,870 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 0.038,  Train_accy 12.83
2025-01-12 05:10:41,050 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 0.033,  Train_accy 11.98
2025-01-12 05:10:45,683 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.031,  Train_accy 76.40
2025-01-12 05:11:01,384 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.031,  Train_accy 76.86
2025-01-12 05:11:07,960 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 0.038,  Train_accy 12.88
2025-01-12 05:11:08,108 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 0.033,  Train_accy 11.95
2025-01-12 05:11:22,591 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.050,  Train_accy 75.89, Test_accy 59.10
2025-01-12 05:11:38,699 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.033,  Train_accy 76.95
2025-01-12 05:11:46,690 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 0.038,  Train_accy 12.90, Test_accy 31.04
2025-01-12 05:11:47,563 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 0.033,  Train_accy 12.09, Test_accy 29.44
2025-01-12 05:11:53,898 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.039,  Train_accy 76.55
2025-01-12 05:12:07,809 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.021,  Train_accy 76.32
2025-01-12 05:12:13,095 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 0.038,  Train_accy 12.88
2025-01-12 05:12:14,651 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 0.033,  Train_accy 11.95
2025-01-12 05:12:23,784 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.029,  Train_accy 76.55
2025-01-12 05:12:39,656 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 0.038,  Train_accy 12.95
2025-01-12 05:12:41,230 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 0.033,  Train_accy 12.14
2025-01-12 05:12:47,973 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.011,  Train_accy 76.65, Test_accy 59.58
2025-01-12 05:12:59,856 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.039,  Train_accy 76.48
2025-01-12 05:13:05,842 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 0.038,  Train_accy 12.83
2025-01-12 05:13:07,896 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 0.033,  Train_accy 11.84
2025-01-12 05:13:11,764 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.030,  Train_accy 76.91
2025-01-12 05:13:23,510 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.034,  Train_accy 76.59
2025-01-12 05:13:32,489 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 0.038,  Train_accy 12.95
2025-01-12 05:13:34,291 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 0.034,  Train_accy 11.82
2025-01-12 05:13:35,600 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.006,  Train_accy 76.59
2025-01-12 05:14:04,719 [der.py] => darknet eval: 
2025-01-12 05:14:04,719 [der.py] => CNN top1 curve: 30.96
2025-01-12 05:14:04,719 [der.py] => CNN top5 curve: 68.22
2025-01-12 05:14:04,721 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 05:14:04,733 [der.py] => darknet eval: 
2025-01-12 05:14:04,734 [der.py] => CNN top1 curve: 29.49
2025-01-12 05:14:04,734 [der.py] => CNN top5 curve: 65.49
2025-01-12 05:14:04,735 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 05:14:12,507 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.985,  Train_accy 76.93, Test_accy 58.09
2025-01-12 05:14:24,853 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.028,  Train_accy 76.84
2025-01-12 05:14:36,656 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.030,  Train_accy 76.82
2025-01-12 05:14:48,448 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.031,  Train_accy 76.99
2025-01-12 05:15:00,203 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.027,  Train_accy 76.76
2025-01-12 05:15:20,493 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.017,  Train_accy 77.45, Test_accy 60.28
2025-01-12 05:15:36,346 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.998,  Train_accy 77.30
2025-01-12 05:15:52,008 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.015,  Train_accy 76.78
2025-01-12 05:16:04,815 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.020,  Train_accy 77.35
2025-01-12 05:16:12,689 [der.py] => Exemplar size: 1650
2025-01-12 05:16:12,690 [trainer.py] => CNN: {'total': 77.15, '0': 60.56, '1': 74.44, '2': 92.22, '3': 49.44, '4': 87.22, '5': 47.78, '6': 71.67, '7': 57.22, '8': 52.78, '9': 60.0, '10': 91.67, '11': 78.89, '12': 85.56, '13': 83.33, '14': 60.0, '15': 93.89, '16': 95.56, '17': 96.11, '18': 91.67, '19': 95.56, '20': 96.67, '21': 90.0, '22': 83.33, '23': 63.33, '24': 66.11, '25': 82.78, '26': 90.0, '27': 92.22, '28': 75.56, '29': 80.56, '30': 91.11, '31': 83.33, '32': 95.56, '33': 68.33, '34': 77.22, '35': 96.67, '36': 96.67, '37': 81.67, '38': 97.78, '39': 95.0, '40': 90.0, '41': 97.22, '42': 99.44, '43': 97.22, '44': 87.22, '45': 52.78, '46': 70.0, '47': 46.67, '48': 57.22, '49': 51.67, '50': 51.67, '51': 60.56, '52': 55.0, '53': 55.56, 'old': 82.23, 'new': 54.28}
2025-01-12 05:16:12,690 [trainer.py] => NME: {'total': 73.45, '0': 70.0, '1': 59.44, '2': 78.89, '3': 33.33, '4': 83.33, '5': 43.33, '6': 59.44, '7': 51.67, '8': 45.56, '9': 51.11, '10': 90.0, '11': 81.11, '12': 77.22, '13': 65.56, '14': 55.0, '15': 88.89, '16': 88.89, '17': 92.78, '18': 90.0, '19': 91.11, '20': 88.89, '21': 87.22, '22': 83.33, '23': 61.67, '24': 72.78, '25': 76.11, '26': 88.33, '27': 82.78, '28': 60.56, '29': 73.33, '30': 76.67, '31': 79.44, '32': 90.56, '33': 60.0, '34': 81.67, '35': 96.67, '36': 87.78, '37': 63.33, '38': 92.78, '39': 85.56, '40': 75.56, '41': 90.56, '42': 97.22, '43': 95.56, '44': 53.89, '45': 78.33, '46': 80.56, '47': 63.89, '48': 61.67, '49': 61.67, '50': 52.22, '51': 65.0, '52': 60.0, '53': 57.78, 'old': 75.53, 'new': 64.11}
2025-01-12 05:16:12,690 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41, 77.15]
2025-01-12 05:16:12,690 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35, 96.05]
2025-01-12 05:16:12,690 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53, 73.45]
2025-01-12 05:16:12,690 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06, 94.92]

2025-01-12 05:16:13,117 [der.py] => Exemplar size: 1650
2025-01-12 05:16:13,118 [trainer.py] => CNN: {'total': 77.15, '0': 60.56, '1': 74.44, '2': 92.22, '3': 49.44, '4': 87.22, '5': 47.78, '6': 71.67, '7': 57.22, '8': 52.78, '9': 60.0, '10': 91.67, '11': 78.89, '12': 85.56, '13': 83.33, '14': 60.0, '15': 93.89, '16': 95.56, '17': 96.11, '18': 91.67, '19': 95.56, '20': 96.67, '21': 90.0, '22': 83.33, '23': 63.33, '24': 66.11, '25': 82.78, '26': 90.0, '27': 92.22, '28': 75.56, '29': 80.56, '30': 91.11, '31': 83.33, '32': 95.56, '33': 68.33, '34': 77.22, '35': 96.67, '36': 96.67, '37': 81.67, '38': 97.78, '39': 95.0, '40': 90.0, '41': 97.22, '42': 99.44, '43': 97.22, '44': 87.22, '45': 52.78, '46': 70.0, '47': 46.67, '48': 57.22, '49': 51.67, '50': 51.67, '51': 60.56, '52': 55.0, '53': 55.56, 'old': 82.23, 'new': 54.28}
2025-01-12 05:16:13,118 [trainer.py] => NME: {'total': 73.45, '0': 70.0, '1': 59.44, '2': 78.89, '3': 33.33, '4': 83.33, '5': 43.33, '6': 59.44, '7': 51.67, '8': 45.56, '9': 51.11, '10': 90.0, '11': 81.11, '12': 77.22, '13': 65.56, '14': 55.0, '15': 88.89, '16': 88.89, '17': 92.78, '18': 90.0, '19': 91.11, '20': 88.89, '21': 87.22, '22': 83.33, '23': 61.67, '24': 72.78, '25': 76.11, '26': 88.33, '27': 82.78, '28': 60.56, '29': 73.33, '30': 76.67, '31': 79.44, '32': 90.56, '33': 60.0, '34': 81.67, '35': 96.67, '36': 87.78, '37': 63.33, '38': 92.78, '39': 85.56, '40': 75.56, '41': 90.56, '42': 97.22, '43': 95.56, '44': 53.89, '45': 78.33, '46': 80.56, '47': 63.89, '48': 61.67, '49': 61.67, '50': 52.22, '51': 65.0, '52': 60.0, '53': 57.78, 'old': 75.53, 'new': 64.11}
2025-01-12 05:16:13,118 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41, 77.15]
2025-01-12 05:16:13,118 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35, 96.05]
2025-01-12 05:16:13,118 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53, 73.45]
2025-01-12 05:16:13,118 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06, 94.92]

2025-01-12 05:16:20,811 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.991,  Train_accy 76.99
2025-01-12 05:16:43,762 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.980,  Train_accy 77.09, Test_accy 60.06
2025-01-12 05:16:57,476 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.044,  Train_accy 76.91
2025-01-12 05:17:13,333 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.040,  Train_accy 76.93
2025-01-12 05:17:29,053 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.017,  Train_accy 76.91
2025-01-12 05:17:41,317 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.018,  Train_accy 76.95
2025-01-12 05:18:00,019 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.021,  Train_accy 77.18, Test_accy 60.96
2025-01-12 05:18:11,707 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.009,  Train_accy 77.28
2025-01-12 05:18:23,276 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.999,  Train_accy 77.43
2025-01-12 05:18:34,919 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.024,  Train_accy 77.07
2025-01-12 05:18:46,815 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.999,  Train_accy 76.72
2025-01-12 05:19:12,639 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.006,  Train_accy 77.07, Test_accy 60.54
2025-01-12 05:19:24,819 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.000,  Train_accy 76.90
2025-01-12 05:19:40,509 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.015,  Train_accy 76.95
2025-01-12 05:19:56,229 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.017,  Train_accy 77.22
2025-01-12 05:20:09,464 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.038,  Train_accy 77.52
2025-01-12 05:20:32,485 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.012,  Train_accy 76.74, Test_accy 57.72
2025-01-12 05:20:48,145 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.999,  Train_accy 76.59
2025-01-12 05:21:00,287 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.018,  Train_accy 77.39
2025-01-12 05:21:16,027 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.013,  Train_accy 77.43
2025-01-12 05:21:31,658 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.014,  Train_accy 77.10
2025-01-12 05:21:52,555 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.982,  Train_accy 77.22, Test_accy 60.14
2025-01-12 05:22:08,307 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.020,  Train_accy 77.09
2025-01-12 05:22:23,931 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.005,  Train_accy 77.35
2025-01-12 05:22:36,802 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.986,  Train_accy 77.35
2025-01-12 05:22:51,842 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.997,  Train_accy 77.75
2025-01-12 05:23:15,148 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.998,  Train_accy 77.30, Test_accy 60.31
2025-01-12 05:23:27,336 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.004,  Train_accy 77.28
2025-01-12 05:23:43,112 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.970,  Train_accy 76.70
2025-01-12 05:23:59,061 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.998,  Train_accy 76.93
2025-01-12 05:24:13,008 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.009,  Train_accy 77.18
2025-01-12 05:24:34,818 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.003,  Train_accy 77.30, Test_accy 59.90
2025-01-12 10:00:47,283 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.005,  Train_accy 77.09
2025-01-12 10:06:39,059 [trainer.py] => 实验名称:kd+wa对比实验
2025-01-12 10:06:39,079 [trainer.py] => config: ./exps/der.json
2025-01-12 10:06:39,079 [trainer.py] => experiment_name: 实验名称:kd+wa对比实验
2025-01-12 10:06:39,079 [trainer.py] => prefix: reproduce
2025-01-12 10:06:39,079 [trainer.py] => dataset: xrfdataset
2025-01-12 10:06:39,079 [trainer.py] => memory_size: 1650
2025-01-12 10:06:39,079 [trainer.py] => memory_per_class: 30
2025-01-12 10:06:39,079 [trainer.py] => fixed_memory: True
2025-01-12 10:06:39,079 [trainer.py] => shuffle: True
2025-01-12 10:06:39,079 [trainer.py] => init_cls: 15
2025-01-12 10:06:39,079 [trainer.py] => increment: 10
2025-01-12 10:06:39,079 [trainer.py] => model_name: der
2025-01-12 10:06:39,079 [trainer.py] => compression_epochs: 130
2025-01-12 10:06:39,079 [trainer.py] => compression_lr: 0.1
2025-01-12 10:06:39,079 [trainer.py] => is_student_wa: True
2025-01-12 10:06:39,079 [trainer.py] => wa_value: 1
2025-01-12 10:06:39,079 [trainer.py] => T: 2
2025-01-12 10:06:39,080 [trainer.py] => convnet_type: unet
2025-01-12 10:06:39,080 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-12 10:06:39,080 [trainer.py] => seed: 1993
2025-01-12 10:06:39,134 [data.py] => 加载完毕XRF原始数据集
2025-01-12 10:06:39,157 [data.py] => 加载完毕XRF原始数据集
2025-01-12 10:06:39,159 [trainer.py] => All params: 0
2025-01-12 10:06:39,159 [trainer.py] => Trainable params: 0
2025-01-12 10:06:39,383 [der.py] => Learning on 0-15
2025-01-12 10:06:39,383 [der.py] => All params: 21045611
2025-01-12 10:06:39,384 [der.py] => Trainable params: 21045611
2025-01-12 10:08:52,369 [trainer.py] => 实验名称:kd*lambda对比实验
2025-01-12 10:08:52,370 [trainer.py] => config: ./exps/der.json
2025-01-12 10:08:52,370 [trainer.py] => experiment_name: 实验名称:kd*lambda对比实验
2025-01-12 10:08:52,370 [trainer.py] => prefix: reproduce
2025-01-12 10:08:52,370 [trainer.py] => dataset: xrfdataset
2025-01-12 10:08:52,370 [trainer.py] => memory_size: 1650
2025-01-12 10:08:52,370 [trainer.py] => memory_per_class: 30
2025-01-12 10:08:52,370 [trainer.py] => fixed_memory: True
2025-01-12 10:08:52,370 [trainer.py] => shuffle: True
2025-01-12 10:08:52,370 [trainer.py] => init_cls: 15
2025-01-12 10:08:52,370 [trainer.py] => increment: 10
2025-01-12 10:08:52,370 [trainer.py] => model_name: der
2025-01-12 10:08:52,370 [trainer.py] => compression_epochs: 130
2025-01-12 10:08:52,370 [trainer.py] => compression_lr: 0.1
2025-01-12 10:08:52,370 [trainer.py] => is_student_wa: False
2025-01-12 10:08:52,370 [trainer.py] => wa_value: 1
2025-01-12 10:08:52,370 [trainer.py] => T: 2
2025-01-12 10:08:52,370 [trainer.py] => convnet_type: unet
2025-01-12 10:08:52,370 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-01-12 10:08:52,370 [trainer.py] => seed: 1993
2025-01-12 10:08:52,382 [data.py] => 加载完毕XRF原始数据集
2025-01-12 10:08:52,387 [data.py] => 加载完毕XRF原始数据集
2025-01-12 10:08:52,388 [trainer.py] => All params: 0
2025-01-12 10:08:52,388 [trainer.py] => Trainable params: 0
2025-01-12 10:08:52,560 [der.py] => Learning on 0-15
2025-01-12 10:08:52,560 [der.py] => All params: 21045611
2025-01-12 10:08:52,560 [der.py] => Trainable params: 21045611
2025-01-12 10:41:06,162 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-12 10:41:06,163 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 10:41:30,078 [der.py] => Exemplar size: 450
2025-01-12 10:41:30,078 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-12 10:41:30,078 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-12 10:41:30,078 [trainer.py] => CNN top1 curve: [89.44]
2025-01-12 10:41:30,078 [trainer.py] => CNN top5 curve: [98.93]
2025-01-12 10:41:30,078 [trainer.py] => NME top1 curve: [88.22]
2025-01-12 10:41:30,078 [trainer.py] => NME top5 curve: [98.81]

2025-01-12 10:41:30,079 [trainer.py] => All params: 21045611
2025-01-12 10:41:30,079 [trainer.py] => Trainable params: 21045611
2025-01-12 10:41:30,255 [der.py] => Learning on 15-25
2025-01-12 10:41:30,256 [der.py] => All params: 42091068
2025-01-12 10:41:30,257 [der.py] => Trainable params: 21049456
2025-01-12 10:43:07,883 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-01-12 10:43:07,884 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 10:43:31,303 [der.py] => Exemplar size: 450
2025-01-12 10:43:31,303 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-01-12 10:43:31,303 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-01-12 10:43:31,304 [trainer.py] => CNN top1 curve: [89.44]
2025-01-12 10:43:31,304 [trainer.py] => CNN top5 curve: [98.93]
2025-01-12 10:43:31,304 [trainer.py] => NME top1 curve: [88.22]
2025-01-12 10:43:31,304 [trainer.py] => NME top5 curve: [98.81]

2025-01-12 10:43:31,304 [trainer.py] => All params: 21045611
2025-01-12 10:43:31,305 [trainer.py] => Trainable params: 21045611
2025-01-12 10:43:31,457 [der.py] => Learning on 15-25
2025-01-12 10:43:31,458 [der.py] => All params: 42091068
2025-01-12 10:43:31,458 [der.py] => Trainable params: 21049456
2025-01-12 11:20:00,932 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-12 11:20:21,715 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 1.272,  Train_accy 43.23, Test_accy 44.69
2025-01-12 11:20:36,364 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 0.942,  Train_accy 68.75
2025-01-12 11:20:51,314 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 0.806,  Train_accy 78.80
2025-01-12 11:21:05,945 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 0.720,  Train_accy 85.81
2025-01-12 11:21:06,263 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-01-12 11:21:20,695 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 0.675,  Train_accy 88.60
2025-01-12 11:21:27,278 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.035,  Train_accy 45.59, Test_accy 43.49
2025-01-12 11:21:40,412 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.469,  Train_accy 70.65
2025-01-12 11:21:40,414 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.645,  Train_accy 91.55, Test_accy 71.47
2025-01-12 11:21:55,490 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.276,  Train_accy 80.43
2025-01-12 11:21:55,615 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 0.621,  Train_accy 93.25
2025-01-12 11:22:10,892 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.600,  Train_accy 94.88
2025-01-12 11:22:10,957 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.148,  Train_accy 87.33
2025-01-12 11:22:26,046 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.085,  Train_accy 89.83
2025-01-12 11:22:26,301 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.593,  Train_accy 95.12
2025-01-12 11:22:41,509 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.591,  Train_accy 95.33
2025-01-12 11:22:47,074 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.049,  Train_accy 91.94, Test_accy 71.58
2025-01-12 11:23:00,256 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.025,  Train_accy 93.01
2025-01-12 11:23:00,965 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.574,  Train_accy 96.90, Test_accy 76.42
2025-01-12 11:23:14,948 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.984,  Train_accy 95.23
2025-01-12 11:23:15,789 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.568,  Train_accy 96.82
2025-01-12 11:23:29,431 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.968,  Train_accy 95.61
2025-01-12 11:23:30,336 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.561,  Train_accy 97.44
2025-01-12 11:23:44,240 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.965,  Train_accy 95.89
2025-01-12 11:23:45,156 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.558,  Train_accy 97.35
2025-01-12 11:24:00,121 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.558,  Train_accy 97.38
2025-01-12 11:24:04,693 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.945,  Train_accy 96.80, Test_accy 75.18
2025-01-12 11:24:19,421 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.934,  Train_accy 97.44
2025-01-12 11:24:20,765 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.561,  Train_accy 97.29, Test_accy 78.27
2025-01-12 11:24:34,490 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.920,  Train_accy 97.96
2025-01-12 11:24:35,714 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.553,  Train_accy 97.81
2025-01-12 11:24:49,891 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.921,  Train_accy 97.70
2025-01-12 11:24:50,768 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.551,  Train_accy 97.98
2025-01-12 11:25:05,716 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.919,  Train_accy 97.81
2025-01-12 11:25:06,342 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.548,  Train_accy 98.28
2025-01-12 11:25:21,321 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.549,  Train_accy 98.37
2025-01-12 11:25:28,261 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.924,  Train_accy 97.72, Test_accy 76.56
2025-01-12 11:25:42,330 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.914,  Train_accy 98.02
2025-01-12 11:25:42,360 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.542,  Train_accy 98.67, Test_accy 78.96
2025-01-12 11:25:58,422 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.540,  Train_accy 98.60
2025-01-12 11:25:58,462 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.908,  Train_accy 98.15
2025-01-12 11:26:14,195 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.537,  Train_accy 98.88
2025-01-12 11:26:14,478 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.905,  Train_accy 98.52
2025-01-12 11:26:30,291 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.538,  Train_accy 98.84
2025-01-12 11:26:30,551 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.906,  Train_accy 98.34
2025-01-12 11:26:45,786 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.536,  Train_accy 99.10
2025-01-12 11:26:52,827 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.895,  Train_accy 98.62, Test_accy 78.49
2025-01-12 11:27:05,474 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.534,  Train_accy 98.65, Test_accy 79.22
2025-01-12 11:27:06,130 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.893,  Train_accy 98.69
2025-01-12 11:27:20,467 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.533,  Train_accy 99.14
2025-01-12 11:27:21,652 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.888,  Train_accy 98.82
2025-01-12 11:27:34,858 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.531,  Train_accy 99.03
2025-01-12 11:27:36,065 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.888,  Train_accy 98.97
2025-01-12 11:27:50,004 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.530,  Train_accy 99.03
2025-01-12 11:27:51,138 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.884,  Train_accy 98.99
2025-01-12 11:28:05,058 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.532,  Train_accy 98.99
2025-01-12 11:28:12,653 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.882,  Train_accy 98.97, Test_accy 79.53
2025-01-12 11:28:24,616 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.530,  Train_accy 98.95, Test_accy 79.78
2025-01-12 11:28:25,932 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.882,  Train_accy 99.14
2025-01-12 11:28:38,694 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.533,  Train_accy 98.77
2025-01-12 11:28:40,337 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.877,  Train_accy 99.05
2025-01-12 11:28:53,847 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.527,  Train_accy 99.10
2025-01-12 11:28:55,129 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.876,  Train_accy 99.01
2025-01-12 11:29:08,131 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.526,  Train_accy 98.86
2025-01-12 11:29:09,317 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.879,  Train_accy 99.08
2025-01-12 11:29:22,526 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.525,  Train_accy 98.99
2025-01-12 11:29:59,866 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.525,  Train_accy 99.10, Test_accy 80.07
2025-01-12 11:29:59,882 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.878,  Train_accy 99.05, Test_accy 78.36
2025-01-12 11:31:37,253 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.524,  Train_accy 99.03
2025-01-12 11:31:38,709 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.881,  Train_accy 99.05
2025-01-12 11:31:52,424 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.526,  Train_accy 99.01
2025-01-12 11:31:53,256 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.871,  Train_accy 99.18
2025-01-12 11:32:06,587 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.527,  Train_accy 99.08
2025-01-12 11:32:07,899 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.869,  Train_accy 99.12
2025-01-12 11:32:21,110 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.523,  Train_accy 99.05
2025-01-12 11:32:22,680 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.870,  Train_accy 98.92
2025-01-12 11:33:02,923 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.523,  Train_accy 99.18, Test_accy 80.04
2025-01-12 11:33:02,942 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.870,  Train_accy 99.12, Test_accy 79.73
2025-01-12 11:33:18,479 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.524,  Train_accy 99.20
2025-01-12 11:33:18,571 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.868,  Train_accy 98.86
2025-01-12 11:33:33,137 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.524,  Train_accy 99.14
2025-01-12 11:33:33,483 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.871,  Train_accy 99.08
2025-01-12 11:33:47,614 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.519,  Train_accy 99.40
2025-01-12 11:33:48,253 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.870,  Train_accy 98.99
2025-01-12 11:34:02,538 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.519,  Train_accy 99.33
2025-01-12 11:34:03,626 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.867,  Train_accy 99.14
2025-01-12 11:34:23,175 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.523,  Train_accy 99.18, Test_accy 80.47
2025-01-12 11:34:23,533 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.865,  Train_accy 99.16, Test_accy 79.91
2025-01-12 11:34:38,356 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.522,  Train_accy 98.99
2025-01-12 11:34:38,627 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.867,  Train_accy 99.14
2025-01-12 11:34:53,558 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.519,  Train_accy 99.25
2025-01-12 11:34:53,676 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.868,  Train_accy 99.23
2025-01-12 11:35:08,604 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.522,  Train_accy 99.14
2025-01-12 11:35:08,659 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.859,  Train_accy 99.46
2025-01-12 11:35:23,758 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.859,  Train_accy 99.40
2025-01-12 11:35:23,768 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.521,  Train_accy 99.14
2025-01-12 11:35:45,288 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.864,  Train_accy 99.31, Test_accy 80.24
2025-01-12 11:35:45,471 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.521,  Train_accy 99.08, Test_accy 80.20
2025-01-12 11:36:00,307 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.864,  Train_accy 99.23
2025-01-12 11:36:00,429 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.520,  Train_accy 99.12
2025-01-12 11:36:15,193 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.859,  Train_accy 99.42
2025-01-12 11:36:15,563 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.519,  Train_accy 99.38
2025-01-12 11:36:29,965 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.864,  Train_accy 99.14
2025-01-12 11:36:30,547 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.521,  Train_accy 99.25
2025-01-12 11:36:44,880 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.863,  Train_accy 99.25
2025-01-12 11:36:45,589 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.520,  Train_accy 99.27
2025-01-12 11:37:05,303 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.862,  Train_accy 99.20, Test_accy 79.67
2025-01-12 11:37:06,021 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.517,  Train_accy 99.18, Test_accy 80.58
2025-01-12 11:37:19,525 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.862,  Train_accy 99.03
2025-01-12 11:37:20,460 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.516,  Train_accy 99.53
2025-01-12 11:37:33,616 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.860,  Train_accy 99.38
2025-01-12 11:37:34,754 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.516,  Train_accy 99.42
2025-01-12 11:37:47,892 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.862,  Train_accy 99.31
2025-01-12 11:37:49,216 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.516,  Train_accy 99.31
2025-01-12 11:38:02,493 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.861,  Train_accy 99.20
2025-01-12 11:38:04,063 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.514,  Train_accy 99.40
2025-01-12 11:38:23,035 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.855,  Train_accy 99.25, Test_accy 80.80
2025-01-12 11:38:25,152 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.512,  Train_accy 99.40, Test_accy 80.38
2025-01-12 11:38:36,979 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.853,  Train_accy 99.59
2025-01-12 11:38:39,575 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.516,  Train_accy 99.16
2025-01-12 11:38:51,439 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.854,  Train_accy 99.38
2025-01-12 11:38:53,821 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.515,  Train_accy 99.31
2025-01-12 11:39:05,731 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.854,  Train_accy 99.35
2025-01-12 11:39:08,013 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.515,  Train_accy 99.31
2025-01-12 11:39:20,622 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.852,  Train_accy 99.46
2025-01-12 11:39:22,789 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.513,  Train_accy 99.35
2025-01-12 11:39:41,443 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.849,  Train_accy 99.46, Test_accy 80.51
2025-01-12 11:39:43,566 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.512,  Train_accy 99.38, Test_accy 80.29
2025-01-12 11:39:56,303 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.854,  Train_accy 99.25
2025-01-12 11:39:58,428 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.514,  Train_accy 99.46
2025-01-12 11:40:10,231 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.853,  Train_accy 99.40
2025-01-12 11:40:12,015 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.514,  Train_accy 99.25
2025-01-12 11:41:02,600 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.515,  Train_accy 99.40
2025-01-12 11:41:02,862 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.853,  Train_accy 99.31
2025-01-12 11:41:18,091 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.850,  Train_accy 99.27
2025-01-12 11:41:18,456 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.515,  Train_accy 99.44
2025-01-12 11:42:50,428 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.514,  Train_accy 99.31, Test_accy 80.84
2025-01-12 11:42:50,457 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.849,  Train_accy 99.27, Test_accy 80.36
2025-01-12 11:43:07,852 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.850,  Train_accy 99.48
2025-01-12 11:43:08,172 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.513,  Train_accy 99.38
2025-01-12 11:43:22,298 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.852,  Train_accy 99.27
2025-01-12 11:43:23,362 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.512,  Train_accy 99.44
2025-01-12 11:43:36,366 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.852,  Train_accy 99.53
2025-01-12 11:43:38,480 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.514,  Train_accy 99.33
2025-01-12 11:43:50,622 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.852,  Train_accy 99.51
2025-01-12 11:43:53,340 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.512,  Train_accy 99.42
2025-01-12 11:44:58,602 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.851,  Train_accy 99.33, Test_accy 80.27
2025-01-12 11:44:58,610 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.513,  Train_accy 99.33, Test_accy 80.78
2025-01-12 11:45:49,668 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.850,  Train_accy 99.38
2025-01-12 11:45:49,891 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.514,  Train_accy 99.42
2025-01-12 11:46:04,461 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.847,  Train_accy 99.51
2025-01-12 11:46:05,146 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.511,  Train_accy 99.27
2025-01-12 11:46:19,114 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.852,  Train_accy 99.29
2025-01-12 11:46:20,122 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.511,  Train_accy 99.46
2025-01-12 11:46:33,490 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.848,  Train_accy 99.35
2025-01-12 11:46:34,872 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.513,  Train_accy 99.27
2025-01-12 11:47:51,748 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.849,  Train_accy 99.31, Test_accy 80.56
2025-01-12 11:47:51,748 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.511,  Train_accy 99.57, Test_accy 80.80
2025-01-12 11:48:49,220 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.513,  Train_accy 99.29
2025-01-12 11:48:49,774 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.851,  Train_accy 99.44
2025-01-12 11:49:04,024 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.512,  Train_accy 99.38
2025-01-12 11:49:04,607 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.847,  Train_accy 99.38
2025-01-12 11:49:18,695 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.510,  Train_accy 99.25
2025-01-12 11:49:19,772 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.846,  Train_accy 99.40
2025-01-12 11:49:32,914 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.510,  Train_accy 99.53
2025-01-12 11:49:34,009 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.849,  Train_accy 99.46
2025-01-12 11:50:41,365 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.846,  Train_accy 99.66, Test_accy 80.87
2025-01-12 11:50:41,365 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.508,  Train_accy 99.42, Test_accy 81.38
2025-01-12 11:51:23,461 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.850,  Train_accy 99.33
2025-01-12 11:51:25,332 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.511,  Train_accy 99.53
2025-01-12 11:51:38,158 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.848,  Train_accy 99.42
2025-01-12 11:51:39,806 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.512,  Train_accy 99.35
2025-01-12 11:51:52,799 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.845,  Train_accy 99.27
2025-01-12 11:51:54,604 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.511,  Train_accy 99.44
2025-01-12 11:52:07,169 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.845,  Train_accy 99.70
2025-01-12 11:52:09,638 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.510,  Train_accy 99.38
2025-01-12 11:52:49,760 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.510,  Train_accy 99.33, Test_accy 81.16
2025-01-12 11:52:49,796 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.842,  Train_accy 99.53, Test_accy 81.56
2025-01-12 11:53:05,133 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.846,  Train_accy 99.51
2025-01-12 11:53:05,155 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.510,  Train_accy 99.33
2025-01-12 11:53:20,280 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.849,  Train_accy 99.31
2025-01-12 11:53:20,378 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.509,  Train_accy 99.40
2025-01-12 11:53:37,605 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.846,  Train_accy 99.42
2025-01-12 11:53:37,876 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.509,  Train_accy 99.44
2025-01-12 11:53:52,481 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.844,  Train_accy 99.46
2025-01-12 11:53:53,278 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.511,  Train_accy 99.35
2025-01-12 11:54:23,575 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.845,  Train_accy 99.18, Test_accy 80.96
2025-01-12 11:54:23,658 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.508,  Train_accy 99.31, Test_accy 81.27
2025-01-12 11:54:39,096 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.844,  Train_accy 99.53
2025-01-12 11:54:39,371 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.510,  Train_accy 99.55
2025-01-12 11:54:54,252 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.843,  Train_accy 99.44
2025-01-12 11:54:54,756 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.509,  Train_accy 99.40
2025-01-12 11:55:09,364 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.843,  Train_accy 99.48
2025-01-12 11:55:10,078 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.508,  Train_accy 99.42
2025-01-12 11:55:23,905 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.846,  Train_accy 99.44
2025-01-12 11:55:25,377 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.512,  Train_accy 99.46
2025-01-12 11:55:46,582 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.842,  Train_accy 99.35, Test_accy 80.93
2025-01-12 11:55:46,906 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.509,  Train_accy 99.53, Test_accy 81.27
2025-01-12 11:56:01,542 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.844,  Train_accy 99.61
2025-01-12 11:56:02,255 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.510,  Train_accy 99.44
2025-01-12 11:56:16,720 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.843,  Train_accy 99.42
2025-01-12 11:56:17,274 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.507,  Train_accy 99.48
2025-01-12 11:56:32,013 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.842,  Train_accy 99.35
2025-01-12 11:56:32,741 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.508,  Train_accy 99.51
2025-01-12 11:56:46,564 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.847,  Train_accy 99.48
2025-01-12 11:56:47,507 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.509,  Train_accy 99.44
2025-01-12 11:57:12,901 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.844,  Train_accy 99.48, Test_accy 81.33
2025-01-12 11:57:13,116 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.507,  Train_accy 99.55, Test_accy 81.24
2025-01-12 11:57:28,133 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.844,  Train_accy 99.51
2025-01-12 11:57:28,485 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.507,  Train_accy 99.53
2025-01-12 11:57:42,872 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.840,  Train_accy 99.59
2025-01-12 11:57:43,711 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.510,  Train_accy 99.42
2025-01-12 11:57:57,745 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.841,  Train_accy 99.61
2025-01-12 11:57:58,648 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.507,  Train_accy 99.33
2025-01-12 11:58:12,259 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.842,  Train_accy 99.48
2025-01-12 11:58:13,618 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.509,  Train_accy 99.42
2025-01-12 11:58:32,009 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.839,  Train_accy 99.51, Test_accy 80.84
2025-01-12 11:58:34,422 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.509,  Train_accy 99.27, Test_accy 80.89
2025-01-12 11:58:46,219 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.839,  Train_accy 99.57
2025-01-12 11:58:49,416 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.508,  Train_accy 99.53
2025-01-12 11:59:00,548 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.845,  Train_accy 99.46
2025-01-12 11:59:04,297 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.508,  Train_accy 99.48
2025-01-12 11:59:14,601 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.839,  Train_accy 99.35
2025-01-12 11:59:19,440 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.508,  Train_accy 99.53
2025-01-12 11:59:28,951 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.843,  Train_accy 99.38
2025-01-12 11:59:34,512 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.508,  Train_accy 99.40
2025-01-12 11:59:49,943 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.11
2025-01-12 11:59:54,499 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.508,  Train_accy 99.40, Test_accy 81.47
2025-01-12 12:00:03,514 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.841,  Train_accy 99.61
2025-01-12 12:00:09,456 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.507,  Train_accy 99.48
2025-01-12 12:00:17,605 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.841,  Train_accy 99.57
2025-01-12 12:00:24,432 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.507,  Train_accy 99.51
2025-01-12 12:00:32,292 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.842,  Train_accy 99.59
2025-01-12 12:00:39,316 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.509,  Train_accy 99.55
2025-01-12 12:00:46,588 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.841,  Train_accy 99.57
2025-01-12 12:00:54,121 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.509,  Train_accy 99.44
2025-01-12 12:01:07,885 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.841,  Train_accy 99.44, Test_accy 81.33
2025-01-12 12:01:13,631 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.509,  Train_accy 99.51, Test_accy 81.78
2025-01-12 12:01:21,941 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.839,  Train_accy 99.57
2025-01-12 12:01:28,545 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.509,  Train_accy 99.38
2025-01-12 12:01:36,305 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.840,  Train_accy 99.44
2025-01-12 12:01:43,591 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.508,  Train_accy 99.46
2025-01-12 12:01:50,762 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.843,  Train_accy 99.59
2025-01-12 12:01:58,266 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.507,  Train_accy 99.48
2025-01-12 12:02:05,588 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.842,  Train_accy 99.46
2025-01-12 12:02:13,291 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.507,  Train_accy 99.55
2025-01-12 12:02:25,628 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.47
2025-01-12 12:02:33,140 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.506,  Train_accy 99.48, Test_accy 81.69
2025-01-12 12:02:37,969 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.843,  Train_accy 99.48
2025-01-12 12:02:47,936 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.509,  Train_accy 99.55
2025-01-12 12:02:52,331 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.841,  Train_accy 99.53
2025-01-12 12:03:03,308 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.509,  Train_accy 99.31
2025-01-12 12:03:06,839 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.839,  Train_accy 99.53
2025-01-12 12:03:18,513 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.506,  Train_accy 99.55
2025-01-12 12:03:21,748 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.839,  Train_accy 99.57
2025-01-12 12:03:33,183 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.506,  Train_accy 99.46
2025-01-12 12:03:33,184 [der.py] => do not weight align student!
2025-01-12 12:03:42,605 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.838,  Train_accy 99.53, Test_accy 81.62
2025-01-12 12:03:43,412 [der.py] => darknet eval: 
2025-01-12 12:03:43,412 [der.py] => CNN top1 curve: 81.04
2025-01-12 12:03:43,412 [der.py] => CNN top5 curve: 97.93
2025-01-12 12:03:43,414 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 12:03:52,656 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.842,  Train_accy 99.51
2025-01-12 12:04:03,433 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.843,  Train_accy 99.48
2025-01-12 12:04:14,949 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.838,  Train_accy 99.59
2025-01-12 12:04:21,692 [der.py] => Exemplar size: 750
2025-01-12 12:04:21,692 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-12 12:04:21,692 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-12 12:04:21,692 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-12 12:04:21,692 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-12 12:04:21,692 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-12 12:04:21,692 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-12 12:04:21,693 [trainer.py] => All params: 42091068
2025-01-12 12:04:21,694 [trainer.py] => Trainable params: 21049456
2025-01-12 12:04:21,888 [der.py] => Learning on 25-35
2025-01-12 12:04:21,891 [der.py] => All params: 63139730
2025-01-12 12:04:21,893 [der.py] => Trainable params: 21056506
2025-01-12 12:04:26,030 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.838,  Train_accy 99.48
2025-01-12 12:04:26,030 [der.py] => weight align student!
2025-01-12 12:04:44,553 [der.py] => darknet eval: 
2025-01-12 12:04:44,553 [der.py] => CNN top1 curve: 82.24
2025-01-12 12:04:44,553 [der.py] => CNN top5 curve: 97.98
2025-01-12 12:04:44,555 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 12:05:16,615 [der.py] => Exemplar size: 750
2025-01-12 12:05:16,615 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-01-12 12:05:16,615 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-01-12 12:05:16,615 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-01-12 12:05:16,615 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-01-12 12:05:16,615 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-01-12 12:05:16,615 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-01-12 12:05:16,616 [trainer.py] => All params: 42091068
2025-01-12 12:05:16,617 [trainer.py] => Trainable params: 21049456
2025-01-12 12:05:16,764 [der.py] => Learning on 25-35
2025-01-12 12:05:16,765 [der.py] => All params: 63139730
2025-01-12 12:05:16,766 [der.py] => Trainable params: 21056506
2025-01-12 12:58:01,425 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-12 12:58:28,016 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.588,  Train_accy 36.85, Test_accy 39.98
2025-01-12 12:58:46,316 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.191,  Train_accy 59.35
2025-01-12 12:59:04,837 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.005, Loss_aux 0.005, Train_accy 99.98
2025-01-12 12:59:04,959 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 2.021,  Train_accy 67.94
2025-01-12 12:59:24,107 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.919,  Train_accy 73.39
2025-01-12 12:59:31,677 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 1.875,  Train_accy 35.23, Test_accy 39.05
2025-01-12 12:59:40,905 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.851,  Train_accy 77.17
2025-01-12 12:59:49,616 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.608,  Train_accy 56.73
2025-01-12 13:00:06,189 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.477,  Train_accy 66.24
2025-01-12 13:00:07,330 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.800,  Train_accy 80.12, Test_accy 54.38
2025-01-12 13:00:24,868 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.404,  Train_accy 71.98
2025-01-12 13:00:25,485 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.785,  Train_accy 81.47
2025-01-12 13:00:43,959 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.352,  Train_accy 75.07
2025-01-12 13:00:44,326 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.748,  Train_accy 82.91
2025-01-12 13:01:03,343 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.726,  Train_accy 84.40
2025-01-12 13:01:11,527 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.308,  Train_accy 79.19, Test_accy 53.11
2025-01-12 13:01:20,130 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.703,  Train_accy 86.10
2025-01-12 13:01:30,326 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.289,  Train_accy 80.51
2025-01-12 13:01:45,744 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.677,  Train_accy 87.33, Test_accy 59.14
2025-01-12 13:01:46,642 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.262,  Train_accy 82.02
2025-01-12 13:02:03,819 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.666,  Train_accy 87.56
2025-01-12 13:02:04,947 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.247,  Train_accy 83.68
2025-01-12 13:02:22,043 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.651,  Train_accy 88.93
2025-01-12 13:02:23,611 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.230,  Train_accy 84.63
2025-01-12 13:02:40,105 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.639,  Train_accy 89.19
2025-01-12 13:02:50,708 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.212,  Train_accy 86.65, Test_accy 57.17
2025-01-12 13:02:55,436 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.633,  Train_accy 89.82
2025-01-12 13:03:09,162 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.205,  Train_accy 86.95
2025-01-12 13:03:20,995 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.627,  Train_accy 89.29, Test_accy 63.97
2025-01-12 13:03:25,409 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.189,  Train_accy 88.67
2025-01-12 13:03:39,560 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.618,  Train_accy 90.71
2025-01-12 13:03:43,851 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.182,  Train_accy 88.57
2025-01-12 13:03:57,285 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.601,  Train_accy 91.01
2025-01-12 13:04:02,535 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.177,  Train_accy 89.25
2025-01-12 13:04:15,797 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.595,  Train_accy 91.09
2025-01-12 13:04:29,970 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.173,  Train_accy 89.37, Test_accy 61.19
2025-01-12 13:04:30,867 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.589,  Train_accy 91.58
2025-01-12 13:04:48,540 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.165,  Train_accy 90.89
2025-01-12 13:04:57,159 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.584,  Train_accy 92.42, Test_accy 64.16
2025-01-12 13:05:05,200 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.157,  Train_accy 90.61
2025-01-12 13:05:15,474 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.576,  Train_accy 92.24
2025-01-12 13:05:23,920 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.153,  Train_accy 90.69
2025-01-12 13:05:34,004 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.565,  Train_accy 93.25
2025-01-12 13:05:42,820 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.145,  Train_accy 91.49
2025-01-12 13:05:52,527 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.569,  Train_accy 93.64
2025-01-12 13:06:08,838 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.566,  Train_accy 92.91
2025-01-12 13:06:10,007 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.141,  Train_accy 92.08, Test_accy 64.17
2025-01-12 13:06:28,254 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.133,  Train_accy 92.08
2025-01-12 13:06:34,429 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.556,  Train_accy 93.52, Test_accy 68.05
2025-01-12 13:06:45,762 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.127,  Train_accy 92.55
2025-01-12 13:06:52,843 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.548,  Train_accy 93.86
2025-01-12 13:07:03,807 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.129,  Train_accy 93.07
2025-01-12 13:07:11,373 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.547,  Train_accy 93.94
2025-01-12 13:07:21,569 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.127,  Train_accy 92.75
2025-01-12 13:07:29,414 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.542,  Train_accy 93.96
2025-01-12 13:07:46,450 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.542,  Train_accy 93.88
2025-01-12 13:07:47,830 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.119,  Train_accy 93.68, Test_accy 68.73
2025-01-12 13:08:05,771 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.115,  Train_accy 93.43
2025-01-12 13:08:12,811 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.536,  Train_accy 94.36, Test_accy 69.16
2025-01-12 13:08:22,334 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.115,  Train_accy 93.33
2025-01-12 13:08:31,218 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.528,  Train_accy 94.59
2025-01-12 13:08:40,129 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.110,  Train_accy 93.56
2025-01-12 13:08:49,362 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.534,  Train_accy 94.71
2025-01-12 13:08:57,793 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.110,  Train_accy 93.88
2025-01-12 13:09:07,776 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.531,  Train_accy 94.89
2025-01-12 13:09:24,042 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.525,  Train_accy 94.81
2025-01-12 13:09:24,228 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.106,  Train_accy 93.92, Test_accy 68.67
2025-01-12 13:09:42,744 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.099,  Train_accy 94.67
2025-01-12 13:09:52,207 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.525,  Train_accy 94.63, Test_accy 67.49
2025-01-12 13:09:59,115 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.104,  Train_accy 94.51
2025-01-12 13:10:10,539 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.525,  Train_accy 94.83
2025-01-12 13:10:16,606 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.101,  Train_accy 94.55
2025-01-12 13:10:29,552 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.522,  Train_accy 94.69
2025-01-12 13:10:34,556 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.097,  Train_accy 94.44
2025-01-12 13:10:47,667 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.513,  Train_accy 95.45
2025-01-12 13:11:00,371 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.097,  Train_accy 94.38, Test_accy 68.79
2025-01-12 13:11:03,761 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.514,  Train_accy 95.05
2025-01-12 13:11:18,212 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.096,  Train_accy 94.71
2025-01-12 13:11:30,282 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.513,  Train_accy 95.39, Test_accy 68.73
2025-01-12 13:11:34,750 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.095,  Train_accy 94.55
2025-01-12 13:11:48,356 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.512,  Train_accy 95.35
2025-01-12 13:11:52,771 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.089,  Train_accy 94.89
2025-01-12 13:12:07,050 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.513,  Train_accy 94.71
2025-01-12 13:12:10,885 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.090,  Train_accy 94.48
2025-01-12 13:12:25,411 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.507,  Train_accy 95.33
2025-01-12 13:12:41,404 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.504,  Train_accy 95.29
2025-01-12 13:12:46,405 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.088,  Train_accy 94.63, Test_accy 69.51
2025-01-12 13:13:03,099 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.087,  Train_accy 94.89
2025-01-12 13:13:06,836 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.504,  Train_accy 95.27, Test_accy 69.43
2025-01-12 13:13:20,229 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.087,  Train_accy 94.53
2025-01-12 13:13:25,509 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.500,  Train_accy 95.58
2025-01-12 13:13:37,914 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.083,  Train_accy 95.39
2025-01-12 13:13:44,260 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.499,  Train_accy 95.68
2025-01-12 13:13:56,133 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.081,  Train_accy 94.97
2025-01-12 13:14:02,796 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.498,  Train_accy 95.94
2025-01-12 13:14:20,593 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.499,  Train_accy 95.15
2025-01-12 13:14:21,522 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.082,  Train_accy 95.07, Test_accy 69.62
2025-01-12 13:14:39,873 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.078,  Train_accy 95.70
2025-01-12 13:14:47,840 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.494,  Train_accy 95.56, Test_accy 70.37
2025-01-12 13:14:56,153 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.077,  Train_accy 95.23
2025-01-12 13:15:06,630 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.492,  Train_accy 96.16
2025-01-12 13:15:13,967 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.076,  Train_accy 95.58
2025-01-12 13:15:25,238 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.493,  Train_accy 95.62
2025-01-12 13:15:31,438 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.077,  Train_accy 95.19
2025-01-12 13:15:44,014 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.492,  Train_accy 95.54
2025-01-12 13:15:57,005 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.073,  Train_accy 95.86, Test_accy 70.13
2025-01-12 13:16:00,843 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.490,  Train_accy 96.18
2025-01-12 13:16:14,712 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.072,  Train_accy 95.72
2025-01-12 13:16:28,215 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.487,  Train_accy 96.12, Test_accy 70.08
2025-01-12 13:16:29,859 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.073,  Train_accy 95.54
2025-01-12 13:16:46,687 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.488,  Train_accy 95.76
2025-01-12 13:16:47,872 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.073,  Train_accy 95.23
2025-01-12 13:17:05,002 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.485,  Train_accy 95.78
2025-01-12 13:17:06,343 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.071,  Train_accy 95.84
2025-01-12 13:17:23,403 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.485,  Train_accy 96.14
2025-01-12 13:17:32,046 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.068,  Train_accy 95.82, Test_accy 69.98
2025-01-12 13:17:40,067 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.484,  Train_accy 95.98
2025-01-12 13:17:49,919 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.070,  Train_accy 95.70
2025-01-12 13:18:05,813 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.067,  Train_accy 95.27
2025-01-12 13:18:06,840 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.483,  Train_accy 96.22, Test_accy 70.33
2025-01-12 13:18:23,666 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.066,  Train_accy 96.00
2025-01-12 13:18:25,222 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.488,  Train_accy 95.92
2025-01-12 13:18:41,447 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.067,  Train_accy 95.78
2025-01-12 13:18:43,947 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.480,  Train_accy 95.94
2025-01-12 13:19:01,685 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.483,  Train_accy 96.26
2025-01-12 13:19:06,374 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.065,  Train_accy 96.02, Test_accy 70.67
2025-01-12 13:19:19,603 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.479,  Train_accy 96.04
2025-01-12 13:19:24,104 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.068,  Train_accy 95.74
2025-01-12 13:19:41,423 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.062,  Train_accy 95.94
2025-01-12 13:19:46,275 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.480,  Train_accy 95.92, Test_accy 69.95
2025-01-12 13:19:58,475 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.065,  Train_accy 96.10
2025-01-12 13:20:04,928 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.481,  Train_accy 96.18
2025-01-12 13:20:16,070 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.062,  Train_accy 95.88
2025-01-12 13:20:23,183 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.475,  Train_accy 96.24
2025-01-12 13:20:40,727 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.476,  Train_accy 96.02
2025-01-12 13:20:41,060 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.063,  Train_accy 96.08, Test_accy 71.10
2025-01-12 13:21:00,025 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.064,  Train_accy 96.22
2025-01-12 13:21:00,244 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.477,  Train_accy 96.12
2025-01-12 13:21:18,475 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.060,  Train_accy 96.04
2025-01-12 13:21:27,756 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.476,  Train_accy 96.14, Test_accy 70.73
2025-01-12 13:21:33,557 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.061,  Train_accy 95.90
2025-01-12 13:21:46,278 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.475,  Train_accy 96.32
2025-01-12 13:21:51,534 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.062,  Train_accy 95.86
2025-01-12 13:22:04,761 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.475,  Train_accy 96.06
2025-01-12 13:22:17,223 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.060,  Train_accy 95.86, Test_accy 70.51
2025-01-12 13:22:21,542 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.473,  Train_accy 96.40
2025-01-12 13:22:35,324 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.059,  Train_accy 96.38
2025-01-12 13:22:40,086 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.476,  Train_accy 96.59
2025-01-12 13:22:52,944 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.058,  Train_accy 95.92
2025-01-12 13:23:06,452 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.473,  Train_accy 95.84, Test_accy 71.11
2025-01-12 13:23:08,244 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.058,  Train_accy 96.36
2025-01-12 13:23:24,378 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.471,  Train_accy 96.63
2025-01-12 13:23:26,950 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.060,  Train_accy 96.10
2025-01-12 13:23:42,436 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.471,  Train_accy 96.08
2025-01-12 13:23:52,848 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.058,  Train_accy 95.86, Test_accy 71.35
2025-01-12 13:23:58,317 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.472,  Train_accy 96.61
2025-01-12 13:24:11,004 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.057,  Train_accy 96.57
2025-01-12 13:24:16,754 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.473,  Train_accy 96.22
2025-01-12 13:24:28,878 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.057,  Train_accy 95.80
2025-01-12 13:24:43,282 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.471,  Train_accy 96.32, Test_accy 71.43
2025-01-12 13:24:43,993 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.057,  Train_accy 96.40
2025-01-12 13:25:01,471 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.469,  Train_accy 96.36
2025-01-12 13:25:02,405 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.058,  Train_accy 96.04
2025-01-12 13:25:19,330 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.466,  Train_accy 96.26
2025-01-12 13:25:28,303 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.056,  Train_accy 96.22, Test_accy 71.49
2025-01-12 13:25:35,272 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.469,  Train_accy 96.38
2025-01-12 13:25:46,103 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.055,  Train_accy 96.00
2025-01-12 13:25:53,479 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.466,  Train_accy 96.65
2025-01-12 13:26:03,862 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.053,  Train_accy 96.24
2025-01-12 13:26:19,948 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.055,  Train_accy 96.18
2025-01-12 13:26:20,482 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.468,  Train_accy 96.71, Test_accy 71.00
2025-01-12 13:26:38,102 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.052,  Train_accy 96.46
2025-01-12 13:26:39,147 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.465,  Train_accy 96.34
2025-01-12 13:26:57,454 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.467,  Train_accy 96.16
2025-01-12 13:27:03,581 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.053,  Train_accy 96.32, Test_accy 71.22
2025-01-12 13:27:15,081 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.463,  Train_accy 96.48
2025-01-12 13:27:21,848 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.051,  Train_accy 96.06
2025-01-12 13:27:33,679 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.464,  Train_accy 96.14
2025-01-12 13:27:39,843 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.052,  Train_accy 95.84
2025-01-12 13:27:56,678 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.050,  Train_accy 96.63
2025-01-12 13:28:00,688 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.463,  Train_accy 96.44, Test_accy 71.44
2025-01-12 13:28:13,807 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.051,  Train_accy 96.08
2025-01-12 13:28:19,645 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.462,  Train_accy 96.71
2025-01-12 13:28:37,663 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.464,  Train_accy 96.10
2025-01-12 13:28:38,816 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.050,  Train_accy 96.42, Test_accy 71.70
2025-01-12 13:28:56,134 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.464,  Train_accy 96.48
2025-01-12 13:28:57,019 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.049,  Train_accy 96.57
2025-01-12 13:29:15,160 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.463,  Train_accy 96.73
2025-01-12 13:29:15,438 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.051,  Train_accy 96.30
2025-01-12 13:29:34,181 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.051,  Train_accy 96.44
2025-01-12 13:29:42,926 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.466,  Train_accy 96.44, Test_accy 71.40
2025-01-12 13:29:49,759 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.050,  Train_accy 96.48
2025-01-12 13:30:01,567 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.462,  Train_accy 96.30
2025-01-12 13:30:15,549 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.053,  Train_accy 96.46, Test_accy 71.14
2025-01-12 13:30:18,482 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.464,  Train_accy 96.67
2025-01-12 13:30:33,301 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.049,  Train_accy 96.44
2025-01-12 13:30:36,668 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.463,  Train_accy 96.57
2025-01-12 13:30:51,236 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.051,  Train_accy 96.55
2025-01-12 13:30:55,105 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.462,  Train_accy 96.57
2025-01-12 13:31:09,158 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.050,  Train_accy 96.48
2025-01-12 13:31:21,855 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.464,  Train_accy 96.20, Test_accy 71.76
2025-01-12 13:31:23,926 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.050,  Train_accy 96.40
2025-01-12 13:31:40,135 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.461,  Train_accy 96.46
2025-01-12 13:31:49,437 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.051,  Train_accy 96.24, Test_accy 71.75
2025-01-12 13:31:56,612 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.461,  Train_accy 96.61
2025-01-12 13:32:07,444 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.049,  Train_accy 96.26
2025-01-12 13:32:14,914 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.463,  Train_accy 96.59
2025-01-12 13:32:25,599 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.048,  Train_accy 96.57
2025-01-12 13:32:33,120 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.460,  Train_accy 96.71
2025-01-12 13:32:43,997 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.050,  Train_accy 96.34
2025-01-12 13:32:59,651 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.459,  Train_accy 96.75, Test_accy 71.33
2025-01-12 13:32:59,931 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.048,  Train_accy 96.46
2025-01-12 13:33:17,811 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.462,  Train_accy 96.55
2025-01-12 13:33:26,811 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.047,  Train_accy 96.67, Test_accy 71.35
2025-01-12 13:33:33,698 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.460,  Train_accy 96.79
2025-01-12 13:33:44,848 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.049,  Train_accy 96.55
2025-01-12 13:33:51,546 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.460,  Train_accy 96.75
2025-01-12 13:34:03,081 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.048,  Train_accy 96.59
2025-01-12 13:34:09,639 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.458,  Train_accy 96.38
2025-01-12 13:34:21,398 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.047,  Train_accy 96.55
2025-01-12 13:34:36,196 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.458,  Train_accy 96.57, Test_accy 71.51
2025-01-12 13:34:37,192 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.047,  Train_accy 96.71
2025-01-12 13:34:54,184 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.460,  Train_accy 96.61
2025-01-12 13:35:03,553 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.046,  Train_accy 96.61, Test_accy 71.79
2025-01-12 13:35:09,740 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.454,  Train_accy 96.99
2025-01-12 13:35:21,274 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.048,  Train_accy 96.61
2025-01-12 13:35:27,860 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.459,  Train_accy 96.46
2025-01-12 13:35:39,074 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.043,  Train_accy 96.75
2025-01-12 13:35:46,129 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.461,  Train_accy 96.16
2025-01-12 13:35:57,021 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.047,  Train_accy 96.28
2025-01-12 13:36:12,272 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.459,  Train_accy 96.55, Test_accy 71.41
2025-01-12 13:36:12,749 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.049,  Train_accy 96.02
2025-01-12 13:36:30,303 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.459,  Train_accy 96.61
2025-01-12 13:36:39,517 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.047,  Train_accy 96.20, Test_accy 71.68
2025-01-12 13:36:46,031 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.457,  Train_accy 96.81
2025-01-12 13:36:57,200 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.048,  Train_accy 96.36
2025-01-12 13:37:03,909 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.461,  Train_accy 96.34
2025-01-12 13:37:15,200 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.046,  Train_accy 96.63
2025-01-12 13:37:21,655 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.459,  Train_accy 96.32
2025-01-12 13:37:32,994 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.049,  Train_accy 96.28
2025-01-12 13:37:47,593 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.460,  Train_accy 96.28, Test_accy 71.57
2025-01-12 13:37:48,918 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.047,  Train_accy 96.20
2025-01-12 13:38:05,437 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.458,  Train_accy 96.36
2025-01-12 13:38:15,085 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.047,  Train_accy 96.59, Test_accy 71.78
2025-01-12 13:38:21,685 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.459,  Train_accy 96.69
2025-01-12 13:38:33,003 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.046,  Train_accy 96.24
2025-01-12 13:38:39,473 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.458,  Train_accy 96.79
2025-01-12 13:38:50,636 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.047,  Train_accy 96.57
2025-01-12 13:38:57,584 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.455,  Train_accy 96.89
2025-01-12 13:39:08,719 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.047,  Train_accy 96.83
2025-01-12 13:39:23,825 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.044,  Train_accy 96.79
2025-01-12 13:39:28,436 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.455,  Train_accy 96.65, Test_accy 71.32
2025-01-12 13:39:45,720 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.460,  Train_accy 96.36
2025-01-12 13:39:49,242 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.044,  Train_accy 96.53, Test_accy 71.90
2025-01-12 13:40:03,043 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.458,  Train_accy 97.09
2025-01-12 13:40:07,423 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.048,  Train_accy 96.40
2025-01-12 13:40:20,610 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.458,  Train_accy 96.71
2025-01-12 13:40:25,740 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.046,  Train_accy 96.79
2025-01-12 13:40:38,511 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.460,  Train_accy 96.46
2025-01-12 13:40:38,512 [der.py] => weight align student!
2025-01-12 13:40:42,780 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.046,  Train_accy 96.81
2025-01-12 13:40:45,839 [der.py] => darknet eval: 
2025-01-12 13:40:45,839 [der.py] => CNN top1 curve: 68.48
2025-01-12 13:40:45,839 [der.py] => CNN top5 curve: 96.51
2025-01-12 13:40:45,840 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 13:40:55,468 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.048,  Train_accy 96.48
2025-01-12 13:40:55,468 [der.py] => do not weight align student!
2025-01-12 13:41:01,577 [der.py] => darknet eval: 
2025-01-12 13:41:01,577 [der.py] => CNN top1 curve: 71.6
2025-01-12 13:41:01,577 [der.py] => CNN top5 curve: 96.46
2025-01-12 13:41:01,579 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 13:41:37,312 [der.py] => Exemplar size: 1050
2025-01-12 13:41:37,335 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-12 13:41:37,335 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-12 13:41:37,335 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-12 13:41:37,335 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-12 13:41:37,336 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-12 13:41:37,336 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-12 13:41:37,337 [trainer.py] => All params: 63139730
2025-01-12 13:41:37,337 [trainer.py] => Trainable params: 21056506
2025-01-12 13:41:37,482 [der.py] => Learning on 35-45
2025-01-12 13:41:37,483 [der.py] => All params: 84190952
2025-01-12 13:41:37,484 [der.py] => Trainable params: 21066116
2025-01-12 13:42:01,596 [der.py] => Exemplar size: 1050
2025-01-12 13:42:01,596 [trainer.py] => CNN: {'total': 82.7, '0': 85.0, '1': 73.89, '2': 93.33, '3': 79.44, '4': 90.56, '5': 58.33, '6': 76.67, '7': 58.89, '8': 48.89, '9': 60.56, '10': 96.67, '11': 99.44, '12': 87.78, '13': 89.44, '14': 68.89, '15': 95.56, '16': 98.33, '17': 96.67, '18': 97.22, '19': 96.67, '20': 98.33, '21': 90.0, '22': 92.78, '23': 88.89, '24': 83.89, '25': 67.78, '26': 77.78, '27': 82.78, '28': 64.44, '29': 79.44, '30': 81.67, '31': 81.67, '32': 81.11, '33': 82.78, 'old': 84.24, 'new': 78.83}
2025-01-12 13:42:01,596 [trainer.py] => NME: {'total': 79.59, '0': 77.22, '1': 63.89, '2': 90.56, '3': 71.67, '4': 86.67, '5': 50.0, '6': 61.67, '7': 57.78, '8': 50.0, '9': 62.22, '10': 96.11, '11': 95.56, '12': 85.56, '13': 82.22, '14': 57.22, '15': 90.56, '16': 96.11, '17': 93.33, '18': 91.11, '19': 95.56, '20': 95.0, '21': 92.22, '22': 85.0, '23': 66.67, '24': 75.56, '25': 82.78, '26': 92.78, '27': 86.11, '28': 67.78, '29': 78.33, '30': 76.11, '31': 79.44, '32': 94.44, '33': 73.89, 'old': 78.78, 'new': 81.61}
2025-01-12 13:42:01,596 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7]
2025-01-12 13:42:01,596 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62]
2025-01-12 13:42:01,596 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59]
2025-01-12 13:42:01,596 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59]

2025-01-12 13:42:01,597 [trainer.py] => All params: 63139730
2025-01-12 13:42:01,598 [trainer.py] => Trainable params: 21056506
2025-01-12 13:42:01,774 [der.py] => Learning on 35-45
2025-01-12 13:42:01,776 [der.py] => All params: 84190952
2025-01-12 13:42:01,777 [der.py] => Trainable params: 21066116
2025-01-12 15:05:17,825 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-12 15:05:37,307 [der.py] => Task 3, Epoch 150/150 => Loss 0.102, Loss_clf 0.034, Loss_aux 0.068, Train_accy 99.90
2025-01-12 15:06:13,448 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.042,  Train_accy 26.99, Test_accy 29.09
2025-01-12 15:06:13,830 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.607,  Train_accy 27.92, Test_accy 28.06
2025-01-12 15:06:36,686 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.585,  Train_accy 44.67
2025-01-12 15:06:36,821 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.033,  Train_accy 44.70
2025-01-12 15:06:59,867 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.856,  Train_accy 49.37
2025-01-12 15:06:59,897 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.431,  Train_accy 50.84
2025-01-12 15:07:22,961 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.365,  Train_accy 52.86
2025-01-12 15:07:23,122 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.775,  Train_accy 52.78
2025-01-12 15:07:45,666 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.321,  Train_accy 56.00
2025-01-12 15:07:46,115 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.708,  Train_accy 55.20
2025-01-12 15:08:16,645 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.245,  Train_accy 58.11, Test_accy 36.69
2025-01-12 15:08:17,435 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.610,  Train_accy 57.92, Test_accy 32.85
2025-01-12 15:08:39,019 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.208,  Train_accy 59.01
2025-01-12 15:08:40,179 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.558,  Train_accy 58.76
2025-01-12 15:09:01,349 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.176,  Train_accy 61.39
2025-01-12 15:09:02,429 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.511,  Train_accy 61.31
2025-01-12 15:09:23,634 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.144,  Train_accy 63.01
2025-01-12 15:09:25,125 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.471,  Train_accy 62.91
2025-01-12 15:09:45,867 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.117,  Train_accy 63.62
2025-01-12 15:09:47,470 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.438,  Train_accy 63.30
2025-01-12 15:10:17,210 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.102,  Train_accy 65.09, Test_accy 41.67
2025-01-12 15:10:18,248 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.420,  Train_accy 64.91, Test_accy 38.54
2025-01-12 15:10:39,591 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.094,  Train_accy 64.59
2025-01-12 15:10:40,730 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.405,  Train_accy 64.29
2025-01-12 15:11:02,102 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.077,  Train_accy 65.31
2025-01-12 15:11:03,242 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.378,  Train_accy 65.62
2025-01-12 15:11:24,377 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.101,  Train_accy 65.66
2025-01-12 15:11:25,505 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.403,  Train_accy 66.59
2025-01-12 15:11:46,679 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.080,  Train_accy 67.31
2025-01-12 15:11:47,751 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.396,  Train_accy 67.52
2025-01-12 15:12:18,109 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.070,  Train_accy 65.85, Test_accy 46.11
2025-01-12 15:12:18,470 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.393,  Train_accy 65.54, Test_accy 41.41
2025-01-12 15:12:40,436 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.026,  Train_accy 68.25
2025-01-12 15:12:41,216 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.336,  Train_accy 67.50
2025-01-12 15:13:02,591 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.015,  Train_accy 69.52
2025-01-12 15:13:03,740 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.306,  Train_accy 69.31
2025-01-12 15:13:25,078 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.000,  Train_accy 69.26
2025-01-12 15:13:26,351 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.295,  Train_accy 68.38
2025-01-12 15:13:46,913 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.017,  Train_accy 68.25
2025-01-12 15:13:48,575 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.323,  Train_accy 67.18
2025-01-12 15:14:19,079 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 0.985,  Train_accy 70.88, Test_accy 45.67
2025-01-12 15:14:20,928 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.281,  Train_accy 70.34, Test_accy 48.26
2025-01-12 15:14:40,558 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 0.972,  Train_accy 70.59
2025-01-12 15:14:43,532 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.266,  Train_accy 70.17
2025-01-12 15:15:03,150 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 0.980,  Train_accy 70.50
2025-01-12 15:15:06,016 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.274,  Train_accy 69.83
2025-01-12 15:15:25,498 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 0.961,  Train_accy 71.33
2025-01-12 15:15:28,384 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.243,  Train_accy 71.52
2025-01-12 15:15:47,820 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 0.964,  Train_accy 71.41
2025-01-12 15:15:50,481 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.239,  Train_accy 70.97
2025-01-12 15:16:38,211 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 0.955,  Train_accy 71.62, Test_accy 51.56
2025-01-12 15:16:38,239 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.224,  Train_accy 71.18, Test_accy 51.59
2025-01-12 15:17:01,266 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 0.963,  Train_accy 73.12
2025-01-12 15:17:01,475 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.244,  Train_accy 72.91
2025-01-12 15:17:23,898 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 0.936,  Train_accy 72.23
2025-01-12 15:17:24,755 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.192,  Train_accy 73.18
2025-01-12 15:17:45,907 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 0.928,  Train_accy 72.30
2025-01-12 15:17:47,256 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.197,  Train_accy 72.36
2025-01-12 15:18:07,918 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 0.925,  Train_accy 73.14
2025-01-12 15:18:09,643 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.194,  Train_accy 72.84
2025-01-12 15:18:40,463 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 0.912,  Train_accy 73.96, Test_accy 53.42
2025-01-12 15:18:42,649 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.177,  Train_accy 73.70, Test_accy 54.56
2025-01-12 15:19:01,987 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 0.920,  Train_accy 74.04
2025-01-12 15:19:04,957 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.176,  Train_accy 74.11
2025-01-12 15:19:23,921 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 0.895,  Train_accy 74.11
2025-01-12 15:19:27,362 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.146,  Train_accy 74.38
2025-01-12 15:19:46,431 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 0.883,  Train_accy 74.46
2025-01-12 15:19:49,736 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.137,  Train_accy 74.11
2025-01-12 15:20:08,323 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 0.897,  Train_accy 74.72
2025-01-12 15:20:12,492 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.163,  Train_accy 74.27
2025-01-12 15:20:40,739 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 0.885,  Train_accy 75.20, Test_accy 51.85
2025-01-12 15:20:44,159 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.134,  Train_accy 74.88, Test_accy 54.99
2025-01-12 15:21:02,241 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 0.897,  Train_accy 73.52
2025-01-12 15:21:06,547 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.149,  Train_accy 73.45
2025-01-12 15:21:24,042 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 0.890,  Train_accy 74.51
2025-01-12 15:21:28,847 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.141,  Train_accy 74.78
2025-01-12 15:21:46,082 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 0.875,  Train_accy 74.88
2025-01-12 15:21:50,943 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.115,  Train_accy 74.91
2025-01-12 15:22:07,971 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 0.874,  Train_accy 74.44
2025-01-12 15:22:13,705 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.116,  Train_accy 74.70
2025-01-12 15:22:48,252 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 0.890,  Train_accy 75.66, Test_accy 52.86
2025-01-12 15:22:48,752 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.139,  Train_accy 75.60, Test_accy 54.36
2025-01-12 15:23:10,451 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 0.867,  Train_accy 74.19
2025-01-12 15:23:11,287 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.112,  Train_accy 73.71
2025-01-12 15:23:32,472 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 0.871,  Train_accy 75.16
2025-01-12 15:23:34,097 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.110,  Train_accy 75.35
2025-01-12 15:23:54,697 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 0.874,  Train_accy 75.64
2025-01-12 15:23:56,403 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.124,  Train_accy 75.60
2025-01-12 15:24:16,690 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 0.857,  Train_accy 75.31
2025-01-12 15:24:19,246 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.092,  Train_accy 75.24
2025-01-12 15:24:55,579 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 0.839,  Train_accy 75.81, Test_accy 51.91
2025-01-12 15:24:55,998 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.069,  Train_accy 76.04, Test_accy 54.15
2025-01-12 15:25:17,811 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 0.869,  Train_accy 75.18
2025-01-12 15:25:18,653 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.112,  Train_accy 75.09
2025-01-12 15:25:39,917 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 0.860,  Train_accy 75.22
2025-01-12 15:25:41,195 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.101,  Train_accy 75.81
2025-01-12 15:26:02,130 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 0.870,  Train_accy 75.30
2025-01-12 15:26:03,812 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.101,  Train_accy 75.68
2025-01-12 15:26:24,571 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 0.858,  Train_accy 75.47
2025-01-12 15:26:26,297 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.104,  Train_accy 75.10
2025-01-12 15:26:55,236 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 0.840,  Train_accy 75.77, Test_accy 56.43
2025-01-12 15:26:58,241 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.080,  Train_accy 75.92, Test_accy 58.16
2025-01-12 15:27:16,757 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 0.837,  Train_accy 76.38
2025-01-12 15:27:21,457 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.073,  Train_accy 76.27
2025-01-12 15:27:39,020 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 0.832,  Train_accy 76.19
2025-01-12 15:27:44,255 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.064,  Train_accy 76.17
2025-01-12 15:28:01,032 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 0.838,  Train_accy 76.08
2025-01-12 15:28:06,725 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.070,  Train_accy 76.17
2025-01-12 15:28:23,099 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 0.847,  Train_accy 76.06
2025-01-12 15:28:29,583 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.071,  Train_accy 76.21
2025-01-12 15:28:54,451 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 0.849,  Train_accy 75.94, Test_accy 51.49
2025-01-12 15:29:00,911 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.093,  Train_accy 76.15, Test_accy 53.70
2025-01-12 15:29:15,348 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 0.835,  Train_accy 76.34
2025-01-12 15:29:23,532 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.066,  Train_accy 76.40
2025-01-12 15:29:37,663 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 0.835,  Train_accy 75.73
2025-01-12 15:29:46,188 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.066,  Train_accy 76.13
2025-01-12 15:29:59,772 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 0.826,  Train_accy 76.04
2025-01-12 15:30:08,827 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.049,  Train_accy 76.40
2025-01-12 15:30:22,077 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 0.842,  Train_accy 76.17
2025-01-12 15:30:31,249 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.072,  Train_accy 76.29
2025-01-12 15:30:54,105 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 0.818,  Train_accy 76.40, Test_accy 51.25
2025-01-12 15:31:02,140 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.049,  Train_accy 76.36, Test_accy 54.84
2025-01-12 15:31:13,968 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 0.831,  Train_accy 76.53
2025-01-12 15:31:25,062 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.059,  Train_accy 76.48
2025-01-12 15:31:36,256 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 0.830,  Train_accy 76.19
2025-01-12 15:31:47,727 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.058,  Train_accy 76.53
2025-01-12 15:31:58,488 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 0.823,  Train_accy 76.11
2025-01-12 15:32:10,562 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.048,  Train_accy 76.57
2025-01-12 15:32:20,516 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 0.803,  Train_accy 76.78
2025-01-12 15:32:32,732 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.025,  Train_accy 76.46
2025-01-12 15:32:52,166 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 0.826,  Train_accy 76.23, Test_accy 57.17
2025-01-12 15:33:03,150 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.058,  Train_accy 76.00, Test_accy 59.36
2025-01-12 15:33:11,117 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 0.815,  Train_accy 76.55
2025-01-12 15:33:25,569 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.040,  Train_accy 76.72
2025-01-12 15:33:33,090 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 0.809,  Train_accy 76.13
2025-01-12 15:33:48,324 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.031,  Train_accy 76.36
2025-01-12 15:33:55,073 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 0.801,  Train_accy 76.29
2025-01-12 15:34:10,891 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.025,  Train_accy 76.61
2025-01-12 15:34:17,102 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 0.792,  Train_accy 76.02
2025-01-12 15:34:33,131 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.010,  Train_accy 76.50
2025-01-12 15:34:49,208 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 0.810,  Train_accy 76.93, Test_accy 58.88
2025-01-12 15:35:03,243 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.036,  Train_accy 76.61, Test_accy 60.73
2025-01-12 15:35:07,131 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 0.828,  Train_accy 77.05
2025-01-12 15:35:25,595 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.057,  Train_accy 77.26
2025-01-12 15:35:29,276 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 0.811,  Train_accy 76.90
2025-01-12 15:35:47,959 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.037,  Train_accy 76.51
2025-01-12 15:35:51,669 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 0.809,  Train_accy 76.50
2025-01-12 15:36:10,370 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.031,  Train_accy 76.40
2025-01-12 15:36:14,083 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 0.806,  Train_accy 76.44
2025-01-12 15:36:32,744 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.031,  Train_accy 76.86
2025-01-12 15:36:46,232 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 0.823,  Train_accy 76.40, Test_accy 54.85
2025-01-12 15:37:03,047 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.050,  Train_accy 75.89, Test_accy 59.10
2025-01-12 15:37:04,529 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 0.804,  Train_accy 76.69
2025-01-12 15:37:25,160 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.033,  Train_accy 76.95
2025-01-12 15:37:26,839 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 0.810,  Train_accy 76.51
2025-01-12 15:37:47,401 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.039,  Train_accy 76.55
2025-01-12 15:37:48,973 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 0.800,  Train_accy 76.19
2025-01-12 15:38:09,793 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.021,  Train_accy 76.32
2025-01-12 15:38:11,219 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 0.805,  Train_accy 76.61
2025-01-12 15:38:32,308 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.029,  Train_accy 76.55
2025-01-12 15:38:43,541 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 0.795,  Train_accy 77.01, Test_accy 58.51
2025-01-12 15:39:02,570 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.011,  Train_accy 76.65, Test_accy 59.58
2025-01-12 15:39:02,702 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 0.808,  Train_accy 76.80
2025-01-12 15:39:25,651 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 0.806,  Train_accy 77.03
2025-01-12 15:39:25,831 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.039,  Train_accy 76.48
2025-01-12 15:39:48,622 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 0.808,  Train_accy 76.93
2025-01-12 15:39:48,823 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.030,  Train_accy 76.91
2025-01-12 15:40:11,459 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 0.788,  Train_accy 76.50
2025-01-12 15:40:11,659 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.034,  Train_accy 76.59
2025-01-12 15:40:34,584 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.006,  Train_accy 76.59
2025-01-12 15:40:44,272 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.771,  Train_accy 76.91, Test_accy 54.72
2025-01-12 15:41:03,986 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 0.800,  Train_accy 77.10
2025-01-12 15:41:05,298 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 0.985,  Train_accy 76.93, Test_accy 58.09
2025-01-12 15:41:25,844 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 0.806,  Train_accy 76.69
2025-01-12 15:41:27,699 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.028,  Train_accy 76.84
2025-01-12 15:41:47,817 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 0.805,  Train_accy 77.03
2025-01-12 15:41:50,018 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.030,  Train_accy 76.82
2025-01-12 15:42:09,745 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 0.804,  Train_accy 76.84
2025-01-12 15:42:12,483 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.031,  Train_accy 76.99
2025-01-12 15:42:34,292 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.027,  Train_accy 76.76
2025-01-12 15:42:41,583 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 0.794,  Train_accy 77.45, Test_accy 58.84
2025-01-12 15:43:01,824 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.783,  Train_accy 77.39
2025-01-12 15:43:05,057 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.017,  Train_accy 77.45, Test_accy 60.28
2025-01-12 15:43:23,426 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 0.795,  Train_accy 76.90
2025-01-12 15:43:27,175 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.998,  Train_accy 77.30
2025-01-12 15:43:45,728 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 0.798,  Train_accy 77.07
2025-01-12 15:43:49,101 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.015,  Train_accy 76.78
2025-01-12 15:44:08,847 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.774,  Train_accy 76.76
2025-01-12 15:44:11,529 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.020,  Train_accy 77.35
2025-01-12 15:44:33,274 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.991,  Train_accy 76.99
2025-01-12 15:44:41,047 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.765,  Train_accy 77.12, Test_accy 56.48
2025-01-12 15:45:01,744 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 0.814,  Train_accy 77.18
2025-01-12 15:45:04,318 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.980,  Train_accy 77.09, Test_accy 60.06
2025-01-12 15:45:23,690 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 0.814,  Train_accy 77.10
2025-01-12 15:45:26,429 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.044,  Train_accy 76.91
2025-01-12 15:45:45,884 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 0.794,  Train_accy 77.26
2025-01-12 15:45:48,672 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.040,  Train_accy 76.93
2025-01-12 15:46:07,950 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 0.794,  Train_accy 76.51
2025-01-12 15:46:11,190 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.017,  Train_accy 76.91
2025-01-12 15:46:33,245 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.018,  Train_accy 76.95
2025-01-12 15:46:39,247 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 0.797,  Train_accy 77.22, Test_accy 58.86
2025-01-12 15:47:00,258 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 0.788,  Train_accy 77.33
2025-01-12 15:47:05,192 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.021,  Train_accy 77.18, Test_accy 60.96
2025-01-12 15:47:21,471 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.782,  Train_accy 77.64
2025-01-12 15:47:28,016 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.009,  Train_accy 77.28
2025-01-12 15:47:43,938 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 0.797,  Train_accy 77.16
2025-01-12 15:47:50,396 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 0.999,  Train_accy 77.43
2025-01-12 15:48:06,242 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.781,  Train_accy 77.18
2025-01-12 15:48:12,751 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.024,  Train_accy 77.07
2025-01-12 15:48:34,095 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 0.999,  Train_accy 76.72
2025-01-12 15:48:37,628 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 0.785,  Train_accy 76.76, Test_accy 55.04
2025-01-12 15:48:59,112 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 0.781,  Train_accy 76.69
2025-01-12 15:49:06,429 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.006,  Train_accy 77.07, Test_accy 60.54
2025-01-12 15:49:19,423 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 0.792,  Train_accy 76.99
2025-01-12 15:49:29,204 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.000,  Train_accy 76.90
2025-01-12 15:49:41,449 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 0.794,  Train_accy 77.58
2025-01-12 15:49:51,715 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.015,  Train_accy 76.95
2025-01-12 15:50:04,108 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 0.811,  Train_accy 77.35
2025-01-12 15:50:14,125 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.017,  Train_accy 77.22
2025-01-12 15:50:34,512 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.038,  Train_accy 77.52
2025-01-12 15:50:36,203 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 0.794,  Train_accy 76.50, Test_accy 52.96
2025-01-12 15:50:58,167 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.780,  Train_accy 76.86
2025-01-12 15:51:06,653 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.012,  Train_accy 76.74, Test_accy 57.72
2025-01-12 15:51:18,130 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 0.795,  Train_accy 77.39
2025-01-12 15:51:28,902 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.999,  Train_accy 76.59
2025-01-12 15:51:40,496 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 0.789,  Train_accy 77.26
2025-01-12 15:51:51,266 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.018,  Train_accy 77.39
2025-01-12 15:52:02,914 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.794,  Train_accy 77.30
2025-01-12 15:52:13,618 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.013,  Train_accy 77.43
2025-01-12 15:52:34,225 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.014,  Train_accy 77.10
2025-01-12 15:52:34,584 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.770,  Train_accy 77.10, Test_accy 55.42
2025-01-12 15:52:57,332 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 0.798,  Train_accy 77.14
2025-01-12 15:53:07,409 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.982,  Train_accy 77.22, Test_accy 60.14
2025-01-12 15:53:16,864 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 0.784,  Train_accy 77.33
2025-01-12 15:53:29,830 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.020,  Train_accy 77.09
2025-01-12 15:53:38,661 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.771,  Train_accy 77.30
2025-01-12 15:53:52,233 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.005,  Train_accy 77.35
2025-01-12 15:54:01,141 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.776,  Train_accy 77.33
2025-01-12 15:54:14,826 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 0.986,  Train_accy 77.35
2025-01-12 15:54:32,004 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.777,  Train_accy 77.31, Test_accy 60.46
2025-01-12 15:54:35,101 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.997,  Train_accy 77.75
2025-01-12 15:54:53,760 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 0.786,  Train_accy 77.07
2025-01-12 15:55:08,349 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.762,  Train_accy 77.05
2025-01-12 15:55:21,956 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.781,  Train_accy 77.14
2025-01-12 15:55:35,519 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 0.786,  Train_accy 77.30
2025-01-12 15:56:51,079 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.998,  Train_accy 77.30, Test_accy 60.31
2025-01-12 15:56:51,100 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 0.783,  Train_accy 77.28, Test_accy 57.77
2025-01-12 15:57:13,754 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.004,  Train_accy 77.28
2025-01-12 15:57:13,881 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 0.781,  Train_accy 76.70
2025-01-12 15:57:36,606 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.970,  Train_accy 76.70
2025-01-12 15:57:36,719 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.788,  Train_accy 77.05
2025-01-12 15:58:00,218 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.998,  Train_accy 76.93
2025-01-12 15:58:00,522 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 0.794,  Train_accy 76.70
2025-01-12 15:58:27,790 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.780,  Train_accy 77.12
2025-01-12 15:58:27,805 [der.py] => do not weight align student!
2025-01-12 15:58:28,390 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.009,  Train_accy 77.18
2025-01-12 15:59:02,544 [der.py] => darknet eval: 
2025-01-12 15:59:02,544 [der.py] => CNN top1 curve: 60.91
2025-01-12 15:59:02,544 [der.py] => CNN top5 curve: 90.98
2025-01-12 15:59:02,546 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 15:59:02,676 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.003,  Train_accy 77.30, Test_accy 59.90
2025-01-12 15:59:17,598 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.005,  Train_accy 77.09
2025-01-12 15:59:33,456 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.007,  Train_accy 76.97
2025-01-12 15:59:50,755 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.016,  Train_accy 77.43
2025-01-12 16:00:10,990 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.996,  Train_accy 77.14
2025-01-12 16:00:10,991 [der.py] => weight align student!
2025-01-12 16:00:29,779 [der.py] => Exemplar size: 1350
2025-01-12 16:00:29,780 [trainer.py] => CNN: {'total': 76.41, '0': 63.89, '1': 72.22, '2': 91.67, '3': 66.67, '4': 82.78, '5': 40.56, '6': 75.56, '7': 58.89, '8': 42.22, '9': 56.11, '10': 92.22, '11': 95.0, '12': 83.33, '13': 79.44, '14': 56.11, '15': 96.67, '16': 93.89, '17': 95.0, '18': 92.78, '19': 93.89, '20': 96.11, '21': 91.67, '22': 73.33, '23': 71.11, '24': 62.22, '25': 88.33, '26': 93.33, '27': 93.33, '28': 69.44, '29': 79.44, '30': 94.44, '31': 83.33, '32': 98.89, '33': 83.33, '34': 81.67, '35': 90.0, '36': 87.78, '37': 22.78, '38': 4.44, '39': 40.56, '40': 73.89, '41': 96.11, '42': 97.22, '43': 96.11, 'old': 79.68, 'new': 64.94}
2025-01-12 16:00:29,780 [trainer.py] => NME: {'total': 78.53, '0': 66.11, '1': 64.44, '2': 85.56, '3': 52.78, '4': 85.0, '5': 45.0, '6': 65.56, '7': 55.0, '8': 47.78, '9': 59.44, '10': 91.67, '11': 83.33, '12': 82.22, '13': 76.67, '14': 56.67, '15': 89.44, '16': 90.0, '17': 93.89, '18': 89.44, '19': 93.33, '20': 92.22, '21': 88.33, '22': 86.11, '23': 62.78, '24': 75.56, '25': 78.89, '26': 91.67, '27': 85.0, '28': 63.33, '29': 76.67, '30': 76.11, '31': 83.33, '32': 91.67, '33': 62.78, '34': 81.67, '35': 97.22, '36': 89.44, '37': 66.67, '38': 89.44, '39': 85.0, '40': 84.44, '41': 91.11, '42': 97.22, '43': 94.44, 'old': 76.27, 'new': 86.44}
2025-01-12 16:00:29,780 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41]
2025-01-12 16:00:29,780 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35]
2025-01-12 16:00:29,780 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53]
2025-01-12 16:00:29,780 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06]

2025-01-12 16:00:29,781 [trainer.py] => All params: 84190952
2025-01-12 16:00:29,782 [trainer.py] => Trainable params: 21066116
2025-01-12 16:00:29,972 [der.py] => Learning on 45-55
2025-01-12 16:00:29,975 [der.py] => All params: 105244734
2025-01-12 16:00:29,976 [der.py] => Trainable params: 21078286
2025-01-12 16:00:35,391 [der.py] => darknet eval: 
2025-01-12 16:00:35,391 [der.py] => CNN top1 curve: 61.04
2025-01-12 16:00:35,391 [der.py] => CNN top5 curve: 91.12
2025-01-12 16:00:35,393 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 16:03:05,857 [der.py] => Exemplar size: 1350
2025-01-12 16:03:05,857 [trainer.py] => CNN: {'total': 76.41, '0': 63.89, '1': 72.22, '2': 91.67, '3': 66.67, '4': 82.78, '5': 40.56, '6': 75.56, '7': 58.89, '8': 42.22, '9': 56.11, '10': 92.22, '11': 95.0, '12': 83.33, '13': 79.44, '14': 56.11, '15': 96.67, '16': 93.89, '17': 95.0, '18': 92.78, '19': 93.89, '20': 96.11, '21': 91.67, '22': 73.33, '23': 71.11, '24': 62.22, '25': 88.33, '26': 93.33, '27': 93.33, '28': 69.44, '29': 79.44, '30': 94.44, '31': 83.33, '32': 98.89, '33': 83.33, '34': 81.67, '35': 90.0, '36': 87.78, '37': 22.78, '38': 4.44, '39': 40.56, '40': 73.89, '41': 96.11, '42': 97.22, '43': 96.11, 'old': 79.68, 'new': 64.94}
2025-01-12 16:03:05,858 [trainer.py] => NME: {'total': 78.53, '0': 66.11, '1': 64.44, '2': 85.56, '3': 52.78, '4': 85.0, '5': 45.0, '6': 65.56, '7': 55.0, '8': 47.78, '9': 59.44, '10': 91.67, '11': 83.33, '12': 82.22, '13': 76.67, '14': 56.67, '15': 89.44, '16': 90.0, '17': 93.89, '18': 89.44, '19': 93.33, '20': 92.22, '21': 88.33, '22': 86.11, '23': 62.78, '24': 75.56, '25': 78.89, '26': 91.67, '27': 85.0, '28': 63.33, '29': 76.67, '30': 76.11, '31': 83.33, '32': 91.67, '33': 62.78, '34': 81.67, '35': 97.22, '36': 89.44, '37': 66.67, '38': 89.44, '39': 85.0, '40': 84.44, '41': 91.11, '42': 97.22, '43': 94.44, 'old': 76.27, 'new': 86.44}
2025-01-12 16:03:05,858 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41]
2025-01-12 16:03:05,858 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35]
2025-01-12 16:03:05,858 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53]
2025-01-12 16:03:05,858 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06]

2025-01-12 16:03:05,859 [trainer.py] => All params: 84190952
2025-01-12 16:03:05,860 [trainer.py] => Trainable params: 21066116
2025-01-12 16:03:06,010 [der.py] => Learning on 45-55
2025-01-12 16:03:06,012 [der.py] => All params: 105244734
2025-01-12 16:03:06,013 [der.py] => Trainable params: 21078286
2025-01-12 18:19:33,825 [der.py] => Task 4, Epoch 150/150 => Loss 0.016, Loss_clf 0.007, Loss_aux 0.008, Train_accy 100.00
2025-01-12 18:19:33,827 [der.py] => Task 4, Epoch 150/150 => Loss 0.016, Loss_clf 0.007, Loss_aux 0.008, Train_accy 100.00
2025-01-12 18:20:20,883 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.471,  Train_accy 11.42, Test_accy 26.07
2025-01-12 18:20:20,883 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.847,  Train_accy 11.01, Test_accy 26.21
2025-01-12 18:20:50,383 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.705,  Train_accy 16.18
2025-01-12 18:20:50,912 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 3.286,  Train_accy 17.08
2025-01-12 18:21:17,856 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 3.185,  Train_accy 23.05
2025-01-12 18:21:18,691 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.628,  Train_accy 21.33
2025-01-12 18:21:44,918 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 3.102,  Train_accy 28.58
2025-01-12 18:21:45,750 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.563,  Train_accy 25.93
2025-01-12 18:22:11,943 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 3.029,  Train_accy 34.92
2025-01-12 18:22:12,778 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.506,  Train_accy 31.66
2025-01-12 18:22:59,226 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.466,  Train_accy 35.80, Test_accy 38.53
2025-01-12 18:22:59,274 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.981,  Train_accy 39.17, Test_accy 38.40
2025-01-12 18:23:26,719 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.923,  Train_accy 44.13
2025-01-12 18:23:26,851 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.418,  Train_accy 40.83
2025-01-12 18:23:53,991 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.877,  Train_accy 48.70
2025-01-12 18:23:54,176 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.380,  Train_accy 46.50
2025-01-12 18:24:21,194 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.860,  Train_accy 51.08
2025-01-12 18:24:21,367 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.360,  Train_accy 49.41
2025-01-12 18:24:48,433 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.822,  Train_accy 54.27
2025-01-12 18:24:48,569 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.328,  Train_accy 50.99
2025-01-12 18:25:27,032 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.305,  Train_accy 53.60, Test_accy 44.21
2025-01-12 18:25:27,050 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.797,  Train_accy 55.48, Test_accy 43.93
2025-01-12 18:25:54,626 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.286,  Train_accy 56.05
2025-01-12 18:25:54,721 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.772,  Train_accy 58.40
2025-01-12 18:26:21,813 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.272,  Train_accy 58.31
2025-01-12 18:26:22,023 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.757,  Train_accy 60.20
2025-01-12 18:26:49,228 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.250,  Train_accy 60.40
2025-01-12 18:26:49,398 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.728,  Train_accy 62.09
2025-01-12 18:27:16,695 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.235,  Train_accy 62.38
2025-01-12 18:27:16,825 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.715,  Train_accy 63.62
2025-01-12 18:27:54,796 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.227,  Train_accy 63.14, Test_accy 48.34
2025-01-12 18:27:55,276 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.709,  Train_accy 63.41, Test_accy 46.99
2025-01-12 18:28:21,699 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.215,  Train_accy 63.26
2025-01-12 18:28:22,229 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.692,  Train_accy 64.85
2025-01-12 18:28:48,342 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.202,  Train_accy 64.13
2025-01-12 18:28:49,230 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.678,  Train_accy 65.57
2025-01-12 18:29:14,595 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.193,  Train_accy 66.45
2025-01-12 18:29:16,070 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.665,  Train_accy 67.68
2025-01-12 18:29:44,468 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.179,  Train_accy 67.35
2025-01-12 18:29:47,501 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.651,  Train_accy 68.76
2025-01-12 18:31:50,762 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.179,  Train_accy 68.18, Test_accy 52.94
2025-01-12 18:31:50,820 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.647,  Train_accy 69.55, Test_accy 53.18
2025-01-12 18:32:17,641 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.168,  Train_accy 69.59
2025-01-12 18:32:17,829 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.637,  Train_accy 70.18
2025-01-12 18:32:44,611 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.166,  Train_accy 68.34
2025-01-12 18:32:44,819 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.630,  Train_accy 69.46
2025-01-12 18:33:18,119 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.154,  Train_accy 70.86
2025-01-12 18:33:18,301 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.619,  Train_accy 72.05
2025-01-12 18:33:45,140 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.146,  Train_accy 70.07
2025-01-12 18:33:45,331 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.609,  Train_accy 71.50
2025-01-12 18:34:32,927 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.139,  Train_accy 71.69, Test_accy 52.02
2025-01-12 18:34:33,826 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.599,  Train_accy 72.94, Test_accy 52.15
2025-01-12 18:34:59,129 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.134,  Train_accy 72.49
2025-01-12 18:35:00,887 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.593,  Train_accy 73.48
2025-01-12 18:35:25,607 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.122,  Train_accy 72.79
2025-01-12 18:35:27,764 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.579,  Train_accy 73.75
2025-01-12 18:35:52,150 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.123,  Train_accy 72.72
2025-01-12 18:35:54,389 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.584,  Train_accy 72.86
2025-01-12 18:36:19,005 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.117,  Train_accy 73.15
2025-01-12 18:36:20,808 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.575,  Train_accy 73.77
2025-01-12 18:38:55,459 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.117,  Train_accy 73.35, Test_accy 54.86
2025-01-12 18:38:55,461 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.578,  Train_accy 73.08, Test_accy 55.93
2025-01-12 18:39:23,302 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.107,  Train_accy 74.20
2025-01-12 18:39:23,435 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.566,  Train_accy 74.25
2025-01-12 18:39:50,992 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.560,  Train_accy 75.55
2025-01-12 18:39:51,028 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.104,  Train_accy 74.77
2025-01-12 18:40:18,871 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.550,  Train_accy 75.42
2025-01-12 18:40:18,997 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.098,  Train_accy 74.56
2025-01-12 18:40:46,030 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.089,  Train_accy 75.84
2025-01-12 18:40:46,276 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.540,  Train_accy 76.22
2025-01-12 18:44:31,648 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.544,  Train_accy 76.76, Test_accy 56.27
2025-01-12 18:44:31,667 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.091,  Train_accy 75.80, Test_accy 55.68
2025-01-12 18:44:58,333 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.545,  Train_accy 76.38
2025-01-12 18:44:58,531 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.091,  Train_accy 75.64
2025-01-12 18:45:25,355 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.545,  Train_accy 76.85
2025-01-12 18:45:25,528 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.091,  Train_accy 76.14
2025-01-12 18:45:52,876 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.539,  Train_accy 76.65
2025-01-12 18:45:53,083 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.086,  Train_accy 76.88
2025-01-12 18:46:19,800 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.532,  Train_accy 76.83
2025-01-12 18:46:20,317 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.079,  Train_accy 76.07
2025-01-12 18:47:05,968 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.536,  Train_accy 76.70, Test_accy 58.33
2025-01-12 18:47:06,083 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.080,  Train_accy 76.58, Test_accy 58.04
2025-01-12 18:47:33,213 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.522,  Train_accy 77.60
2025-01-12 18:47:33,369 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.072,  Train_accy 77.39
2025-01-12 18:48:00,123 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.516,  Train_accy 78.47
2025-01-12 18:48:00,574 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.067,  Train_accy 77.12
2025-01-12 18:50:18,963 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.515,  Train_accy 78.18
2025-01-12 18:50:19,006 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.065,  Train_accy 78.00
2025-01-12 18:51:46,152 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.520,  Train_accy 77.60
2025-01-12 18:51:46,192 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.071,  Train_accy 77.21
2025-01-12 18:55:26,019 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.514,  Train_accy 78.29, Test_accy 58.66
2025-01-12 18:55:26,061 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.064,  Train_accy 77.69, Test_accy 59.14
2025-01-12 18:56:48,485 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.517,  Train_accy 78.07
2025-01-12 18:56:48,643 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.070,  Train_accy 77.69
2025-01-12 18:57:15,388 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.507,  Train_accy 79.51
2025-01-12 18:57:15,538 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.059,  Train_accy 78.61
2025-01-12 18:57:42,628 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.504,  Train_accy 78.77
2025-01-12 18:57:42,839 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.056,  Train_accy 78.25
2025-01-12 18:58:09,652 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.499,  Train_accy 79.15
2025-01-12 18:58:09,826 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.051,  Train_accy 78.49
2025-01-12 19:00:06,016 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.052,  Train_accy 78.52, Test_accy 59.78
2025-01-12 19:00:06,027 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.502,  Train_accy 78.56, Test_accy 59.56
2025-01-12 19:00:34,138 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.500,  Train_accy 78.99
2025-01-12 19:00:34,311 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.052,  Train_accy 78.81
2025-01-12 19:01:01,387 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.495,  Train_accy 79.59
2025-01-12 19:01:01,562 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.049,  Train_accy 79.23
2025-01-12 19:01:28,313 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.488,  Train_accy 80.45
2025-01-12 19:01:28,922 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.042,  Train_accy 79.98
2025-01-12 19:01:54,510 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.487,  Train_accy 80.31
2025-01-12 19:01:55,517 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.041,  Train_accy 79.68
2025-01-12 19:02:31,914 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.490,  Train_accy 80.11, Test_accy 59.99
2025-01-12 19:02:33,630 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.044,  Train_accy 79.51, Test_accy 59.87
2025-01-12 19:02:58,608 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.482,  Train_accy 80.16
2025-01-12 19:03:01,221 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.037,  Train_accy 79.93
2025-01-12 19:03:25,220 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.483,  Train_accy 80.02
2025-01-12 19:03:27,927 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.040,  Train_accy 79.19
2025-01-12 19:03:51,863 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.483,  Train_accy 79.64
2025-01-12 19:03:54,795 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.039,  Train_accy 79.23
2025-01-12 19:04:18,983 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.477,  Train_accy 80.97
2025-01-12 19:04:21,066 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.035,  Train_accy 80.97
2025-01-12 19:06:04,801 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.486,  Train_accy 80.31, Test_accy 61.53
2025-01-12 19:06:04,808 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.041,  Train_accy 79.82, Test_accy 61.89
2025-01-12 19:06:32,152 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.474,  Train_accy 80.74
2025-01-12 19:06:32,358 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.029,  Train_accy 80.25
2025-01-12 19:06:59,603 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.482,  Train_accy 80.20
2025-01-12 19:06:59,740 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.033,  Train_accy 79.96
2025-01-12 19:07:26,866 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.476,  Train_accy 80.20
2025-01-12 19:07:26,983 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.031,  Train_accy 80.05
2025-01-12 19:07:53,987 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.027,  Train_accy 80.61
2025-01-12 19:07:54,166 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.472,  Train_accy 80.70
2025-01-12 19:08:31,456 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.026,  Train_accy 80.67, Test_accy 61.13
2025-01-12 19:08:32,699 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.471,  Train_accy 80.94, Test_accy 61.66
2025-01-12 19:08:57,603 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.024,  Train_accy 81.01
2025-01-12 19:08:59,232 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.469,  Train_accy 81.15
2025-01-12 19:09:24,205 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.024,  Train_accy 80.56
2025-01-12 19:09:25,724 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.468,  Train_accy 81.03
2025-01-12 19:09:50,855 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.025,  Train_accy 80.83
2025-01-12 19:09:52,089 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.468,  Train_accy 80.68
2025-01-12 19:10:17,615 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.024,  Train_accy 80.85
2025-01-12 19:10:18,602 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.467,  Train_accy 80.86
2025-01-12 19:10:55,970 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.020,  Train_accy 81.32, Test_accy 61.10
2025-01-12 19:10:56,922 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.461,  Train_accy 82.09, Test_accy 61.56
2025-01-12 19:11:22,591 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.024,  Train_accy 80.05
2025-01-12 19:11:23,484 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.467,  Train_accy 80.86
2025-01-12 19:11:48,865 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.021,  Train_accy 81.35
2025-01-12 19:11:49,955 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.463,  Train_accy 81.41
2025-01-12 19:12:15,665 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.017,  Train_accy 81.15
2025-01-12 19:12:16,663 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.458,  Train_accy 81.35
2025-01-12 19:12:42,386 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.019,  Train_accy 81.44
2025-01-12 19:12:43,257 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.461,  Train_accy 81.51
2025-01-12 19:13:21,176 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.013,  Train_accy 81.69, Test_accy 62.25
2025-01-12 19:13:22,070 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.454,  Train_accy 81.68, Test_accy 62.39
2025-01-12 19:13:47,688 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.016,  Train_accy 82.38
2025-01-12 19:13:48,704 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.457,  Train_accy 82.29
2025-01-12 19:14:14,253 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.017,  Train_accy 81.03
2025-01-12 19:14:15,162 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.459,  Train_accy 81.68
2025-01-12 19:14:40,530 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.015,  Train_accy 82.22
2025-01-12 19:14:41,387 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.456,  Train_accy 82.41
2025-01-12 19:15:07,108 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.014,  Train_accy 82.22
2025-01-12 19:15:08,069 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.454,  Train_accy 82.58
2025-01-12 19:15:45,393 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.012,  Train_accy 81.62, Test_accy 62.09
2025-01-12 19:15:46,136 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.452,  Train_accy 82.14, Test_accy 62.30
2025-01-12 19:16:11,732 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.008,  Train_accy 82.36
2025-01-12 19:16:12,804 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.447,  Train_accy 82.59
2025-01-12 19:16:38,015 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.011,  Train_accy 81.44
2025-01-12 19:16:39,548 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.451,  Train_accy 82.09
2025-01-12 19:17:04,360 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.014,  Train_accy 81.46
2025-01-12 19:17:05,997 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.455,  Train_accy 82.14
2025-01-12 19:17:30,903 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.013,  Train_accy 81.60
2025-01-12 19:17:32,368 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.454,  Train_accy 81.84
2025-01-12 19:18:09,345 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.010,  Train_accy 82.40, Test_accy 62.36
2025-01-12 19:18:10,980 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.450,  Train_accy 82.97, Test_accy 62.53
2025-01-12 19:18:35,286 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.006,  Train_accy 82.29
2025-01-12 19:18:37,353 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.446,  Train_accy 82.18
2025-01-12 19:19:01,749 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.007,  Train_accy 82.49
2025-01-12 19:19:03,947 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.446,  Train_accy 82.72
2025-01-12 19:19:28,250 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.005,  Train_accy 82.25
2025-01-12 19:19:31,019 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.445,  Train_accy 82.99
2025-01-12 19:19:54,777 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.011,  Train_accy 81.82
2025-01-12 19:19:57,516 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.451,  Train_accy 82.02
2025-01-12 19:20:31,579 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.006,  Train_accy 82.54, Test_accy 62.95
2025-01-12 19:20:34,455 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.446,  Train_accy 82.92, Test_accy 62.78
2025-01-12 19:20:57,536 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.008,  Train_accy 82.50
2025-01-12 19:21:01,469 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.446,  Train_accy 82.88
2025-01-12 19:21:24,135 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.005,  Train_accy 82.49
2025-01-12 19:21:28,697 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.445,  Train_accy 82.70
2025-01-12 19:21:50,924 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.004,  Train_accy 82.13
2025-01-12 19:21:55,306 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.444,  Train_accy 82.36
2025-01-12 19:22:17,177 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.002,  Train_accy 83.01
2025-01-12 19:22:21,837 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.441,  Train_accy 83.28
2025-01-12 19:22:54,540 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.002,  Train_accy 82.32, Test_accy 63.28
2025-01-12 19:22:58,819 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.440,  Train_accy 82.58, Test_accy 63.42
2025-01-12 19:23:20,316 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.004,  Train_accy 82.11
2025-01-12 19:23:25,517 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.443,  Train_accy 82.40
2025-01-12 19:23:47,179 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.007,  Train_accy 82.76
2025-01-12 19:23:52,388 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.447,  Train_accy 83.23
2025-01-12 19:24:14,113 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.001,  Train_accy 82.49
2025-01-12 19:24:19,186 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.439,  Train_accy 82.92
2025-01-12 19:24:40,857 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.001,  Train_accy 82.83
2025-01-12 19:24:46,001 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.440,  Train_accy 83.12
2025-01-12 19:25:17,781 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 1.999,  Train_accy 83.37, Test_accy 63.21
2025-01-12 19:25:23,441 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.437,  Train_accy 83.51, Test_accy 63.59
2025-01-12 19:25:42,476 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.002,  Train_accy 82.20
2025-01-12 19:25:50,879 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.440,  Train_accy 82.67
2025-01-12 19:26:09,209 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.002,  Train_accy 82.94
2025-01-12 19:26:17,771 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.440,  Train_accy 83.06
2025-01-12 19:26:35,853 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 1.998,  Train_accy 82.63
2025-01-12 19:26:44,738 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.437,  Train_accy 82.81
2025-01-12 19:27:02,141 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.000,  Train_accy 82.49
2025-01-12 19:27:11,559 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.438,  Train_accy 82.97
2025-01-12 19:27:40,015 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.001,  Train_accy 82.27, Test_accy 63.48
2025-01-12 19:27:49,071 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.439,  Train_accy 82.47, Test_accy 63.76
2025-01-12 19:28:03,889 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.000,  Train_accy 82.67
2025-01-12 19:28:16,342 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.439,  Train_accy 83.35
2025-01-12 19:28:30,304 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.002,  Train_accy 82.90
2025-01-12 19:28:43,498 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.442,  Train_accy 82.97
2025-01-12 19:28:56,931 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 1.999,  Train_accy 82.29
2025-01-12 19:29:10,202 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.437,  Train_accy 82.74
2025-01-12 19:29:23,604 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 1.997,  Train_accy 82.54
2025-01-12 19:29:37,393 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.434,  Train_accy 83.08
2025-01-12 19:30:02,394 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.000,  Train_accy 82.85, Test_accy 63.67
2025-01-12 19:30:14,222 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.438,  Train_accy 82.86, Test_accy 63.74
2025-01-12 19:30:25,357 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.001,  Train_accy 82.97
2025-01-12 19:30:40,713 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.439,  Train_accy 83.46
2025-01-12 19:30:51,589 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.001,  Train_accy 82.20
2025-01-12 19:31:06,975 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.439,  Train_accy 82.67
2025-01-12 19:31:18,028 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 1.999,  Train_accy 83.06
2025-01-12 19:31:33,492 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.436,  Train_accy 83.42
2025-01-12 19:31:44,400 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 1.999,  Train_accy 82.99
2025-01-12 19:32:00,402 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.437,  Train_accy 82.65
2025-01-12 19:32:23,065 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.001,  Train_accy 83.14, Test_accy 63.06
2025-01-12 19:32:36,522 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.439,  Train_accy 83.01, Test_accy 63.23
2025-01-12 19:32:44,894 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 1.999,  Train_accy 82.97
2025-01-12 19:33:03,548 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.436,  Train_accy 83.28
2025-01-12 19:33:11,561 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 1.998,  Train_accy 82.70
2025-01-12 19:33:30,461 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.436,  Train_accy 83.06
2025-01-12 19:33:37,910 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 1.999,  Train_accy 83.59
2025-01-12 19:33:56,873 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.438,  Train_accy 83.96
2025-01-12 19:34:04,378 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 1.995,  Train_accy 83.10
2025-01-12 19:34:23,509 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.433,  Train_accy 83.21
2025-01-12 19:34:42,479 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.000,  Train_accy 82.43, Test_accy 63.73
2025-01-12 19:34:59,678 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.438,  Train_accy 82.22, Test_accy 63.86
2025-01-12 19:35:04,726 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 1.998,  Train_accy 82.32
2025-01-12 19:35:26,285 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.436,  Train_accy 82.59
2025-01-12 19:35:31,267 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 1.996,  Train_accy 82.36
2025-01-12 19:35:52,740 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.434,  Train_accy 82.58
2025-01-12 19:35:57,881 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.000,  Train_accy 82.88
2025-01-12 19:36:19,489 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.438,  Train_accy 83.14
2025-01-12 19:36:24,565 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 1.996,  Train_accy 83.26
2025-01-12 19:36:46,416 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.434,  Train_accy 83.64
2025-01-12 19:37:36,846 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 1.994,  Train_accy 82.97, Test_accy 63.72
2025-01-12 19:37:36,955 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.431,  Train_accy 83.69, Test_accy 64.11
2025-01-12 19:38:03,516 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 1.999,  Train_accy 83.62
2025-01-12 19:38:04,110 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.437,  Train_accy 84.05
2025-01-12 19:38:30,431 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 1.998,  Train_accy 83.10
2025-01-12 19:38:31,489 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.436,  Train_accy 83.71
2025-01-12 19:38:56,786 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 1.994,  Train_accy 83.44
2025-01-12 19:38:58,376 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.431,  Train_accy 83.82
2025-01-12 19:39:23,405 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.000,  Train_accy 82.94
2025-01-12 19:39:23,407 [der.py] => do not weight align student!
2025-01-12 19:39:24,702 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.438,  Train_accy 83.21
2025-01-12 19:39:24,703 [der.py] => weight align student!
2025-01-12 19:39:32,231 [der.py] => darknet eval: 
2025-01-12 19:39:32,231 [der.py] => CNN top1 curve: 63.45
2025-01-12 19:39:32,231 [der.py] => CNN top5 curve: 92.33
2025-01-12 19:39:32,233 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 19:39:34,248 [der.py] => darknet eval: 
2025-01-12 19:39:34,248 [der.py] => CNN top1 curve: 61.02
2025-01-12 19:39:34,248 [der.py] => CNN top5 curve: 91.85
2025-01-12 19:39:34,250 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-01-12 19:41:10,569 [der.py] => Exemplar size: 1650
2025-01-12 19:41:10,569 [trainer.py] => CNN: {'total': 77.15, '0': 60.56, '1': 74.44, '2': 92.22, '3': 49.44, '4': 87.22, '5': 47.78, '6': 71.67, '7': 57.22, '8': 52.78, '9': 60.0, '10': 91.67, '11': 78.89, '12': 85.56, '13': 83.33, '14': 60.0, '15': 93.89, '16': 95.56, '17': 96.11, '18': 91.67, '19': 95.56, '20': 96.67, '21': 90.0, '22': 83.33, '23': 63.33, '24': 66.11, '25': 82.78, '26': 90.0, '27': 92.22, '28': 75.56, '29': 80.56, '30': 91.11, '31': 83.33, '32': 95.56, '33': 68.33, '34': 77.22, '35': 96.67, '36': 96.67, '37': 81.67, '38': 97.78, '39': 95.0, '40': 90.0, '41': 97.22, '42': 99.44, '43': 97.22, '44': 87.22, '45': 52.78, '46': 70.0, '47': 46.67, '48': 57.22, '49': 51.67, '50': 51.67, '51': 60.56, '52': 55.0, '53': 55.56, 'old': 82.23, 'new': 54.28}
2025-01-12 19:41:10,570 [trainer.py] => NME: {'total': 73.45, '0': 70.0, '1': 59.44, '2': 78.89, '3': 33.33, '4': 83.33, '5': 43.33, '6': 59.44, '7': 51.67, '8': 45.56, '9': 51.11, '10': 90.0, '11': 81.11, '12': 77.22, '13': 65.56, '14': 55.0, '15': 88.89, '16': 88.89, '17': 92.78, '18': 90.0, '19': 91.11, '20': 88.89, '21': 87.22, '22': 83.33, '23': 61.67, '24': 72.78, '25': 76.11, '26': 88.33, '27': 82.78, '28': 60.56, '29': 73.33, '30': 76.67, '31': 79.44, '32': 90.56, '33': 60.0, '34': 81.67, '35': 96.67, '36': 87.78, '37': 63.33, '38': 92.78, '39': 85.56, '40': 75.56, '41': 90.56, '42': 97.22, '43': 95.56, '44': 53.89, '45': 78.33, '46': 80.56, '47': 63.89, '48': 61.67, '49': 61.67, '50': 52.22, '51': 65.0, '52': 60.0, '53': 57.78, 'old': 75.53, 'new': 64.11}
2025-01-12 19:41:10,570 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41, 77.15]
2025-01-12 19:41:10,570 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35, 96.05]
2025-01-12 19:41:10,570 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53, 73.45]
2025-01-12 19:41:10,570 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06, 94.92]

2025-01-12 19:41:14,956 [der.py] => Exemplar size: 1650
2025-01-12 19:41:14,956 [trainer.py] => CNN: {'total': 77.15, '0': 60.56, '1': 74.44, '2': 92.22, '3': 49.44, '4': 87.22, '5': 47.78, '6': 71.67, '7': 57.22, '8': 52.78, '9': 60.0, '10': 91.67, '11': 78.89, '12': 85.56, '13': 83.33, '14': 60.0, '15': 93.89, '16': 95.56, '17': 96.11, '18': 91.67, '19': 95.56, '20': 96.67, '21': 90.0, '22': 83.33, '23': 63.33, '24': 66.11, '25': 82.78, '26': 90.0, '27': 92.22, '28': 75.56, '29': 80.56, '30': 91.11, '31': 83.33, '32': 95.56, '33': 68.33, '34': 77.22, '35': 96.67, '36': 96.67, '37': 81.67, '38': 97.78, '39': 95.0, '40': 90.0, '41': 97.22, '42': 99.44, '43': 97.22, '44': 87.22, '45': 52.78, '46': 70.0, '47': 46.67, '48': 57.22, '49': 51.67, '50': 51.67, '51': 60.56, '52': 55.0, '53': 55.56, 'old': 82.23, 'new': 54.28}
2025-01-12 19:41:14,957 [trainer.py] => NME: {'total': 73.45, '0': 70.0, '1': 59.44, '2': 78.89, '3': 33.33, '4': 83.33, '5': 43.33, '6': 59.44, '7': 51.67, '8': 45.56, '9': 51.11, '10': 90.0, '11': 81.11, '12': 77.22, '13': 65.56, '14': 55.0, '15': 88.89, '16': 88.89, '17': 92.78, '18': 90.0, '19': 91.11, '20': 88.89, '21': 87.22, '22': 83.33, '23': 61.67, '24': 72.78, '25': 76.11, '26': 88.33, '27': 82.78, '28': 60.56, '29': 73.33, '30': 76.67, '31': 79.44, '32': 90.56, '33': 60.0, '34': 81.67, '35': 96.67, '36': 87.78, '37': 63.33, '38': 92.78, '39': 85.56, '40': 75.56, '41': 90.56, '42': 97.22, '43': 95.56, '44': 53.89, '45': 78.33, '46': 80.56, '47': 63.89, '48': 61.67, '49': 61.67, '50': 52.22, '51': 65.0, '52': 60.0, '53': 57.78, 'old': 75.53, 'new': 64.11}
2025-01-12 19:41:14,957 [trainer.py] => CNN top1 curve: [89.44, 88.07, 82.7, 76.41, 77.15]
2025-01-12 19:41:14,957 [trainer.py] => CNN top5 curve: [98.93, 98.76, 97.62, 96.35, 96.05]
2025-01-12 19:41:14,957 [trainer.py] => NME top1 curve: [88.22, 84.98, 79.59, 78.53, 73.45]
2025-01-12 19:41:14,957 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.59, 97.06, 94.92]


2025-02-04 14:36:35,900 [trainer.py] => 实验名称:BKD平衡知识蒸馏*0.40实验
2025-02-04 14:36:35,900 [trainer.py] => config: ./exps/der.json
2025-02-04 14:36:35,900 [trainer.py] => experiment_name: 实验名称:BKD平衡知识蒸馏*0.40实验
2025-02-04 14:36:35,900 [trainer.py] => prefix: reproduce
2025-02-04 14:36:35,900 [trainer.py] => dataset: xrfdataset
2025-02-04 14:36:35,900 [trainer.py] => memory_size: 1650
2025-02-04 14:36:35,900 [trainer.py] => memory_per_class: 30
2025-02-04 14:36:35,900 [trainer.py] => fixed_memory: True
2025-02-04 14:36:35,900 [trainer.py] => shuffle: True
2025-02-04 14:36:35,900 [trainer.py] => init_cls: 15
2025-02-04 14:36:35,900 [trainer.py] => increment: 10
2025-02-04 14:36:35,900 [trainer.py] => model_name: der
2025-02-04 14:36:35,900 [trainer.py] => compression_epochs: 130
2025-02-04 14:36:35,901 [trainer.py] => compression_lr: 0.1
2025-02-04 14:36:35,901 [trainer.py] => is_student_wa: False
2025-02-04 14:36:35,901 [trainer.py] => wa_value: 1
2025-02-04 14:36:35,901 [trainer.py] => T: 2
2025-02-04 14:36:35,901 [trainer.py] => convnet_type: unet
2025-02-04 14:36:35,901 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-04 14:36:35,901 [trainer.py] => seed: 1993
2025-02-04 14:36:35,912 [data.py] => 加载完毕XRF原始数据集
2025-02-04 14:36:35,917 [data.py] => 加载完毕XRF原始数据集
2025-02-04 14:36:35,918 [trainer.py] => All params: 0
2025-02-04 14:36:35,918 [trainer.py] => Trainable params: 0
2025-02-04 14:36:36,089 [der.py] => Learning on 0-15
2025-02-04 14:36:36,089 [der.py] => All params: 21045611
2025-02-04 14:36:36,089 [der.py] => Trainable params: 21045611
2025-02-04 14:57:30,868 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-04 14:57:30,868 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 14:57:54,370 [der.py] => Exemplar size: 450
2025-02-04 14:57:54,371 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-04 14:57:54,371 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-04 14:57:54,371 [trainer.py] => CNN top1 curve: [89.44]
2025-02-04 14:57:54,371 [trainer.py] => CNN top5 curve: [98.93]
2025-02-04 14:57:54,371 [trainer.py] => NME top1 curve: [88.22]
2025-02-04 14:57:54,371 [trainer.py] => NME top5 curve: [98.81]

2025-02-04 14:57:54,372 [trainer.py] => All params: 21045611
2025-02-04 14:57:54,372 [trainer.py] => Trainable params: 21045611
2025-02-04 14:57:54,526 [der.py] => Learning on 15-25
2025-02-04 14:57:54,526 [der.py] => All params: 42091068
2025-02-04 14:57:54,527 [der.py] => Trainable params: 21049456
2025-02-04 14:57:54,604 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 14:57:54,604 [der.py] => per cls weights : [1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 0.39805845 0.39805845 0.39805845
 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845
 0.39805845]
2025-02-04 15:18:37,257 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-02-04 15:18:37,260 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 15:18:37,260 [der.py] => per cls weights : [1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 0.39805845 0.39805845 0.39805845
 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845
 0.39805845]
2025-02-04 15:18:50,179 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.195,  Train_accy 41.48, Test_accy 59.82
2025-02-04 15:18:58,441 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.736,  Train_accy 65.51
2025-02-04 15:19:06,758 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.568,  Train_accy 74.41
2025-02-04 15:19:15,284 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.452,  Train_accy 81.18
2025-02-04 15:19:23,586 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.399,  Train_accy 83.16
2025-02-04 15:19:36,281 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.359,  Train_accy 85.66, Test_accy 76.11
2025-02-04 15:19:44,657 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.334,  Train_accy 86.62
2025-02-04 15:19:53,052 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.301,  Train_accy 89.40
2025-02-04 15:20:01,339 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.284,  Train_accy 89.35
2025-02-04 15:20:09,643 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.282,  Train_accy 89.72
2025-02-04 15:20:22,233 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.262,  Train_accy 91.03, Test_accy 78.09
2025-02-04 15:20:30,586 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.252,  Train_accy 91.10
2025-02-04 15:20:38,941 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.239,  Train_accy 91.44
2025-02-04 15:20:47,327 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.238,  Train_accy 91.72
2025-02-04 15:20:55,687 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.231,  Train_accy 91.35
2025-02-04 15:21:08,237 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.241,  Train_accy 91.48, Test_accy 77.78
2025-02-04 15:21:16,554 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.230,  Train_accy 92.04
2025-02-04 15:21:24,967 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.225,  Train_accy 91.94
2025-02-04 15:21:33,298 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.220,  Train_accy 92.65
2025-02-04 15:21:41,631 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.224,  Train_accy 92.13
2025-02-04 15:21:54,271 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.211,  Train_accy 92.58, Test_accy 80.29
2025-02-04 15:22:02,620 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.208,  Train_accy 92.73
2025-02-04 15:22:10,948 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.206,  Train_accy 92.90
2025-02-04 15:22:19,291 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.204,  Train_accy 93.03
2025-02-04 15:22:27,592 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.199,  Train_accy 92.92
2025-02-04 15:22:40,098 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.198,  Train_accy 92.86, Test_accy 80.38
2025-02-04 15:22:48,391 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.199,  Train_accy 93.20
2025-02-04 15:22:56,833 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.193,  Train_accy 93.10
2025-02-04 15:23:05,155 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.189,  Train_accy 92.86
2025-02-04 15:23:13,454 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.192,  Train_accy 93.20
2025-02-04 15:23:26,027 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.192,  Train_accy 92.92, Test_accy 80.56
2025-02-04 15:23:34,308 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.196,  Train_accy 92.75
2025-02-04 15:23:42,838 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.185,  Train_accy 93.35
2025-02-04 15:23:51,209 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.182,  Train_accy 93.44
2025-02-04 15:23:59,543 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.182,  Train_accy 93.08
2025-02-04 15:24:12,071 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.180,  Train_accy 93.63, Test_accy 81.51
2025-02-04 15:24:20,392 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.180,  Train_accy 93.81
2025-02-04 15:24:28,756 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.185,  Train_accy 93.42
2025-02-04 15:24:37,091 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.183,  Train_accy 93.38
2025-02-04 15:24:45,504 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.176,  Train_accy 93.29
2025-02-04 15:24:57,904 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.175,  Train_accy 93.53, Test_accy 81.27
2025-02-04 15:25:06,204 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.179,  Train_accy 93.53
2025-02-04 15:25:14,642 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.183,  Train_accy 93.63
2025-02-04 15:25:22,978 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.170,  Train_accy 93.31
2025-02-04 15:25:31,383 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.169,  Train_accy 93.83
2025-02-04 15:25:43,850 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.176,  Train_accy 93.70, Test_accy 81.00
2025-02-04 15:25:52,293 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.174,  Train_accy 93.12
2025-02-04 15:26:00,676 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.168,  Train_accy 93.81
2025-02-04 15:26:09,085 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.174,  Train_accy 93.57
2025-02-04 15:26:17,538 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.173,  Train_accy 93.48
2025-02-04 15:26:30,099 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.173,  Train_accy 93.20, Test_accy 80.67
2025-02-04 15:26:38,467 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.171,  Train_accy 93.33
2025-02-04 15:26:46,772 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.170,  Train_accy 93.33
2025-02-04 15:26:55,040 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.173,  Train_accy 93.96
2025-02-04 15:27:03,396 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.170,  Train_accy 93.53
2025-02-04 15:27:15,889 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.164,  Train_accy 93.57, Test_accy 81.40
2025-02-04 15:27:24,273 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.161,  Train_accy 93.72
2025-02-04 15:27:32,611 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.164,  Train_accy 93.94
2025-02-04 15:27:41,058 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.164,  Train_accy 93.61
2025-02-04 15:27:49,510 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.161,  Train_accy 93.48
2025-02-04 15:28:01,991 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.158,  Train_accy 93.98, Test_accy 80.87
2025-02-04 15:28:10,347 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.162,  Train_accy 93.14
2025-02-04 15:28:18,676 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.163,  Train_accy 93.85
2025-02-04 15:28:26,983 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.163,  Train_accy 93.74
2025-02-04 15:28:35,355 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.158,  Train_accy 93.70
2025-02-04 15:28:47,815 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.157,  Train_accy 93.94, Test_accy 80.96
2025-02-04 15:28:56,186 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.159,  Train_accy 93.63
2025-02-04 15:29:04,477 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.161,  Train_accy 93.81
2025-02-04 15:29:12,851 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.162,  Train_accy 93.76
2025-02-04 15:29:21,266 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.160,  Train_accy 93.23
2025-02-04 15:29:33,765 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.158,  Train_accy 93.96, Test_accy 81.20
2025-02-04 15:29:42,362 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.158,  Train_accy 93.98
2025-02-04 15:29:50,691 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.155,  Train_accy 93.85
2025-02-04 15:29:59,138 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.161,  Train_accy 93.53
2025-02-04 15:30:07,423 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.155,  Train_accy 93.94
2025-02-04 15:30:20,249 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.155,  Train_accy 93.51, Test_accy 80.60
2025-02-04 15:30:28,582 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.158,  Train_accy 94.37
2025-02-04 15:30:36,978 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.154,  Train_accy 94.06
2025-02-04 15:30:45,420 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.154,  Train_accy 94.17
2025-02-04 15:30:53,712 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.156,  Train_accy 93.48
2025-02-04 15:31:06,280 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.153,  Train_accy 93.78, Test_accy 80.78
2025-02-04 15:31:14,579 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.157,  Train_accy 93.87
2025-02-04 15:31:22,916 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.155,  Train_accy 94.00
2025-02-04 15:31:31,288 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.153,  Train_accy 93.81
2025-02-04 15:31:39,567 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.152,  Train_accy 93.94
2025-02-04 15:31:52,124 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.149,  Train_accy 94.39, Test_accy 81.42
2025-02-04 15:32:00,402 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.153,  Train_accy 93.78
2025-02-04 15:32:08,762 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.155,  Train_accy 93.94
2025-02-04 15:32:17,124 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.153,  Train_accy 94.11
2025-02-04 15:32:25,405 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.150,  Train_accy 94.02
2025-02-04 15:32:37,952 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.152,  Train_accy 93.91, Test_accy 81.40
2025-02-04 15:32:46,259 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.151,  Train_accy 93.89
2025-02-04 15:32:54,674 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.149,  Train_accy 93.78
2025-02-04 15:33:03,004 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.150,  Train_accy 93.85
2025-02-04 15:33:11,382 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.152,  Train_accy 93.68
2025-02-04 15:33:24,051 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.148,  Train_accy 93.94, Test_accy 81.51
2025-02-04 15:33:32,373 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.149,  Train_accy 94.39
2025-02-04 15:33:40,768 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.149,  Train_accy 93.85
2025-02-04 15:33:49,087 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.148,  Train_accy 93.94
2025-02-04 15:33:57,346 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.154,  Train_accy 93.83
2025-02-04 15:34:09,792 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.150,  Train_accy 93.96, Test_accy 81.20
2025-02-04 15:34:18,129 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.150,  Train_accy 94.04
2025-02-04 15:34:26,448 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.148,  Train_accy 93.78
2025-02-04 15:34:34,707 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.148,  Train_accy 94.06
2025-02-04 15:34:43,080 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.149,  Train_accy 93.72
2025-02-04 15:34:55,817 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.144,  Train_accy 94.22, Test_accy 81.64
2025-02-04 15:35:04,217 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.145,  Train_accy 93.83
2025-02-04 15:35:12,628 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.151,  Train_accy 94.24
2025-02-04 15:35:20,945 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.145,  Train_accy 93.91
2025-02-04 15:35:29,213 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.150,  Train_accy 94.11
2025-02-04 15:35:41,825 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.148,  Train_accy 94.15, Test_accy 81.47
2025-02-04 15:35:50,146 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.147,  Train_accy 93.76
2025-02-04 15:35:58,517 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.147,  Train_accy 93.87
2025-02-04 15:36:06,808 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.147,  Train_accy 94.24
2025-02-04 15:36:15,249 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.148,  Train_accy 93.68
2025-02-04 15:36:27,790 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.147,  Train_accy 93.98, Test_accy 82.20
2025-02-04 15:36:36,168 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.145,  Train_accy 93.70
2025-02-04 15:36:44,612 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.147,  Train_accy 94.06
2025-02-04 15:36:52,925 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.148,  Train_accy 94.04
2025-02-04 15:37:01,284 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.148,  Train_accy 94.04
2025-02-04 15:37:13,808 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.147,  Train_accy 94.06, Test_accy 82.13
2025-02-04 15:37:22,123 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.149,  Train_accy 93.66
2025-02-04 15:37:30,552 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.145,  Train_accy 94.15
2025-02-04 15:37:38,905 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.143,  Train_accy 93.89
2025-02-04 15:37:47,295 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.145,  Train_accy 93.72
2025-02-04 15:37:59,816 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.143,  Train_accy 94.00, Test_accy 81.69
2025-02-04 15:38:08,137 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.148,  Train_accy 93.94
2025-02-04 15:38:16,533 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.148,  Train_accy 94.06
2025-02-04 15:38:24,780 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.143,  Train_accy 94.13
2025-02-04 15:38:33,174 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.144,  Train_accy 94.06
2025-02-04 15:38:33,175 [der.py] => do not weight align student!
2025-02-04 15:38:37,282 [der.py] => darknet eval: 
2025-02-04 15:38:37,282 [der.py] => CNN top1 curve: 81.87
2025-02-04 15:38:37,282 [der.py] => CNN top5 curve: 98.4
2025-02-04 15:38:37,284 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 15:39:08,719 [der.py] => Exemplar size: 750
2025-02-04 15:39:08,720 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-02-04 15:39:08,720 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-02-04 15:39:08,720 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-02-04 15:39:08,720 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-02-04 15:39:08,720 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-02-04 15:39:08,720 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-02-04 15:39:08,720 [trainer.py] => All params: 42091068
2025-02-04 15:39:08,721 [trainer.py] => Trainable params: 21049456
2025-02-04 15:39:08,865 [der.py] => Learning on 25-35
2025-02-04 15:39:08,866 [der.py] => All params: 42093638
2025-02-04 15:39:08,866 [der.py] => Trainable params: 21052026
2025-02-04 15:39:08,950 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 15:39:08,950 [der.py] => per cls weights : [1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342
 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342]
2025-02-04 16:01:52,272 [der.py] => Task 2, Epoch 150/150 => Loss 0.012, Loss_clf 0.006, Loss_aux 0.005, Train_accy 100.00
2025-02-04 16:01:52,274 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 16:01:52,275 [der.py] => per cls weights : [1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342
 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342]
2025-02-04 16:02:06,831 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.336,  Train_accy 39.07, Test_accy 59.25
2025-02-04 16:02:15,761 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.065,  Train_accy 59.56
2025-02-04 16:02:24,627 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.961,  Train_accy 67.43
2025-02-04 16:02:33,584 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.901,  Train_accy 72.12
2025-02-04 16:02:42,532 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.866,  Train_accy 74.38
2025-02-04 16:02:56,907 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.834,  Train_accy 76.71, Test_accy 67.27
2025-02-04 16:03:05,884 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.808,  Train_accy 77.70
2025-02-04 16:03:14,737 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.800,  Train_accy 78.89
2025-02-04 16:03:23,838 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.782,  Train_accy 79.72
2025-02-04 16:03:32,707 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.776,  Train_accy 80.06
2025-02-04 16:03:47,134 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.763,  Train_accy 81.45, Test_accy 69.10
2025-02-04 16:03:55,985 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.755,  Train_accy 81.15
2025-02-04 16:04:04,785 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.746,  Train_accy 82.16
2025-02-04 16:04:13,851 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.743,  Train_accy 81.98
2025-02-04 16:04:22,693 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.738,  Train_accy 82.91
2025-02-04 16:04:37,220 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.735,  Train_accy 82.71, Test_accy 69.46
2025-02-04 16:04:46,041 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.729,  Train_accy 83.47
2025-02-04 16:04:54,936 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.726,  Train_accy 83.47
2025-02-04 16:05:03,804 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.720,  Train_accy 83.94
2025-02-04 16:05:12,690 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.718,  Train_accy 84.18
2025-02-04 16:05:27,069 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.714,  Train_accy 83.94, Test_accy 70.65
2025-02-04 16:05:35,969 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.715,  Train_accy 84.22
2025-02-04 16:05:44,771 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.708,  Train_accy 84.83
2025-02-04 16:05:53,564 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.706,  Train_accy 84.87
2025-02-04 16:06:02,424 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.703,  Train_accy 85.39
2025-02-04 16:06:17,125 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.701,  Train_accy 84.20, Test_accy 70.81
2025-02-04 16:06:26,039 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.694,  Train_accy 85.41
2025-02-04 16:06:34,888 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.692,  Train_accy 85.49
2025-02-04 16:06:43,926 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.691,  Train_accy 85.01
2025-02-04 16:06:52,982 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.690,  Train_accy 85.68
2025-02-04 16:07:07,368 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.691,  Train_accy 85.49, Test_accy 72.05
2025-02-04 16:07:16,315 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.688,  Train_accy 85.13
2025-02-04 16:07:25,191 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.684,  Train_accy 85.94
2025-02-04 16:07:34,155 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.682,  Train_accy 85.86
2025-02-04 16:07:43,036 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.681,  Train_accy 86.20
2025-02-04 16:07:57,383 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.682,  Train_accy 85.94, Test_accy 72.22
2025-02-04 16:08:06,188 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.680,  Train_accy 85.45
2025-02-04 16:08:15,081 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.676,  Train_accy 86.24
2025-02-04 16:08:23,976 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.674,  Train_accy 86.00
2025-02-04 16:08:32,868 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.674,  Train_accy 86.57
2025-02-04 16:08:47,312 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.676,  Train_accy 85.82, Test_accy 71.33
2025-02-04 16:08:56,173 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.671,  Train_accy 86.38
2025-02-04 16:09:05,133 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.674,  Train_accy 85.92
2025-02-04 16:09:13,961 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.671,  Train_accy 85.74
2025-02-04 16:09:22,778 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.669,  Train_accy 86.40
2025-02-04 16:09:37,088 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.669,  Train_accy 86.85, Test_accy 72.44
2025-02-04 16:09:46,037 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.671,  Train_accy 86.16
2025-02-04 16:09:54,853 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.667,  Train_accy 87.03
2025-02-04 16:10:03,699 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.667,  Train_accy 86.57
2025-02-04 16:10:12,714 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.664,  Train_accy 86.73
2025-02-04 16:10:27,119 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.663,  Train_accy 86.48, Test_accy 72.02
2025-02-04 16:10:36,049 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.666,  Train_accy 86.65
2025-02-04 16:10:44,847 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.666,  Train_accy 86.81
2025-02-04 16:10:53,768 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.660,  Train_accy 87.29
2025-02-04 16:11:02,632 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.661,  Train_accy 86.63
2025-02-04 16:11:17,766 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.660,  Train_accy 87.11, Test_accy 72.32
2025-02-04 16:11:26,660 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.659,  Train_accy 87.21
2025-02-04 16:11:35,517 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.660,  Train_accy 86.30
2025-02-04 16:11:44,468 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.660,  Train_accy 86.89
2025-02-04 16:11:53,301 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.658,  Train_accy 86.63
2025-02-04 16:12:07,729 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.658,  Train_accy 86.61, Test_accy 71.81
2025-02-04 16:12:16,527 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.657,  Train_accy 87.25
2025-02-04 16:12:25,660 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.663,  Train_accy 87.19
2025-02-04 16:12:34,587 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.654,  Train_accy 87.35
2025-02-04 16:12:43,385 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.654,  Train_accy 86.83
2025-02-04 16:12:57,728 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.654,  Train_accy 86.69, Test_accy 72.70
2025-02-04 16:13:06,541 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.654,  Train_accy 87.23
2025-02-04 16:13:15,407 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.653,  Train_accy 87.43
2025-02-04 16:13:24,262 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.651,  Train_accy 87.41
2025-02-04 16:13:33,186 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.650,  Train_accy 87.25
2025-02-04 16:13:47,630 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.652,  Train_accy 86.85, Test_accy 72.71
2025-02-04 16:13:56,547 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.652,  Train_accy 87.23
2025-02-04 16:14:05,351 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.652,  Train_accy 87.07
2025-02-04 16:14:14,183 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.647,  Train_accy 87.52
2025-02-04 16:14:23,089 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.650,  Train_accy 87.35
2025-02-04 16:14:37,513 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.650,  Train_accy 87.37, Test_accy 72.57
2025-02-04 16:14:46,462 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.650,  Train_accy 87.41
2025-02-04 16:14:55,287 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.647,  Train_accy 88.04
2025-02-04 16:15:04,133 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.648,  Train_accy 87.74
2025-02-04 16:15:12,984 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.646,  Train_accy 87.72
2025-02-04 16:15:27,383 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.648,  Train_accy 87.29, Test_accy 72.40
2025-02-04 16:15:36,168 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.646,  Train_accy 87.86
2025-02-04 16:15:45,037 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.641,  Train_accy 87.52
2025-02-04 16:15:53,962 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.642,  Train_accy 87.43
2025-02-04 16:16:02,790 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.646,  Train_accy 87.27
2025-02-04 16:16:17,118 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.644,  Train_accy 87.29, Test_accy 72.49
2025-02-04 16:16:25,925 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.642,  Train_accy 87.66
2025-02-04 16:16:34,925 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.642,  Train_accy 87.74
2025-02-04 16:16:44,163 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.643,  Train_accy 87.66
2025-02-04 16:16:53,007 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.644,  Train_accy 87.49
2025-02-04 16:17:07,481 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.640,  Train_accy 87.35, Test_accy 72.75
2025-02-04 16:17:16,398 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.642,  Train_accy 87.54
2025-02-04 16:17:25,817 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.642,  Train_accy 87.39
2025-02-04 16:17:34,977 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.640,  Train_accy 87.92
2025-02-04 16:17:43,985 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.640,  Train_accy 87.76
2025-02-04 16:17:58,292 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.641,  Train_accy 88.04, Test_accy 73.21
2025-02-04 16:18:07,446 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.640,  Train_accy 87.96
2025-02-04 16:18:16,365 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.640,  Train_accy 88.14
2025-02-04 16:18:25,332 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.638,  Train_accy 87.49
2025-02-04 16:18:34,209 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.637,  Train_accy 88.06
2025-02-04 16:18:48,685 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.640,  Train_accy 87.64, Test_accy 72.89
2025-02-04 16:18:57,544 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.641,  Train_accy 87.70
2025-02-04 16:19:06,386 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.640,  Train_accy 87.64
2025-02-04 16:19:15,299 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.639,  Train_accy 87.62
2025-02-04 16:19:24,134 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.638,  Train_accy 87.88
2025-02-04 16:19:38,605 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.638,  Train_accy 88.22, Test_accy 72.94
2025-02-04 16:19:47,441 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.639,  Train_accy 87.58
2025-02-04 16:19:56,380 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.637,  Train_accy 88.20
2025-02-04 16:20:05,206 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.641,  Train_accy 88.10
2025-02-04 16:20:14,129 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.638,  Train_accy 87.72
2025-02-04 16:20:28,586 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.639,  Train_accy 87.94, Test_accy 73.00
2025-02-04 16:20:37,540 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.639,  Train_accy 87.68
2025-02-04 16:20:46,321 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.637,  Train_accy 87.88
2025-02-04 16:20:55,115 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.635,  Train_accy 87.92
2025-02-04 16:21:03,960 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.637,  Train_accy 87.80
2025-02-04 16:21:18,469 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.638,  Train_accy 87.62, Test_accy 73.16
2025-02-04 16:21:27,362 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.638,  Train_accy 87.54
2025-02-04 16:21:36,179 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.637,  Train_accy 88.44
2025-02-04 16:21:45,073 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.638,  Train_accy 87.86
2025-02-04 16:21:53,848 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.639,  Train_accy 87.94
2025-02-04 16:22:08,394 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.637,  Train_accy 87.96, Test_accy 73.25
2025-02-04 16:22:17,199 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.637,  Train_accy 88.26
2025-02-04 16:22:26,083 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.639,  Train_accy 88.08
2025-02-04 16:22:35,072 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.639,  Train_accy 87.78
2025-02-04 16:22:44,015 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.637,  Train_accy 87.07
2025-02-04 16:22:58,523 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.637,  Train_accy 87.96, Test_accy 73.19
2025-02-04 16:23:07,392 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.638,  Train_accy 87.88
2025-02-04 16:23:16,278 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.637,  Train_accy 87.94
2025-02-04 16:23:25,101 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.638,  Train_accy 87.94
2025-02-04 16:23:33,947 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.636,  Train_accy 88.00
2025-02-04 16:23:33,947 [der.py] => do not weight align student!
2025-02-04 16:23:39,342 [der.py] => darknet eval: 
2025-02-04 16:23:39,342 [der.py] => CNN top1 curve: 73.27
2025-02-04 16:23:39,342 [der.py] => CNN top5 curve: 96.13
2025-02-04 16:23:39,344 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 16:24:18,734 [der.py] => Exemplar size: 1050
2025-02-04 16:24:18,734 [trainer.py] => CNN: {'total': 79.22, '0': 83.89, '1': 62.22, '2': 81.11, '3': 62.22, '4': 82.22, '5': 41.67, '6': 63.89, '7': 51.11, '8': 40.0, '9': 53.33, '10': 88.89, '11': 95.0, '12': 72.22, '13': 65.0, '14': 64.44, '15': 95.0, '16': 99.44, '17': 96.11, '18': 95.0, '19': 96.67, '20': 96.67, '21': 90.56, '22': 91.67, '23': 79.44, '24': 79.44, '25': 83.33, '26': 83.89, '27': 86.67, '28': 73.89, '29': 82.78, '30': 85.56, '31': 86.11, '32': 96.67, '33': 80.0, 'old': 77.09, 'new': 84.56}
2025-02-04 16:24:18,734 [trainer.py] => NME: {'total': 76.67, '0': 86.11, '1': 61.67, '2': 76.67, '3': 66.67, '4': 77.78, '5': 37.78, '6': 55.0, '7': 54.44, '8': 45.56, '9': 60.0, '10': 88.33, '11': 94.44, '12': 70.0, '13': 56.67, '14': 56.11, '15': 87.22, '16': 95.56, '17': 90.0, '18': 91.11, '19': 86.67, '20': 93.89, '21': 85.0, '22': 81.67, '23': 65.0, '24': 61.11, '25': 85.0, '26': 93.89, '27': 87.78, '28': 70.56, '29': 82.22, '30': 87.22, '31': 90.56, '32': 97.22, '33': 73.89, 'old': 72.98, 'new': 85.89}
2025-02-04 16:24:18,734 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.22]
2025-02-04 16:24:18,734 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.94]
2025-02-04 16:24:18,734 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.67]
2025-02-04 16:24:18,734 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.14]

2025-02-04 16:24:18,735 [trainer.py] => All params: 42093638
2025-02-04 16:24:18,735 [trainer.py] => Trainable params: 21052026
2025-02-04 16:24:18,878 [der.py] => Learning on 35-45
2025-02-04 16:24:18,879 [der.py] => All params: 42096208
2025-02-04 16:24:18,879 [der.py] => Trainable params: 21054596
2025-02-04 16:24:18,973 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 16:24:18,974 [der.py] => per cls weights : [1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 0.33780916
 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916
 0.33780916 0.33780916 0.33780916]
2025-02-04 16:48:59,291 [der.py] => Task 3, Epoch 150/150 => Loss 0.087, Loss_clf 0.018, Loss_aux 0.068, Train_accy 99.92
2025-02-04 16:48:59,294 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 16:48:59,296 [der.py] => per cls weights : [1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 0.33780916
 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916
 0.33780916 0.33780916 0.33780916]
2025-02-04 16:49:15,541 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.998,  Train_accy 43.01, Test_accy 41.25
2025-02-04 16:49:24,871 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.681,  Train_accy 54.97
2025-02-04 16:49:34,259 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.580,  Train_accy 59.87
2025-02-04 16:49:43,625 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.499,  Train_accy 62.46
2025-02-04 16:49:53,558 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.495,  Train_accy 64.72
2025-02-04 16:50:09,830 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.500,  Train_accy 65.54, Test_accy 47.02
2025-02-04 16:50:19,236 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.424,  Train_accy 66.46
2025-02-04 16:50:28,647 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.381,  Train_accy 68.06
2025-02-04 16:50:38,070 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.373,  Train_accy 68.00
2025-02-04 16:50:47,457 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.389,  Train_accy 69.30
2025-02-04 16:51:03,791 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.355,  Train_accy 68.70, Test_accy 54.11
2025-02-04 16:51:13,122 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.359,  Train_accy 70.44
2025-02-04 16:51:22,539 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.372,  Train_accy 69.01
2025-02-04 16:51:31,871 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.346,  Train_accy 70.19
2025-02-04 16:51:41,314 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.330,  Train_accy 70.36
2025-02-04 16:51:57,438 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.297,  Train_accy 70.29, Test_accy 59.21
2025-02-04 16:52:06,845 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.356,  Train_accy 69.64
2025-02-04 16:52:16,374 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.335,  Train_accy 70.10
2025-02-04 16:52:25,870 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.292,  Train_accy 71.49
2025-02-04 16:52:35,234 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.320,  Train_accy 70.82
2025-02-04 16:52:51,483 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.317,  Train_accy 71.77, Test_accy 59.22
2025-02-04 16:53:00,799 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.355,  Train_accy 69.39
2025-02-04 16:53:10,239 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.296,  Train_accy 71.75
2025-02-04 16:53:19,617 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.287,  Train_accy 71.30
2025-02-04 16:53:29,036 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.300,  Train_accy 71.77
2025-02-04 16:53:45,584 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.291,  Train_accy 71.94, Test_accy 60.17
2025-02-04 16:53:54,976 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.260,  Train_accy 72.10
2025-02-04 16:54:04,302 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.278,  Train_accy 72.46
2025-02-04 16:54:13,681 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.288,  Train_accy 72.46
2025-02-04 16:54:23,087 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.270,  Train_accy 72.48
2025-02-04 16:54:39,493 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.247,  Train_accy 72.78, Test_accy 59.36
2025-02-04 16:54:48,819 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.276,  Train_accy 72.17
2025-02-04 16:54:58,216 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.250,  Train_accy 73.03
2025-02-04 16:55:07,780 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.251,  Train_accy 72.74
2025-02-04 16:55:17,156 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.289,  Train_accy 71.28
2025-02-04 16:55:33,430 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.257,  Train_accy 73.01, Test_accy 59.10
2025-02-04 16:55:42,761 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.262,  Train_accy 73.12
2025-02-04 16:55:52,151 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.286,  Train_accy 72.53
2025-02-04 16:56:01,516 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.267,  Train_accy 72.55
2025-02-04 16:56:10,929 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.256,  Train_accy 72.72
2025-02-04 16:56:27,083 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.258,  Train_accy 72.74, Test_accy 60.91
2025-02-04 16:56:36,469 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.246,  Train_accy 72.65
2025-02-04 16:56:45,790 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.263,  Train_accy 72.80
2025-02-04 16:56:55,183 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.273,  Train_accy 73.28
2025-02-04 16:57:04,529 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.258,  Train_accy 72.72
2025-02-04 16:57:20,718 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.260,  Train_accy 73.20, Test_accy 60.95
2025-02-04 16:57:30,031 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.248,  Train_accy 73.22
2025-02-04 16:57:39,416 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.237,  Train_accy 72.88
2025-02-04 16:57:48,766 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.253,  Train_accy 73.33
2025-02-04 16:57:58,224 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.241,  Train_accy 72.69
2025-02-04 16:58:14,491 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.239,  Train_accy 73.24, Test_accy 57.17
2025-02-04 16:58:23,821 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.233,  Train_accy 73.30
2025-02-04 16:58:33,251 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.249,  Train_accy 72.82
2025-02-04 16:58:42,702 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.256,  Train_accy 73.33
2025-02-04 16:58:52,218 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.228,  Train_accy 73.50
2025-02-04 16:59:08,452 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.230,  Train_accy 73.50, Test_accy 63.73
2025-02-04 16:59:17,882 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.242,  Train_accy 73.31
2025-02-04 16:59:27,263 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.236,  Train_accy 74.02
2025-02-04 16:59:36,736 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.220,  Train_accy 73.68
2025-02-04 16:59:46,062 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.224,  Train_accy 73.52
2025-02-04 17:00:02,578 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.232,  Train_accy 72.91, Test_accy 63.79
2025-02-04 17:00:11,946 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.218,  Train_accy 73.09
2025-02-04 17:00:21,428 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.219,  Train_accy 73.03
2025-02-04 17:00:30,784 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.235,  Train_accy 73.66
2025-02-04 17:00:40,249 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.222,  Train_accy 73.54
2025-02-04 17:00:56,460 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.225,  Train_accy 73.47, Test_accy 62.02
2025-02-04 17:01:05,863 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.242,  Train_accy 73.58
2025-02-04 17:01:15,262 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.218,  Train_accy 73.05
2025-02-04 17:01:24,747 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.214,  Train_accy 73.35
2025-02-04 17:01:34,191 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.230,  Train_accy 73.98
2025-02-04 17:01:50,565 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.206,  Train_accy 74.04, Test_accy 64.27
2025-02-04 17:01:59,861 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.222,  Train_accy 73.30
2025-02-04 17:02:09,238 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.218,  Train_accy 73.87
2025-02-04 17:02:18,560 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.197,  Train_accy 73.83
2025-02-04 17:02:27,908 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.224,  Train_accy 73.54
2025-02-04 17:02:44,305 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.218,  Train_accy 73.39, Test_accy 61.33
2025-02-04 17:02:53,656 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.212,  Train_accy 74.38
2025-02-04 17:03:02,984 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.214,  Train_accy 73.77
2025-02-04 17:03:12,416 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.244,  Train_accy 73.81
2025-02-04 17:03:21,740 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.230,  Train_accy 74.23
2025-02-04 17:03:37,868 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.212,  Train_accy 73.47, Test_accy 63.44
2025-02-04 17:03:47,214 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.188,  Train_accy 73.60
2025-02-04 17:03:56,629 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.213,  Train_accy 73.64
2025-02-04 17:04:05,933 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.202,  Train_accy 73.58
2025-02-04 17:04:15,249 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.196,  Train_accy 74.17
2025-02-04 17:04:31,568 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.215,  Train_accy 73.77, Test_accy 64.28
2025-02-04 17:04:40,883 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.216,  Train_accy 73.81
2025-02-04 17:04:50,370 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.207,  Train_accy 74.59
2025-02-04 17:04:59,705 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.193,  Train_accy 73.73
2025-02-04 17:05:09,138 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.204,  Train_accy 73.79
2025-02-04 17:05:25,265 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.234,  Train_accy 73.81, Test_accy 64.51
2025-02-04 17:05:34,674 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.188,  Train_accy 74.29
2025-02-04 17:05:43,993 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.201,  Train_accy 73.60
2025-02-04 17:05:53,414 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.204,  Train_accy 73.18
2025-02-04 17:06:02,761 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.208,  Train_accy 73.58
2025-02-04 17:06:19,012 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.199,  Train_accy 74.51, Test_accy 64.44
2025-02-04 17:06:28,392 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.186,  Train_accy 74.19
2025-02-04 17:06:37,852 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.205,  Train_accy 74.32
2025-02-04 17:06:47,138 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.207,  Train_accy 73.47
2025-02-04 17:06:56,567 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.204,  Train_accy 73.79
2025-02-04 17:07:12,790 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.201,  Train_accy 73.64, Test_accy 63.60
2025-02-04 17:07:22,231 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.210,  Train_accy 73.49
2025-02-04 17:07:31,570 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.206,  Train_accy 73.41
2025-02-04 17:07:41,025 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.211,  Train_accy 74.15
2025-02-04 17:07:50,531 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.207,  Train_accy 73.54
2025-02-04 17:08:06,815 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.201,  Train_accy 73.62, Test_accy 65.09
2025-02-04 17:08:16,191 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.200,  Train_accy 74.19
2025-02-04 17:08:25,582 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.189,  Train_accy 73.49
2025-02-04 17:08:34,962 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.202,  Train_accy 74.06
2025-02-04 17:08:44,342 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.200,  Train_accy 73.98
2025-02-04 17:09:01,017 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.197,  Train_accy 73.96, Test_accy 64.32
2025-02-04 17:09:10,487 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.197,  Train_accy 74.15
2025-02-04 17:09:19,878 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.192,  Train_accy 73.70
2025-02-04 17:09:29,190 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.190,  Train_accy 73.75
2025-02-04 17:09:38,601 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.191,  Train_accy 74.00
2025-02-04 17:09:54,891 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.187,  Train_accy 74.29, Test_accy 64.22
2025-02-04 17:10:04,376 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.192,  Train_accy 74.70
2025-02-04 17:10:13,816 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.208,  Train_accy 74.53
2025-02-04 17:10:23,263 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.198,  Train_accy 74.15
2025-02-04 17:10:32,581 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.189,  Train_accy 73.94
2025-02-04 17:10:48,815 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.205,  Train_accy 73.68, Test_accy 64.98
2025-02-04 17:10:58,156 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.195,  Train_accy 73.89
2025-02-04 17:11:07,642 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.183,  Train_accy 74.08
2025-02-04 17:11:17,021 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.188,  Train_accy 73.56
2025-02-04 17:11:26,494 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.209,  Train_accy 73.96
2025-02-04 17:11:42,813 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.198,  Train_accy 73.94, Test_accy 64.65
2025-02-04 17:11:52,488 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.198,  Train_accy 73.70
2025-02-04 17:12:01,887 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.184,  Train_accy 73.85
2025-02-04 17:12:11,390 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.193,  Train_accy 74.02
2025-02-04 17:12:20,787 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.187,  Train_accy 73.66
2025-02-04 17:12:20,788 [der.py] => do not weight align student!
2025-02-04 17:12:27,462 [der.py] => darknet eval: 
2025-02-04 17:12:27,463 [der.py] => CNN top1 curve: 63.49
2025-02-04 17:12:27,463 [der.py] => CNN top5 curve: 91.58
2025-02-04 17:12:27,465 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 17:13:15,072 [der.py] => Exemplar size: 1350
2025-02-04 17:13:15,073 [trainer.py] => CNN: {'total': 71.57, '0': 82.78, '1': 54.44, '2': 70.0, '3': 50.56, '4': 74.44, '5': 33.89, '6': 59.44, '7': 45.0, '8': 26.11, '9': 31.11, '10': 83.33, '11': 88.33, '12': 58.89, '13': 55.0, '14': 47.22, '15': 91.67, '16': 90.0, '17': 87.78, '18': 81.67, '19': 83.33, '20': 90.0, '21': 86.11, '22': 78.89, '23': 63.89, '24': 60.56, '25': 73.89, '26': 87.22, '27': 87.22, '28': 73.89, '29': 82.22, '30': 85.0, '31': 86.67, '32': 82.22, '33': 77.22, '34': 84.44, '35': 93.33, '36': 91.11, '37': 40.0, '38': 11.11, '39': 94.44, '40': 58.33, '41': 92.22, '42': 95.56, '43': 95.56, 'old': 71.27, 'new': 72.61}
2025-02-04 17:13:15,073 [trainer.py] => NME: {'total': 71.43, '0': 71.67, '1': 54.44, '2': 65.56, '3': 47.78, '4': 71.11, '5': 31.11, '6': 52.22, '7': 49.44, '8': 33.89, '9': 58.33, '10': 86.11, '11': 86.67, '12': 62.22, '13': 51.11, '14': 56.67, '15': 89.44, '16': 85.0, '17': 86.11, '18': 82.78, '19': 87.78, '20': 83.33, '21': 75.56, '22': 75.56, '23': 56.67, '24': 55.0, '25': 58.89, '26': 71.67, '27': 73.89, '28': 57.22, '29': 72.78, '30': 70.0, '31': 74.44, '32': 77.22, '33': 53.89, '34': 72.78, '35': 97.22, '36': 88.89, '37': 66.67, '38': 93.89, '39': 94.44, '40': 75.56, '41': 90.56, '42': 97.78, '43': 95.56, 'old': 66.81, 'new': 87.61}
2025-02-04 17:13:15,073 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.22, 71.57]
2025-02-04 17:13:15,073 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.94, 94.21]
2025-02-04 17:13:15,073 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.67, 71.43]
2025-02-04 17:13:15,073 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.14, 95.28]

2025-02-04 17:13:15,073 [trainer.py] => All params: 42096208
2025-02-04 17:13:15,074 [trainer.py] => Trainable params: 21054596
2025-02-04 17:13:15,212 [der.py] => Learning on 45-55
2025-02-04 17:13:15,213 [der.py] => All params: 42098778
2025-02-04 17:13:15,213 [der.py] => Trainable params: 21057166
2025-02-04 17:13:15,324 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 17:13:15,325 [der.py] => per cls weights : [1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 0.32657513 0.32657513 0.32657513
 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513
 0.32657513]
2025-02-04 17:39:43,034 [der.py] => Task 4, Epoch 150/150 => Loss 0.020, Loss_clf 0.013, Loss_aux 0.007, Train_accy 100.00
2025-02-04 17:39:43,037 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 17:39:43,038 [der.py] => per cls weights : [1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 0.32657513 0.32657513 0.32657513
 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513
 0.32657513]
2025-02-04 17:40:01,205 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.928,  Train_accy 27.39, Test_accy 55.96
2025-02-04 17:40:11,066 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.747,  Train_accy 39.06
2025-02-04 17:40:20,867 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.665,  Train_accy 47.77
2025-02-04 17:40:30,761 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.595,  Train_accy 54.74
2025-02-04 17:40:40,569 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.561,  Train_accy 59.59
2025-02-04 17:40:58,512 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.529,  Train_accy 63.80, Test_accy 60.48
2025-02-04 17:41:08,280 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.512,  Train_accy 65.37
2025-02-04 17:41:18,143 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.491,  Train_accy 68.02
2025-02-04 17:41:27,928 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.480,  Train_accy 68.83
2025-02-04 17:41:37,801 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.470,  Train_accy 69.71
2025-02-04 17:41:55,799 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.457,  Train_accy 72.11, Test_accy 62.44
2025-02-04 17:42:05,636 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.457,  Train_accy 72.23
2025-02-04 17:42:15,422 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.443,  Train_accy 73.05
2025-02-04 17:42:25,256 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.443,  Train_accy 73.50
2025-02-04 17:42:35,063 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.437,  Train_accy 73.98
2025-02-04 17:42:52,930 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.429,  Train_accy 74.81, Test_accy 63.30
2025-02-04 17:43:02,686 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.428,  Train_accy 74.81
2025-02-04 17:43:12,615 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.422,  Train_accy 75.14
2025-02-04 17:43:22,517 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.422,  Train_accy 75.60
2025-02-04 17:43:32,349 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.419,  Train_accy 76.45
2025-02-04 17:43:50,216 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.413,  Train_accy 76.79, Test_accy 63.13
2025-02-04 17:44:00,075 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.409,  Train_accy 76.34
2025-02-04 17:44:09,889 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.406,  Train_accy 76.90
2025-02-04 17:44:19,850 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.407,  Train_accy 78.22
2025-02-04 17:44:29,687 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.407,  Train_accy 77.91
2025-02-04 17:44:47,636 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.402,  Train_accy 77.60, Test_accy 63.94
2025-02-04 17:44:57,426 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.401,  Train_accy 78.14
2025-02-04 17:45:07,568 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.398,  Train_accy 78.18
2025-02-04 17:45:17,411 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.391,  Train_accy 78.90
2025-02-04 17:45:27,424 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.391,  Train_accy 78.92
2025-02-04 17:45:45,743 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.398,  Train_accy 78.52, Test_accy 63.99
2025-02-04 17:45:55,755 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.393,  Train_accy 79.03
2025-02-04 17:46:05,653 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.389,  Train_accy 79.51
2025-02-04 17:46:15,527 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.387,  Train_accy 79.46
2025-02-04 17:46:25,322 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.381,  Train_accy 80.09
2025-02-04 17:46:43,525 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.387,  Train_accy 78.97, Test_accy 64.15
2025-02-04 17:46:53,277 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.383,  Train_accy 79.62
2025-02-04 17:47:03,190 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.378,  Train_accy 79.84
2025-02-04 17:47:12,996 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.378,  Train_accy 80.31
2025-02-04 17:47:22,838 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.376,  Train_accy 80.34
2025-02-04 17:47:40,851 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.378,  Train_accy 80.13, Test_accy 65.35
2025-02-04 17:47:50,723 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.373,  Train_accy 80.59
2025-02-04 17:48:00,604 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.379,  Train_accy 80.85
2025-02-04 17:48:10,474 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.377,  Train_accy 80.05
2025-02-04 17:48:20,210 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.377,  Train_accy 80.38
2025-02-04 17:48:38,190 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.372,  Train_accy 80.83, Test_accy 65.10
2025-02-04 17:48:47,978 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.368,  Train_accy 81.12
2025-02-04 17:48:57,770 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.373,  Train_accy 80.70
2025-02-04 17:49:07,684 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.374,  Train_accy 81.41
2025-02-04 17:49:17,457 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.367,  Train_accy 81.44
2025-02-04 17:49:35,367 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.366,  Train_accy 81.05, Test_accy 64.72
2025-02-04 17:49:45,183 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.367,  Train_accy 81.05
2025-02-04 17:49:55,003 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.368,  Train_accy 81.03
2025-02-04 17:50:04,867 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.362,  Train_accy 81.64
2025-02-04 17:50:14,680 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.362,  Train_accy 81.69
2025-02-04 17:50:32,660 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.364,  Train_accy 81.44, Test_accy 64.46
2025-02-04 17:50:42,507 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.365,  Train_accy 81.53
2025-02-04 17:50:52,261 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.362,  Train_accy 81.21
2025-02-04 17:51:02,071 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.360,  Train_accy 81.86
2025-02-04 17:51:11,880 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.362,  Train_accy 81.53
2025-02-04 17:51:29,879 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.365,  Train_accy 81.26, Test_accy 65.22
2025-02-04 17:51:39,658 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.360,  Train_accy 81.33
2025-02-04 17:51:49,552 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.356,  Train_accy 82.31
2025-02-04 17:51:59,330 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.359,  Train_accy 82.04
2025-02-04 17:52:09,253 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.354,  Train_accy 82.05
2025-02-04 17:52:27,222 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.356,  Train_accy 81.95, Test_accy 65.36
2025-02-04 17:52:37,103 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.358,  Train_accy 82.25
2025-02-04 17:52:46,875 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.352,  Train_accy 82.36
2025-02-04 17:52:56,744 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.352,  Train_accy 82.41
2025-02-04 17:53:06,646 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.356,  Train_accy 81.86
2025-02-04 17:53:24,766 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.351,  Train_accy 82.25, Test_accy 65.95
2025-02-04 17:53:34,612 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.353,  Train_accy 82.70
2025-02-04 17:53:44,479 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.353,  Train_accy 81.60
2025-02-04 17:53:54,258 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.352,  Train_accy 82.63
2025-02-04 17:54:04,109 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.350,  Train_accy 82.59
2025-02-04 17:54:22,069 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.349,  Train_accy 82.50, Test_accy 65.94
2025-02-04 17:54:31,832 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.350,  Train_accy 82.18
2025-02-04 17:54:41,601 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.352,  Train_accy 82.79
2025-02-04 17:54:51,429 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.348,  Train_accy 82.97
2025-02-04 17:55:01,223 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.352,  Train_accy 82.09
2025-02-04 17:55:19,227 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.349,  Train_accy 82.25, Test_accy 65.53
2025-02-04 17:55:29,231 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.350,  Train_accy 82.61
2025-02-04 17:55:38,994 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.346,  Train_accy 82.36
2025-02-04 17:55:48,828 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.345,  Train_accy 82.77
2025-02-04 17:55:58,645 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.349,  Train_accy 83.14
2025-02-04 17:56:16,697 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.347,  Train_accy 82.97, Test_accy 65.76
2025-02-04 17:56:26,504 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.350,  Train_accy 82.13
2025-02-04 17:56:36,379 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.347,  Train_accy 82.65
2025-02-04 17:56:46,131 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.349,  Train_accy 82.49
2025-02-04 17:56:56,023 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.344,  Train_accy 82.79
2025-02-04 17:57:14,166 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.345,  Train_accy 83.26, Test_accy 65.90
2025-02-04 17:57:24,060 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.345,  Train_accy 82.74
2025-02-04 17:57:33,941 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.344,  Train_accy 82.50
2025-02-04 17:57:43,882 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.343,  Train_accy 83.15
2025-02-04 17:57:53,730 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.343,  Train_accy 82.88
2025-02-04 17:58:11,913 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.342,  Train_accy 83.60, Test_accy 66.02
2025-02-04 17:58:21,740 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.343,  Train_accy 83.26
2025-02-04 17:58:31,591 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.346,  Train_accy 83.28
2025-02-04 17:58:41,368 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.342,  Train_accy 82.88
2025-02-04 17:58:51,269 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.344,  Train_accy 84.09
2025-02-04 17:59:09,249 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.345,  Train_accy 83.10, Test_accy 66.38
2025-02-04 17:59:19,091 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.344,  Train_accy 83.62
2025-02-04 17:59:28,914 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.342,  Train_accy 83.86
2025-02-04 17:59:38,743 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.339,  Train_accy 82.65
2025-02-04 17:59:48,493 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.343,  Train_accy 82.92
2025-02-04 18:00:06,431 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.339,  Train_accy 83.28, Test_accy 65.94
2025-02-04 18:00:16,297 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.341,  Train_accy 83.46
2025-02-04 18:00:26,108 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.344,  Train_accy 83.50
2025-02-04 18:00:35,866 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.341,  Train_accy 83.03
2025-02-04 18:00:45,792 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.344,  Train_accy 83.33
2025-02-04 18:01:03,925 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.344,  Train_accy 83.32, Test_accy 66.15
2025-02-04 18:01:13,703 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.341,  Train_accy 83.33
2025-02-04 18:01:23,578 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.339,  Train_accy 83.80
2025-02-04 18:01:33,422 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.341,  Train_accy 83.35
2025-02-04 18:01:43,369 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.341,  Train_accy 83.57
2025-02-04 18:02:01,569 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.338,  Train_accy 83.78, Test_accy 66.28
2025-02-04 18:02:11,406 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.339,  Train_accy 82.90
2025-02-04 18:02:21,491 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.338,  Train_accy 83.19
2025-02-04 18:02:31,713 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.338,  Train_accy 83.64
2025-02-04 18:02:41,529 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.343,  Train_accy 83.51
2025-02-04 18:02:59,656 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.338,  Train_accy 83.08, Test_accy 66.04
2025-02-04 18:03:09,412 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.340,  Train_accy 83.03
2025-02-04 18:03:19,303 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.339,  Train_accy 83.50
2025-02-04 18:03:29,095 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.341,  Train_accy 83.80
2025-02-04 18:03:38,897 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.338,  Train_accy 83.24
2025-02-04 18:03:56,998 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.341,  Train_accy 83.12, Test_accy 65.87
2025-02-04 18:04:06,917 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.337,  Train_accy 83.28
2025-02-04 18:04:16,730 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.335,  Train_accy 83.57
2025-02-04 18:04:26,684 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.342,  Train_accy 83.14
2025-02-04 18:04:36,570 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.339,  Train_accy 83.50
2025-02-04 18:04:36,571 [der.py] => do not weight align student!
2025-02-04 18:04:44,563 [der.py] => darknet eval: 
2025-02-04 18:04:44,563 [der.py] => CNN top1 curve: 65.89
2025-02-04 18:04:44,564 [der.py] => CNN top5 curve: 91.12
2025-02-04 18:04:44,565 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 18:05:40,717 [der.py] => Exemplar size: 1650
2025-02-04 18:05:40,718 [trainer.py] => CNN: {'total': 69.9, '0': 63.89, '1': 56.11, '2': 53.89, '3': 28.33, '4': 65.56, '5': 33.33, '6': 52.22, '7': 45.0, '8': 36.67, '9': 48.89, '10': 80.0, '11': 75.56, '12': 52.78, '13': 50.0, '14': 56.67, '15': 78.33, '16': 79.44, '17': 83.33, '18': 66.67, '19': 83.33, '20': 82.22, '21': 73.89, '22': 79.44, '23': 55.0, '24': 63.33, '25': 61.11, '26': 76.11, '27': 73.33, '28': 42.22, '29': 64.44, '30': 61.11, '31': 75.0, '32': 78.89, '33': 49.44, '34': 53.33, '35': 96.11, '36': 88.89, '37': 66.11, '38': 91.67, '39': 92.22, '40': 77.22, '41': 95.0, '42': 92.78, '43': 97.22, '44': 72.78, '45': 86.67, '46': 85.0, '47': 77.22, '48': 85.56, '49': 72.22, '50': 72.78, '51': 82.22, '52': 77.22, '53': 72.78, 'old': 67.75, 'new': 79.56}
2025-02-04 18:05:40,718 [trainer.py] => NME: {'total': 64.16, '0': 58.33, '1': 45.0, '2': 54.44, '3': 31.11, '4': 63.33, '5': 38.89, '6': 49.44, '7': 53.33, '8': 30.0, '9': 52.78, '10': 80.0, '11': 79.44, '12': 51.67, '13': 45.56, '14': 56.11, '15': 75.0, '16': 80.0, '17': 77.22, '18': 65.56, '19': 76.67, '20': 74.44, '21': 70.56, '22': 68.33, '23': 48.33, '24': 52.22, '25': 52.22, '26': 63.89, '27': 53.33, '28': 32.78, '29': 44.44, '30': 46.11, '31': 65.0, '32': 69.44, '33': 32.78, '34': 57.22, '35': 85.56, '36': 76.67, '37': 40.56, '38': 91.67, '39': 88.33, '40': 45.0, '41': 92.22, '42': 85.56, '43': 96.11, '44': 47.22, '45': 88.33, '46': 87.22, '47': 83.89, '48': 82.78, '49': 72.22, '50': 65.56, '51': 77.78, '52': 75.56, '53': 73.89, 'old': 60.98, 'new': 78.5}
2025-02-04 18:05:40,718 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.22, 71.57, 69.9]
2025-02-04 18:05:40,718 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.94, 94.21, 92.34]
2025-02-04 18:05:40,718 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.67, 71.43, 64.16]
2025-02-04 18:05:40,718 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.14, 95.28, 91.7]

2025-02-04 18:29:19,882 [trainer.py] => 实验名称:kd对比实验
2025-02-04 18:29:19,883 [trainer.py] => config: ./exps/der.json
2025-02-04 18:29:19,883 [trainer.py] => experiment_name: 实验名称:kd对比实验
2025-02-04 18:29:19,883 [trainer.py] => prefix: reproduce
2025-02-04 18:29:19,883 [trainer.py] => dataset: xrfdataset
2025-02-04 18:29:19,883 [trainer.py] => memory_size: 1650
2025-02-04 18:29:19,883 [trainer.py] => memory_per_class: 30
2025-02-04 18:29:19,883 [trainer.py] => fixed_memory: True
2025-02-04 18:29:19,883 [trainer.py] => shuffle: True
2025-02-04 18:29:19,883 [trainer.py] => init_cls: 15
2025-02-04 18:29:19,883 [trainer.py] => increment: 10
2025-02-04 18:29:19,883 [trainer.py] => model_name: der
2025-02-04 18:29:19,883 [trainer.py] => compression_epochs: 130
2025-02-04 18:29:19,884 [trainer.py] => compression_lr: 0.1
2025-02-04 18:29:19,884 [trainer.py] => is_student_wa: False
2025-02-04 18:29:19,884 [trainer.py] => wa_value: 1
2025-02-04 18:29:19,884 [trainer.py] => T: 2
2025-02-04 18:29:19,884 [trainer.py] => convnet_type: unet
2025-02-04 18:29:19,884 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-04 18:29:19,884 [trainer.py] => seed: 1993
2025-02-04 18:29:19,896 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:29:19,901 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:29:19,902 [trainer.py] => All params: 0
2025-02-04 18:29:19,902 [trainer.py] => Trainable params: 0
2025-02-04 18:29:20,066 [der.py] => Learning on 0-15
2025-02-04 18:29:20,066 [der.py] => All params: 21045611
2025-02-04 18:29:20,067 [der.py] => Trainable params: 21045611
2025-02-04 18:30:58,734 [trainer.py] => 实验名称:BKD*0.3对比实验
2025-02-04 18:30:58,735 [trainer.py] => config: ./exps/der.json
2025-02-04 18:30:58,735 [trainer.py] => experiment_name: 实验名称:BKD*0.3对比实验
2025-02-04 18:30:58,735 [trainer.py] => prefix: reproduce
2025-02-04 18:30:58,735 [trainer.py] => dataset: xrfdataset
2025-02-04 18:30:58,735 [trainer.py] => memory_size: 1650
2025-02-04 18:30:58,735 [trainer.py] => memory_per_class: 30
2025-02-04 18:30:58,735 [trainer.py] => fixed_memory: True
2025-02-04 18:30:58,735 [trainer.py] => shuffle: True
2025-02-04 18:30:58,735 [trainer.py] => init_cls: 15
2025-02-04 18:30:58,735 [trainer.py] => increment: 10
2025-02-04 18:30:58,735 [trainer.py] => model_name: der
2025-02-04 18:30:58,735 [trainer.py] => compression_epochs: 130
2025-02-04 18:30:58,735 [trainer.py] => compression_lr: 0.1
2025-02-04 18:30:58,735 [trainer.py] => is_student_wa: False
2025-02-04 18:30:58,735 [trainer.py] => wa_value: 1
2025-02-04 18:30:58,735 [trainer.py] => T: 2
2025-02-04 18:30:58,735 [trainer.py] => convnet_type: unet
2025-02-04 18:30:58,735 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-04 18:30:58,735 [trainer.py] => seed: 1993
2025-02-04 18:30:58,747 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:30:58,753 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:30:58,754 [trainer.py] => All params: 0
2025-02-04 18:30:58,754 [trainer.py] => Trainable params: 0
2025-02-04 18:30:58,911 [der.py] => Learning on 0-15
2025-02-04 18:30:58,911 [der.py] => All params: 21045611
2025-02-04 18:30:58,911 [der.py] => Trainable params: 21045611
2025-02-04 18:49:53,608 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-04 18:49:53,609 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 18:50:19,071 [der.py] => Exemplar size: 450
2025-02-04 18:50:19,071 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-04 18:50:19,071 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-04 18:50:19,072 [trainer.py] => CNN top1 curve: [89.44]
2025-02-04 18:50:19,072 [trainer.py] => CNN top5 curve: [98.93]
2025-02-04 18:50:19,072 [trainer.py] => NME top1 curve: [88.22]
2025-02-04 18:50:19,072 [trainer.py] => NME top5 curve: [98.81]

2025-02-04 18:50:19,072 [trainer.py] => All params: 21045611
2025-02-04 18:50:19,073 [trainer.py] => Trainable params: 21045611
2025-02-04 18:50:19,232 [der.py] => Learning on 15-25
2025-02-04 18:50:19,233 [der.py] => All params: 42091068
2025-02-04 18:50:19,233 [der.py] => Trainable params: 21049456
2025-02-04 18:50:19,305 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 18:50:19,305 [der.py] => per cls weights : [1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 0.39805845 0.39805845 0.39805845
 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845
 0.39805845]
2025-02-04 18:54:31,293 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-04 18:54:31,294 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 18:54:59,117 [der.py] => Exemplar size: 450
2025-02-04 18:54:59,118 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-04 18:54:59,118 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-04 18:54:59,118 [trainer.py] => CNN top1 curve: [89.44]
2025-02-04 18:54:59,118 [trainer.py] => CNN top5 curve: [98.93]
2025-02-04 18:54:59,118 [trainer.py] => NME top1 curve: [88.22]
2025-02-04 18:54:59,118 [trainer.py] => NME top5 curve: [98.81]

2025-02-04 18:54:59,118 [trainer.py] => All params: 21045611
2025-02-04 18:54:59,118 [trainer.py] => Trainable params: 21045611
2025-02-04 18:54:59,276 [der.py] => Learning on 15-25
2025-02-04 18:54:59,276 [der.py] => All params: 42091068
2025-02-04 18:54:59,277 [der.py] => Trainable params: 21049456
2025-02-04 18:54:59,344 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 18:54:59,344 [der.py] => per cls weights : [1.35405306 1.35405306 1.35405306 1.35405306 1.35405306 1.35405306
 1.35405306 1.35405306 1.35405306 1.35405306 1.35405306 1.35405306
 1.35405306 1.35405306 1.35405306 0.46892042 0.46892042 0.46892042
 0.46892042 0.46892042 0.46892042 0.46892042 0.46892042 0.46892042
 0.46892042]
2025-02-04 18:55:35,413 [trainer.py] => 实验名称:BKD*0.3对比实验
2025-02-04 18:55:35,414 [trainer.py] => config: ./exps/der.json
2025-02-04 18:55:35,414 [trainer.py] => experiment_name: 实验名称:BKD*0.3对比实验
2025-02-04 18:55:35,414 [trainer.py] => prefix: reproduce
2025-02-04 18:55:35,414 [trainer.py] => dataset: xrfdataset
2025-02-04 18:55:35,414 [trainer.py] => memory_size: 1650
2025-02-04 18:55:35,414 [trainer.py] => memory_per_class: 0
2025-02-04 18:55:35,414 [trainer.py] => fixed_memory: True
2025-02-04 18:55:35,414 [trainer.py] => shuffle: True
2025-02-04 18:55:35,414 [trainer.py] => init_cls: 15
2025-02-04 18:55:35,414 [trainer.py] => increment: 10
2025-02-04 18:55:35,414 [trainer.py] => model_name: der
2025-02-04 18:55:35,414 [trainer.py] => compression_epochs: 1
2025-02-04 18:55:35,414 [trainer.py] => compression_lr: 0.1
2025-02-04 18:55:35,414 [trainer.py] => is_student_wa: False
2025-02-04 18:55:35,414 [trainer.py] => wa_value: 1
2025-02-04 18:55:35,414 [trainer.py] => T: 2
2025-02-04 18:55:35,414 [trainer.py] => convnet_type: unet
2025-02-04 18:55:35,414 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-04 18:55:35,414 [trainer.py] => seed: 1993
2025-02-04 18:55:35,427 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:55:35,432 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:55:35,433 [trainer.py] => All params: 0
2025-02-04 18:55:35,434 [trainer.py] => Trainable params: 0
2025-02-04 18:55:35,598 [der.py] => Learning on 0-15
2025-02-04 18:55:35,599 [der.py] => All params: 21045611
2025-02-04 18:55:35,599 [der.py] => Trainable params: 21045611
2025-02-04 18:56:01,177 [der.py] => Task 0, Epoch 1/1 => Loss 2.524, Train_accy 14.41, Test_accy 15.48
2025-02-04 18:56:01,179 [base.py] => Constructing exemplars for new classes...(0 per classes)
2025-02-04 18:56:53,446 [trainer.py] => 实验名称:no_examplar对比实验
2025-02-04 18:56:53,446 [trainer.py] => config: ./exps/der.json
2025-02-04 18:56:53,447 [trainer.py] => experiment_name: 实验名称:no_examplar对比实验
2025-02-04 18:56:53,447 [trainer.py] => prefix: reproduce
2025-02-04 18:56:53,447 [trainer.py] => dataset: xrfdataset
2025-02-04 18:56:53,447 [trainer.py] => memory_size: 1650
2025-02-04 18:56:53,447 [trainer.py] => memory_per_class: 0
2025-02-04 18:56:53,447 [trainer.py] => fixed_memory: True
2025-02-04 18:56:53,447 [trainer.py] => shuffle: True
2025-02-04 18:56:53,447 [trainer.py] => init_cls: 15
2025-02-04 18:56:53,447 [trainer.py] => increment: 10
2025-02-04 18:56:53,447 [trainer.py] => model_name: der
2025-02-04 18:56:53,447 [trainer.py] => compression_epochs: 1
2025-02-04 18:56:53,447 [trainer.py] => compression_lr: 0.1
2025-02-04 18:56:53,447 [trainer.py] => is_student_wa: False
2025-02-04 18:56:53,447 [trainer.py] => wa_value: 1
2025-02-04 18:56:53,447 [trainer.py] => T: 2
2025-02-04 18:56:53,447 [trainer.py] => convnet_type: unet
2025-02-04 18:56:53,447 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-04 18:56:53,447 [trainer.py] => seed: 1993
2025-02-04 18:56:53,459 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:56:53,464 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:56:53,465 [trainer.py] => All params: 0
2025-02-04 18:56:53,465 [trainer.py] => Trainable params: 0
2025-02-04 18:56:53,625 [der.py] => Learning on 0-15
2025-02-04 18:56:53,626 [der.py] => All params: 21045611
2025-02-04 18:56:53,626 [der.py] => Trainable params: 21045611
2025-02-04 18:57:13,884 [trainer.py] => 实验名称:no_examplar对比实验
2025-02-04 18:57:13,884 [trainer.py] => config: ./exps/der.json
2025-02-04 18:57:13,885 [trainer.py] => experiment_name: 实验名称:no_examplar对比实验
2025-02-04 18:57:13,885 [trainer.py] => prefix: reproduce
2025-02-04 18:57:13,885 [trainer.py] => dataset: xrfdataset
2025-02-04 18:57:13,885 [trainer.py] => memory_size: 1650
2025-02-04 18:57:13,885 [trainer.py] => memory_per_class: 0
2025-02-04 18:57:13,885 [trainer.py] => fixed_memory: True
2025-02-04 18:57:13,885 [trainer.py] => shuffle: True
2025-02-04 18:57:13,885 [trainer.py] => init_cls: 15
2025-02-04 18:57:13,885 [trainer.py] => increment: 10
2025-02-04 18:57:13,885 [trainer.py] => model_name: der
2025-02-04 18:57:13,885 [trainer.py] => compression_epochs: 1
2025-02-04 18:57:13,885 [trainer.py] => compression_lr: 0.1
2025-02-04 18:57:13,885 [trainer.py] => is_student_wa: False
2025-02-04 18:57:13,885 [trainer.py] => wa_value: 1
2025-02-04 18:57:13,885 [trainer.py] => T: 2
2025-02-04 18:57:13,885 [trainer.py] => convnet_type: unet
2025-02-04 18:57:13,885 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-04 18:57:13,885 [trainer.py] => seed: 1993
2025-02-04 18:57:13,897 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:57:13,903 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:57:13,905 [trainer.py] => All params: 0
2025-02-04 18:57:13,905 [trainer.py] => Trainable params: 0
2025-02-04 18:57:14,071 [der.py] => Learning on 0-15
2025-02-04 18:57:14,072 [der.py] => All params: 21045611
2025-02-04 18:57:14,072 [der.py] => Trainable params: 21045611
2025-02-04 18:57:41,491 [der.py] => Task 0, Epoch 1/1 => Loss 2.524, Train_accy 14.41, Test_accy 15.48
2025-02-04 18:57:45,475 [der.py] => Exemplar size: 0
2025-02-04 18:57:45,475 [trainer.py] => No NME accuracy.
2025-02-04 18:57:45,476 [trainer.py] => CNN: {'total': 15.48, '0': 56.11, '1': 0.0, '2': 0.56, '3': 0.0, '4': 0.0, '5': 49.44, '6': 0.0, '7': 0.0, '8': 2.22, '9': 8.89, '10': 40.0, '11': 43.33, '12': 1.11, '13': 0.56, 'old': 0, 'new': 15.48}
2025-02-04 18:57:45,476 [trainer.py] => CNN top1 curve: [15.48]
2025-02-04 18:57:45,476 [trainer.py] => CNN top5 curve: [57.56]

2025-02-04 18:57:45,477 [trainer.py] => All params: 21045611
2025-02-04 18:57:45,477 [trainer.py] => Trainable params: 21045611
2025-02-04 18:57:45,648 [der.py] => Learning on 15-25
2025-02-04 18:57:45,649 [der.py] => All params: 42091068
2025-02-04 18:57:45,649 [der.py] => Trainable params: 21049456
2025-02-04 18:57:45,799 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 18:57:45,800 [der.py] => per cls weights : [ 1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914  -0.37398709 -0.37398709 -0.37398709
 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709
 -0.37398709]
2025-02-04 18:58:05,109 [der.py] => Task 1, Epoch 1/1 => Loss 4.847, Loss_clf 2.668, Loss_aux 2.179, Train_accy 18.62, Test_accy 7.89
2025-02-04 18:58:05,121 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 18:58:05,121 [der.py] => per cls weights : [ 1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914  -0.37398709 -0.37398709 -0.37398709
 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709
 -0.37398709]
2025-02-04 18:58:24,974 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 1.975,  Train_accy 13.48, Test_accy 6.22
2025-02-04 18:58:24,975 [der.py] => do not weight align student!
2025-02-04 18:58:30,665 [der.py] => darknet eval: 
2025-02-04 18:58:30,665 [der.py] => CNN top1 curve: 6.22
2025-02-04 18:58:30,665 [der.py] => CNN top5 curve: 25.53
2025-02-04 18:58:38,058 [der.py] => Exemplar size: 0
2025-02-04 18:58:38,058 [trainer.py] => No NME accuracy.
2025-02-04 18:58:38,058 [trainer.py] => CNN: {'total': 7.91, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 7.22, '16': 0.56, '17': 17.22, '18': 15.0, '19': 1.67, '20': 20.56, '21': 0.0, '22': 40.56, '23': 48.89, 'old': 0.0, 'new': 19.78}
2025-02-04 18:58:38,059 [trainer.py] => CNN top1 curve: [15.48, 7.91]
2025-02-04 18:58:38,059 [trainer.py] => CNN top5 curve: [57.56, 28.2]

2025-02-04 18:58:38,060 [trainer.py] => All params: 42091068
2025-02-04 18:58:38,061 [trainer.py] => Trainable params: 21049456
2025-02-04 18:58:38,226 [der.py] => Learning on 25-35
2025-02-04 18:58:38,227 [der.py] => All params: 42093638
2025-02-04 18:58:38,227 [der.py] => Trainable params: 21052026
2025-02-04 18:58:38,323 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 18:58:38,324 [der.py] => per cls weights : [ 1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498 -0.29641245 -0.29641245 -0.29641245 -0.29641245 -0.29641245
 -0.29641245 -0.29641245 -0.29641245 -0.29641245 -0.29641245]
2025-02-04 18:59:20,448 [trainer.py] => 实验名称:no_examplar_kd对比实验
2025-02-04 18:59:20,449 [trainer.py] => config: ./exps/der.json
2025-02-04 18:59:20,449 [trainer.py] => experiment_name: 实验名称:no_examplar_kd对比实验
2025-02-04 18:59:20,449 [trainer.py] => prefix: reproduce
2025-02-04 18:59:20,449 [trainer.py] => dataset: xrfdataset
2025-02-04 18:59:20,449 [trainer.py] => memory_size: 1650
2025-02-04 18:59:20,449 [trainer.py] => memory_per_class: 0
2025-02-04 18:59:20,449 [trainer.py] => fixed_memory: True
2025-02-04 18:59:20,449 [trainer.py] => shuffle: True
2025-02-04 18:59:20,449 [trainer.py] => init_cls: 15
2025-02-04 18:59:20,449 [trainer.py] => increment: 10
2025-02-04 18:59:20,449 [trainer.py] => model_name: der
2025-02-04 18:59:20,449 [trainer.py] => compression_epochs: 1
2025-02-04 18:59:20,449 [trainer.py] => compression_lr: 0.1
2025-02-04 18:59:20,450 [trainer.py] => is_student_wa: False
2025-02-04 18:59:20,450 [trainer.py] => wa_value: 1
2025-02-04 18:59:20,450 [trainer.py] => T: 2
2025-02-04 18:59:20,450 [trainer.py] => convnet_type: unet
2025-02-04 18:59:20,450 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-04 18:59:20,450 [trainer.py] => seed: 1993
2025-02-04 18:59:20,462 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:59:20,467 [data.py] => 加载完毕XRF原始数据集
2025-02-04 18:59:20,468 [trainer.py] => All params: 0
2025-02-04 18:59:20,468 [trainer.py] => Trainable params: 0
2025-02-04 18:59:20,646 [der.py] => Learning on 0-15
2025-02-04 18:59:20,647 [der.py] => All params: 21045611
2025-02-04 18:59:20,647 [der.py] => Trainable params: 21045611
2025-02-04 18:59:46,530 [der.py] => Task 0, Epoch 1/1 => Loss 2.524, Train_accy 14.41, Test_accy 15.48
2025-02-04 18:59:50,493 [der.py] => Exemplar size: 0
2025-02-04 18:59:50,493 [trainer.py] => No NME accuracy.
2025-02-04 18:59:50,494 [trainer.py] => CNN: {'total': 15.48, '0': 56.11, '1': 0.0, '2': 0.56, '3': 0.0, '4': 0.0, '5': 49.44, '6': 0.0, '7': 0.0, '8': 2.22, '9': 8.89, '10': 40.0, '11': 43.33, '12': 1.11, '13': 0.56, 'old': 0, 'new': 15.48}
2025-02-04 18:59:50,494 [trainer.py] => CNN top1 curve: [15.48]
2025-02-04 18:59:50,494 [trainer.py] => CNN top5 curve: [57.56]

2025-02-04 18:59:50,495 [trainer.py] => All params: 21045611
2025-02-04 18:59:50,495 [trainer.py] => Trainable params: 21045611
2025-02-04 18:59:50,667 [der.py] => Learning on 15-25
2025-02-04 18:59:50,668 [der.py] => All params: 42091068
2025-02-04 18:59:50,668 [der.py] => Trainable params: 21049456
2025-02-04 18:59:50,749 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 18:59:50,749 [der.py] => per cls weights : [ 1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914  -0.37398709 -0.37398709 -0.37398709
 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709
 -0.37398709]
2025-02-04 19:00:10,219 [der.py] => Task 1, Epoch 1/1 => Loss 4.847, Loss_clf 2.668, Loss_aux 2.179, Train_accy 18.62, Test_accy 7.89
2025-02-04 19:00:10,232 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:00:10,233 [der.py] => per cls weights : [ 1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914   1.9159914   1.9159914   1.9159914
  1.9159914   1.9159914   1.9159914  -0.37398709 -0.37398709 -0.37398709
 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709 -0.37398709
 -0.37398709]
2025-02-04 19:00:31,528 [der.py] => SNet: Task 1, Epoch 1/1 => Loss 2.117,  Train_accy 14.07, Test_accy 6.09
2025-02-04 19:00:31,529 [der.py] => do not weight align student!
2025-02-04 19:00:37,231 [der.py] => darknet eval: 
2025-02-04 19:00:37,231 [der.py] => CNN top1 curve: 6.09
2025-02-04 19:00:37,232 [der.py] => CNN top5 curve: 25.44
2025-02-04 19:00:45,254 [der.py] => Exemplar size: 0
2025-02-04 19:00:45,254 [trainer.py] => No NME accuracy.
2025-02-04 19:00:45,254 [trainer.py] => CNN: {'total': 7.91, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 7.22, '16': 0.56, '17': 17.22, '18': 15.0, '19': 1.67, '20': 20.56, '21': 0.0, '22': 40.56, '23': 48.89, 'old': 0.0, 'new': 19.78}
2025-02-04 19:00:45,255 [trainer.py] => CNN top1 curve: [15.48, 7.91]
2025-02-04 19:00:45,255 [trainer.py] => CNN top5 curve: [57.56, 28.2]

2025-02-04 19:00:45,256 [trainer.py] => All params: 42091068
2025-02-04 19:00:45,257 [trainer.py] => Trainable params: 21049456
2025-02-04 19:00:45,422 [der.py] => Learning on 25-35
2025-02-04 19:00:45,423 [der.py] => All params: 42093638
2025-02-04 19:00:45,424 [der.py] => Trainable params: 21052026
2025-02-04 19:00:45,573 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:00:45,574 [der.py] => per cls weights : [ 1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498 -0.29641245 -0.29641245 -0.29641245 -0.29641245 -0.29641245
 -0.29641245 -0.29641245 -0.29641245 -0.29641245 -0.29641245]
2025-02-04 19:01:07,199 [der.py] => Task 2, Epoch 1/1 => Loss 4.787, Loss_clf 2.688, Loss_aux 2.100, Train_accy 20.86, Test_accy 6.75
2025-02-04 19:01:07,202 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:01:07,203 [der.py] => per cls weights : [ 1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498  1.51856498
  1.51856498 -0.29641245 -0.29641245 -0.29641245 -0.29641245 -0.29641245
 -0.29641245 -0.29641245 -0.29641245 -0.29641245 -0.29641245]
2025-02-04 19:01:29,858 [der.py] => SNet: Task 2, Epoch 1/1 => Loss 2.201,  Train_accy 19.57, Test_accy 5.79
2025-02-04 19:01:29,858 [der.py] => do not weight align student!
2025-02-04 19:01:37,344 [der.py] => darknet eval: 
2025-02-04 19:01:37,344 [der.py] => CNN top1 curve: 5.79
2025-02-04 19:01:37,344 [der.py] => CNN top5 curve: 19.95
2025-02-04 19:01:47,197 [der.py] => Exemplar size: 0
2025-02-04 19:01:47,198 [trainer.py] => No NME accuracy.
2025-02-04 19:01:47,198 [trainer.py] => CNN: {'total': 6.75, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 48.33, '26': 8.33, '27': 67.22, '28': 5.0, '29': 0.56, '30': 11.67, '31': 2.78, '32': 61.11, '33': 15.56, 'old': 0.0, 'new': 23.61}
2025-02-04 19:01:47,198 [trainer.py] => CNN top1 curve: [15.48, 7.91, 6.75]
2025-02-04 19:01:47,198 [trainer.py] => CNN top5 curve: [57.56, 28.2, 21.24]

2025-02-04 19:01:47,199 [trainer.py] => All params: 42093638
2025-02-04 19:01:47,200 [trainer.py] => Trainable params: 21052026
2025-02-04 19:01:47,377 [der.py] => Learning on 35-45
2025-02-04 19:01:47,378 [der.py] => All params: 42096208
2025-02-04 19:01:47,378 [der.py] => Trainable params: 21054596
2025-02-04 19:01:47,614 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:01:47,615 [der.py] => per cls weights : [ 1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267 -0.26578435
 -0.26578435 -0.26578435 -0.26578435 -0.26578435 -0.26578435 -0.26578435
 -0.26578435 -0.26578435 -0.26578435]
2025-02-04 19:02:11,673 [der.py] => Task 3, Epoch 1/1 => Loss 4.854, Loss_clf 2.775, Loss_aux 2.079, Train_accy 19.00, Test_accy 5.98
2025-02-04 19:02:11,676 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:02:11,676 [der.py] => per cls weights : [ 1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267
  1.36165267  1.36165267  1.36165267  1.36165267  1.36165267 -0.26578435
 -0.26578435 -0.26578435 -0.26578435 -0.26578435 -0.26578435 -0.26578435
 -0.26578435 -0.26578435 -0.26578435]
2025-02-04 19:02:36,600 [der.py] => SNet: Task 3, Epoch 1/1 => Loss 2.190,  Train_accy 21.33, Test_accy 5.22
2025-02-04 19:02:36,601 [der.py] => do not weight align student!
2025-02-04 19:02:45,579 [der.py] => darknet eval: 
2025-02-04 19:02:45,579 [der.py] => CNN top1 curve: 5.22
2025-02-04 19:02:45,580 [der.py] => CNN top5 curve: 17.21
2025-02-04 19:02:58,208 [der.py] => Exemplar size: 0
2025-02-04 19:02:58,209 [trainer.py] => No NME accuracy.
2025-02-04 19:02:58,209 [trainer.py] => CNN: {'total': 6.0, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 3.33, '36': 23.33, '37': 26.11, '38': 63.89, '39': 46.67, '40': 26.11, '41': 21.11, '42': 8.89, '43': 15.0, 'old': 0.0, 'new': 27.0}
2025-02-04 19:02:58,209 [trainer.py] => CNN top1 curve: [15.48, 7.91, 6.75, 6.0]
2025-02-04 19:02:58,209 [trainer.py] => CNN top5 curve: [57.56, 28.2, 21.24, 17.96]

2025-02-04 19:02:58,210 [trainer.py] => All params: 42096208
2025-02-04 19:02:58,211 [trainer.py] => Trainable params: 21054596
2025-02-04 19:02:58,365 [der.py] => Learning on 45-55
2025-02-04 19:02:58,366 [der.py] => All params: 42098778
2025-02-04 19:02:58,366 [der.py] => Trainable params: 21057166
2025-02-04 19:02:58,583 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:02:58,584 [der.py] => per cls weights : [ 1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133 -0.24938597 -0.24938597 -0.24938597
 -0.24938597 -0.24938597 -0.24938597 -0.24938597 -0.24938597 -0.24938597
 -0.24938597]
2025-02-04 19:03:26,614 [der.py] => Task 4, Epoch 1/1 => Loss 5.540, Loss_clf 3.175, Loss_aux 2.365, Train_accy 11.93, Test_accy 3.24
2025-02-04 19:03:26,616 [der.py] => cls_num_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:03:26,617 [der.py] => per cls weights : [ 1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133  1.27764133
  1.27764133  1.27764133  1.27764133 -0.24938597 -0.24938597 -0.24938597
 -0.24938597 -0.24938597 -0.24938597 -0.24938597 -0.24938597 -0.24938597
 -0.24938597]
2025-02-04 19:04:07,727 [trainer.py] => 实验名称:no_examplar_kd对比实验
2025-02-04 19:04:07,727 [trainer.py] => config: ./exps/der.json
2025-02-04 19:04:07,727 [trainer.py] => experiment_name: 实验名称:no_examplar_kd对比实验
2025-02-04 19:04:07,727 [trainer.py] => prefix: reproduce
2025-02-04 19:04:07,727 [trainer.py] => dataset: xrfdataset
2025-02-04 19:04:07,727 [trainer.py] => memory_size: 1650
2025-02-04 19:04:07,727 [trainer.py] => memory_per_class: 0
2025-02-04 19:04:07,727 [trainer.py] => fixed_memory: True
2025-02-04 19:04:07,727 [trainer.py] => shuffle: True
2025-02-04 19:04:07,727 [trainer.py] => init_cls: 15
2025-02-04 19:04:07,728 [trainer.py] => increment: 10
2025-02-04 19:04:07,728 [trainer.py] => model_name: der
2025-02-04 19:04:07,728 [trainer.py] => compression_epochs: 130
2025-02-04 19:04:07,728 [trainer.py] => compression_lr: 0.1
2025-02-04 19:04:07,728 [trainer.py] => is_student_wa: False
2025-02-04 19:04:07,728 [trainer.py] => wa_value: 1
2025-02-04 19:04:07,728 [trainer.py] => T: 2
2025-02-04 19:04:07,728 [trainer.py] => convnet_type: unet
2025-02-04 19:04:07,728 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-04 19:04:07,728 [trainer.py] => seed: 1993
2025-02-04 19:04:07,740 [data.py] => 加载完毕XRF原始数据集
2025-02-04 19:04:07,745 [data.py] => 加载完毕XRF原始数据集
2025-02-04 19:04:07,747 [trainer.py] => All params: 0
2025-02-04 19:04:07,747 [trainer.py] => Trainable params: 0
2025-02-04 19:04:07,913 [der.py] => Learning on 0-15
2025-02-04 19:04:07,913 [der.py] => All params: 21045611
2025-02-04 19:04:07,913 [der.py] => Trainable params: 21045611
2025-02-04 19:11:47,709 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-02-04 19:11:47,713 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:11:47,714 [der.py] => per cls weights : [1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436 1.40129436
 1.40129436 1.40129436 1.40129436 0.39805845 0.39805845 0.39805845
 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845 0.39805845
 0.39805845]
2025-02-04 19:12:02,513 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.035,  Train_accy 45.59, Test_accy 43.49
2025-02-04 19:12:11,794 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.469,  Train_accy 70.65
2025-02-04 19:12:20,869 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.276,  Train_accy 80.43
2025-02-04 19:12:29,789 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.148,  Train_accy 87.33
2025-02-04 19:12:38,965 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.085,  Train_accy 89.83
2025-02-04 19:12:53,034 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.049,  Train_accy 91.94, Test_accy 71.58
2025-02-04 19:13:02,069 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.025,  Train_accy 93.01
2025-02-04 19:13:11,127 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.984,  Train_accy 95.23
2025-02-04 19:13:20,434 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.968,  Train_accy 95.61
2025-02-04 19:13:28,956 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.965,  Train_accy 95.89
2025-02-04 19:13:42,830 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.945,  Train_accy 96.80, Test_accy 75.18
2025-02-04 19:13:52,001 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.934,  Train_accy 97.44
2025-02-04 19:14:00,513 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.920,  Train_accy 97.96
2025-02-04 19:14:09,465 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.921,  Train_accy 97.70
2025-02-04 19:14:18,288 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.919,  Train_accy 97.81
2025-02-04 19:14:31,650 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.924,  Train_accy 97.72, Test_accy 76.56
2025-02-04 19:14:40,235 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.914,  Train_accy 98.02
2025-02-04 19:14:49,079 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.908,  Train_accy 98.15
2025-02-04 19:14:57,788 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.905,  Train_accy 98.52
2025-02-04 19:15:06,650 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.906,  Train_accy 98.34
2025-02-04 19:15:20,271 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.895,  Train_accy 98.62, Test_accy 78.49
2025-02-04 19:15:28,992 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.893,  Train_accy 98.69
2025-02-04 19:15:38,222 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.888,  Train_accy 98.82
2025-02-04 19:15:47,015 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.888,  Train_accy 98.97
2025-02-04 19:15:55,858 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.884,  Train_accy 98.99
2025-02-04 19:16:09,868 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.882,  Train_accy 98.97, Test_accy 79.53
2025-02-04 19:16:18,604 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.882,  Train_accy 99.14
2025-02-04 19:16:27,507 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.877,  Train_accy 99.05
2025-02-04 19:16:36,355 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.876,  Train_accy 99.01
2025-02-04 19:16:44,884 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.879,  Train_accy 99.08
2025-02-04 19:16:58,060 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.878,  Train_accy 99.05, Test_accy 78.36
2025-02-04 19:17:06,858 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.881,  Train_accy 99.05
2025-02-04 19:17:15,779 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.871,  Train_accy 99.18
2025-02-04 19:17:24,390 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.869,  Train_accy 99.12
2025-02-04 19:17:33,158 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.870,  Train_accy 98.92
2025-02-04 19:17:46,564 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.870,  Train_accy 99.12, Test_accy 79.73
2025-02-04 19:17:55,739 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.868,  Train_accy 98.86
2025-02-04 19:18:04,694 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.871,  Train_accy 99.08
2025-02-04 19:18:13,620 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.870,  Train_accy 98.99
2025-02-04 19:18:22,924 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.867,  Train_accy 99.14
2025-02-04 19:18:37,045 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.865,  Train_accy 99.16, Test_accy 79.91
2025-02-04 19:18:45,588 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.867,  Train_accy 99.14
2025-02-04 19:18:54,532 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.868,  Train_accy 99.23
2025-02-04 19:19:03,929 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.859,  Train_accy 99.46
2025-02-04 19:19:12,978 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.859,  Train_accy 99.40
2025-02-04 19:19:27,264 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.864,  Train_accy 99.31, Test_accy 80.24
2025-02-04 19:19:36,122 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.864,  Train_accy 99.23
2025-02-04 19:19:45,354 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.859,  Train_accy 99.42
2025-02-04 19:19:54,443 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.864,  Train_accy 99.14
2025-02-04 19:20:03,834 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.863,  Train_accy 99.25
2025-02-04 19:20:17,011 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.862,  Train_accy 99.20, Test_accy 79.67
2025-02-04 19:20:25,364 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.862,  Train_accy 99.03
2025-02-04 19:20:34,389 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.860,  Train_accy 99.38
2025-02-04 19:20:43,094 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.862,  Train_accy 99.31
2025-02-04 19:20:51,652 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.861,  Train_accy 99.20
2025-02-04 19:21:04,897 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.855,  Train_accy 99.25, Test_accy 80.80
2025-02-04 19:21:13,897 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.853,  Train_accy 99.59
2025-02-04 19:21:23,312 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.854,  Train_accy 99.38
2025-02-04 19:21:32,191 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.854,  Train_accy 99.35
2025-02-04 19:21:41,365 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.852,  Train_accy 99.46
2025-02-04 19:21:55,516 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.849,  Train_accy 99.46, Test_accy 80.51
2025-02-04 19:22:04,542 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.854,  Train_accy 99.25
2025-02-04 19:22:13,605 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.853,  Train_accy 99.40
2025-02-04 19:22:22,720 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.853,  Train_accy 99.31
2025-02-04 19:22:31,668 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.850,  Train_accy 99.27
2025-02-04 19:22:45,469 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.849,  Train_accy 99.27, Test_accy 80.36
2025-02-04 19:22:54,507 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.850,  Train_accy 99.48
2025-02-04 19:23:03,408 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.852,  Train_accy 99.27
2025-02-04 19:23:12,105 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.852,  Train_accy 99.53
2025-02-04 19:23:21,195 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.852,  Train_accy 99.51
2025-02-04 19:23:35,049 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.851,  Train_accy 99.33, Test_accy 80.27
2025-02-04 19:23:44,144 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.850,  Train_accy 99.38
2025-02-04 19:23:53,198 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.847,  Train_accy 99.51
2025-02-04 19:24:02,296 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.852,  Train_accy 99.29
2025-02-04 19:24:11,144 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.848,  Train_accy 99.35
2025-02-04 19:24:24,891 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.849,  Train_accy 99.31, Test_accy 80.56
2025-02-04 19:24:33,887 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.851,  Train_accy 99.44
2025-02-04 19:24:42,816 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.847,  Train_accy 99.38
2025-02-04 19:24:51,600 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.846,  Train_accy 99.40
2025-02-04 19:25:00,592 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.849,  Train_accy 99.46
2025-02-04 19:25:14,467 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.846,  Train_accy 99.66, Test_accy 80.87
2025-02-04 19:25:23,456 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.850,  Train_accy 99.33
2025-02-04 19:25:32,437 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.848,  Train_accy 99.42
2025-02-04 19:25:41,414 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.845,  Train_accy 99.27
2025-02-04 19:25:50,336 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.845,  Train_accy 99.70
2025-02-04 19:26:04,308 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.842,  Train_accy 99.53, Test_accy 81.56
2025-02-04 19:26:13,444 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.846,  Train_accy 99.51
2025-02-04 19:26:22,554 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.849,  Train_accy 99.31
2025-02-04 19:26:31,606 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.846,  Train_accy 99.42
2025-02-04 19:26:40,520 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.844,  Train_accy 99.46
2025-02-04 19:26:54,021 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.845,  Train_accy 99.18, Test_accy 80.96
2025-02-04 19:27:03,194 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.844,  Train_accy 99.53
2025-02-04 19:27:12,129 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.843,  Train_accy 99.44
2025-02-04 19:27:21,058 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.843,  Train_accy 99.48
2025-02-04 19:27:29,676 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-02-04 19:27:29,688 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:27:29,689 [der.py] => per cls weights : [1.35405306 1.35405306 1.35405306 1.35405306 1.35405306 1.35405306
 1.35405306 1.35405306 1.35405306 1.35405306 1.35405306 1.35405306
 1.35405306 1.35405306 1.35405306 0.46892042 0.46892042 0.46892042
 0.46892042 0.46892042 0.46892042 0.46892042 0.46892042 0.46892042
 0.46892042]
2025-02-04 19:27:29,943 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.846,  Train_accy 99.44
2025-02-04 19:27:43,659 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.842,  Train_accy 99.35, Test_accy 80.93
2025-02-04 19:27:49,500 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.169,  Train_accy 42.82, Test_accy 58.18
2025-02-04 19:27:52,946 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.844,  Train_accy 99.61
2025-02-04 19:28:01,755 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.843,  Train_accy 99.42
2025-02-04 19:28:03,332 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.690,  Train_accy 67.98
2025-02-04 19:28:10,702 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.842,  Train_accy 99.35
2025-02-04 19:28:17,156 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.516,  Train_accy 76.11
2025-02-04 19:28:19,530 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.847,  Train_accy 99.48
2025-02-04 19:28:30,266 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.400,  Train_accy 83.29
2025-02-04 19:28:33,222 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.844,  Train_accy 99.48, Test_accy 81.33
2025-02-04 19:28:42,113 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.844,  Train_accy 99.51
2025-02-04 19:28:44,175 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.341,  Train_accy 85.44
2025-02-04 19:28:51,272 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.840,  Train_accy 99.59
2025-02-04 19:29:00,207 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.841,  Train_accy 99.61
2025-02-04 19:29:03,840 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.304,  Train_accy 87.81, Test_accy 75.58
2025-02-04 19:29:09,449 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.842,  Train_accy 99.48
2025-02-04 19:29:17,492 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.280,  Train_accy 88.09
2025-02-04 19:29:22,967 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.839,  Train_accy 99.51, Test_accy 80.84
2025-02-04 19:29:31,330 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.243,  Train_accy 91.74
2025-02-04 19:29:31,663 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.839,  Train_accy 99.57
2025-02-04 19:29:41,061 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.845,  Train_accy 99.46
2025-02-04 19:29:44,164 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.228,  Train_accy 91.05
2025-02-04 19:29:49,938 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.839,  Train_accy 99.35
2025-02-04 19:29:57,850 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.229,  Train_accy 91.31
2025-02-04 19:29:58,806 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.843,  Train_accy 99.38
2025-02-04 19:30:12,312 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.11
2025-02-04 19:30:17,391 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.204,  Train_accy 92.56, Test_accy 77.98
2025-02-04 19:30:21,476 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.841,  Train_accy 99.61
2025-02-04 19:30:30,307 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.841,  Train_accy 99.57
2025-02-04 19:30:31,486 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.195,  Train_accy 92.77
2025-02-04 19:30:39,211 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.842,  Train_accy 99.59
2025-02-04 19:30:45,717 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.183,  Train_accy 93.38
2025-02-04 19:30:48,202 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.841,  Train_accy 99.57
2025-02-04 19:30:59,798 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.180,  Train_accy 93.55
2025-02-04 19:31:01,759 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.841,  Train_accy 99.44, Test_accy 81.33
2025-02-04 19:31:10,513 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.839,  Train_accy 99.57
2025-02-04 19:31:13,722 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.177,  Train_accy 93.35
2025-02-04 19:31:19,443 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.840,  Train_accy 99.44
2025-02-04 19:31:28,249 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.843,  Train_accy 99.59
2025-02-04 19:31:33,130 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.185,  Train_accy 93.25, Test_accy 79.27
2025-02-04 19:31:37,453 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.842,  Train_accy 99.46
2025-02-04 19:31:46,985 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.173,  Train_accy 93.94
2025-02-04 19:31:50,845 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.842,  Train_accy 99.38, Test_accy 81.47
2025-02-04 19:31:59,627 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.843,  Train_accy 99.48
2025-02-04 19:32:00,369 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.168,  Train_accy 93.48
2025-02-04 19:32:08,618 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.841,  Train_accy 99.53
2025-02-04 19:32:14,973 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.163,  Train_accy 94.32
2025-02-04 19:32:17,392 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.839,  Train_accy 99.53
2025-02-04 19:32:26,331 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.839,  Train_accy 99.57
2025-02-04 19:32:28,919 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.166,  Train_accy 94.06
2025-02-04 19:32:39,748 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.838,  Train_accy 99.53, Test_accy 81.62
2025-02-04 19:32:48,480 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.154,  Train_accy 94.75, Test_accy 79.76
2025-02-04 19:32:48,677 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.842,  Train_accy 99.51
2025-02-04 19:32:57,999 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.843,  Train_accy 99.48
2025-02-04 19:33:01,742 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.152,  Train_accy 94.41
2025-02-04 19:33:06,992 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.838,  Train_accy 99.59
2025-02-04 19:33:15,851 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.838,  Train_accy 99.48
2025-02-04 19:33:15,851 [der.py] => do not weight align student!
2025-02-04 19:33:16,000 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.148,  Train_accy 94.80
2025-02-04 19:33:20,891 [der.py] => darknet eval: 
2025-02-04 19:33:20,891 [der.py] => CNN top1 curve: 81.18
2025-02-04 19:33:20,892 [der.py] => CNN top5 curve: 97.73
2025-02-04 19:33:20,893 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 19:33:30,212 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.148,  Train_accy 94.71
2025-02-04 19:33:44,003 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.144,  Train_accy 94.39
2025-02-04 19:34:00,119 [der.py] => Exemplar size: 750
2025-02-04 19:34:00,120 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-02-04 19:34:00,120 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-02-04 19:34:00,120 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-02-04 19:34:00,120 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-02-04 19:34:00,120 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-02-04 19:34:00,120 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-02-04 19:34:00,120 [trainer.py] => All params: 42091068
2025-02-04 19:34:00,121 [trainer.py] => Trainable params: 21049456
2025-02-04 19:34:00,275 [der.py] => Learning on 25-35
2025-02-04 19:34:00,276 [der.py] => All params: 42093638
2025-02-04 19:34:00,276 [der.py] => Trainable params: 21052026
2025-02-04 19:34:00,369 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:34:00,370 [der.py] => per cls weights : [1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342
 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342]
2025-02-04 19:34:03,747 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.142,  Train_accy 94.73, Test_accy 80.31
2025-02-04 19:34:17,301 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.142,  Train_accy 94.88
2025-02-04 19:34:31,171 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.137,  Train_accy 94.65
2025-02-04 19:34:44,778 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.134,  Train_accy 94.65
2025-02-04 19:34:58,599 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.137,  Train_accy 94.65
2025-02-04 19:35:17,861 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.138,  Train_accy 94.67, Test_accy 80.96
2025-02-04 19:35:31,858 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.140,  Train_accy 94.62
2025-02-04 19:35:45,787 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.129,  Train_accy 95.01
2025-02-04 19:35:59,633 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.126,  Train_accy 95.08
2025-02-04 19:36:13,544 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.126,  Train_accy 94.80
2025-02-04 19:36:33,050 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.126,  Train_accy 94.86, Test_accy 81.11
2025-02-04 19:36:46,922 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.125,  Train_accy 95.16
2025-02-04 19:37:00,766 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.131,  Train_accy 94.86
2025-02-04 19:37:14,595 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.127,  Train_accy 95.05
2025-02-04 19:37:28,426 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.120,  Train_accy 95.16
2025-02-04 19:37:47,072 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.120,  Train_accy 95.23, Test_accy 81.69
2025-02-04 19:38:01,135 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.122,  Train_accy 95.27
2025-02-04 19:38:14,970 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.125,  Train_accy 94.97
2025-02-04 19:38:26,195 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-04 19:38:28,604 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.115,  Train_accy 94.80
2025-02-04 19:38:29,614 [der.py] => Exemplar size: 0
2025-02-04 19:38:29,614 [trainer.py] => No NME accuracy.
2025-02-04 19:38:29,614 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-04 19:38:29,614 [trainer.py] => CNN top1 curve: [89.44]
2025-02-04 19:38:29,614 [trainer.py] => CNN top5 curve: [98.93]

2025-02-04 19:38:29,615 [trainer.py] => All params: 21045611
2025-02-04 19:38:29,615 [trainer.py] => Trainable params: 21045611
2025-02-04 19:38:29,777 [der.py] => Learning on 15-25
2025-02-04 19:38:29,778 [der.py] => All params: 42091068
2025-02-04 19:38:29,778 [der.py] => Trainable params: 21049456
2025-02-04 19:38:42,938 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.115,  Train_accy 95.53
2025-02-04 19:39:02,583 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.121,  Train_accy 95.25, Test_accy 80.87
2025-02-04 19:39:17,436 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.118,  Train_accy 94.75
2025-02-04 19:39:31,751 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.114,  Train_accy 95.23
2025-02-04 19:39:45,995 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.119,  Train_accy 95.29
2025-02-04 19:39:59,011 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.119,  Train_accy 95.44
2025-02-04 19:40:19,340 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.118,  Train_accy 94.82, Test_accy 81.04
2025-02-04 19:40:33,695 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.115,  Train_accy 94.99
2025-02-04 19:40:48,489 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.115,  Train_accy 94.95
2025-02-04 19:41:02,474 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.117,  Train_accy 95.40
2025-02-04 19:41:16,557 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.116,  Train_accy 95.12
2025-02-04 19:41:37,144 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.109,  Train_accy 95.20, Test_accy 81.82
2025-02-04 19:41:51,725 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.106,  Train_accy 95.25
2025-02-04 19:42:06,171 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.109,  Train_accy 95.25
2025-02-04 19:42:20,530 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.108,  Train_accy 95.14
2025-02-04 19:42:34,657 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.105,  Train_accy 95.23
2025-02-04 19:42:55,584 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.103,  Train_accy 95.51, Test_accy 81.00
2025-02-04 19:43:09,743 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.107,  Train_accy 95.31
2025-02-04 19:43:23,811 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.107,  Train_accy 95.42
2025-02-04 19:43:38,400 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.108,  Train_accy 95.42
2025-02-04 19:43:52,741 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.103,  Train_accy 95.35
2025-02-04 19:44:14,293 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.102,  Train_accy 94.92, Test_accy 81.29
2025-02-04 19:44:28,606 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.104,  Train_accy 95.29
2025-02-04 19:44:43,236 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.106,  Train_accy 95.14
2025-02-04 19:44:57,693 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.106,  Train_accy 95.74
2025-02-04 19:45:12,568 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.105,  Train_accy 94.92
2025-02-04 19:45:32,225 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.103,  Train_accy 95.38, Test_accy 82.07
2025-02-04 19:45:46,719 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.103,  Train_accy 95.74
2025-02-04 19:46:01,384 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.100,  Train_accy 95.68
2025-02-04 19:46:15,707 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.106,  Train_accy 94.92
2025-02-04 19:46:30,002 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.101,  Train_accy 95.57
2025-02-04 19:46:49,805 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.101,  Train_accy 95.01, Test_accy 80.73
2025-02-04 19:47:04,189 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.103,  Train_accy 95.63
2025-02-04 19:47:18,750 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.100,  Train_accy 95.59
2025-02-04 19:47:33,072 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.100,  Train_accy 95.46
2025-02-04 19:47:46,904 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.102,  Train_accy 95.10
2025-02-04 19:48:06,842 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.099,  Train_accy 95.33, Test_accy 81.27
2025-02-04 19:48:21,055 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.103,  Train_accy 95.20
2025-02-04 19:48:35,611 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.100,  Train_accy 95.61
2025-02-04 19:48:48,724 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.099,  Train_accy 95.51
2025-02-04 19:49:03,325 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.098,  Train_accy 95.05
2025-02-04 19:49:23,772 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.094,  Train_accy 95.91, Test_accy 81.91
2025-02-04 19:49:38,635 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.098,  Train_accy 95.25
2025-02-04 19:49:52,789 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.100,  Train_accy 95.63
2025-02-04 19:50:07,296 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.098,  Train_accy 95.76
2025-02-04 19:50:21,886 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.096,  Train_accy 95.27
2025-02-04 19:50:41,839 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.098,  Train_accy 95.20, Test_accy 81.73
2025-02-04 19:50:56,313 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.097,  Train_accy 95.48
2025-02-04 19:51:10,479 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.095,  Train_accy 95.68
2025-02-04 19:51:24,892 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.095,  Train_accy 95.63
2025-02-04 19:51:39,200 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.097,  Train_accy 95.20
2025-02-04 19:52:00,149 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.094,  Train_accy 95.44, Test_accy 81.87
2025-02-04 19:52:14,034 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.095,  Train_accy 95.63
2025-02-04 19:52:28,529 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.095,  Train_accy 95.46
2025-02-04 19:52:43,160 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.093,  Train_accy 95.61
2025-02-04 19:52:57,819 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.099,  Train_accy 95.16
2025-02-04 19:53:17,903 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.095,  Train_accy 95.38, Test_accy 81.58
2025-02-04 19:53:32,310 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.096,  Train_accy 95.59
2025-02-04 19:53:46,899 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.093,  Train_accy 95.27
2025-02-04 19:54:01,253 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.093,  Train_accy 95.63
2025-02-04 19:54:15,672 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.094,  Train_accy 95.03
2025-02-04 19:54:36,208 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.090,  Train_accy 95.53, Test_accy 81.67
2025-02-04 19:54:50,216 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.091,  Train_accy 95.53
2025-02-04 19:55:04,708 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.097,  Train_accy 95.42
2025-02-04 19:55:19,146 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.091,  Train_accy 95.51
2025-02-04 19:55:32,524 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.095,  Train_accy 95.40
2025-02-04 19:55:52,509 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.094,  Train_accy 95.83, Test_accy 81.49
2025-02-04 19:56:07,163 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.093,  Train_accy 95.46
2025-02-04 19:56:21,694 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.093,  Train_accy 95.42
2025-02-04 19:56:34,707 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.093,  Train_accy 95.51
2025-02-04 19:56:49,571 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.093,  Train_accy 95.51
2025-02-04 19:57:10,079 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.093,  Train_accy 95.61, Test_accy 82.11
2025-02-04 19:57:24,575 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.091,  Train_accy 95.14
2025-02-04 19:57:38,450 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.092,  Train_accy 95.40
2025-02-04 19:57:52,714 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.094,  Train_accy 95.23
2025-02-04 19:58:07,618 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.094,  Train_accy 95.46
2025-02-04 19:58:25,035 [der.py] => Task 2, Epoch 150/150 => Loss 0.013, Loss_clf 0.006, Loss_aux 0.006, Train_accy 100.00
2025-02-04 19:58:25,037 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 19:58:25,038 [der.py] => per cls weights : [1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463 1.25715463
 1.25715463 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342
 0.35711342 0.35711342 0.35711342 0.35711342 0.35711342]
2025-02-04 19:58:27,491 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.094,  Train_accy 95.61, Test_accy 81.80
2025-02-04 19:58:40,804 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.141,  Train_accy 49.15, Test_accy 51.54
2025-02-04 19:58:42,190 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.094,  Train_accy 95.35
2025-02-04 19:58:50,302 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.714,  Train_accy 72.77
2025-02-04 19:58:56,446 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.091,  Train_accy 95.51
2025-02-04 19:58:59,684 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.566,  Train_accy 82.20
2025-02-04 19:59:08,986 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.503,  Train_accy 85.56
2025-02-04 19:59:10,590 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.090,  Train_accy 95.40
2025-02-04 19:59:18,732 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.470,  Train_accy 87.64
2025-02-04 19:59:25,368 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.091,  Train_accy 95.40
2025-02-04 19:59:34,464 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.435,  Train_accy 90.10, Test_accy 64.35
2025-02-04 19:59:44,125 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.412,  Train_accy 90.93
2025-02-04 19:59:45,329 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.089,  Train_accy 95.55, Test_accy 81.80
2025-02-04 19:59:53,673 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.387,  Train_accy 92.57
2025-02-04 19:59:59,398 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.093,  Train_accy 95.42
2025-02-04 20:00:03,196 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.375,  Train_accy 93.47
2025-02-04 20:00:12,439 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.371,  Train_accy 93.58
2025-02-04 20:00:13,779 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.094,  Train_accy 95.53
2025-02-04 20:00:27,623 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.358,  Train_accy 93.88, Test_accy 68.65
2025-02-04 20:00:28,613 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.089,  Train_accy 95.74
2025-02-04 20:00:37,029 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.340,  Train_accy 95.09
2025-02-04 20:00:43,292 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.090,  Train_accy 95.48
2025-02-04 20:00:43,293 [der.py] => do not weight align student!
2025-02-04 20:00:46,364 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.340,  Train_accy 95.07
2025-02-04 20:00:48,311 [der.py] => darknet eval: 
2025-02-04 20:00:48,312 [der.py] => CNN top1 curve: 81.64
2025-02-04 20:00:48,312 [der.py] => CNN top5 curve: 98.24
2025-02-04 20:00:48,314 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 20:00:56,019 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.336,  Train_accy 95.17
2025-02-04 20:01:05,546 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.328,  Train_accy 95.92
2025-02-04 20:01:21,983 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.323,  Train_accy 95.98, Test_accy 69.25
2025-02-04 20:01:31,355 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.316,  Train_accy 96.34
2025-02-04 20:01:31,492 [der.py] => Exemplar size: 750
2025-02-04 20:01:31,492 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-02-04 20:01:31,492 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-02-04 20:01:31,492 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-02-04 20:01:31,492 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-02-04 20:01:31,492 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-02-04 20:01:31,492 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-02-04 20:01:31,493 [trainer.py] => All params: 42091068
2025-02-04 20:01:31,493 [trainer.py] => Trainable params: 21049456
2025-02-04 20:01:31,672 [der.py] => Learning on 25-35
2025-02-04 20:01:31,673 [der.py] => All params: 42093638
2025-02-04 20:01:31,673 [der.py] => Trainable params: 21052026
2025-02-04 20:01:31,770 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 20:01:31,770 [der.py] => per cls weights : [1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 0.42584299 0.42584299 0.42584299 0.42584299 0.42584299
 0.42584299 0.42584299 0.42584299 0.42584299 0.42584299]
2025-02-04 20:01:40,807 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.313,  Train_accy 96.30
2025-02-04 20:01:50,174 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.310,  Train_accy 96.87
2025-02-04 20:01:59,634 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.303,  Train_accy 96.79
2025-02-04 20:02:15,145 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.303,  Train_accy 96.93, Test_accy 71.87
2025-02-04 20:02:24,636 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.303,  Train_accy 97.03
2025-02-04 20:02:33,945 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.300,  Train_accy 96.87
2025-02-04 20:02:43,632 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.293,  Train_accy 97.56
2025-02-04 20:02:53,166 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.290,  Train_accy 97.15
2025-02-04 20:03:08,634 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.287,  Train_accy 97.54, Test_accy 73.22
2025-02-04 20:03:18,241 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.281,  Train_accy 97.62
2025-02-04 20:03:27,489 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.282,  Train_accy 97.72
2025-02-04 20:03:36,770 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.282,  Train_accy 97.70
2025-02-04 20:03:46,530 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.279,  Train_accy 97.90
2025-02-04 20:04:02,188 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.279,  Train_accy 98.04, Test_accy 73.89
2025-02-04 20:04:11,823 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.280,  Train_accy 97.96
2025-02-04 20:04:21,087 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.275,  Train_accy 97.82
2025-02-04 20:04:30,431 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.275,  Train_accy 97.86
2025-02-04 20:04:40,020 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.271,  Train_accy 97.98
2025-02-04 20:04:55,438 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.271,  Train_accy 98.04, Test_accy 73.71
2025-02-04 20:05:05,099 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.269,  Train_accy 98.51
2025-02-04 20:05:14,872 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.268,  Train_accy 98.00
2025-02-04 20:05:24,630 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.266,  Train_accy 98.14
2025-02-04 20:05:33,963 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.265,  Train_accy 98.30
2025-02-04 20:05:49,317 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.269,  Train_accy 98.26, Test_accy 74.84
2025-02-04 20:05:58,657 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.263,  Train_accy 98.61
2025-02-04 20:06:08,079 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.266,  Train_accy 98.46
2025-02-04 20:06:17,620 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.265,  Train_accy 98.22
2025-02-04 20:06:27,216 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.261,  Train_accy 98.26
2025-02-04 20:06:42,526 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.263,  Train_accy 98.38, Test_accy 74.68
2025-02-04 20:06:51,902 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.261,  Train_accy 98.36
2025-02-04 20:07:01,327 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.259,  Train_accy 98.34
2025-02-04 20:07:10,578 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.260,  Train_accy 98.51
2025-02-04 20:07:20,196 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.257,  Train_accy 98.53
2025-02-04 20:07:35,618 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.258,  Train_accy 98.36, Test_accy 74.67
2025-02-04 20:07:44,885 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.259,  Train_accy 98.26
2025-02-04 20:07:54,584 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.259,  Train_accy 98.32
2025-02-04 20:08:03,966 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.254,  Train_accy 98.75
2025-02-04 20:08:13,611 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.255,  Train_accy 98.26
2025-02-04 20:08:28,989 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.253,  Train_accy 98.59, Test_accy 75.10
2025-02-04 20:08:38,410 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.254,  Train_accy 98.63
2025-02-04 20:08:47,784 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.254,  Train_accy 98.48
2025-02-04 20:08:57,119 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.257,  Train_accy 98.65
2025-02-04 20:09:06,887 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.252,  Train_accy 98.85
2025-02-04 20:09:22,877 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.253,  Train_accy 98.46, Test_accy 74.94
2025-02-04 20:09:32,311 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.251,  Train_accy 98.34
2025-02-04 20:09:41,797 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.256,  Train_accy 98.65
2025-02-04 20:09:51,235 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.248,  Train_accy 98.71
2025-02-04 20:10:00,754 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.249,  Train_accy 98.61
2025-02-04 20:10:16,858 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.249,  Train_accy 98.77, Test_accy 75.27
2025-02-04 20:10:26,245 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.249,  Train_accy 98.73
2025-02-04 20:10:36,013 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.249,  Train_accy 98.59
2025-02-04 20:10:45,502 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.248,  Train_accy 98.71
2025-02-04 20:10:54,880 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.245,  Train_accy 98.69
2025-02-04 20:11:10,692 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.248,  Train_accy 98.61, Test_accy 75.43
2025-02-04 20:11:16,140 [der.py] => Task 1, Epoch 150/150 => Loss 0.002, Loss_clf 0.001, Loss_aux 0.001, Train_accy 100.00
2025-02-04 20:11:19,916 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.247,  Train_accy 98.73
2025-02-04 20:11:29,267 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.247,  Train_accy 98.97
2025-02-04 20:11:35,496 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 1.784,  Train_accy 47.81, Test_accy 22.78
2025-02-04 20:11:38,883 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.243,  Train_accy 98.89
2025-02-04 20:11:48,253 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.247,  Train_accy 98.73
2025-02-04 20:11:48,580 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.301,  Train_accy 72.95
2025-02-04 20:12:01,655 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.140,  Train_accy 82.67
2025-02-04 20:12:03,692 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.247,  Train_accy 98.69, Test_accy 75.43
2025-02-04 20:12:12,994 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.245,  Train_accy 98.77
2025-02-04 20:12:15,044 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.039,  Train_accy 89.88
2025-02-04 20:12:22,552 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.244,  Train_accy 98.79
2025-02-04 20:12:28,352 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 0.991,  Train_accy 92.71
2025-02-04 20:12:31,844 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.245,  Train_accy 98.65
2025-02-04 20:12:41,166 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.242,  Train_accy 98.75
2025-02-04 20:12:47,697 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 0.963,  Train_accy 94.95, Test_accy 35.27
2025-02-04 20:12:56,495 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.242,  Train_accy 98.73, Test_accy 75.21
2025-02-04 20:13:00,812 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 0.934,  Train_accy 96.76
2025-02-04 20:13:05,935 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.243,  Train_accy 98.73
2025-02-04 20:13:13,581 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 0.917,  Train_accy 97.52
2025-02-04 20:13:15,276 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.238,  Train_accy 98.91
2025-02-04 20:13:24,561 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.238,  Train_accy 98.83
2025-02-04 20:13:27,024 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 0.907,  Train_accy 97.93
2025-02-04 20:13:33,940 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.243,  Train_accy 98.87
2025-02-04 20:13:40,379 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 0.899,  Train_accy 98.17
2025-02-04 20:13:49,085 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.241,  Train_accy 98.87, Test_accy 75.08
2025-02-04 20:13:58,728 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.239,  Train_accy 98.65
2025-02-04 20:14:00,211 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 0.900,  Train_accy 98.43, Test_accy 37.56
2025-02-04 20:14:08,325 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.240,  Train_accy 98.83
2025-02-04 20:14:13,333 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 0.889,  Train_accy 98.81
2025-02-04 20:14:17,783 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.240,  Train_accy 98.79
2025-02-04 20:14:25,805 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 0.881,  Train_accy 99.21
2025-02-04 20:14:27,214 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.240,  Train_accy 98.87
2025-02-04 20:14:39,419 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 0.877,  Train_accy 99.48
2025-02-04 20:14:42,889 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.238,  Train_accy 98.67, Test_accy 75.46
2025-02-04 20:14:52,096 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.240,  Train_accy 98.85
2025-02-04 20:14:53,141 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 0.870,  Train_accy 99.60
2025-02-04 20:15:01,507 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.240,  Train_accy 98.91
2025-02-04 20:15:10,947 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.239,  Train_accy 98.89
2025-02-04 20:15:13,515 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 0.872,  Train_accy 99.60, Test_accy 37.82
2025-02-04 20:15:20,361 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.239,  Train_accy 98.93
2025-02-04 20:15:26,821 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 0.868,  Train_accy 99.62
2025-02-04 20:15:35,863 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.239,  Train_accy 98.95, Test_accy 75.79
2025-02-04 20:15:39,506 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 0.869,  Train_accy 99.69
2025-02-04 20:15:45,294 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.238,  Train_accy 98.77
2025-02-04 20:15:52,851 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 0.865,  Train_accy 99.79
2025-02-04 20:15:54,662 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.237,  Train_accy 98.67
2025-02-04 20:16:03,970 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.235,  Train_accy 98.99
2025-02-04 20:16:06,077 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 0.865,  Train_accy 99.64
2025-02-04 20:16:13,277 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.237,  Train_accy 98.85
2025-02-04 20:16:25,588 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 0.865,  Train_accy 99.79, Test_accy 38.04
2025-02-04 20:16:29,097 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.238,  Train_accy 98.81, Test_accy 75.59
2025-02-04 20:16:38,355 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.239,  Train_accy 98.87
2025-02-04 20:16:39,100 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 0.860,  Train_accy 99.81
2025-02-04 20:16:47,782 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.238,  Train_accy 98.99
2025-02-04 20:16:52,389 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 0.857,  Train_accy 99.90
2025-02-04 20:16:57,418 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.237,  Train_accy 98.99
2025-02-04 20:17:05,827 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 0.859,  Train_accy 99.74
2025-02-04 20:17:07,180 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.235,  Train_accy 98.87
2025-02-04 20:17:19,006 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 0.857,  Train_accy 99.88
2025-02-04 20:17:22,470 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.237,  Train_accy 98.93, Test_accy 75.94
2025-02-04 20:17:31,789 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.237,  Train_accy 98.93
2025-02-04 20:17:38,561 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 0.857,  Train_accy 99.88, Test_accy 38.02
2025-02-04 20:17:41,344 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.235,  Train_accy 98.79
2025-02-04 20:17:50,602 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.238,  Train_accy 98.81
2025-02-04 20:17:52,634 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 0.856,  Train_accy 99.86
2025-02-04 20:18:00,051 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.237,  Train_accy 99.03
2025-02-04 20:18:06,526 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 0.856,  Train_accy 99.86
2025-02-04 20:18:15,577 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.235,  Train_accy 98.75, Test_accy 75.70
2025-02-04 20:18:19,115 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 0.855,  Train_accy 99.90
2025-02-04 20:18:25,096 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.235,  Train_accy 98.95
2025-02-04 20:18:32,416 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 0.852,  Train_accy 99.98
2025-02-04 20:18:34,414 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.235,  Train_accy 99.11
2025-02-04 20:18:43,787 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.234,  Train_accy 98.93
2025-02-04 20:18:52,334 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 0.852,  Train_accy 99.98, Test_accy 38.47
2025-02-04 20:18:53,279 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.236,  Train_accy 98.73
2025-02-04 20:19:05,544 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 0.853,  Train_accy 99.83
2025-02-04 20:19:08,834 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.235,  Train_accy 98.89, Test_accy 75.59
2025-02-04 20:19:18,171 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.236,  Train_accy 98.93
2025-02-04 20:19:18,659 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 0.854,  Train_accy 99.90
2025-02-04 20:19:27,640 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.235,  Train_accy 98.75
2025-02-04 20:19:31,428 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 0.852,  Train_accy 99.93
2025-02-04 20:19:37,047 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.236,  Train_accy 98.95
2025-02-04 20:19:44,327 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 0.851,  Train_accy 99.98
2025-02-04 20:19:46,445 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.236,  Train_accy 98.79
2025-02-04 20:20:01,840 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.236,  Train_accy 99.05, Test_accy 75.41
2025-02-04 20:20:03,508 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 0.851,  Train_accy 99.95, Test_accy 38.24
2025-02-04 20:20:11,274 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.234,  Train_accy 98.89
2025-02-04 20:20:17,294 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 0.850,  Train_accy 99.90
2025-02-04 20:20:20,628 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.237,  Train_accy 98.97
2025-02-04 20:20:29,811 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.236,  Train_accy 98.77
2025-02-04 20:20:30,691 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 0.850,  Train_accy 99.90
2025-02-04 20:20:39,440 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.235,  Train_accy 98.83
2025-02-04 20:20:44,507 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 0.849,  Train_accy 99.95
2025-02-04 20:20:54,514 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.234,  Train_accy 98.85, Test_accy 76.08
2025-02-04 20:20:56,975 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.849,  Train_accy 99.93
2025-02-04 20:21:03,991 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.237,  Train_accy 98.73
2025-02-04 20:21:13,271 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.236,  Train_accy 98.97
2025-02-04 20:21:16,648 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.847,  Train_accy 99.95, Test_accy 38.29
2025-02-04 20:21:22,713 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.236,  Train_accy 98.73
2025-02-04 20:21:29,524 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.847,  Train_accy 99.98
2025-02-04 20:21:32,084 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.235,  Train_accy 99.09
2025-02-04 20:21:32,084 [der.py] => do not weight align student!
2025-02-04 20:21:37,854 [der.py] => darknet eval: 
2025-02-04 20:21:37,854 [der.py] => CNN top1 curve: 75.79
2025-02-04 20:21:37,855 [der.py] => CNN top5 curve: 95.87
2025-02-04 20:21:37,856 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 20:21:42,788 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 0.846,  Train_accy 99.98
2025-02-04 20:21:55,958 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.843,  Train_accy 100.00
2025-02-04 20:22:08,727 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.846,  Train_accy 100.00
2025-02-04 20:22:27,440 [der.py] => Exemplar size: 1050
2025-02-04 20:22:27,441 [trainer.py] => CNN: {'total': 79.75, '0': 86.11, '1': 56.11, '2': 78.89, '3': 57.22, '4': 75.0, '5': 41.67, '6': 61.67, '7': 50.56, '8': 39.44, '9': 52.22, '10': 93.33, '11': 96.11, '12': 75.56, '13': 71.11, '14': 66.11, '15': 94.44, '16': 97.78, '17': 98.89, '18': 96.67, '19': 97.22, '20': 96.67, '21': 93.33, '22': 93.89, '23': 84.44, '24': 88.89, '25': 81.67, '26': 80.56, '27': 86.67, '28': 75.0, '29': 78.89, '30': 86.11, '31': 88.33, '32': 97.22, '33': 81.67, 'old': 77.73, 'new': 84.78}
2025-02-04 20:22:27,441 [trainer.py] => NME: {'total': 76.95, '0': 84.44, '1': 58.89, '2': 75.0, '3': 56.11, '4': 76.67, '5': 41.11, '6': 49.44, '7': 58.89, '8': 47.78, '9': 59.44, '10': 93.33, '11': 92.78, '12': 72.78, '13': 58.33, '14': 56.11, '15': 88.89, '16': 93.33, '17': 92.22, '18': 90.56, '19': 91.67, '20': 91.11, '21': 88.33, '22': 80.0, '23': 68.89, '24': 65.0, '25': 83.89, '26': 96.11, '27': 88.89, '28': 70.56, '29': 83.33, '30': 87.78, '31': 89.44, '32': 98.33, '33': 70.0, 'old': 73.24, 'new': 86.22}
2025-02-04 20:22:27,441 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.75]
2025-02-04 20:22:27,441 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.59]
2025-02-04 20:22:27,441 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.95]
2025-02-04 20:22:27,441 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.67]

2025-02-04 20:22:27,442 [trainer.py] => All params: 42093638
2025-02-04 20:22:27,442 [trainer.py] => Trainable params: 21052026
2025-02-04 20:22:27,458 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.847,  Train_accy 99.93, Test_accy 38.69
2025-02-04 20:22:27,591 [der.py] => Learning on 35-45
2025-02-04 20:22:27,592 [der.py] => All params: 42096208
2025-02-04 20:22:27,592 [der.py] => Trainable params: 21054596
2025-02-04 20:22:27,691 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 20:22:27,692 [der.py] => per cls weights : [1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 0.33780916
 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916
 0.33780916 0.33780916 0.33780916]
2025-02-04 20:22:40,873 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.847,  Train_accy 99.98
2025-02-04 20:22:54,422 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.843,  Train_accy 99.98
2025-02-04 20:23:07,884 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.845,  Train_accy 99.98
2025-02-04 20:23:21,342 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.844,  Train_accy 100.00
2025-02-04 20:23:40,881 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.844,  Train_accy 100.00, Test_accy 38.18
2025-02-04 20:23:53,957 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.846,  Train_accy 99.93
2025-02-04 20:24:07,075 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.843,  Train_accy 100.00
2025-02-04 20:24:20,033 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.843,  Train_accy 99.95
2025-02-04 20:24:33,252 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.842,  Train_accy 99.98
2025-02-04 20:24:51,890 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.841,  Train_accy 99.95, Test_accy 38.71
2025-02-04 20:25:04,976 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.843,  Train_accy 100.00
2025-02-04 20:25:18,157 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.842,  Train_accy 99.98
2025-02-04 20:25:31,513 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.843,  Train_accy 100.00
2025-02-04 20:25:44,733 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.843,  Train_accy 100.00
2025-02-04 20:26:04,063 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.843,  Train_accy 100.00, Test_accy 38.51
2025-02-04 20:26:16,584 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.842,  Train_accy 100.00
2025-02-04 20:26:29,415 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.841,  Train_accy 99.98
2025-02-04 20:26:42,574 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:26:55,805 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.841,  Train_accy 99.98
2025-02-04 20:27:15,330 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.840,  Train_accy 99.95, Test_accy 38.64
2025-02-04 20:27:27,500 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.841,  Train_accy 100.00
2025-02-04 20:27:41,285 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.840,  Train_accy 100.00
2025-02-04 20:27:54,895 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.841,  Train_accy 100.00
2025-02-04 20:28:08,237 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.840,  Train_accy 100.00
2025-02-04 20:28:27,031 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.841,  Train_accy 100.00, Test_accy 38.78
2025-02-04 20:28:40,212 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:28:52,904 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.839,  Train_accy 99.98
2025-02-04 20:29:06,291 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:29:19,329 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.840,  Train_accy 99.98
2025-02-04 20:29:38,711 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.839,  Train_accy 100.00, Test_accy 38.78
2025-02-04 20:29:51,890 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.838,  Train_accy 100.00
2025-02-04 20:30:03,768 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:30:16,597 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:30:29,212 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:30:47,368 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.838,  Train_accy 100.00, Test_accy 38.80
2025-02-04 20:31:00,577 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.838,  Train_accy 100.00
2025-02-04 20:31:14,169 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:31:26,366 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.838,  Train_accy 100.00
2025-02-04 20:31:40,026 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.838,  Train_accy 100.00
2025-02-04 20:31:59,229 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.838,  Train_accy 100.00, Test_accy 38.76
2025-02-04 20:32:12,257 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.839,  Train_accy 100.00
2025-02-04 20:32:25,321 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.838,  Train_accy 100.00
2025-02-04 20:32:38,325 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.837,  Train_accy 99.98
2025-02-04 20:32:51,067 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:33:10,641 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.836,  Train_accy 100.00, Test_accy 38.71
2025-02-04 20:33:23,839 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.835,  Train_accy 100.00
2025-02-04 20:33:36,926 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:33:50,037 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.836,  Train_accy 99.98
2025-02-04 20:34:02,237 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:34:21,687 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.836,  Train_accy 100.00, Test_accy 38.82
2025-02-04 20:34:35,276 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:34:48,537 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:35:02,163 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:35:15,341 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:35:34,631 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.837,  Train_accy 100.00, Test_accy 38.82
2025-02-04 20:35:47,841 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.837,  Train_accy 99.98
2025-02-04 20:36:01,024 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:36:14,107 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:36:27,620 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:36:45,892 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.835,  Train_accy 100.00, Test_accy 38.76
2025-02-04 20:36:59,046 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:37:12,156 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:37:25,226 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:37:38,897 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.835,  Train_accy 100.00
2025-02-04 20:37:59,008 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.836,  Train_accy 100.00, Test_accy 38.78
2025-02-04 20:38:11,909 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.836,  Train_accy 99.98
2025-02-04 20:38:25,088 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:38:38,396 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:38:51,548 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.835,  Train_accy 100.00
2025-02-04 20:39:10,445 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.836,  Train_accy 100.00, Test_accy 38.87
2025-02-04 20:39:23,096 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:39:36,511 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.834,  Train_accy 100.00
2025-02-04 20:39:49,871 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:40:02,994 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:40:14,544 [der.py] => Task 2, Epoch 150/150 => Loss 0.011, Loss_clf 0.006, Loss_aux 0.005, Train_accy 100.00
2025-02-04 20:40:14,557 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 20:40:14,558 [der.py] => per cls weights : [1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281 1.22966281
 1.22966281 0.42584299 0.42584299 0.42584299 0.42584299 0.42584299
 0.42584299 0.42584299 0.42584299 0.42584299 0.42584299]
2025-02-04 20:40:22,489 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.835,  Train_accy 100.00, Test_accy 38.76
2025-02-04 20:40:34,697 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:40:36,683 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.308,  Train_accy 41.80, Test_accy 59.05
2025-02-04 20:40:48,002 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:40:52,803 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.011,  Train_accy 63.43
2025-02-04 20:41:01,058 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:41:08,650 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.899,  Train_accy 70.73
2025-02-04 20:41:14,213 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.835,  Train_accy 100.00
2025-02-04 20:41:24,878 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.839,  Train_accy 75.29
2025-02-04 20:41:34,068 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.836,  Train_accy 100.00, Test_accy 38.84
2025-02-04 20:41:39,246 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.799,  Train_accy 77.98
2025-02-04 20:41:47,341 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.835,  Train_accy 100.00
2025-02-04 20:41:59,639 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.837,  Train_accy 100.00
2025-02-04 20:42:03,226 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.772,  Train_accy 79.56, Test_accy 66.70
2025-02-04 20:42:12,388 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:42:18,844 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.754,  Train_accy 80.53
2025-02-04 20:42:25,350 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.836,  Train_accy 100.00
2025-02-04 20:42:25,351 [der.py] => do not weight align student!
2025-02-04 20:42:30,993 [der.py] => darknet eval: 
2025-02-04 20:42:30,993 [der.py] => CNN top1 curve: 38.73
2025-02-04 20:42:30,993 [der.py] => CNN top5 curve: 39.96
2025-02-04 20:42:32,487 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.736,  Train_accy 82.32
2025-02-04 20:42:38,103 [der.py] => Exemplar size: 0
2025-02-04 20:42:38,103 [trainer.py] => No NME accuracy.
2025-02-04 20:42:38,103 [trainer.py] => CNN: {'total': 39.22, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 1.11, '12': 0.0, '13': 0.0, '14': 0.0, '15': 97.22, '16': 97.78, '17': 98.33, '18': 99.44, '19': 98.33, '20': 98.33, '21': 94.44, '22': 98.89, '23': 99.44, 'old': 0.07, 'new': 97.94}
2025-02-04 20:42:38,104 [trainer.py] => CNN top1 curve: [89.44, 39.22]
2025-02-04 20:42:38,104 [trainer.py] => CNN top5 curve: [98.93, 45.16]

2025-02-04 20:42:38,105 [trainer.py] => All params: 42091068
2025-02-04 20:42:38,105 [trainer.py] => Trainable params: 21049456
2025-02-04 20:42:38,268 [der.py] => Learning on 25-35
2025-02-04 20:42:38,269 [der.py] => All params: 42093638
2025-02-04 20:42:38,270 [der.py] => Trainable params: 21052026
2025-02-04 20:42:47,144 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.717,  Train_accy 83.64
2025-02-04 20:43:01,687 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.709,  Train_accy 83.68
2025-02-04 20:43:26,909 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.690,  Train_accy 84.97, Test_accy 70.22
2025-02-04 20:43:42,833 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.684,  Train_accy 85.13
2025-02-04 20:43:57,901 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.679,  Train_accy 85.70
2025-02-04 20:44:13,450 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.677,  Train_accy 85.27
2025-02-04 20:44:29,656 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.666,  Train_accy 86.44
2025-02-04 20:44:53,209 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.666,  Train_accy 86.61, Test_accy 68.94
2025-02-04 20:45:08,615 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.666,  Train_accy 86.28
2025-02-04 20:45:23,590 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.657,  Train_accy 86.79
2025-02-04 20:45:39,182 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.650,  Train_accy 87.58
2025-02-04 20:45:55,223 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.643,  Train_accy 88.00
2025-02-04 20:46:20,107 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.648,  Train_accy 87.72, Test_accy 69.98
2025-02-04 20:46:35,344 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.644,  Train_accy 87.70
2025-02-04 20:46:51,525 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.638,  Train_accy 88.00
2025-02-04 20:47:07,052 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.633,  Train_accy 88.06
2025-02-04 20:47:22,118 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.632,  Train_accy 88.61
2025-02-04 20:47:45,731 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.629,  Train_accy 88.00, Test_accy 71.84
2025-02-04 20:48:01,755 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.626,  Train_accy 88.97
2025-02-04 20:48:16,965 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.623,  Train_accy 88.67
2025-02-04 20:48:32,851 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.622,  Train_accy 88.24
2025-02-04 20:48:48,227 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.619,  Train_accy 88.77
2025-02-04 20:48:56,304 [der.py] => Task 3, Epoch 150/150 => Loss 0.229, Loss_clf 0.162, Loss_aux 0.066, Train_accy 99.98
2025-02-04 20:48:56,306 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 20:48:56,307 [der.py] => per cls weights : [1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738
 1.18919738 1.18919738 1.18919738 1.18919738 1.18919738 0.33780916
 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916 0.33780916
 0.33780916 0.33780916 0.33780916]
2025-02-04 20:49:12,327 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.622,  Train_accy 88.99, Test_accy 71.98
2025-02-04 20:49:14,141 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.895,  Train_accy 49.14, Test_accy 39.86
2025-02-04 20:49:23,940 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.527,  Train_accy 64.63
2025-02-04 20:49:28,241 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.620,  Train_accy 88.71
2025-02-04 20:49:33,902 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.392,  Train_accy 69.83
2025-02-04 20:49:43,345 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.618,  Train_accy 89.58
2025-02-04 20:49:44,013 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.331,  Train_accy 72.06
2025-02-04 20:49:54,178 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.321,  Train_accy 74.04
2025-02-04 20:49:58,933 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.616,  Train_accy 89.41
2025-02-04 20:50:11,773 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.322,  Train_accy 75.20, Test_accy 50.95
2025-02-04 20:50:14,631 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.614,  Train_accy 89.35
2025-02-04 20:50:21,693 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.264,  Train_accy 76.08
2025-02-04 20:50:31,692 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.224,  Train_accy 77.43
2025-02-04 20:50:38,552 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.613,  Train_accy 89.11, Test_accy 72.43
2025-02-04 20:50:42,074 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.201,  Train_accy 78.88
2025-02-04 20:50:52,229 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.225,  Train_accy 78.91
2025-02-04 20:50:52,822 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.612,  Train_accy 89.49
2025-02-04 20:51:08,953 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.609,  Train_accy 89.56
2025-02-04 20:51:09,690 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.209,  Train_accy 78.34, Test_accy 52.96
2025-02-04 20:51:19,920 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.188,  Train_accy 80.32
2025-02-04 20:51:24,728 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.606,  Train_accy 89.23
2025-02-04 20:51:29,880 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.201,  Train_accy 78.95
2025-02-04 20:51:39,844 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.171,  Train_accy 80.57
2025-02-04 20:51:39,950 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.604,  Train_accy 89.82
2025-02-04 20:51:50,098 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.163,  Train_accy 80.84
2025-02-04 20:52:03,922 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.608,  Train_accy 89.21, Test_accy 72.08
2025-02-04 20:52:07,847 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.124,  Train_accy 80.59, Test_accy 59.68
2025-02-04 20:52:17,722 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.216,  Train_accy 79.30
2025-02-04 20:52:19,636 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.603,  Train_accy 89.72
2025-02-04 20:52:27,747 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.157,  Train_accy 80.72
2025-02-04 20:52:35,286 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.604,  Train_accy 89.74
2025-02-04 20:52:37,752 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.139,  Train_accy 80.80
2025-02-04 20:52:47,747 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.144,  Train_accy 81.37
2025-02-04 20:52:50,656 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.602,  Train_accy 90.22
2025-02-04 20:53:05,557 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.160,  Train_accy 82.29, Test_accy 60.40
2025-02-04 20:53:05,981 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.600,  Train_accy 89.41
2025-02-04 20:53:16,041 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.202,  Train_accy 79.43
2025-02-04 20:53:25,984 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.131,  Train_accy 82.27
2025-02-04 20:53:30,115 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.600,  Train_accy 90.06, Test_accy 73.29
2025-02-04 20:53:36,106 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.136,  Train_accy 81.77
2025-02-04 20:53:45,681 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.601,  Train_accy 89.96
2025-02-04 20:53:45,946 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.123,  Train_accy 82.06
2025-02-04 20:54:01,571 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.599,  Train_accy 89.98
2025-02-04 20:54:03,912 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.148,  Train_accy 81.94, Test_accy 64.53
2025-02-04 20:54:13,850 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.099,  Train_accy 82.55
2025-02-04 20:54:16,759 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.598,  Train_accy 90.04
2025-02-04 20:54:23,958 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.133,  Train_accy 82.00
2025-02-04 20:54:31,991 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.594,  Train_accy 90.51
2025-02-04 20:54:33,847 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.126,  Train_accy 82.99
2025-02-04 20:54:43,653 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.120,  Train_accy 82.17
2025-02-04 20:54:56,292 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.595,  Train_accy 89.88, Test_accy 72.87
2025-02-04 20:55:01,347 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.095,  Train_accy 82.93, Test_accy 63.91
2025-02-04 20:55:11,393 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.115,  Train_accy 82.46
2025-02-04 20:55:12,004 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.597,  Train_accy 90.51
2025-02-04 20:55:21,364 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.089,  Train_accy 82.95
2025-02-04 20:55:26,717 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.595,  Train_accy 90.59
2025-02-04 20:55:31,358 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.083,  Train_accy 82.78
2025-02-04 20:55:41,252 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.117,  Train_accy 81.79
2025-02-04 20:55:42,723 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.591,  Train_accy 90.83
2025-02-04 20:55:58,357 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.593,  Train_accy 89.94
2025-02-04 20:55:58,627 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.100,  Train_accy 83.37, Test_accy 62.41
2025-02-04 20:56:08,776 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.119,  Train_accy 82.38
2025-02-04 20:56:18,773 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.102,  Train_accy 83.47
2025-02-04 20:56:21,824 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.590,  Train_accy 90.28, Test_accy 73.68
2025-02-04 20:56:28,991 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.120,  Train_accy 82.38
2025-02-04 20:56:36,838 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.591,  Train_accy 90.93
2025-02-04 20:56:38,970 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.096,  Train_accy 83.10
2025-02-04 20:56:52,439 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.593,  Train_accy 90.00
2025-02-04 20:56:56,454 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.100,  Train_accy 83.66, Test_accy 64.15
2025-02-04 20:57:06,447 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.084,  Train_accy 82.19
2025-02-04 20:57:08,214 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.593,  Train_accy 90.61
2025-02-04 20:57:16,343 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.106,  Train_accy 83.43
2025-02-04 20:57:24,297 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.587,  Train_accy 90.71
2025-02-04 20:57:26,638 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.090,  Train_accy 83.47
2025-02-04 20:57:36,633 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.098,  Train_accy 83.58
2025-02-04 20:57:47,945 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.589,  Train_accy 90.48, Test_accy 73.00
2025-02-04 20:57:54,398 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.104,  Train_accy 83.33, Test_accy 65.22
2025-02-04 20:58:03,578 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.588,  Train_accy 90.36
2025-02-04 20:58:04,229 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.100,  Train_accy 82.99
2025-02-04 20:58:14,651 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.074,  Train_accy 83.73
2025-02-04 20:58:19,285 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.592,  Train_accy 90.34
2025-02-04 20:58:24,692 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.098,  Train_accy 83.18
2025-02-04 20:58:34,696 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.082,  Train_accy 84.13
2025-02-04 20:58:35,070 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.585,  Train_accy 90.51
2025-02-04 20:58:49,922 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.586,  Train_accy 90.22
2025-02-04 20:58:52,685 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.087,  Train_accy 83.71, Test_accy 57.07
2025-02-04 20:59:02,599 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.070,  Train_accy 83.43
2025-02-04 20:59:12,897 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.079,  Train_accy 83.87
2025-02-04 20:59:14,716 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.585,  Train_accy 90.73, Test_accy 73.21
2025-02-04 20:59:22,957 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.088,  Train_accy 83.52
2025-02-04 20:59:30,541 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.585,  Train_accy 91.13
2025-02-04 20:59:33,166 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.069,  Train_accy 83.62
2025-02-04 20:59:46,329 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.584,  Train_accy 91.27
2025-02-04 20:59:50,603 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.059,  Train_accy 83.62, Test_accy 64.84
2025-02-04 21:00:00,561 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.094,  Train_accy 84.02
2025-02-04 21:00:01,945 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.583,  Train_accy 91.03
2025-02-04 21:00:10,643 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.069,  Train_accy 84.13
2025-02-04 21:00:17,778 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.580,  Train_accy 90.79
2025-02-04 21:00:20,642 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.065,  Train_accy 84.29
2025-02-04 21:00:30,522 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.083,  Train_accy 83.90
2025-02-04 21:00:41,819 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.584,  Train_accy 91.17, Test_accy 73.00
2025-02-04 21:00:48,251 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.074,  Train_accy 83.31, Test_accy 65.14
2025-02-04 21:00:57,660 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.583,  Train_accy 90.65
2025-02-04 21:00:58,077 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.066,  Train_accy 83.64
2025-02-04 21:01:08,390 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.062,  Train_accy 83.60
2025-02-04 21:01:13,012 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.584,  Train_accy 90.57
2025-02-04 21:01:18,250 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.076,  Train_accy 84.00
2025-02-04 21:01:28,249 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.066,  Train_accy 84.23
2025-02-04 21:01:28,344 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.579,  Train_accy 90.97
2025-02-04 21:01:44,256 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.581,  Train_accy 90.38
2025-02-04 21:01:45,866 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.073,  Train_accy 83.70, Test_accy 64.58
2025-02-04 21:01:55,857 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.083,  Train_accy 84.48
2025-02-04 21:02:05,894 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.078,  Train_accy 83.41
2025-02-04 21:02:08,082 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.581,  Train_accy 91.05, Test_accy 73.24
2025-02-04 21:02:15,947 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.053,  Train_accy 84.02
2025-02-04 21:02:23,526 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.580,  Train_accy 91.05
2025-02-04 21:02:26,153 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.074,  Train_accy 83.98
2025-02-04 21:02:39,983 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.578,  Train_accy 91.11
2025-02-04 21:02:43,623 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.053,  Train_accy 84.34, Test_accy 65.62
2025-02-04 21:02:53,478 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.062,  Train_accy 84.00
2025-02-04 21:02:56,056 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.580,  Train_accy 90.85
2025-02-04 21:03:03,395 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.061,  Train_accy 84.38
2025-02-04 21:03:11,143 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.578,  Train_accy 91.37
2025-02-04 21:03:13,470 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.034,  Train_accy 84.23
2025-02-04 21:03:23,420 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.077,  Train_accy 83.79
2025-02-04 21:03:34,889 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.579,  Train_accy 90.67, Test_accy 73.21
2025-02-04 21:03:41,076 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.056,  Train_accy 83.98, Test_accy 59.65
2025-02-04 21:03:50,747 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.579,  Train_accy 90.53
2025-02-04 21:03:51,043 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.066,  Train_accy 84.42
2025-02-04 21:04:01,123 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.053,  Train_accy 84.02
2025-02-04 21:04:05,942 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.573,  Train_accy 91.09
2025-02-04 21:04:11,098 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.070,  Train_accy 84.29
2025-02-04 21:04:21,113 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.081,  Train_accy 84.17
2025-02-04 21:04:21,684 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.573,  Train_accy 90.89
2025-02-04 21:04:37,289 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.578,  Train_accy 90.95
2025-02-04 21:04:38,647 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.063,  Train_accy 83.98, Test_accy 66.58
2025-02-04 21:04:48,586 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.043,  Train_accy 84.48
2025-02-04 21:04:58,559 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.056,  Train_accy 84.29
2025-02-04 21:05:01,005 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.576,  Train_accy 90.61, Test_accy 73.30
2025-02-04 21:05:08,624 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.048,  Train_accy 84.11
2025-02-04 21:05:17,073 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.573,  Train_accy 91.52
2025-02-04 21:05:18,567 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.043,  Train_accy 84.57
2025-02-04 21:05:32,432 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.574,  Train_accy 91.45
2025-02-04 21:05:36,313 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.062,  Train_accy 84.67, Test_accy 67.64
2025-02-04 21:05:46,205 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.061,  Train_accy 83.71
2025-02-04 21:05:47,614 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.574,  Train_accy 90.75
2025-02-04 21:05:56,383 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.053,  Train_accy 84.48
2025-02-04 21:06:03,448 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.576,  Train_accy 91.19
2025-02-04 21:06:06,326 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.035,  Train_accy 84.44
2025-02-04 21:06:16,414 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.047,  Train_accy 84.19
2025-02-04 21:06:27,303 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.572,  Train_accy 90.85, Test_accy 73.70
2025-02-04 21:06:34,126 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.063,  Train_accy 84.11, Test_accy 66.53
2025-02-04 21:06:42,095 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.574,  Train_accy 91.41
2025-02-04 21:06:44,274 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.035,  Train_accy 83.96
2025-02-04 21:06:54,361 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.057,  Train_accy 84.19
2025-02-04 21:06:58,583 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.574,  Train_accy 91.31
2025-02-04 21:07:04,485 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.051,  Train_accy 83.58
2025-02-04 21:07:14,379 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.572,  Train_accy 91.41
2025-02-04 21:07:14,440 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.042,  Train_accy 84.10
2025-02-04 21:07:29,544 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.571,  Train_accy 91.05
2025-02-04 21:07:32,076 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.046,  Train_accy 84.55, Test_accy 65.64
2025-02-04 21:07:41,928 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.042,  Train_accy 84.42
2025-02-04 21:07:52,086 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.048,  Train_accy 84.82
2025-02-04 21:07:53,051 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.572,  Train_accy 91.23, Test_accy 73.95
2025-02-04 21:08:02,154 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.063,  Train_accy 83.96
2025-02-04 21:08:08,835 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.571,  Train_accy 91.33
2025-02-04 21:08:12,046 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.042,  Train_accy 84.15
2025-02-04 21:08:24,588 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.570,  Train_accy 91.13
2025-02-04 21:08:29,761 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.050,  Train_accy 84.13, Test_accy 64.47
2025-02-04 21:08:39,682 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.061,  Train_accy 83.94
2025-02-04 21:08:40,623 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.570,  Train_accy 91.64
2025-02-04 21:08:49,712 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.056,  Train_accy 84.23
2025-02-04 21:08:55,895 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.570,  Train_accy 91.39
2025-02-04 21:08:59,612 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.064,  Train_accy 84.63
2025-02-04 21:09:09,714 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.049,  Train_accy 84.29
2025-02-04 21:09:20,104 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.572,  Train_accy 91.56, Test_accy 74.02
2025-02-04 21:09:27,376 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.047,  Train_accy 83.96, Test_accy 66.84
2025-02-04 21:09:36,597 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.573,  Train_accy 91.29
2025-02-04 21:09:37,463 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.055,  Train_accy 84.65
2025-02-04 21:09:47,546 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.052,  Train_accy 84.55
2025-02-04 21:09:52,279 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.572,  Train_accy 91.90
2025-02-04 21:09:57,592 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.044,  Train_accy 84.13
2025-02-04 21:10:07,238 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.570,  Train_accy 90.91
2025-02-04 21:10:07,527 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.046,  Train_accy 84.34
2025-02-04 21:10:23,360 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.569,  Train_accy 91.29
2025-02-04 21:10:25,366 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.044,  Train_accy 84.55, Test_accy 61.98
2025-02-04 21:10:35,203 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.043,  Train_accy 84.27
2025-02-04 21:10:45,331 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.046,  Train_accy 83.85
2025-02-04 21:10:47,627 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.569,  Train_accy 91.74, Test_accy 74.27
2025-02-04 21:10:55,299 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.041,  Train_accy 84.13
2025-02-04 21:11:03,405 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.571,  Train_accy 90.75
2025-02-04 21:11:05,336 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.025,  Train_accy 84.11
2025-02-04 21:11:18,427 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.569,  Train_accy 91.60
2025-02-04 21:11:22,927 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.029,  Train_accy 84.63, Test_accy 66.64
2025-02-04 21:11:32,899 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.042,  Train_accy 84.15
2025-02-04 21:11:34,496 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.572,  Train_accy 90.83
2025-02-04 21:11:42,792 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.051,  Train_accy 84.50
2025-02-04 21:11:49,958 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.569,  Train_accy 91.52
2025-02-04 21:11:52,666 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.058,  Train_accy 84.65
2025-02-04 21:12:02,554 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.034,  Train_accy 84.11
2025-02-04 21:12:14,227 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.570,  Train_accy 91.03, Test_accy 73.81
2025-02-04 21:12:20,791 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.046,  Train_accy 84.21, Test_accy 67.05
2025-02-04 21:12:29,373 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.570,  Train_accy 91.31
2025-02-04 21:12:30,757 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.044,  Train_accy 84.91
2025-02-04 21:12:40,742 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.023,  Train_accy 84.38
2025-02-04 21:12:45,165 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.568,  Train_accy 91.07
2025-02-04 21:12:50,756 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.025,  Train_accy 84.50
2025-02-04 21:13:00,320 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.567,  Train_accy 91.19
2025-02-04 21:13:00,613 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.056,  Train_accy 84.53
2025-02-04 21:13:15,997 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.569,  Train_accy 91.33
2025-02-04 21:13:18,472 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.044,  Train_accy 84.59, Test_accy 66.93
2025-02-04 21:13:28,402 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.035,  Train_accy 84.19
2025-02-04 21:13:38,579 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.025,  Train_accy 84.44
2025-02-04 21:13:39,209 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.569,  Train_accy 91.49, Test_accy 74.48
2025-02-04 21:13:48,481 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.044,  Train_accy 84.59
2025-02-04 21:13:55,090 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.570,  Train_accy 91.47
2025-02-04 21:13:58,403 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.045,  Train_accy 84.50
2025-02-04 21:13:58,404 [der.py] => do not weight align student!
2025-02-04 21:14:05,484 [der.py] => darknet eval: 
2025-02-04 21:14:05,484 [der.py] => CNN top1 curve: 64.54
2025-02-04 21:14:05,484 [der.py] => CNN top5 curve: 91.83
2025-02-04 21:14:05,485 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 21:14:11,170 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.568,  Train_accy 91.37
2025-02-04 21:14:26,902 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.570,  Train_accy 91.17
2025-02-04 21:14:41,152 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.569,  Train_accy 91.13
2025-02-04 21:15:05,285 [der.py] => Exemplar size: 1350
2025-02-04 21:15:05,285 [trainer.py] => CNN: {'total': 72.43, '0': 86.67, '1': 50.56, '2': 68.89, '3': 57.22, '4': 68.89, '5': 26.11, '6': 57.22, '7': 47.22, '8': 37.22, '9': 51.67, '10': 76.67, '11': 84.44, '12': 57.22, '13': 50.56, '14': 49.44, '15': 93.89, '16': 87.22, '17': 87.78, '18': 82.22, '19': 84.44, '20': 87.22, '21': 85.56, '22': 78.33, '23': 63.33, '24': 62.78, '25': 82.78, '26': 90.56, '27': 87.22, '28': 77.78, '29': 85.56, '30': 88.33, '31': 91.67, '32': 96.11, '33': 73.89, '34': 89.44, '35': 90.0, '36': 96.11, '37': 43.89, '38': 11.11, '39': 66.11, '40': 66.67, '41': 89.44, '42': 98.89, '43': 95.56, 'old': 72.75, 'new': 71.33}
2025-02-04 21:15:05,285 [trainer.py] => NME: {'total': 72.67, '0': 67.78, '1': 53.89, '2': 62.22, '3': 40.56, '4': 62.78, '5': 31.11, '6': 57.22, '7': 52.78, '8': 37.22, '9': 55.56, '10': 84.44, '11': 80.0, '12': 65.0, '13': 53.33, '14': 58.33, '15': 85.56, '16': 80.56, '17': 90.56, '18': 83.89, '19': 83.33, '20': 83.89, '21': 79.44, '22': 68.89, '23': 58.89, '24': 61.11, '25': 64.44, '26': 88.89, '27': 79.44, '28': 66.67, '29': 68.33, '30': 76.11, '31': 79.44, '32': 88.33, '33': 62.22, '34': 78.33, '35': 96.67, '36': 94.44, '37': 71.67, '38': 93.33, '39': 90.0, '40': 72.78, '41': 91.67, '42': 99.44, '43': 91.11, 'old': 68.3, 'new': 87.94}
2025-02-04 21:15:05,285 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.75, 72.43]
2025-02-04 21:15:05,285 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.59, 94.4]
2025-02-04 21:15:05,285 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.95, 72.67]
2025-02-04 21:15:05,285 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.67, 95.43]

2025-02-04 21:15:05,286 [trainer.py] => All params: 42096208
2025-02-04 21:15:05,286 [trainer.py] => Trainable params: 21054596
2025-02-04 21:15:05,430 [der.py] => Learning on 45-55
2025-02-04 21:15:05,431 [der.py] => All params: 42098778
2025-02-04 21:15:05,432 [der.py] => Trainable params: 21057166
2025-02-04 21:15:05,536 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.569,  Train_accy 91.21, Test_accy 74.16
2025-02-04 21:15:05,541 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 21:15:05,542 [der.py] => per cls weights : [1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 0.32657513 0.32657513 0.32657513
 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513
 0.32657513]
2025-02-04 21:15:21,445 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.568,  Train_accy 91.45
2025-02-04 21:15:36,607 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.569,  Train_accy 91.35
2025-02-04 21:15:52,017 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.570,  Train_accy 92.02
2025-02-04 21:16:07,577 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.568,  Train_accy 91.21
2025-02-04 21:16:30,949 [der.py] => Task 2, Epoch 150/150 => Loss 0.006, Loss_clf 0.003, Loss_aux 0.003, Train_accy 99.98
2025-02-04 21:16:31,336 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.568,  Train_accy 91.23, Test_accy 74.19
2025-02-04 21:16:47,112 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.570,  Train_accy 91.31
2025-02-04 21:16:52,526 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 1.994,  Train_accy 48.24, Test_accy 15.78
2025-02-04 21:17:01,868 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.570,  Train_accy 91.43
2025-02-04 21:17:05,466 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.773,  Train_accy 67.29
2025-02-04 21:17:18,095 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.569,  Train_accy 91.39
2025-02-04 21:17:19,170 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.688,  Train_accy 78.86
2025-02-04 21:17:33,833 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.644,  Train_accy 83.69
2025-02-04 21:17:34,065 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.568,  Train_accy 91.39
2025-02-04 21:17:34,066 [der.py] => do not weight align student!
2025-02-04 21:17:41,918 [der.py] => darknet eval: 
2025-02-04 21:17:41,919 [der.py] => CNN top1 curve: 74.41
2025-02-04 21:17:41,919 [der.py] => CNN top5 curve: 96.08
2025-02-04 21:17:41,921 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 21:17:44,264 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.614,  Train_accy 88.55
2025-02-04 21:18:00,237 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.598,  Train_accy 90.79, Test_accy 23.89
2025-02-04 21:18:10,363 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.579,  Train_accy 93.52
2025-02-04 21:18:20,900 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.575,  Train_accy 93.67
2025-02-04 21:18:32,573 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.565,  Train_accy 95.07
2025-02-04 21:18:37,545 [der.py] => Exemplar size: 1050
2025-02-04 21:18:37,546 [trainer.py] => CNN: {'total': 78.86, '0': 85.0, '1': 62.22, '2': 81.67, '3': 62.22, '4': 75.56, '5': 39.44, '6': 63.89, '7': 51.67, '8': 35.56, '9': 51.67, '10': 90.56, '11': 94.44, '12': 72.78, '13': 62.22, '14': 62.78, '15': 95.0, '16': 98.33, '17': 96.67, '18': 93.89, '19': 95.56, '20': 97.22, '21': 91.11, '22': 92.78, '23': 83.89, '24': 83.89, '25': 78.33, '26': 85.0, '27': 83.89, '28': 72.78, '29': 81.11, '30': 85.56, '31': 90.56, '32': 97.22, '33': 82.22, 'old': 76.8, 'new': 84.0}
2025-02-04 21:18:37,546 [trainer.py] => NME: {'total': 76.67, '0': 83.33, '1': 63.89, '2': 74.44, '3': 63.33, '4': 77.22, '5': 37.22, '6': 51.67, '7': 58.89, '8': 48.89, '9': 61.11, '10': 91.11, '11': 97.78, '12': 73.89, '13': 59.44, '14': 53.89, '15': 86.11, '16': 96.11, '17': 90.56, '18': 90.0, '19': 88.33, '20': 93.89, '21': 87.22, '22': 80.0, '23': 70.0, '24': 65.0, '25': 81.67, '26': 92.22, '27': 87.22, '28': 66.11, '29': 78.89, '30': 87.78, '31': 90.0, '32': 98.33, '33': 73.89, 'old': 73.73, 'new': 84.0}
2025-02-04 21:18:37,546 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.86]
2025-02-04 21:18:37,546 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.57]
2025-02-04 21:18:37,546 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.67]
2025-02-04 21:18:37,546 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.78]

2025-02-04 21:18:37,546 [trainer.py] => All params: 42093638
2025-02-04 21:18:37,547 [trainer.py] => Trainable params: 21052026
2025-02-04 21:18:37,692 [der.py] => Learning on 35-45
2025-02-04 21:18:37,693 [der.py] => All params: 42096208
2025-02-04 21:18:37,694 [der.py] => Trainable params: 21054596
2025-02-04 21:18:37,936 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 21:18:37,936 [der.py] => per cls weights : [1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 0.40516492
 0.40516492 0.40516492 0.40516492 0.40516492 0.40516492 0.40516492
 0.40516492 0.40516492 0.40516492]
2025-02-04 21:18:44,920 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.561,  Train_accy 95.55
2025-02-04 21:19:05,568 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.553,  Train_accy 96.71, Test_accy 25.14
2025-02-04 21:19:19,064 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.553,  Train_accy 96.05
2025-02-04 21:19:31,980 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.550,  Train_accy 97.40
2025-02-04 21:19:45,040 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.550,  Train_accy 97.10
2025-02-04 21:19:57,817 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.548,  Train_accy 97.33
2025-02-04 21:20:19,321 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.543,  Train_accy 98.05, Test_accy 25.10
2025-02-04 21:20:32,160 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.542,  Train_accy 98.33
2025-02-04 21:20:46,554 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.541,  Train_accy 98.43
2025-02-04 21:21:00,166 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.539,  Train_accy 98.43
2025-02-04 21:21:13,307 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.537,  Train_accy 98.48
2025-02-04 21:21:33,997 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.535,  Train_accy 98.79, Test_accy 25.49
2025-02-04 21:21:47,201 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.533,  Train_accy 98.71
2025-02-04 21:21:59,900 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.534,  Train_accy 98.45
2025-02-04 21:22:13,714 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.532,  Train_accy 98.86
2025-02-04 21:22:28,161 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.531,  Train_accy 99.14
2025-02-04 21:22:50,513 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.531,  Train_accy 99.10, Test_accy 25.56
2025-02-04 21:23:03,469 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.529,  Train_accy 99.07
2025-02-04 21:23:16,255 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.528,  Train_accy 99.26
2025-02-04 21:23:29,140 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.530,  Train_accy 99.07
2025-02-04 21:23:42,296 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.529,  Train_accy 99.21
2025-02-04 21:24:04,271 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.526,  Train_accy 99.57, Test_accy 25.52
2025-02-04 21:24:17,130 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.529,  Train_accy 99.48
2025-02-04 21:24:30,088 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.529,  Train_accy 99.38
2025-02-04 21:24:42,998 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.526,  Train_accy 99.55
2025-02-04 21:24:55,982 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.526,  Train_accy 99.43
2025-02-04 21:25:18,255 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.526,  Train_accy 99.31, Test_accy 25.68
2025-02-04 21:25:31,609 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.525,  Train_accy 99.48
2025-02-04 21:25:44,378 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.525,  Train_accy 99.60
2025-02-04 21:25:57,535 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.524,  Train_accy 99.64
2025-02-04 21:26:10,131 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.524,  Train_accy 99.55
2025-02-04 21:26:31,105 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.525,  Train_accy 99.45, Test_accy 25.84
2025-02-04 21:26:45,066 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.523,  Train_accy 99.60
2025-02-04 21:26:59,108 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.522,  Train_accy 99.50
2025-02-04 21:27:13,425 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.525,  Train_accy 99.62
2025-02-04 21:27:27,056 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.522,  Train_accy 99.48
2025-02-04 21:27:46,957 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.521,  Train_accy 99.74, Test_accy 25.49
2025-02-04 21:28:00,200 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.522,  Train_accy 99.64
2025-02-04 21:28:13,714 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.521,  Train_accy 99.69
2025-02-04 21:28:26,880 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.521,  Train_accy 99.76
2025-02-04 21:28:40,533 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.520,  Train_accy 99.71
2025-02-04 21:29:02,358 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.520,  Train_accy 99.81, Test_accy 25.65
2025-02-04 21:29:15,436 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.520,  Train_accy 99.69
2025-02-04 21:29:28,376 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.518,  Train_accy 99.81
2025-02-04 21:29:41,586 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.519,  Train_accy 99.62
2025-02-04 21:29:55,039 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.519,  Train_accy 99.74
2025-02-04 21:30:16,942 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.520,  Train_accy 99.64, Test_accy 25.78
2025-02-04 21:30:29,399 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.520,  Train_accy 99.67
2025-02-04 21:30:42,305 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.519,  Train_accy 99.64
2025-02-04 21:30:55,693 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.519,  Train_accy 99.71
2025-02-04 21:31:09,039 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.517,  Train_accy 99.83
2025-02-04 21:31:30,488 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.518,  Train_accy 99.83, Test_accy 25.84
2025-02-04 21:31:44,417 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.519,  Train_accy 99.69
2025-02-04 21:31:57,398 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.517,  Train_accy 99.76
2025-02-04 21:32:11,508 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.517,  Train_accy 99.81
2025-02-04 21:32:24,795 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.517,  Train_accy 99.79
2025-02-04 21:32:45,745 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.518,  Train_accy 99.83, Test_accy 25.79
2025-02-04 21:32:58,947 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.518,  Train_accy 99.86
2025-02-04 21:33:12,095 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.516,  Train_accy 99.86
2025-02-04 21:33:25,060 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.517,  Train_accy 99.93
2025-02-04 21:33:38,978 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.516,  Train_accy 99.76
2025-02-04 21:34:01,993 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.516,  Train_accy 99.88, Test_accy 26.05
2025-02-04 21:34:15,279 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.518,  Train_accy 99.81
2025-02-04 21:34:28,424 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.516,  Train_accy 99.79
2025-02-04 21:34:41,242 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.514,  Train_accy 99.88
2025-02-04 21:34:53,582 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.516,  Train_accy 99.81
2025-02-04 21:35:15,718 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.514,  Train_accy 99.93, Test_accy 26.10
2025-02-04 21:35:28,771 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.514,  Train_accy 99.90
2025-02-04 21:35:41,743 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.516,  Train_accy 99.86
2025-02-04 21:35:54,765 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.516,  Train_accy 99.93
2025-02-04 21:36:07,423 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.515,  Train_accy 99.86
2025-02-04 21:36:28,606 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.513,  Train_accy 99.93, Test_accy 26.11
2025-02-04 21:36:42,693 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.514,  Train_accy 99.95
2025-02-04 21:36:56,141 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.514,  Train_accy 99.90
2025-02-04 21:37:09,086 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.515,  Train_accy 99.88
2025-02-04 21:37:21,722 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.515,  Train_accy 99.90
2025-02-04 21:37:42,165 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.516,  Train_accy 99.90, Test_accy 25.94
2025-02-04 21:37:56,463 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:38:10,364 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.516,  Train_accy 99.98
2025-02-04 21:38:23,666 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.515,  Train_accy 99.90
2025-02-04 21:38:36,635 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.514,  Train_accy 99.88
2025-02-04 21:38:58,110 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.513,  Train_accy 99.95, Test_accy 26.05
2025-02-04 21:39:10,506 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.514,  Train_accy 100.00
2025-02-04 21:39:24,217 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.514,  Train_accy 99.88
2025-02-04 21:39:38,392 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.515,  Train_accy 99.71
2025-02-04 21:39:51,695 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.513,  Train_accy 99.98
2025-02-04 21:40:12,974 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.514,  Train_accy 99.79, Test_accy 26.00
2025-02-04 21:40:25,931 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:40:38,446 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.514,  Train_accy 99.83
2025-02-04 21:40:51,899 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:41:05,431 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:41:28,331 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.513,  Train_accy 99.86, Test_accy 26.11
2025-02-04 21:41:41,495 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.514,  Train_accy 99.95
2025-02-04 21:41:53,778 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.513,  Train_accy 99.90
2025-02-04 21:42:06,761 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:42:20,061 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.514,  Train_accy 99.88
2025-02-04 21:42:42,082 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.512,  Train_accy 99.98, Test_accy 26.13
2025-02-04 21:42:55,628 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.512,  Train_accy 99.95
2025-02-04 21:43:08,359 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.513,  Train_accy 99.90
2025-02-04 21:43:20,870 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.512,  Train_accy 99.95
2025-02-04 21:43:27,685 [der.py] => Task 4, Epoch 150/150 => Loss 0.023, Loss_clf 0.014, Loss_aux 0.009, Train_accy 100.00
2025-02-04 21:43:27,687 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 21:43:27,688 [der.py] => per cls weights : [1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997 1.14964997
 1.14964997 1.14964997 1.14964997 0.32657513 0.32657513 0.32657513
 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513 0.32657513
 0.32657513]
2025-02-04 21:43:33,637 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.512,  Train_accy 99.93
2025-02-04 21:43:47,055 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.811,  Train_accy 37.32, Test_accy 57.69
2025-02-04 21:43:55,310 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.513,  Train_accy 99.95, Test_accy 25.97
2025-02-04 21:43:57,920 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.502,  Train_accy 58.86
2025-02-04 21:44:08,363 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.367,  Train_accy 68.13
2025-02-04 21:44:09,078 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.513,  Train_accy 99.90
2025-02-04 21:44:18,832 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.282,  Train_accy 74.68
2025-02-04 21:44:22,964 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.513,  Train_accy 99.90
2025-02-04 21:44:29,346 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.231,  Train_accy 80.32
2025-02-04 21:44:36,864 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.513,  Train_accy 99.95
2025-02-04 21:44:48,633 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.193,  Train_accy 83.30, Test_accy 59.84
2025-02-04 21:44:49,171 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.514,  Train_accy 99.93
2025-02-04 21:44:59,088 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.175,  Train_accy 85.33
2025-02-04 21:45:09,524 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.145,  Train_accy 87.55
2025-02-04 21:45:09,977 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.512,  Train_accy 99.90, Test_accy 25.98
2025-02-04 21:45:20,042 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.129,  Train_accy 88.41
2025-02-04 21:45:23,137 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.512,  Train_accy 99.95
2025-02-04 21:45:30,493 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.127,  Train_accy 88.74
2025-02-04 21:45:36,406 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.514,  Train_accy 99.90
2025-02-04 21:45:49,602 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.114,  Train_accy 89.68, Test_accy 62.81
2025-02-04 21:45:50,160 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.513,  Train_accy 99.88
2025-02-04 21:46:00,142 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.110,  Train_accy 90.52
2025-02-04 21:46:04,357 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:46:10,547 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.094,  Train_accy 91.57
2025-02-04 21:46:21,287 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.094,  Train_accy 91.26
2025-02-04 21:46:24,362 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.512,  Train_accy 99.93, Test_accy 26.05
2025-02-04 21:46:31,679 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.088,  Train_accy 92.02
2025-02-04 21:46:37,436 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.513,  Train_accy 99.90
2025-02-04 21:46:50,703 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.513,  Train_accy 99.98
2025-02-04 21:46:50,968 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.079,  Train_accy 92.85, Test_accy 65.30
2025-02-04 21:47:01,558 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.079,  Train_accy 93.10
2025-02-04 21:47:04,022 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.512,  Train_accy 99.95
2025-02-04 21:47:12,004 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.073,  Train_accy 93.28
2025-02-04 21:47:17,484 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.513,  Train_accy 99.93
2025-02-04 21:47:22,337 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.070,  Train_accy 93.42
2025-02-04 21:47:32,917 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.060,  Train_accy 93.98
2025-02-04 21:47:39,725 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.512,  Train_accy 99.93, Test_accy 26.06
2025-02-04 21:47:52,464 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.057,  Train_accy 94.63, Test_accy 66.25
2025-02-04 21:47:52,600 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.512,  Train_accy 99.95
2025-02-04 21:48:03,089 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.055,  Train_accy 94.47
2025-02-04 21:48:05,830 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.512,  Train_accy 99.93
2025-02-04 21:48:13,368 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.048,  Train_accy 94.38
2025-02-04 21:48:18,926 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.511,  Train_accy 99.98
2025-02-04 21:48:23,904 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.047,  Train_accy 94.85
2025-02-04 21:48:31,798 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.511,  Train_accy 99.98
2025-02-04 21:48:31,798 [der.py] => do not weight align student!
2025-02-04 21:48:34,337 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.050,  Train_accy 95.19
2025-02-04 21:48:38,967 [der.py] => darknet eval: 
2025-02-04 21:48:38,967 [der.py] => CNN top1 curve: 26.05
2025-02-04 21:48:38,968 [der.py] => CNN top5 curve: 28.46
2025-02-04 21:48:48,892 [der.py] => Exemplar size: 0
2025-02-04 21:48:48,892 [trainer.py] => No NME accuracy.
2025-02-04 21:48:48,892 [trainer.py] => CNN: {'total': 26.35, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 92.78, '26': 95.0, '27': 93.89, '28': 83.33, '29': 93.89, '30': 92.78, '31': 91.67, '32': 100.0, '33': 88.89, 'old': 0.0, 'new': 92.22}
2025-02-04 21:48:48,893 [trainer.py] => CNN top1 curve: [89.44, 39.22, 26.35]
2025-02-04 21:48:48,893 [trainer.py] => CNN top5 curve: [98.93, 45.16, 28.46]

2025-02-04 21:48:48,894 [trainer.py] => All params: 42093638
2025-02-04 21:48:48,894 [trainer.py] => Trainable params: 21052026
2025-02-04 21:48:49,060 [der.py] => Learning on 35-45
2025-02-04 21:48:49,061 [der.py] => All params: 42096208
2025-02-04 21:48:49,061 [der.py] => Trainable params: 21054596
2025-02-04 21:48:53,909 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.044,  Train_accy 94.43, Test_accy 66.27
2025-02-04 21:49:04,704 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.042,  Train_accy 95.86
2025-02-04 21:49:15,317 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.043,  Train_accy 94.90
2025-02-04 21:49:25,573 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.037,  Train_accy 95.10
2025-02-04 21:49:36,445 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.038,  Train_accy 95.62
2025-02-04 21:49:56,117 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.041,  Train_accy 95.19, Test_accy 65.67
2025-02-04 21:50:06,664 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.034,  Train_accy 95.59
2025-02-04 21:50:17,138 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.026,  Train_accy 96.00
2025-02-04 21:50:27,780 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.033,  Train_accy 96.41
2025-02-04 21:50:38,238 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.026,  Train_accy 95.91
2025-02-04 21:50:57,596 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.026,  Train_accy 95.91, Test_accy 66.38
2025-02-04 21:51:07,943 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.021,  Train_accy 96.43
2025-02-04 21:51:18,410 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.021,  Train_accy 96.38
2025-02-04 21:51:28,728 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.020,  Train_accy 96.63
2025-02-04 21:51:39,324 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.018,  Train_accy 96.94
2025-02-04 21:51:58,646 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.018,  Train_accy 96.76, Test_accy 66.89
2025-02-04 21:52:09,243 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.015,  Train_accy 96.07
2025-02-04 21:52:19,590 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.020,  Train_accy 96.88
2025-02-04 21:52:30,034 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.016,  Train_accy 96.86
2025-02-04 21:52:40,381 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.015,  Train_accy 96.83
2025-02-04 21:53:00,220 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.012,  Train_accy 96.99, Test_accy 67.45
2025-02-04 21:53:10,784 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.010,  Train_accy 97.14
2025-02-04 21:53:21,197 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.014,  Train_accy 96.90
2025-02-04 21:53:31,846 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.015,  Train_accy 96.90
2025-02-04 21:53:42,481 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.012,  Train_accy 97.24
2025-02-04 21:54:02,215 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.009,  Train_accy 97.26, Test_accy 67.13
2025-02-04 21:54:12,586 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.011,  Train_accy 96.99
2025-02-04 21:54:23,024 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.010,  Train_accy 97.01
2025-02-04 21:54:33,490 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.002,  Train_accy 97.05
2025-02-04 21:54:44,123 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.003,  Train_accy 97.17
2025-02-04 21:55:03,746 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.005,  Train_accy 97.37, Test_accy 67.54
2025-02-04 21:55:14,371 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.005,  Train_accy 97.15
2025-02-04 21:55:24,894 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.004,  Train_accy 97.41
2025-02-04 21:55:35,436 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.001,  Train_accy 97.28
2025-02-04 21:55:45,840 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.004,  Train_accy 97.46
2025-02-04 21:56:05,416 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.004,  Train_accy 97.17, Test_accy 66.62
2025-02-04 21:56:16,199 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 1.999,  Train_accy 97.23
2025-02-04 21:56:26,662 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.000,  Train_accy 97.42
2025-02-04 21:56:37,098 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.001,  Train_accy 97.26
2025-02-04 21:56:47,589 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 1.997,  Train_accy 97.55
2025-02-04 21:57:06,841 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 1.997,  Train_accy 97.64, Test_accy 67.74
2025-02-04 21:57:17,406 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.001,  Train_accy 97.44
2025-02-04 21:57:27,997 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 1.992,  Train_accy 97.86
2025-02-04 21:57:38,660 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 1.992,  Train_accy 97.78
2025-02-04 21:57:49,149 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 1.996,  Train_accy 97.78
2025-02-04 21:58:08,265 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 1.993,  Train_accy 97.60, Test_accy 67.64
2025-02-04 21:58:18,553 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 1.993,  Train_accy 97.91
2025-02-04 21:58:28,961 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 1.994,  Train_accy 97.80
2025-02-04 21:58:39,360 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 1.993,  Train_accy 98.00
2025-02-04 21:58:49,910 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 1.993,  Train_accy 98.05
2025-02-04 21:59:09,490 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 1.989,  Train_accy 97.86, Test_accy 67.96
2025-02-04 21:59:19,949 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 1.993,  Train_accy 97.71
2025-02-04 21:59:30,199 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 1.992,  Train_accy 97.75
2025-02-04 21:59:40,557 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 1.992,  Train_accy 98.00
2025-02-04 21:59:51,050 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 1.992,  Train_accy 97.57
2025-02-04 22:00:10,499 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 1.988,  Train_accy 97.86, Test_accy 67.95
2025-02-04 22:00:20,940 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 1.993,  Train_accy 97.91
2025-02-04 22:00:31,536 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 1.987,  Train_accy 97.96
2025-02-04 22:00:41,806 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 1.986,  Train_accy 97.98
2025-02-04 22:00:52,579 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 1.991,  Train_accy 97.86
2025-02-04 22:01:12,243 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 1.989,  Train_accy 97.89, Test_accy 67.75
2025-02-04 22:01:22,693 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 1.991,  Train_accy 97.71
2025-02-04 22:01:24,344 [der.py] => Task 3, Epoch 150/150 => Loss 0.150, Loss_clf 0.080, Loss_aux 0.070, Train_accy 99.94
2025-02-04 22:01:24,356 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 22:01:24,357 [der.py] => per cls weights : [1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288
 1.16995288 1.16995288 1.16995288 1.16995288 1.16995288 0.40516492
 0.40516492 0.40516492 0.40516492 0.40516492 0.40516492 0.40516492
 0.40516492 0.40516492 0.40516492]
2025-02-04 22:01:33,115 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 1.988,  Train_accy 98.00
2025-02-04 22:01:43,589 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 1.989,  Train_accy 98.00
2025-02-04 22:01:52,009 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.977,  Train_accy 44.10, Test_accy 43.48
2025-02-04 22:01:54,267 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 1.984,  Train_accy 98.29
2025-02-04 22:02:08,240 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.626,  Train_accy 56.48
2025-02-04 22:02:13,797 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 1.988,  Train_accy 98.32, Test_accy 68.33
2025-02-04 22:02:24,380 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 1.986,  Train_accy 98.27
2025-02-04 22:02:24,496 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.505,  Train_accy 62.25
2025-02-04 22:02:34,901 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 1.986,  Train_accy 98.09
2025-02-04 22:02:41,227 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.431,  Train_accy 66.04
2025-02-04 22:02:45,334 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 1.984,  Train_accy 98.22
2025-02-04 22:02:55,672 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 1.986,  Train_accy 97.89
2025-02-04 22:02:57,677 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.405,  Train_accy 67.92
2025-02-04 22:03:15,234 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 1.983,  Train_accy 98.09, Test_accy 68.28
2025-02-04 22:03:23,846 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.435,  Train_accy 67.75, Test_accy 50.94
2025-02-04 22:03:26,256 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 1.986,  Train_accy 98.05
2025-02-04 22:03:36,828 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 1.987,  Train_accy 98.00
2025-02-04 22:03:39,884 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.376,  Train_accy 68.38
2025-02-04 22:03:47,362 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 1.985,  Train_accy 97.84
2025-02-04 22:03:55,746 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.324,  Train_accy 70.59
2025-02-04 22:03:57,827 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 1.984,  Train_accy 98.02
2025-02-04 22:04:12,370 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.314,  Train_accy 70.57
2025-02-04 22:04:17,073 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 1.985,  Train_accy 98.04, Test_accy 67.90
2025-02-04 22:04:27,661 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 1.983,  Train_accy 98.27
2025-02-04 22:04:29,244 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.337,  Train_accy 72.00
2025-02-04 22:04:38,171 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 1.985,  Train_accy 97.98
2025-02-04 22:04:48,691 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 1.980,  Train_accy 98.47
2025-02-04 22:04:55,907 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.305,  Train_accy 71.35, Test_accy 56.64
2025-02-04 22:04:59,238 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 1.984,  Train_accy 98.11
2025-02-04 22:05:12,516 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.295,  Train_accy 73.24
2025-02-04 22:05:18,602 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 1.981,  Train_accy 98.34, Test_accy 67.97
2025-02-04 22:05:28,711 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.303,  Train_accy 72.38
2025-02-04 22:05:29,056 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 1.982,  Train_accy 98.11
2025-02-04 22:05:39,625 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 1.986,  Train_accy 98.04
2025-02-04 22:05:45,000 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.288,  Train_accy 72.80
2025-02-04 22:05:50,136 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 1.983,  Train_accy 98.07
2025-02-04 22:06:00,493 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 1.985,  Train_accy 98.32
2025-02-04 22:06:01,614 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.260,  Train_accy 73.33
2025-02-04 22:06:19,841 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 1.983,  Train_accy 98.14, Test_accy 67.99
2025-02-04 22:06:28,741 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.244,  Train_accy 72.76, Test_accy 58.81
2025-02-04 22:06:30,546 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 1.982,  Train_accy 98.11
2025-02-04 22:06:41,029 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 1.983,  Train_accy 98.31
2025-02-04 22:06:45,639 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.298,  Train_accy 72.23
2025-02-04 22:06:51,441 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 1.983,  Train_accy 98.20
2025-02-04 22:07:00,943 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.271,  Train_accy 73.24
2025-02-04 22:07:01,901 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 1.981,  Train_accy 98.09
2025-02-04 22:07:16,705 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.232,  Train_accy 74.17
2025-02-04 22:07:21,593 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 1.979,  Train_accy 98.43, Test_accy 68.26
2025-02-04 22:07:32,165 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 1.979,  Train_accy 98.14
2025-02-04 22:07:33,343 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.250,  Train_accy 73.64
2025-02-04 22:07:42,555 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 1.981,  Train_accy 98.11
2025-02-04 22:07:53,115 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 1.980,  Train_accy 98.07
2025-02-04 22:08:00,627 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.246,  Train_accy 73.94, Test_accy 56.94
2025-02-04 22:08:03,738 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 1.984,  Train_accy 98.07
2025-02-04 22:08:16,608 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.297,  Train_accy 71.85
2025-02-04 22:08:23,179 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 1.981,  Train_accy 98.07, Test_accy 68.02
2025-02-04 22:08:33,416 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.251,  Train_accy 74.19
2025-02-04 22:08:33,515 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 1.982,  Train_accy 98.31
2025-02-04 22:08:43,836 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 1.981,  Train_accy 98.25
2025-02-04 22:08:49,362 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.229,  Train_accy 74.63
2025-02-04 22:08:54,246 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 1.982,  Train_accy 98.22
2025-02-04 22:09:04,580 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 1.980,  Train_accy 97.98
2025-02-04 22:09:06,200 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.245,  Train_accy 74.02
2025-02-04 22:09:24,088 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 1.981,  Train_accy 98.56, Test_accy 67.88
2025-02-04 22:09:32,458 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.234,  Train_accy 74.67, Test_accy 59.60
2025-02-04 22:09:34,776 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 1.979,  Train_accy 98.38
2025-02-04 22:09:45,410 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 1.978,  Train_accy 98.34
2025-02-04 22:09:48,325 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.200,  Train_accy 75.35
2025-02-04 22:09:55,800 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 1.984,  Train_accy 98.14
2025-02-04 22:10:05,046 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.229,  Train_accy 74.95
2025-02-04 22:10:06,305 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 1.981,  Train_accy 98.18
2025-02-04 22:10:06,305 [der.py] => do not weight align student!
2025-02-04 22:10:14,824 [der.py] => darknet eval: 
2025-02-04 22:10:14,824 [der.py] => CNN top1 curve: 68.03
2025-02-04 22:10:14,824 [der.py] => CNN top5 curve: 91.05
2025-02-04 22:10:14,826 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 22:10:21,457 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.228,  Train_accy 74.65
2025-02-04 22:10:37,667 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.212,  Train_accy 75.50
2025-02-04 22:11:04,927 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.196,  Train_accy 75.33, Test_accy 59.99
2025-02-04 22:11:21,334 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.213,  Train_accy 74.78
2025-02-04 22:11:24,290 [der.py] => Exemplar size: 1650
2025-02-04 22:11:24,291 [trainer.py] => CNN: {'total': 70.35, '0': 66.11, '1': 53.89, '2': 51.67, '3': 26.11, '4': 55.0, '5': 29.44, '6': 55.56, '7': 53.33, '8': 40.0, '9': 49.44, '10': 79.44, '11': 72.22, '12': 54.44, '13': 55.0, '14': 53.89, '15': 80.56, '16': 84.44, '17': 78.89, '18': 73.33, '19': 75.56, '20': 83.89, '21': 70.0, '22': 70.0, '23': 51.11, '24': 63.33, '25': 61.67, '26': 72.78, '27': 73.89, '28': 43.89, '29': 64.44, '30': 68.89, '31': 71.67, '32': 81.67, '33': 47.78, '34': 66.67, '35': 96.11, '36': 92.22, '37': 72.78, '38': 90.0, '39': 93.33, '40': 78.89, '41': 97.22, '42': 95.0, '43': 96.11, '44': 73.89, '45': 89.44, '46': 88.89, '47': 79.44, '48': 81.11, '49': 73.33, '50': 75.0, '51': 76.11, '52': 80.0, '53': 77.78, 'old': 68.12, 'new': 80.39}
2025-02-04 22:11:24,291 [trainer.py] => NME: {'total': 64.23, '0': 63.89, '1': 46.11, '2': 52.22, '3': 25.56, '4': 57.78, '5': 31.67, '6': 53.33, '7': 56.67, '8': 42.78, '9': 46.11, '10': 71.67, '11': 75.0, '12': 50.56, '13': 52.78, '14': 52.78, '15': 73.89, '16': 82.78, '17': 77.22, '18': 72.78, '19': 73.33, '20': 79.44, '21': 73.33, '22': 59.44, '23': 42.22, '24': 51.11, '25': 45.56, '26': 66.11, '27': 54.44, '28': 37.22, '29': 52.78, '30': 58.89, '31': 60.56, '32': 68.33, '33': 38.33, '34': 59.44, '35': 88.89, '36': 86.11, '37': 51.67, '38': 82.22, '39': 75.0, '40': 50.0, '41': 90.56, '42': 94.44, '43': 87.78, '44': 49.44, '45': 87.78, '46': 85.56, '47': 78.33, '48': 84.44, '49': 70.56, '50': 62.78, '51': 78.33, '52': 76.67, '53': 75.56, 'old': 61.38, 'new': 77.06}
2025-02-04 22:11:24,291 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.75, 72.43, 70.35]
2025-02-04 22:11:24,291 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.59, 94.4, 92.8]
2025-02-04 22:11:24,291 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.95, 72.67, 64.23]
2025-02-04 22:11:24,291 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.67, 95.43, 92.11]

2025-02-04 22:11:37,645 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.188,  Train_accy 75.83
2025-02-04 22:11:53,872 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.184,  Train_accy 75.20
2025-02-04 22:12:09,909 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.231,  Train_accy 74.19
2025-02-04 22:12:36,531 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.194,  Train_accy 74.76, Test_accy 61.02
2025-02-04 22:12:52,049 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.212,  Train_accy 75.24
2025-02-04 22:13:08,197 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.200,  Train_accy 74.99
2025-02-04 22:13:25,117 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.222,  Train_accy 75.12
2025-02-04 22:13:41,453 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.199,  Train_accy 76.13
2025-02-04 22:14:07,076 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.202,  Train_accy 75.50, Test_accy 60.05
2025-02-04 22:14:23,461 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.181,  Train_accy 75.07
2025-02-04 22:14:39,911 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.202,  Train_accy 75.73
2025-02-04 22:14:55,756 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.193,  Train_accy 75.64
2025-02-04 22:15:11,989 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.189,  Train_accy 75.81
2025-02-04 22:15:37,798 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.194,  Train_accy 75.70, Test_accy 59.17
2025-02-04 22:15:54,076 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.189,  Train_accy 75.89
2025-02-04 22:16:11,218 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.179,  Train_accy 75.85
2025-02-04 22:16:27,118 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.207,  Train_accy 75.68
2025-02-04 22:16:42,924 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.187,  Train_accy 75.75
2025-02-04 22:17:10,184 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.179,  Train_accy 75.70, Test_accy 56.12
2025-02-04 22:17:26,610 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.170,  Train_accy 75.89
2025-02-04 22:17:42,862 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.170,  Train_accy 75.79
2025-02-04 22:17:59,667 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.183,  Train_accy 75.70
2025-02-04 22:18:16,806 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.160,  Train_accy 76.30
2025-02-04 22:18:44,771 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.148,  Train_accy 76.29, Test_accy 56.23
2025-02-04 22:19:00,872 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.176,  Train_accy 76.34
2025-02-04 22:19:17,776 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.187,  Train_accy 76.29
2025-02-04 22:19:33,976 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.169,  Train_accy 76.13
2025-02-04 22:19:50,318 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.172,  Train_accy 76.08
2025-02-04 22:20:17,436 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.173,  Train_accy 75.45, Test_accy 62.47
2025-02-04 22:20:34,466 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.168,  Train_accy 76.55
2025-02-04 22:20:50,534 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.167,  Train_accy 75.62
2025-02-04 22:21:07,163 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.181,  Train_accy 76.08
2025-02-04 22:21:24,079 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.161,  Train_accy 76.11
2025-02-04 22:21:51,115 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.169,  Train_accy 76.36, Test_accy 62.14
2025-02-04 22:22:07,501 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.178,  Train_accy 76.15
2025-02-04 22:22:23,744 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.163,  Train_accy 76.02
2025-02-04 22:22:40,657 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.152,  Train_accy 76.70
2025-02-04 22:22:57,064 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.182,  Train_accy 76.06
2025-02-04 22:23:23,808 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.150,  Train_accy 76.10, Test_accy 61.74
2025-02-04 22:23:39,841 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.161,  Train_accy 75.83
2025-02-04 22:23:56,990 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.146,  Train_accy 76.30
2025-02-04 22:23:59,438 [der.py] => Task 3, Epoch 150/150 => Loss 0.004, Loss_clf 0.002, Loss_aux 0.002, Train_accy 100.00
2025-02-04 22:24:13,728 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.126,  Train_accy 76.44
2025-02-04 22:24:22,907 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.356,  Train_accy 53.74, Test_accy 14.72
2025-02-04 22:24:29,277 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.182,  Train_accy 76.65
2025-02-04 22:24:35,786 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.203,  Train_accy 76.07
2025-02-04 22:24:48,554 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 2.165,  Train_accy 83.69
2025-02-04 22:24:56,757 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.150,  Train_accy 76.72, Test_accy 56.06
2025-02-04 22:24:59,748 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 2.152,  Train_accy 87.60
2025-02-04 22:25:13,358 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 2.139,  Train_accy 89.79
2025-02-04 22:25:13,664 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.162,  Train_accy 76.65
2025-02-04 22:25:30,349 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.142,  Train_accy 76.76
2025-02-04 22:25:36,025 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.129,  Train_accy 92.45, Test_accy 19.91
2025-02-04 22:25:46,561 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.162,  Train_accy 76.29
2025-02-04 22:25:48,945 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 2.126,  Train_accy 92.95
2025-02-04 22:26:02,475 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 2.121,  Train_accy 94.21
2025-02-04 22:26:03,299 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.193,  Train_accy 76.61
2025-02-04 22:26:15,519 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 2.114,  Train_accy 95.21
2025-02-04 22:26:26,972 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 2.108,  Train_accy 96.05
2025-02-04 22:26:31,039 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.158,  Train_accy 76.38, Test_accy 63.33
2025-02-04 22:26:46,989 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.136,  Train_accy 76.00
2025-02-04 22:26:48,368 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 2.110,  Train_accy 96.55, Test_accy 20.40
2025-02-04 22:27:02,114 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 2.104,  Train_accy 96.76
2025-02-04 22:27:03,656 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.148,  Train_accy 76.44
2025-02-04 22:27:14,924 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 2.103,  Train_accy 97.45
2025-02-04 22:27:20,871 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.150,  Train_accy 76.46
2025-02-04 22:27:27,584 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 2.101,  Train_accy 98.00
2025-02-04 22:27:37,855 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.148,  Train_accy 77.05
2025-02-04 22:27:40,356 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 2.098,  Train_accy 98.24
2025-02-04 22:28:01,952 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 2.099,  Train_accy 98.17, Test_accy 20.79
2025-02-04 22:28:04,800 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.162,  Train_accy 76.88, Test_accy 64.07
2025-02-04 22:28:14,322 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 2.097,  Train_accy 98.48
2025-02-04 22:28:22,167 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.145,  Train_accy 76.40
2025-02-04 22:28:27,418 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 2.096,  Train_accy 98.64
2025-02-04 22:28:39,241 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.135,  Train_accy 76.95
2025-02-04 22:28:40,757 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 2.097,  Train_accy 98.50
2025-02-04 22:28:54,602 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 2.095,  Train_accy 98.88
2025-02-04 22:28:55,799 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.127,  Train_accy 76.38
2025-02-04 22:29:12,376 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.140,  Train_accy 76.30
2025-02-04 22:29:16,386 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 2.096,  Train_accy 98.67, Test_accy 20.96
2025-02-04 22:29:29,725 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 2.093,  Train_accy 98.98
2025-02-04 22:29:40,096 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.154,  Train_accy 76.48, Test_accy 64.64
2025-02-04 22:29:40,982 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 2.093,  Train_accy 99.02
2025-02-04 22:29:54,941 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 2.090,  Train_accy 99.12
2025-02-04 22:29:56,669 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.125,  Train_accy 76.67
2025-02-04 22:30:07,834 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 2.091,  Train_accy 99.24
2025-02-04 22:30:13,787 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.140,  Train_accy 76.50
2025-02-04 22:30:29,467 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.147,  Train_accy 76.00
2025-02-04 22:30:29,646 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 2.092,  Train_accy 99.19, Test_accy 21.06
2025-02-04 22:30:43,409 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 2.093,  Train_accy 99.14
2025-02-04 22:30:46,730 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.148,  Train_accy 76.23
2025-02-04 22:30:56,056 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 2.090,  Train_accy 99.21
2025-02-04 22:31:08,135 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 2.090,  Train_accy 99.12
2025-02-04 22:31:14,400 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.146,  Train_accy 76.59, Test_accy 63.46
2025-02-04 22:31:19,873 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 2.089,  Train_accy 99.45
2025-02-04 22:31:31,589 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.141,  Train_accy 76.93
2025-02-04 22:31:42,211 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 2.087,  Train_accy 99.38, Test_accy 21.06
2025-02-04 22:31:46,362 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.137,  Train_accy 76.99
2025-02-04 22:31:54,996 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 2.088,  Train_accy 99.62
2025-02-04 22:32:03,706 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.139,  Train_accy 76.21
2025-02-04 22:32:07,834 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 2.088,  Train_accy 99.43
2025-02-04 22:32:20,960 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.140,  Train_accy 76.48
2025-02-04 22:32:21,219 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 2.088,  Train_accy 99.50
2025-02-04 22:32:34,954 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 2.088,  Train_accy 99.55
2025-02-04 22:32:48,816 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.140,  Train_accy 76.55, Test_accy 62.20
2025-02-04 22:32:55,299 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 2.086,  Train_accy 99.74, Test_accy 21.26
2025-02-04 22:33:05,294 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.139,  Train_accy 76.57
2025-02-04 22:33:08,038 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 2.088,  Train_accy 99.55
2025-02-04 22:33:21,823 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 2.087,  Train_accy 99.57
2025-02-04 22:33:22,274 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.147,  Train_accy 76.15
2025-02-04 22:33:34,858 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 2.085,  Train_accy 99.62
2025-02-04 22:33:39,392 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.161,  Train_accy 76.11
2025-02-04 22:33:47,600 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 2.086,  Train_accy 99.67
2025-02-04 22:33:56,700 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.142,  Train_accy 76.42
2025-02-04 22:34:09,772 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 2.084,  Train_accy 99.71, Test_accy 21.19
2025-02-04 22:34:20,894 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 2.086,  Train_accy 99.79
2025-02-04 22:34:22,038 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.141,  Train_accy 76.44, Test_accy 63.70
2025-02-04 22:34:33,606 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 2.086,  Train_accy 99.67
2025-02-04 22:34:39,241 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.164,  Train_accy 76.84
2025-02-04 22:34:46,185 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 2.085,  Train_accy 99.62
2025-02-04 22:34:56,383 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.147,  Train_accy 76.53
2025-02-04 22:34:59,350 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 2.084,  Train_accy 99.79
2025-02-04 22:35:13,319 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.140,  Train_accy 76.53
2025-02-04 22:35:22,126 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 2.085,  Train_accy 99.76, Test_accy 21.14
2025-02-04 22:35:29,138 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.139,  Train_accy 76.36
2025-02-04 22:35:34,872 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 2.085,  Train_accy 99.69
2025-02-04 22:35:47,549 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 2.085,  Train_accy 99.79
2025-02-04 22:35:56,903 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.134,  Train_accy 76.46, Test_accy 57.52
2025-02-04 22:35:58,776 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 2.084,  Train_accy 99.71
2025-02-04 22:36:12,596 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 2.083,  Train_accy 99.79
2025-02-04 22:36:13,525 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.138,  Train_accy 76.70
2025-02-04 22:36:30,132 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.134,  Train_accy 76.50
2025-02-04 22:36:34,431 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 2.084,  Train_accy 99.74, Test_accy 21.19
2025-02-04 22:36:46,862 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.126,  Train_accy 76.80
2025-02-04 22:36:47,687 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 2.083,  Train_accy 99.86
2025-02-04 22:37:01,624 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 2.083,  Train_accy 99.93
2025-02-04 22:37:03,646 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.127,  Train_accy 76.55
2025-02-04 22:37:14,407 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 2.082,  Train_accy 99.95
2025-02-04 22:37:26,554 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 2.082,  Train_accy 99.86
2025-02-04 22:37:31,671 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.117,  Train_accy 76.84, Test_accy 63.12
2025-02-04 22:37:47,633 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.128,  Train_accy 76.82
2025-02-04 22:37:47,945 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 2.083,  Train_accy 99.81, Test_accy 21.19
2025-02-04 22:38:01,674 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 2.081,  Train_accy 99.93
2025-02-04 22:38:04,622 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.157,  Train_accy 76.65
2025-02-04 22:38:14,632 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 2.083,  Train_accy 99.95
2025-02-04 22:38:21,984 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.162,  Train_accy 76.63
2025-02-04 22:38:27,662 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 2.083,  Train_accy 99.90
2025-02-04 22:38:39,378 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.124,  Train_accy 76.84
2025-02-04 22:38:40,921 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 2.082,  Train_accy 99.86
2025-02-04 22:39:02,563 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 2.083,  Train_accy 99.88, Test_accy 21.25
2025-02-04 22:39:06,386 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.136,  Train_accy 76.65, Test_accy 64.74
2025-02-04 22:39:14,891 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 2.080,  Train_accy 99.88
2025-02-04 22:39:23,734 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.137,  Train_accy 76.55
2025-02-04 22:39:27,828 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 2.084,  Train_accy 99.86
2025-02-04 22:39:41,014 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.113,  Train_accy 76.63
2025-02-04 22:39:41,208 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 2.083,  Train_accy 99.79
2025-02-04 22:39:55,127 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 2.083,  Train_accy 99.83
2025-02-04 22:39:58,464 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.120,  Train_accy 76.55
2025-02-04 22:40:14,456 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.143,  Train_accy 76.59
2025-02-04 22:40:17,187 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 2.083,  Train_accy 99.88, Test_accy 21.28
2025-02-04 22:40:30,828 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 2.083,  Train_accy 99.95
2025-02-04 22:40:42,044 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 2.082,  Train_accy 99.88
2025-02-04 22:40:42,387 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.139,  Train_accy 76.76, Test_accy 62.75
2025-02-04 22:40:55,373 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 2.082,  Train_accy 99.93
2025-02-04 22:40:59,790 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.133,  Train_accy 76.70
2025-02-04 22:41:08,156 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 2.081,  Train_accy 99.83
2025-02-04 22:41:17,030 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.119,  Train_accy 76.63
2025-02-04 22:41:30,499 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 2.080,  Train_accy 99.86, Test_accy 21.25
2025-02-04 22:41:31,800 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.132,  Train_accy 76.72
2025-02-04 22:41:43,382 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 2.080,  Train_accy 99.88
2025-02-04 22:41:49,091 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.140,  Train_accy 76.40
2025-02-04 22:41:49,092 [der.py] => do not weight align student!
2025-02-04 22:41:55,114 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 2.081,  Train_accy 99.90
2025-02-04 22:41:58,162 [der.py] => darknet eval: 
2025-02-04 22:41:58,162 [der.py] => CNN top1 curve: 61.3
2025-02-04 22:41:58,162 [der.py] => CNN top5 curve: 90.77
2025-02-04 22:41:58,164 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-04 22:42:04,295 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 2.080,  Train_accy 99.88
2025-02-04 22:42:13,047 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 2.081,  Train_accy 99.93
2025-02-04 22:42:29,734 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 2.082,  Train_accy 99.79, Test_accy 21.20
2025-02-04 22:42:39,296 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 2.081,  Train_accy 99.95
2025-02-04 22:42:50,777 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 2.081,  Train_accy 99.95
2025-02-04 22:43:02,158 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 2.080,  Train_accy 99.93
2025-02-04 22:43:03,958 [der.py] => Exemplar size: 1350
2025-02-04 22:43:03,959 [trainer.py] => CNN: {'total': 71.48, '0': 80.0, '1': 47.78, '2': 68.33, '3': 57.22, '4': 76.11, '5': 18.89, '6': 56.11, '7': 46.67, '8': 28.89, '9': 51.11, '10': 77.78, '11': 83.33, '12': 62.22, '13': 52.78, '14': 50.56, '15': 90.56, '16': 88.89, '17': 90.0, '18': 81.67, '19': 77.78, '20': 88.33, '21': 85.56, '22': 80.56, '23': 62.22, '24': 62.22, '25': 83.33, '26': 83.89, '27': 81.11, '28': 66.67, '29': 79.44, '30': 85.56, '31': 84.44, '32': 85.0, '33': 81.67, '34': 84.44, '35': 91.11, '36': 96.11, '37': 36.67, '38': 11.11, '39': 76.67, '40': 73.33, '41': 95.0, '42': 98.89, '43': 93.33, 'old': 70.89, 'new': 73.56}
2025-02-04 22:43:03,959 [trainer.py] => NME: {'total': 72.44, '0': 69.44, '1': 51.67, '2': 66.11, '3': 49.44, '4': 74.44, '5': 35.56, '6': 53.89, '7': 49.44, '8': 36.11, '9': 59.44, '10': 83.89, '11': 86.11, '12': 62.78, '13': 48.33, '14': 56.11, '15': 87.22, '16': 83.33, '17': 88.33, '18': 80.56, '19': 82.78, '20': 85.56, '21': 77.78, '22': 76.11, '23': 59.44, '24': 63.33, '25': 63.89, '26': 80.56, '27': 76.11, '28': 59.44, '29': 70.0, '30': 74.44, '31': 81.11, '32': 80.56, '33': 47.78, '34': 78.33, '35': 95.0, '36': 91.11, '37': 71.11, '38': 93.89, '39': 90.56, '40': 80.0, '41': 93.33, '42': 95.56, '43': 94.44, 'old': 67.98, 'new': 88.06}
2025-02-04 22:43:03,959 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.86, 71.48]
2025-02-04 22:43:03,959 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.57, 94.31]
2025-02-04 22:43:03,959 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.67, 72.44]
2025-02-04 22:43:03,959 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.78, 95.46]

2025-02-04 22:43:03,959 [trainer.py] => All params: 42096208
2025-02-04 22:43:03,960 [trainer.py] => Trainable params: 21054596
2025-02-04 22:43:04,111 [der.py] => Learning on 45-55
2025-02-04 22:43:04,112 [der.py] => All params: 42098778
2025-02-04 22:43:04,112 [der.py] => Trainable params: 21057166
2025-02-04 22:43:04,246 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 22:43:04,247 [der.py] => per cls weights : [1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 0.39302038 0.39302038 0.39302038
 0.39302038 0.39302038 0.39302038 0.39302038 0.39302038 0.39302038
 0.39302038]
2025-02-04 22:43:14,474 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 2.081,  Train_accy 99.98
2025-02-04 22:43:35,411 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 2.081,  Train_accy 99.93, Test_accy 21.27
2025-02-04 22:43:48,548 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 2.080,  Train_accy 99.95
2025-02-04 22:44:01,192 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 2.082,  Train_accy 99.90
2025-02-04 22:44:13,816 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 2.080,  Train_accy 99.93
2025-02-04 22:44:26,533 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 2.080,  Train_accy 99.98
2025-02-04 22:44:49,690 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 2.080,  Train_accy 99.98, Test_accy 21.28
2025-02-04 22:45:01,545 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 2.080,  Train_accy 99.95
2025-02-04 22:45:13,967 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 2.081,  Train_accy 99.90
2025-02-04 22:45:26,665 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 2.080,  Train_accy 99.95
2025-02-04 22:45:40,189 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 2.080,  Train_accy 99.93
2025-02-04 22:46:02,118 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 2.080,  Train_accy 99.93, Test_accy 21.21
2025-02-04 22:46:14,891 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 2.080,  Train_accy 99.90
2025-02-04 22:46:28,001 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 2.079,  Train_accy 100.00
2025-02-04 22:46:40,601 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 2.079,  Train_accy 99.93
2025-02-04 22:46:53,022 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 2.078,  Train_accy 99.98
2025-02-04 22:47:14,622 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 2.079,  Train_accy 99.95, Test_accy 21.19
2025-02-04 22:47:28,188 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 2.079,  Train_accy 99.90
2025-02-04 22:47:40,817 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 2.079,  Train_accy 99.98
2025-02-04 22:47:53,728 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 2.079,  Train_accy 99.90
2025-02-04 22:48:05,914 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 2.081,  Train_accy 99.93
2025-02-04 22:48:27,355 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 2.079,  Train_accy 99.93, Test_accy 21.30
2025-02-04 22:48:40,057 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 2.080,  Train_accy 100.00
2025-02-04 22:48:52,920 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 2.079,  Train_accy 99.90
2025-02-04 22:49:05,660 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 2.079,  Train_accy 99.95
2025-02-04 22:49:18,271 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 2.079,  Train_accy 99.93
2025-02-04 22:49:40,661 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 2.079,  Train_accy 99.98, Test_accy 21.25
2025-02-04 22:49:52,797 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 2.079,  Train_accy 99.95
2025-02-04 22:50:05,420 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 2.079,  Train_accy 99.95
2025-02-04 22:50:18,790 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 2.078,  Train_accy 99.95
2025-02-04 22:50:32,342 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 2.079,  Train_accy 100.00
2025-02-04 22:50:54,069 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 2.079,  Train_accy 99.98, Test_accy 21.27
2025-02-04 22:51:06,630 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 2.080,  Train_accy 100.00
2025-02-04 22:51:18,848 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 2.080,  Train_accy 99.95
2025-02-04 22:51:31,534 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 2.079,  Train_accy 99.95
2025-02-04 22:51:44,455 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 2.078,  Train_accy 99.95
2025-02-04 22:52:06,104 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 2.080,  Train_accy 99.88, Test_accy 21.28
2025-02-04 22:52:19,760 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 2.078,  Train_accy 100.00
2025-02-04 22:52:32,943 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 2.079,  Train_accy 99.95
2025-02-04 22:52:44,784 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 2.078,  Train_accy 100.00
2025-02-04 22:52:56,963 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 2.078,  Train_accy 99.98
2025-02-04 22:53:18,943 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 2.078,  Train_accy 100.00, Test_accy 21.25
2025-02-04 22:53:31,637 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 2.079,  Train_accy 100.00
2025-02-04 22:53:44,346 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 2.078,  Train_accy 99.93
2025-02-04 22:53:57,122 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 2.079,  Train_accy 99.90
2025-02-04 22:54:09,695 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 2.079,  Train_accy 99.98
2025-02-04 22:54:30,931 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 2.078,  Train_accy 99.95, Test_accy 21.23
2025-02-04 22:54:43,645 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 2.079,  Train_accy 100.00
2025-02-04 22:54:56,666 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 2.078,  Train_accy 99.98
2025-02-04 22:55:09,546 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 2.079,  Train_accy 100.00
2025-02-04 22:55:23,246 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 2.079,  Train_accy 100.00
2025-02-04 22:55:23,247 [der.py] => do not weight align student!
2025-02-04 22:55:31,280 [der.py] => darknet eval: 
2025-02-04 22:55:31,280 [der.py] => CNN top1 curve: 21.28
2025-02-04 22:55:31,280 [der.py] => CNN top5 curve: 22.2
2025-02-04 22:55:42,185 [der.py] => Exemplar size: 0
2025-02-04 22:55:42,185 [trainer.py] => No NME accuracy.
2025-02-04 22:55:42,185 [trainer.py] => CNN: {'total': 21.36, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 98.33, '36': 98.33, '37': 87.78, '38': 98.89, '39': 100.0, '40': 92.22, '41': 99.44, '42': 99.44, '43': 97.22, 'old': 0.0, 'new': 96.11}
2025-02-04 22:55:42,185 [trainer.py] => CNN top1 curve: [89.44, 39.22, 26.35, 21.36]
2025-02-04 22:55:42,185 [trainer.py] => CNN top5 curve: [98.93, 45.16, 28.46, 22.21]

2025-02-04 22:55:42,186 [trainer.py] => All params: 42096208
2025-02-04 22:55:42,187 [trainer.py] => Trainable params: 21054596
2025-02-04 22:55:42,351 [der.py] => Learning on 45-55
2025-02-04 22:55:42,352 [der.py] => All params: 42098778
2025-02-04 22:55:42,352 [der.py] => Trainable params: 21057166
2025-02-04 23:28:29,205 [der.py] => Task 4, Epoch 150/150 => Loss 0.022, Loss_clf 0.014, Loss_aux 0.008, Train_accy 100.00
2025-02-04 23:28:29,216 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-04 23:28:29,217 [der.py] => per cls weights : [1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436 1.13488436
 1.13488436 1.13488436 1.13488436 0.39302038 0.39302038 0.39302038
 0.39302038 0.39302038 0.39302038 0.39302038 0.39302038 0.39302038
 0.39302038]
2025-02-04 23:28:57,459 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.898,  Train_accy 29.66, Test_accy 55.77
2025-02-04 23:29:13,860 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.700,  Train_accy 43.64
2025-02-04 23:29:31,267 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.600,  Train_accy 54.38
2025-02-04 23:29:47,673 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.530,  Train_accy 61.06
2025-02-04 23:30:03,717 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.489,  Train_accy 65.82
2025-02-04 23:30:33,243 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.456,  Train_accy 69.06, Test_accy 59.59
2025-02-04 23:30:47,020 [der.py] => Task 4, Epoch 150/150 => Loss 0.009, Loss_clf 0.004, Loss_aux 0.005, Train_accy 100.00
2025-02-04 23:30:49,962 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.438,  Train_accy 71.59
2025-02-04 23:31:06,619 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.419,  Train_accy 73.64
2025-02-04 23:31:12,510 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 3.307,  Train_accy 23.43, Test_accy 5.20
2025-02-04 23:31:23,386 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.401,  Train_accy 74.85
2025-02-04 23:31:25,390 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 3.252,  Train_accy 38.12
2025-02-04 23:31:39,654 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 3.232,  Train_accy 46.05
2025-02-04 23:31:40,642 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.399,  Train_accy 75.59
2025-02-04 23:31:52,790 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 3.220,  Train_accy 55.24
2025-02-04 23:32:04,720 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 3.211,  Train_accy 63.12
2025-02-04 23:32:10,170 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.383,  Train_accy 76.86, Test_accy 62.23
2025-02-04 23:32:26,102 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.379,  Train_accy 77.73
2025-02-04 23:32:27,559 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 3.205,  Train_accy 68.14, Test_accy 11.54
2025-02-04 23:32:41,275 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 3.199,  Train_accy 72.48
2025-02-04 23:32:43,076 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.365,  Train_accy 78.76
2025-02-04 23:32:54,352 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 3.195,  Train_accy 76.74
2025-02-04 23:33:00,986 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.362,  Train_accy 78.56
2025-02-04 23:33:07,566 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 3.191,  Train_accy 80.33
2025-02-04 23:33:18,768 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.362,  Train_accy 79.19
2025-02-04 23:33:20,500 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 3.189,  Train_accy 81.81
2025-02-04 23:33:44,145 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 3.187,  Train_accy 84.29, Test_accy 13.22
2025-02-04 23:33:47,189 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.352,  Train_accy 80.09, Test_accy 63.84
2025-02-04 23:33:56,712 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 3.185,  Train_accy 86.02
2025-02-04 23:34:05,198 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.345,  Train_accy 80.41
2025-02-04 23:34:09,689 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 3.183,  Train_accy 86.74
2025-02-04 23:34:22,977 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.344,  Train_accy 81.01
2025-02-04 23:34:23,302 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 3.182,  Train_accy 87.57
2025-02-04 23:34:37,402 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 3.181,  Train_accy 88.24
2025-02-04 23:34:40,493 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.341,  Train_accy 81.69
2025-02-04 23:34:56,824 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.340,  Train_accy 81.93
2025-02-04 23:35:01,281 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 3.180,  Train_accy 89.33, Test_accy 13.89
2025-02-04 23:35:14,959 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 3.179,  Train_accy 90.38
2025-02-04 23:35:26,717 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 3.178,  Train_accy 90.93
2025-02-04 23:35:26,977 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.333,  Train_accy 82.05, Test_accy 63.95
2025-02-04 23:35:40,958 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 3.177,  Train_accy 91.95
2025-02-04 23:35:44,799 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.330,  Train_accy 82.14
2025-02-04 23:35:53,842 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 3.176,  Train_accy 91.95
2025-02-04 23:36:02,497 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.326,  Train_accy 82.50
2025-02-04 23:36:18,082 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 3.175,  Train_accy 93.12, Test_accy 14.30
2025-02-04 23:36:18,090 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.327,  Train_accy 83.23
2025-02-04 23:36:32,195 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 3.175,  Train_accy 93.45
2025-02-04 23:36:36,060 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.331,  Train_accy 82.14
2025-02-04 23:36:45,501 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 3.175,  Train_accy 93.19
2025-02-04 23:36:57,843 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 3.174,  Train_accy 93.40
2025-02-04 23:37:06,339 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.324,  Train_accy 83.41, Test_accy 63.89
2025-02-04 23:37:09,076 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 3.173,  Train_accy 94.02
2025-02-04 23:37:23,729 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.323,  Train_accy 83.17
2025-02-04 23:37:34,049 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 3.173,  Train_accy 93.95, Test_accy 14.66
2025-02-04 23:37:39,758 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.315,  Train_accy 83.64
2025-02-04 23:37:46,886 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 3.173,  Train_accy 94.79
2025-02-04 23:37:57,597 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.313,  Train_accy 83.21
2025-02-04 23:38:00,009 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 3.173,  Train_accy 95.24
2025-02-04 23:38:13,953 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 3.172,  Train_accy 95.10
2025-02-04 23:38:14,925 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.312,  Train_accy 83.24
2025-02-04 23:38:27,127 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 3.172,  Train_accy 95.45
2025-02-04 23:38:44,814 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.318,  Train_accy 82.83, Test_accy 64.48
2025-02-04 23:38:49,433 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 3.171,  Train_accy 95.33, Test_accy 14.79
2025-02-04 23:39:02,091 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.313,  Train_accy 84.14
2025-02-04 23:39:02,737 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 3.171,  Train_accy 95.55
2025-02-04 23:39:16,739 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 3.171,  Train_accy 95.79
2025-02-04 23:39:18,967 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.305,  Train_accy 83.84
2025-02-04 23:39:30,180 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 3.170,  Train_accy 96.00
2025-02-04 23:39:36,872 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.309,  Train_accy 84.29
2025-02-04 23:39:43,149 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 3.171,  Train_accy 95.67
2025-02-04 23:39:54,627 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.303,  Train_accy 84.43
2025-02-04 23:40:07,532 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 3.170,  Train_accy 96.69, Test_accy 14.58
2025-02-04 23:40:18,324 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 3.170,  Train_accy 96.02
2025-02-04 23:40:21,663 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.307,  Train_accy 84.20, Test_accy 64.80
2025-02-04 23:40:30,668 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 3.169,  Train_accy 96.52
2025-02-04 23:40:39,186 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.307,  Train_accy 84.63
2025-02-04 23:40:43,615 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 3.169,  Train_accy 97.19
2025-02-04 23:40:57,293 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.300,  Train_accy 85.26
2025-02-04 23:40:57,562 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 3.169,  Train_accy 96.62
2025-02-04 23:41:14,503 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.297,  Train_accy 85.12
2025-02-04 23:41:22,147 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 3.169,  Train_accy 97.17, Test_accy 15.00
2025-02-04 23:41:31,119 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.297,  Train_accy 85.32
2025-02-04 23:41:35,531 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 3.169,  Train_accy 96.95
2025-02-04 23:41:49,447 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 3.170,  Train_accy 97.02
2025-02-04 23:42:01,086 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 3.169,  Train_accy 97.21
2025-02-04 23:42:01,428 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.297,  Train_accy 85.28, Test_accy 64.51
2025-02-04 23:42:15,051 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 3.169,  Train_accy 97.24
2025-02-04 23:42:19,315 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.294,  Train_accy 85.10
2025-02-04 23:42:35,787 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.299,  Train_accy 85.17
2025-02-04 23:42:39,058 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 3.168,  Train_accy 97.64, Test_accy 14.97
2025-02-04 23:42:53,445 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.295,  Train_accy 85.12
2025-02-04 23:42:53,470 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 3.168,  Train_accy 97.43
2025-02-04 23:43:07,706 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 3.168,  Train_accy 97.52
2025-02-04 23:43:11,175 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.294,  Train_accy 85.82
2025-02-04 23:43:20,497 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 3.168,  Train_accy 97.83
2025-02-04 23:43:32,618 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 3.168,  Train_accy 97.12
2025-02-04 23:43:41,081 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.290,  Train_accy 85.75, Test_accy 65.66
2025-02-04 23:43:54,818 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 3.168,  Train_accy 97.67, Test_accy 15.07
2025-02-04 23:43:55,998 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.286,  Train_accy 85.23
2025-02-04 23:44:08,087 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 3.168,  Train_accy 97.69
2025-02-04 23:44:14,009 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.296,  Train_accy 84.92
2025-02-04 23:44:21,046 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 3.168,  Train_accy 97.71
2025-02-04 23:44:30,804 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.294,  Train_accy 85.50
2025-02-04 23:44:33,997 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 3.167,  Train_accy 98.07
2025-02-04 23:44:47,629 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 3.167,  Train_accy 97.55
2025-02-04 23:44:48,084 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.286,  Train_accy 85.64
2025-02-04 23:45:11,200 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 3.167,  Train_accy 98.07, Test_accy 15.13
2025-02-04 23:45:17,616 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.286,  Train_accy 86.09, Test_accy 63.77
2025-02-04 23:45:23,174 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 3.167,  Train_accy 98.07
2025-02-04 23:45:35,350 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.289,  Train_accy 85.98
2025-02-04 23:45:36,396 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 3.168,  Train_accy 98.00
2025-02-04 23:45:50,685 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 3.167,  Train_accy 98.05
2025-02-04 23:45:52,642 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.287,  Train_accy 85.93
2025-02-04 23:46:03,664 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 3.167,  Train_accy 98.17
2025-02-04 23:46:10,630 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.279,  Train_accy 86.34
2025-02-04 23:46:26,574 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.280,  Train_accy 86.02
2025-02-04 23:46:27,643 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 3.167,  Train_accy 98.48, Test_accy 15.15
2025-02-04 23:46:41,637 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 3.166,  Train_accy 98.48
2025-02-04 23:46:52,832 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 3.167,  Train_accy 98.07
2025-02-04 23:46:56,234 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.284,  Train_accy 86.22, Test_accy 65.89
2025-02-04 23:47:05,421 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 3.167,  Train_accy 97.95
2025-02-04 23:47:14,060 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.283,  Train_accy 86.59
2025-02-04 23:47:18,416 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 3.167,  Train_accy 98.43
2025-02-04 23:47:31,926 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.281,  Train_accy 86.36
2025-02-04 23:47:43,800 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 3.166,  Train_accy 98.24, Test_accy 15.03
2025-02-04 23:47:47,161 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.281,  Train_accy 85.91
2025-02-04 23:47:56,877 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 3.166,  Train_accy 98.17
2025-02-04 23:48:04,938 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.282,  Train_accy 86.23
2025-02-04 23:48:09,943 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 3.166,  Train_accy 98.17
2025-02-04 23:48:23,437 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 3.166,  Train_accy 98.33
2025-02-04 23:48:35,135 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 3.166,  Train_accy 98.43
2025-02-04 23:48:35,286 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.284,  Train_accy 86.67, Test_accy 65.53
2025-02-04 23:48:52,676 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.277,  Train_accy 86.40
2025-02-04 23:49:00,121 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 3.166,  Train_accy 98.69, Test_accy 15.18
2025-02-04 23:49:08,967 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.277,  Train_accy 86.74
2025-02-04 23:49:13,174 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 3.166,  Train_accy 98.43
2025-02-04 23:49:27,032 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.282,  Train_accy 86.79
2025-02-04 23:49:27,119 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 3.166,  Train_accy 98.33
2025-02-04 23:49:40,874 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 3.166,  Train_accy 98.29
2025-02-04 23:49:44,832 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.275,  Train_accy 86.81
2025-02-04 23:49:53,973 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 3.166,  Train_accy 98.29
2025-02-04 23:50:13,758 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.276,  Train_accy 86.31, Test_accy 66.18
2025-02-04 23:50:16,008 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 3.166,  Train_accy 98.45, Test_accy 15.31
2025-02-04 23:50:30,080 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 3.166,  Train_accy 98.62
2025-02-04 23:50:31,101 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.278,  Train_accy 86.81
2025-02-04 23:50:43,329 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 3.166,  Train_accy 98.69
2025-02-04 23:50:49,191 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.272,  Train_accy 86.67
2025-02-04 23:50:56,322 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 3.166,  Train_accy 98.76
2025-02-04 23:51:07,206 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.273,  Train_accy 87.15
2025-02-04 23:51:09,378 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 3.166,  Train_accy 98.67
2025-02-04 23:51:24,475 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.276,  Train_accy 86.81
2025-02-04 23:51:34,013 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 3.166,  Train_accy 98.52, Test_accy 15.13
2025-02-04 23:51:45,980 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 3.166,  Train_accy 98.52
2025-02-04 23:51:53,162 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.271,  Train_accy 86.94, Test_accy 66.09
2025-02-04 23:51:57,556 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 3.165,  Train_accy 98.52
2025-02-04 23:52:11,262 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.273,  Train_accy 86.49
2025-02-04 23:52:11,455 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 3.165,  Train_accy 98.55
2025-02-04 23:52:25,194 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 3.166,  Train_accy 98.81
2025-02-04 23:52:29,122 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.269,  Train_accy 86.61
2025-02-04 23:52:45,798 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.272,  Train_accy 87.44
2025-02-04 23:52:49,710 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 3.165,  Train_accy 98.93, Test_accy 15.17
2025-02-04 23:53:03,186 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.269,  Train_accy 87.68
2025-02-04 23:53:03,449 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 3.165,  Train_accy 98.93
2025-02-04 23:53:17,500 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 3.166,  Train_accy 98.76
2025-02-04 23:53:28,709 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 3.166,  Train_accy 98.76
2025-02-04 23:53:33,334 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.269,  Train_accy 87.75, Test_accy 66.28
2025-02-04 23:53:40,982 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 3.165,  Train_accy 98.62
2025-02-04 23:53:51,282 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.269,  Train_accy 87.08
2025-02-04 23:54:05,694 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 3.165,  Train_accy 98.86, Test_accy 15.29
2025-02-04 23:54:06,403 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.266,  Train_accy 86.50
2025-02-04 23:54:19,214 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 3.165,  Train_accy 99.00
2025-02-04 23:54:24,620 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.268,  Train_accy 87.59
2025-02-04 23:54:32,402 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 3.165,  Train_accy 98.86
2025-02-04 23:54:42,691 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.271,  Train_accy 86.90
2025-02-04 23:54:45,888 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 3.165,  Train_accy 98.90
2025-02-04 23:54:59,667 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 3.165,  Train_accy 98.76
2025-02-04 23:55:12,463 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.267,  Train_accy 87.59, Test_accy 65.59
2025-02-04 23:55:21,686 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 3.165,  Train_accy 98.83, Test_accy 15.16
2025-02-04 23:55:28,595 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.270,  Train_accy 87.60
2025-02-04 23:55:34,598 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 3.165,  Train_accy 98.76
2025-02-04 23:55:46,534 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.265,  Train_accy 86.95
2025-02-04 23:55:47,790 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 3.165,  Train_accy 98.83
2025-02-04 23:56:02,161 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 3.165,  Train_accy 98.88
2025-02-04 23:56:03,829 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.265,  Train_accy 87.60
2025-02-04 23:56:15,086 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 3.165,  Train_accy 98.95
2025-02-04 23:56:21,824 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.270,  Train_accy 87.86
2025-02-04 23:56:39,365 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 3.165,  Train_accy 98.79, Test_accy 15.26
2025-02-04 23:56:50,215 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.263,  Train_accy 87.71, Test_accy 66.15
2025-02-04 23:56:50,536 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 3.165,  Train_accy 98.93
2025-02-04 23:57:04,122 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 3.165,  Train_accy 98.86
2025-02-04 23:57:07,620 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.270,  Train_accy 87.64
2025-02-04 23:57:17,324 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 3.164,  Train_accy 99.02
2025-02-04 23:57:25,344 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.267,  Train_accy 87.35
2025-02-04 23:57:30,481 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 3.165,  Train_accy 98.69
2025-02-04 23:57:43,597 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.270,  Train_accy 87.41
2025-02-04 23:57:55,758 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 3.165,  Train_accy 98.83, Test_accy 15.24
2025-02-04 23:57:58,552 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.262,  Train_accy 87.59
2025-02-04 23:58:08,884 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 3.165,  Train_accy 98.76
2025-02-04 23:58:21,085 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 3.165,  Train_accy 99.07
2025-02-04 23:58:28,839 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.265,  Train_accy 87.80, Test_accy 65.67
2025-02-04 23:58:32,359 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 3.165,  Train_accy 98.86
2025-02-04 23:58:46,479 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.264,  Train_accy 87.77
2025-02-04 23:58:46,541 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 3.164,  Train_accy 98.81
2025-02-04 23:59:03,561 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.262,  Train_accy 87.15
2025-02-04 23:59:10,931 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 3.165,  Train_accy 98.90, Test_accy 15.32
2025-02-04 23:59:20,286 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.264,  Train_accy 87.41
2025-02-04 23:59:24,174 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 3.165,  Train_accy 98.98
2025-02-04 23:59:38,157 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.264,  Train_accy 87.71
2025-02-04 23:59:38,191 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 3.165,  Train_accy 99.17
2025-02-04 23:59:52,347 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 3.165,  Train_accy 99.05
2025-02-05 00:00:03,496 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 3.165,  Train_accy 98.60
2025-02-05 00:00:08,033 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.262,  Train_accy 87.66, Test_accy 66.27
2025-02-05 00:00:24,539 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.265,  Train_accy 87.50
2025-02-05 00:00:26,536 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 3.164,  Train_accy 99.21, Test_accy 15.23
2025-02-05 00:00:40,436 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 3.165,  Train_accy 98.98
2025-02-05 00:00:41,600 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.265,  Train_accy 87.50
2025-02-05 00:00:53,512 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 3.164,  Train_accy 99.14
2025-02-05 00:00:59,534 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.261,  Train_accy 87.44
2025-02-05 00:01:06,495 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 3.165,  Train_accy 98.76
2025-02-05 00:01:17,352 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.262,  Train_accy 87.75
2025-02-05 00:01:19,705 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 3.165,  Train_accy 99.05
2025-02-05 00:01:43,363 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 3.165,  Train_accy 98.93, Test_accy 15.30
2025-02-05 00:01:46,100 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.264,  Train_accy 87.42, Test_accy 65.73
2025-02-05 00:01:56,000 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 3.165,  Train_accy 99.07
2025-02-05 00:02:03,843 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.263,  Train_accy 87.82
2025-02-05 00:02:08,772 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 3.165,  Train_accy 99.00
2025-02-05 00:02:21,577 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.262,  Train_accy 87.87
2025-02-05 00:02:22,247 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 3.164,  Train_accy 98.86
2025-02-05 00:02:36,133 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 3.165,  Train_accy 98.57
2025-02-05 00:02:38,785 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.258,  Train_accy 87.42
2025-02-05 00:02:55,646 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.260,  Train_accy 87.77
2025-02-05 00:02:59,842 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 3.164,  Train_accy 99.12, Test_accy 15.40
2025-02-05 00:03:13,471 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 3.165,  Train_accy 99.02
2025-02-05 00:03:25,212 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 3.164,  Train_accy 99.02
2025-02-05 00:03:25,850 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.260,  Train_accy 88.00, Test_accy 66.04
2025-02-05 00:03:38,748 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 3.165,  Train_accy 98.90
2025-02-05 00:03:43,830 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.262,  Train_accy 88.05
2025-02-05 00:03:51,727 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 3.165,  Train_accy 98.79
2025-02-05 00:03:51,728 [der.py] => do not weight align student!
2025-02-05 00:03:59,845 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.263,  Train_accy 88.05
2025-02-05 00:04:00,800 [der.py] => darknet eval: 
2025-02-05 00:04:00,800 [der.py] => CNN top1 curve: 15.25
2025-02-05 00:04:00,800 [der.py] => CNN top5 curve: 17.94
2025-02-05 00:04:15,160 [der.py] => Exemplar size: 0
2025-02-05 00:04:15,160 [trainer.py] => No NME accuracy.
2025-02-05 00:04:15,160 [trainer.py] => CNN: {'total': 15.96, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.0, '30': 0.0, '31': 0.0, '32': 0.0, '33': 0.0, '34': 0.0, '35': 0.0, '36': 0.0, '37': 0.0, '38': 3.89, '39': 0.0, '40': 0.0, '41': 0.0, '42': 0.0, '43': 0.0, '44': 0.0, '45': 93.33, '46': 91.11, '47': 94.44, '48': 80.56, '49': 87.22, '50': 83.33, '51': 80.0, '52': 88.89, '53': 87.22, 'old': 0.09, 'new': 87.39}
2025-02-05 00:04:15,160 [trainer.py] => CNN top1 curve: [89.44, 39.22, 26.35, 21.36, 15.96]
2025-02-05 00:04:15,160 [trainer.py] => CNN top5 curve: [98.93, 45.16, 28.46, 22.21, 18.63]

2025-02-05 00:04:15,283 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.261,  Train_accy 87.39
2025-02-05 00:04:27,141 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.263,  Train_accy 87.89
2025-02-05 00:04:48,391 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.261,  Train_accy 87.24, Test_accy 66.23
2025-02-05 00:05:00,183 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.261,  Train_accy 87.68
2025-02-05 00:05:12,018 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.259,  Train_accy 87.80
2025-02-05 00:05:23,690 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.260,  Train_accy 88.05
2025-02-05 00:05:35,483 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.258,  Train_accy 87.53
2025-02-05 00:05:56,458 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.259,  Train_accy 88.27, Test_accy 66.19
2025-02-05 00:06:08,079 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.258,  Train_accy 87.51
2025-02-05 00:06:19,892 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.257,  Train_accy 87.77
2025-02-05 00:06:31,478 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.259,  Train_accy 87.68
2025-02-05 00:06:43,136 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.262,  Train_accy 87.91
2025-02-05 00:07:03,948 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.257,  Train_accy 87.82, Test_accy 66.09
2025-02-05 00:07:15,764 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.261,  Train_accy 88.23
2025-02-05 00:07:27,377 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.261,  Train_accy 88.22
2025-02-05 00:07:39,027 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.261,  Train_accy 88.11
2025-02-05 00:07:50,662 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.258,  Train_accy 88.11
2025-02-05 00:08:11,545 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.259,  Train_accy 87.86, Test_accy 66.20
2025-02-05 00:08:23,117 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.256,  Train_accy 88.11
2025-02-05 00:08:34,756 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.255,  Train_accy 88.20
2025-02-05 00:08:46,299 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.259,  Train_accy 88.07
2025-02-05 00:08:57,899 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.258,  Train_accy 88.31
2025-02-05 00:08:57,900 [der.py] => do not weight align student!
2025-02-05 00:09:05,949 [der.py] => darknet eval: 
2025-02-05 00:09:05,950 [der.py] => CNN top1 curve: 66.31
2025-02-05 00:09:05,950 [der.py] => CNN top5 curve: 91.27
2025-02-05 00:09:05,952 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 00:10:07,466 [der.py] => Exemplar size: 1650
2025-02-05 00:10:07,467 [trainer.py] => CNN: {'total': 68.9, '0': 62.78, '1': 50.56, '2': 62.78, '3': 28.33, '4': 53.89, '5': 34.44, '6': 56.67, '7': 45.0, '8': 33.89, '9': 48.33, '10': 77.22, '11': 75.56, '12': 54.44, '13': 49.44, '14': 55.56, '15': 78.33, '16': 82.78, '17': 80.56, '18': 70.0, '19': 72.78, '20': 83.33, '21': 68.33, '22': 75.0, '23': 55.0, '24': 67.78, '25': 60.0, '26': 67.78, '27': 68.89, '28': 43.33, '29': 56.67, '30': 53.33, '31': 70.56, '32': 79.44, '33': 43.89, '34': 65.56, '35': 93.33, '36': 93.89, '37': 72.22, '38': 81.11, '39': 95.0, '40': 77.78, '41': 97.78, '42': 97.22, '43': 97.78, '44': 75.56, '45': 78.33, '46': 82.78, '47': 76.67, '48': 76.67, '49': 72.78, '50': 75.0, '51': 80.56, '52': 76.11, '53': 75.56, 'old': 66.98, 'new': 77.56}
2025-02-05 00:10:07,467 [trainer.py] => NME: {'total': 63.34, '0': 67.22, '1': 49.44, '2': 53.89, '3': 25.56, '4': 60.0, '5': 33.33, '6': 48.89, '7': 51.11, '8': 37.22, '9': 48.33, '10': 78.89, '11': 82.22, '12': 52.78, '13': 48.89, '14': 51.11, '15': 69.44, '16': 79.44, '17': 78.89, '18': 70.0, '19': 70.56, '20': 74.44, '21': 69.44, '22': 63.89, '23': 44.44, '24': 50.56, '25': 53.33, '26': 66.11, '27': 52.22, '28': 36.67, '29': 42.78, '30': 38.33, '31': 66.11, '32': 66.67, '33': 34.44, '34': 59.44, '35': 80.0, '36': 82.78, '37': 46.67, '38': 78.33, '39': 70.0, '40': 45.56, '41': 97.78, '42': 93.89, '43': 95.0, '44': 45.56, '45': 82.22, '46': 87.22, '47': 80.56, '48': 80.0, '49': 71.11, '50': 62.22, '51': 81.11, '52': 76.11, '53': 75.56, 'old': 60.26, 'new': 77.22}
2025-02-05 00:10:07,467 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.86, 71.48, 68.9]
2025-02-05 00:10:07,467 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.57, 94.31, 92.35]
2025-02-05 00:10:07,467 [trainer.py] => NME top1 curve: [88.22, 84.98, 76.67, 72.44, 63.34]
2025-02-05 00:10:07,467 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.78, 95.46, 91.52]

2025-02-05 00:25:45,015 [trainer.py] => 实验名称:BKD*0.1对比实验
2025-02-05 00:25:45,016 [trainer.py] => config: ./exps/der.json
2025-02-05 00:25:45,016 [trainer.py] => experiment_name: 实验名称:BKD*0.1对比实验
2025-02-05 00:25:45,016 [trainer.py] => prefix: reproduce
2025-02-05 00:25:45,016 [trainer.py] => dataset: xrfdataset
2025-02-05 00:25:45,016 [trainer.py] => memory_size: 1650
2025-02-05 00:25:45,016 [trainer.py] => memory_per_class: 30
2025-02-05 00:25:45,016 [trainer.py] => fixed_memory: True
2025-02-05 00:25:45,016 [trainer.py] => shuffle: True
2025-02-05 00:25:45,016 [trainer.py] => init_cls: 15
2025-02-05 00:25:45,016 [trainer.py] => increment: 10
2025-02-05 00:25:45,016 [trainer.py] => model_name: der
2025-02-05 00:25:45,016 [trainer.py] => compression_epochs: 130
2025-02-05 00:25:45,016 [trainer.py] => compression_lr: 0.1
2025-02-05 00:25:45,016 [trainer.py] => is_student_wa: False
2025-02-05 00:25:45,016 [trainer.py] => wa_value: 1
2025-02-05 00:25:45,016 [trainer.py] => T: 2
2025-02-05 00:25:45,016 [trainer.py] => convnet_type: unet
2025-02-05 00:25:45,016 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-05 00:25:45,016 [trainer.py] => seed: 1993
2025-02-05 00:25:45,028 [data.py] => 加载完毕XRF原始数据集
2025-02-05 00:25:45,033 [data.py] => 加载完毕XRF原始数据集
2025-02-05 00:25:45,034 [trainer.py] => All params: 0
2025-02-05 00:25:45,034 [trainer.py] => Trainable params: 0
2025-02-05 00:25:45,205 [der.py] => Learning on 0-15
2025-02-05 00:25:45,206 [der.py] => All params: 21045611
2025-02-05 00:25:45,206 [der.py] => Trainable params: 21045611
2025-02-05 00:26:40,609 [trainer.py] => 实验名称:BKD*0.05对比实验
2025-02-05 00:26:40,609 [trainer.py] => config: ./exps/der.json
2025-02-05 00:26:40,609 [trainer.py] => experiment_name: 实验名称:BKD*0.05对比实验
2025-02-05 00:26:40,609 [trainer.py] => prefix: reproduce
2025-02-05 00:26:40,609 [trainer.py] => dataset: xrfdataset
2025-02-05 00:26:40,609 [trainer.py] => memory_size: 1650
2025-02-05 00:26:40,609 [trainer.py] => memory_per_class: 30
2025-02-05 00:26:40,609 [trainer.py] => fixed_memory: True
2025-02-05 00:26:40,610 [trainer.py] => shuffle: True
2025-02-05 00:26:40,610 [trainer.py] => init_cls: 15
2025-02-05 00:26:40,610 [trainer.py] => increment: 10
2025-02-05 00:26:40,610 [trainer.py] => model_name: der
2025-02-05 00:26:40,610 [trainer.py] => compression_epochs: 130
2025-02-05 00:26:40,610 [trainer.py] => compression_lr: 0.1
2025-02-05 00:26:40,610 [trainer.py] => is_student_wa: False
2025-02-05 00:26:40,610 [trainer.py] => wa_value: 1
2025-02-05 00:26:40,610 [trainer.py] => T: 2
2025-02-05 00:26:40,610 [trainer.py] => convnet_type: unet
2025-02-05 00:26:40,610 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-05 00:26:40,610 [trainer.py] => seed: 1993
2025-02-05 00:26:40,622 [data.py] => 加载完毕XRF原始数据集
2025-02-05 00:26:40,627 [data.py] => 加载完毕XRF原始数据集
2025-02-05 00:26:40,628 [trainer.py] => All params: 0
2025-02-05 00:26:40,628 [trainer.py] => Trainable params: 0
2025-02-05 00:26:40,789 [der.py] => Learning on 0-15
2025-02-05 00:26:40,789 [der.py] => All params: 21045611
2025-02-05 00:26:40,789 [der.py] => Trainable params: 21045611
2025-02-05 00:27:03,061 [trainer.py] => 实验名称:BKD*0.05对比实验
2025-02-05 00:27:03,061 [trainer.py] => config: ./exps/der.json
2025-02-05 00:27:03,061 [trainer.py] => experiment_name: 实验名称:BKD*0.05对比实验
2025-02-05 00:27:03,061 [trainer.py] => prefix: reproduce
2025-02-05 00:27:03,061 [trainer.py] => dataset: xrfdataset
2025-02-05 00:27:03,061 [trainer.py] => memory_size: 1650
2025-02-05 00:27:03,061 [trainer.py] => memory_per_class: 30
2025-02-05 00:27:03,062 [trainer.py] => fixed_memory: True
2025-02-05 00:27:03,062 [trainer.py] => shuffle: True
2025-02-05 00:27:03,062 [trainer.py] => init_cls: 15
2025-02-05 00:27:03,062 [trainer.py] => increment: 10
2025-02-05 00:27:03,062 [trainer.py] => model_name: der
2025-02-05 00:27:03,062 [trainer.py] => compression_epochs: 130
2025-02-05 00:27:03,062 [trainer.py] => compression_lr: 0.1
2025-02-05 00:27:03,062 [trainer.py] => is_student_wa: False
2025-02-05 00:27:03,062 [trainer.py] => wa_value: 1
2025-02-05 00:27:03,062 [trainer.py] => T: 2
2025-02-05 00:27:03,062 [trainer.py] => convnet_type: unet
2025-02-05 00:27:03,062 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-05 00:27:03,062 [trainer.py] => seed: 1993
2025-02-05 00:27:03,074 [data.py] => 加载完毕XRF原始数据集
2025-02-05 00:27:03,080 [data.py] => 加载完毕XRF原始数据集
2025-02-05 00:27:03,081 [trainer.py] => All params: 0
2025-02-05 00:27:03,081 [trainer.py] => Trainable params: 0
2025-02-05 00:27:03,248 [der.py] => Learning on 0-15
2025-02-05 00:27:03,248 [der.py] => All params: 21045611
2025-02-05 00:27:03,249 [der.py] => Trainable params: 21045611
2025-02-05 00:48:06,366 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-05 00:48:06,367 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 00:48:34,712 [der.py] => Exemplar size: 450
2025-02-05 00:48:34,712 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-05 00:48:34,712 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-05 00:48:34,712 [trainer.py] => CNN top1 curve: [89.44]
2025-02-05 00:48:34,712 [trainer.py] => CNN top5 curve: [98.93]
2025-02-05 00:48:34,712 [trainer.py] => NME top1 curve: [88.22]
2025-02-05 00:48:34,712 [trainer.py] => NME top5 curve: [98.81]

2025-02-05 00:48:34,713 [trainer.py] => All params: 21045611
2025-02-05 00:48:34,713 [trainer.py] => Trainable params: 21045611
2025-02-05 00:48:34,871 [der.py] => Learning on 15-25
2025-02-05 00:48:34,872 [der.py] => All params: 42091068
2025-02-05 00:48:34,872 [der.py] => Trainable params: 21049456
2025-02-05 00:49:58,576 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-05 00:49:58,577 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 00:50:23,783 [der.py] => Exemplar size: 450
2025-02-05 00:50:23,784 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-05 00:50:23,784 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-05 00:50:23,784 [trainer.py] => CNN top1 curve: [89.44]
2025-02-05 00:50:23,784 [trainer.py] => CNN top5 curve: [98.93]
2025-02-05 00:50:23,784 [trainer.py] => NME top1 curve: [88.22]
2025-02-05 00:50:23,784 [trainer.py] => NME top5 curve: [98.81]

2025-02-05 00:50:23,784 [trainer.py] => All params: 21045611
2025-02-05 00:50:23,785 [trainer.py] => Trainable params: 21045611
2025-02-05 00:50:23,940 [der.py] => Learning on 15-25
2025-02-05 00:50:23,941 [der.py] => All params: 42091068
2025-02-05 00:50:23,941 [der.py] => Trainable params: 21049456
2025-02-05 01:09:40,022 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-02-05 01:09:52,766 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.114,  Train_accy 44.77, Test_accy 53.31
2025-02-05 01:10:01,202 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.597,  Train_accy 70.13
2025-02-05 01:10:09,602 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.414,  Train_accy 78.67
2025-02-05 01:10:18,085 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.294,  Train_accy 85.48
2025-02-05 01:10:26,575 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.236,  Train_accy 87.48
2025-02-05 01:10:39,252 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.191,  Train_accy 91.01, Test_accy 74.33
2025-02-05 01:10:47,673 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.169,  Train_accy 90.99
2025-02-05 01:10:56,087 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.132,  Train_accy 93.89
2025-02-05 01:11:04,539 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.119,  Train_accy 94.02
2025-02-05 01:11:12,878 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.115,  Train_accy 94.02
2025-02-05 01:11:25,561 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.094,  Train_accy 95.40, Test_accy 76.44
2025-02-05 01:11:34,126 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.083,  Train_accy 95.44
2025-02-05 01:11:42,535 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.071,  Train_accy 95.74
2025-02-05 01:11:51,005 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.068,  Train_accy 96.02
2025-02-05 01:11:59,433 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.064,  Train_accy 96.19
2025-02-05 01:12:12,167 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.073,  Train_accy 95.76, Test_accy 78.04
2025-02-05 01:12:20,742 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.062,  Train_accy 96.04
2025-02-05 01:12:29,327 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.058,  Train_accy 96.13
2025-02-05 01:12:37,865 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.053,  Train_accy 96.92
2025-02-05 01:12:46,208 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.055,  Train_accy 96.69
2025-02-05 01:12:58,887 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.042,  Train_accy 97.01, Test_accy 80.24
2025-02-05 01:13:07,300 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.041,  Train_accy 96.90
2025-02-05 01:13:15,684 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.037,  Train_accy 97.18
2025-02-05 01:13:24,199 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.036,  Train_accy 97.14
2025-02-05 01:13:32,633 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.033,  Train_accy 97.23
2025-02-05 01:13:45,366 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.030,  Train_accy 97.12, Test_accy 80.44
2025-02-05 01:13:53,740 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.031,  Train_accy 97.23
2025-02-05 01:14:02,188 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.026,  Train_accy 97.33
2025-02-05 01:14:10,727 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.025,  Train_accy 97.20
2025-02-05 01:14:19,267 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.026,  Train_accy 97.18
2025-02-05 01:14:32,527 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.026,  Train_accy 97.03, Test_accy 80.40
2025-02-05 01:14:40,855 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.029,  Train_accy 97.10
2025-02-05 01:14:49,286 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.019,  Train_accy 97.46
2025-02-05 01:14:57,727 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.016,  Train_accy 97.63
2025-02-05 01:15:06,319 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.016,  Train_accy 97.31
2025-02-05 01:15:08,231 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-02-05 01:15:18,826 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.016,  Train_accy 97.63, Test_accy 80.91
2025-02-05 01:15:23,539 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.123,  Train_accy 44.65, Test_accy 54.04
2025-02-05 01:15:27,532 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.015,  Train_accy 97.40
2025-02-05 01:15:33,632 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.612,  Train_accy 69.85
2025-02-05 01:15:35,897 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.019,  Train_accy 97.16
2025-02-05 01:15:43,691 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.431,  Train_accy 78.49
2025-02-05 01:15:44,237 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.017,  Train_accy 97.51
2025-02-05 01:15:52,844 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.012,  Train_accy 97.78
2025-02-05 01:15:53,743 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.311,  Train_accy 85.59
2025-02-05 01:16:03,884 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.254,  Train_accy 87.31
2025-02-05 01:16:05,406 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.010,  Train_accy 97.55, Test_accy 81.13
2025-02-05 01:16:13,688 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.013,  Train_accy 97.59
2025-02-05 01:16:19,176 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.210,  Train_accy 90.37, Test_accy 74.64
2025-02-05 01:16:22,130 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.015,  Train_accy 97.10
2025-02-05 01:16:29,247 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.186,  Train_accy 90.56
2025-02-05 01:16:30,568 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.005,  Train_accy 97.40
2025-02-05 01:16:38,879 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.005,  Train_accy 97.68
2025-02-05 01:16:39,260 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.149,  Train_accy 93.59
2025-02-05 01:16:49,600 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.137,  Train_accy 93.68
2025-02-05 01:16:51,529 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.011,  Train_accy 97.70, Test_accy 80.93
2025-02-05 01:16:59,812 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.010,  Train_accy 97.01
2025-02-05 01:16:59,840 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.132,  Train_accy 93.78
2025-02-05 01:17:08,167 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.004,  Train_accy 97.66
2025-02-05 01:17:14,991 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.112,  Train_accy 95.27, Test_accy 76.04
2025-02-05 01:17:16,703 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.009,  Train_accy 97.78
2025-02-05 01:17:24,996 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.009,  Train_accy 97.94
2025-02-05 01:17:25,012 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.101,  Train_accy 94.84
2025-02-05 01:17:35,108 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.090,  Train_accy 95.51
2025-02-05 01:17:37,792 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.007,  Train_accy 97.42, Test_accy 81.18
2025-02-05 01:17:45,441 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.088,  Train_accy 95.40
2025-02-05 01:17:46,156 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.007,  Train_accy 97.44
2025-02-05 01:17:54,805 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.006,  Train_accy 97.48
2025-02-05 01:17:55,458 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.084,  Train_accy 95.63
2025-02-05 01:18:03,134 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.008,  Train_accy 97.70
2025-02-05 01:18:10,723 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.094,  Train_accy 95.23, Test_accy 76.82
2025-02-05 01:18:11,582 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.006,  Train_accy 97.46
2025-02-05 01:18:20,789 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.083,  Train_accy 95.78
2025-02-05 01:18:24,352 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.999,  Train_accy 97.57, Test_accy 81.84
2025-02-05 01:18:31,288 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.077,  Train_accy 95.76
2025-02-05 01:18:32,656 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.997,  Train_accy 97.74
2025-02-05 01:18:41,076 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.000,  Train_accy 97.59
2025-02-05 01:18:41,323 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.072,  Train_accy 96.67
2025-02-05 01:18:49,374 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.999,  Train_accy 97.81
2025-02-05 01:18:51,456 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.075,  Train_accy 96.04
2025-02-05 01:18:57,732 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.997,  Train_accy 97.68
2025-02-05 01:19:06,543 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.062,  Train_accy 96.73, Test_accy 79.73
2025-02-05 01:19:10,492 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.994,  Train_accy 97.66, Test_accy 81.09
2025-02-05 01:19:16,909 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.060,  Train_accy 96.54
2025-02-05 01:19:18,783 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.998,  Train_accy 97.70
2025-02-05 01:19:27,072 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.056,  Train_accy 96.80
2025-02-05 01:19:27,136 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.998,  Train_accy 97.66
2025-02-05 01:19:35,472 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.999,  Train_accy 97.57
2025-02-05 01:19:37,191 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.057,  Train_accy 96.84
2025-02-05 01:19:43,699 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.994,  Train_accy 97.85
2025-02-05 01:19:47,276 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.052,  Train_accy 96.67
2025-02-05 01:19:56,209 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.993,  Train_accy 97.38, Test_accy 81.24
2025-02-05 01:20:02,447 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.049,  Train_accy 96.69, Test_accy 80.89
2025-02-05 01:20:04,910 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.995,  Train_accy 97.57
2025-02-05 01:20:12,498 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.050,  Train_accy 96.54
2025-02-05 01:20:13,386 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.997,  Train_accy 97.51
2025-02-05 01:20:21,920 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.997,  Train_accy 98.06
2025-02-05 01:20:22,563 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.046,  Train_accy 96.99
2025-02-05 01:20:30,253 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.997,  Train_accy 97.55
2025-02-05 01:20:32,704 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.042,  Train_accy 96.82
2025-02-05 01:20:42,795 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.995,  Train_accy 97.66, Test_accy 81.47
2025-02-05 01:20:42,848 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.045,  Train_accy 97.03
2025-02-05 01:20:51,209 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.995,  Train_accy 97.91
2025-02-05 01:20:58,228 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.046,  Train_accy 96.73, Test_accy 80.24
2025-02-05 01:20:59,786 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.991,  Train_accy 97.76
2025-02-05 01:21:08,063 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.997,  Train_accy 97.53
2025-02-05 01:21:08,298 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.047,  Train_accy 96.77
2025-02-05 01:21:16,473 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.992,  Train_accy 97.94
2025-02-05 01:21:18,666 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.036,  Train_accy 97.29
2025-02-05 01:21:28,913 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.035,  Train_accy 97.25
2025-02-05 01:21:29,024 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.993,  Train_accy 97.51, Test_accy 81.09
2025-02-05 01:21:37,338 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.995,  Train_accy 97.91
2025-02-05 01:21:39,091 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.034,  Train_accy 96.92
2025-02-05 01:21:45,794 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.991,  Train_accy 97.74
2025-02-05 01:21:54,258 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.991,  Train_accy 98.11
2025-02-05 01:21:54,307 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.035,  Train_accy 97.18, Test_accy 80.82
2025-02-05 01:22:02,831 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.994,  Train_accy 97.72
2025-02-05 01:22:04,389 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.034,  Train_accy 97.18
2025-02-05 01:22:14,617 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.038,  Train_accy 96.88
2025-02-05 01:22:15,298 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.990,  Train_accy 97.83, Test_accy 81.44
2025-02-05 01:22:23,797 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.995,  Train_accy 97.66
2025-02-05 01:22:24,675 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.036,  Train_accy 96.90
2025-02-05 01:22:32,216 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.993,  Train_accy 97.55
2025-02-05 01:22:34,884 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.030,  Train_accy 97.29
2025-02-05 01:22:40,658 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.990,  Train_accy 97.57
2025-02-05 01:22:49,114 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.989,  Train_accy 97.72
2025-02-05 01:22:49,852 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.029,  Train_accy 97.01, Test_accy 81.76
2025-02-05 01:23:00,053 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.031,  Train_accy 97.18
2025-02-05 01:23:01,621 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.986,  Train_accy 98.06, Test_accy 81.73
2025-02-05 01:23:10,078 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.990,  Train_accy 97.74
2025-02-05 01:23:10,280 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.033,  Train_accy 97.03
2025-02-05 01:23:18,444 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.992,  Train_accy 97.63
2025-02-05 01:23:20,500 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.023,  Train_accy 97.10
2025-02-05 01:23:26,740 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.990,  Train_accy 97.94
2025-02-05 01:23:30,690 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.023,  Train_accy 97.48
2025-02-05 01:23:35,172 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.988,  Train_accy 97.63
2025-02-05 01:23:45,931 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.029,  Train_accy 97.38, Test_accy 81.00
2025-02-05 01:23:47,968 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.989,  Train_accy 97.35, Test_accy 82.31
2025-02-05 01:23:56,214 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.028,  Train_accy 96.73
2025-02-05 01:23:56,315 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.988,  Train_accy 98.02
2025-02-05 01:24:04,813 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.986,  Train_accy 97.98
2025-02-05 01:24:06,240 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.023,  Train_accy 97.14
2025-02-05 01:24:13,166 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.988,  Train_accy 97.91
2025-02-05 01:24:16,399 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.029,  Train_accy 97.29
2025-02-05 01:24:21,611 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.989,  Train_accy 97.61
2025-02-05 01:24:26,569 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.028,  Train_accy 97.38
2025-02-05 01:24:34,078 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.985,  Train_accy 97.74, Test_accy 81.96
2025-02-05 01:24:41,789 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.026,  Train_accy 96.99, Test_accy 80.80
2025-02-05 01:24:42,640 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.987,  Train_accy 97.85
2025-02-05 01:24:51,072 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.987,  Train_accy 97.96
2025-02-05 01:24:51,886 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.025,  Train_accy 97.08
2025-02-05 01:24:59,435 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.985,  Train_accy 97.83
2025-02-05 01:25:02,029 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.024,  Train_accy 97.08
2025-02-05 01:25:07,907 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.992,  Train_accy 97.59
2025-02-05 01:25:12,083 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.026,  Train_accy 97.55
2025-02-05 01:25:20,472 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.987,  Train_accy 97.61, Test_accy 82.07
2025-02-05 01:25:22,328 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.024,  Train_accy 97.03
2025-02-05 01:25:28,928 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.988,  Train_accy 97.70
2025-02-05 01:25:37,256 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.985,  Train_accy 98.04
2025-02-05 01:25:37,393 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.018,  Train_accy 97.14, Test_accy 82.02
2025-02-05 01:25:45,705 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.985,  Train_accy 97.83
2025-02-05 01:25:47,667 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.016,  Train_accy 97.33
2025-02-05 01:25:54,035 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.986,  Train_accy 97.72
2025-02-05 01:25:57,844 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.019,  Train_accy 97.01
2025-02-05 01:26:06,520 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.982,  Train_accy 98.02, Test_accy 81.73
2025-02-05 01:26:08,068 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.018,  Train_accy 97.57
2025-02-05 01:26:15,043 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.983,  Train_accy 97.72
2025-02-05 01:26:18,321 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.015,  Train_accy 97.53
2025-02-05 01:26:23,515 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.989,  Train_accy 97.85
2025-02-05 01:26:31,973 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.983,  Train_accy 97.85
2025-02-05 01:26:33,468 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.012,  Train_accy 97.38, Test_accy 81.11
2025-02-05 01:26:40,322 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.987,  Train_accy 97.66
2025-02-05 01:26:43,684 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.017,  Train_accy 97.31
2025-02-05 01:26:53,016 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.986,  Train_accy 97.89, Test_accy 81.49
2025-02-05 01:26:53,882 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.016,  Train_accy 97.31
2025-02-05 01:27:01,377 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.985,  Train_accy 98.00
2025-02-05 01:27:04,013 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.017,  Train_accy 97.20
2025-02-05 01:27:09,716 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.985,  Train_accy 97.81
2025-02-05 01:27:14,176 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.013,  Train_accy 97.51
2025-02-05 01:27:18,215 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.985,  Train_accy 97.98
2025-02-05 01:27:27,128 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.985,  Train_accy 97.91
2025-02-05 01:27:29,159 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.012,  Train_accy 96.97, Test_accy 81.20
2025-02-05 01:27:39,389 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.013,  Train_accy 97.31
2025-02-05 01:27:39,622 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.985,  Train_accy 98.02, Test_accy 81.64
2025-02-05 01:27:48,051 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.983,  Train_accy 97.81
2025-02-05 01:27:49,429 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.016,  Train_accy 97.12
2025-02-05 01:27:56,421 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.984,  Train_accy 97.76
2025-02-05 01:27:59,582 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.016,  Train_accy 97.74
2025-02-05 01:28:04,880 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.986,  Train_accy 97.96
2025-02-05 01:28:09,674 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.015,  Train_accy 97.16
2025-02-05 01:28:13,285 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.986,  Train_accy 97.91
2025-02-05 01:28:24,945 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.013,  Train_accy 97.25, Test_accy 81.96
2025-02-05 01:28:26,114 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.985,  Train_accy 97.96, Test_accy 81.98
2025-02-05 01:28:34,589 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.987,  Train_accy 98.04
2025-02-05 01:28:35,179 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.014,  Train_accy 97.51
2025-02-05 01:28:42,965 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.984,  Train_accy 98.00
2025-02-05 01:28:45,364 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.010,  Train_accy 97.55
2025-02-05 01:28:51,496 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.982,  Train_accy 98.04
2025-02-05 01:28:55,528 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.015,  Train_accy 97.10
2025-02-05 01:28:59,834 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.983,  Train_accy 97.70
2025-02-05 01:29:05,560 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.011,  Train_accy 97.51
2025-02-05 01:29:12,376 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.981,  Train_accy 98.00, Test_accy 81.98
2025-02-05 01:29:20,710 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.986,  Train_accy 97.94
2025-02-05 01:29:21,129 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.011,  Train_accy 97.12, Test_accy 81.27
2025-02-05 01:29:29,049 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.986,  Train_accy 97.87
2025-02-05 01:29:31,434 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.014,  Train_accy 97.68
2025-02-05 01:29:37,528 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.981,  Train_accy 97.85
2025-02-05 01:29:41,556 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.010,  Train_accy 97.33
2025-02-05 01:29:45,836 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.982,  Train_accy 97.85
2025-02-05 01:29:45,837 [der.py] => do not weight align student!
2025-02-05 01:29:49,814 [der.py] => darknet eval: 
2025-02-05 01:29:49,814 [der.py] => CNN top1 curve: 81.67
2025-02-05 01:29:49,814 [der.py] => CNN top5 curve: 98.11
2025-02-05 01:29:49,816 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 01:29:51,735 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.009,  Train_accy 97.72
2025-02-05 01:30:01,683 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.012,  Train_accy 97.25
2025-02-05 01:30:16,714 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.008,  Train_accy 97.55, Test_accy 81.47
2025-02-05 01:30:25,919 [der.py] => Exemplar size: 750
2025-02-05 01:30:25,919 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-02-05 01:30:25,919 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-02-05 01:30:25,919 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-02-05 01:30:25,919 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-02-05 01:30:25,919 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-02-05 01:30:25,919 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-02-05 01:30:25,920 [trainer.py] => All params: 42091068
2025-02-05 01:30:25,920 [trainer.py] => Trainable params: 21049456
2025-02-05 01:30:26,064 [der.py] => Learning on 25-35
2025-02-05 01:30:26,065 [der.py] => All params: 42093638
2025-02-05 01:30:26,065 [der.py] => Trainable params: 21052026
2025-02-05 01:30:26,972 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.013,  Train_accy 97.42
2025-02-05 01:30:37,088 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.011,  Train_accy 97.29
2025-02-05 01:30:47,267 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.009,  Train_accy 97.18
2025-02-05 01:30:57,282 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.007,  Train_accy 97.35
2025-02-05 01:31:12,431 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.004,  Train_accy 97.63, Test_accy 82.07
2025-02-05 01:31:22,528 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.008,  Train_accy 97.27
2025-02-05 01:31:32,631 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.010,  Train_accy 97.40
2025-02-05 01:31:42,701 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.008,  Train_accy 97.63
2025-02-05 01:31:52,811 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.007,  Train_accy 97.14
2025-02-05 01:32:08,273 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.008,  Train_accy 97.03, Test_accy 81.98
2025-02-05 01:32:18,379 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.007,  Train_accy 97.61
2025-02-05 01:32:28,454 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.005,  Train_accy 97.70
2025-02-05 01:32:38,565 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.005,  Train_accy 97.53
2025-02-05 01:32:48,590 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.007,  Train_accy 97.31
2025-02-05 01:33:04,031 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.004,  Train_accy 97.40, Test_accy 81.64
2025-02-05 01:33:14,118 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.006,  Train_accy 97.57
2025-02-05 01:33:24,162 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.005,  Train_accy 97.48
2025-02-05 01:33:34,296 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.004,  Train_accy 97.51
2025-02-05 01:33:44,568 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.010,  Train_accy 97.44
2025-02-05 01:33:59,664 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.006,  Train_accy 97.29, Test_accy 81.87
2025-02-05 01:34:09,697 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.006,  Train_accy 97.44
2025-02-05 01:34:19,729 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.003,  Train_accy 97.61
2025-02-05 01:34:30,089 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.003,  Train_accy 97.53
2025-02-05 01:34:40,102 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.004,  Train_accy 97.18
2025-02-05 01:34:55,269 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.001,  Train_accy 97.72, Test_accy 81.60
2025-02-05 01:35:05,254 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.001,  Train_accy 97.38
2025-02-05 01:35:15,487 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.007,  Train_accy 97.48
2025-02-05 01:35:25,512 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.001,  Train_accy 97.51
2025-02-05 01:35:35,565 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.005,  Train_accy 97.35
2025-02-05 01:35:50,727 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.004,  Train_accy 97.68, Test_accy 81.56
2025-02-05 01:36:00,904 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.003,  Train_accy 97.63
2025-02-05 01:36:10,970 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.003,  Train_accy 97.40
2025-02-05 01:36:21,035 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.003,  Train_accy 97.66
2025-02-05 01:36:31,114 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.003,  Train_accy 97.48
2025-02-05 01:36:46,334 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.003,  Train_accy 97.51, Test_accy 81.42
2025-02-05 01:36:56,367 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.001,  Train_accy 97.40
2025-02-05 01:37:06,586 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.003,  Train_accy 97.44
2025-02-05 01:37:16,784 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.004,  Train_accy 97.61
2025-02-05 01:37:26,871 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.004,  Train_accy 97.55
2025-02-05 01:37:42,118 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.004,  Train_accy 97.55, Test_accy 81.91
2025-02-05 01:37:52,142 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.005,  Train_accy 97.70
2025-02-05 01:38:02,301 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.002,  Train_accy 97.44
2025-02-05 01:38:12,424 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.000,  Train_accy 97.48
2025-02-05 01:38:22,429 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.001,  Train_accy 97.46
2025-02-05 01:38:37,554 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.000,  Train_accy 97.83, Test_accy 81.93
2025-02-05 01:38:47,555 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.004,  Train_accy 97.46
2025-02-05 01:38:57,710 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.004,  Train_accy 97.44
2025-02-05 01:39:07,748 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.999,  Train_accy 97.48
2025-02-05 01:39:17,713 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.000,  Train_accy 97.63
2025-02-05 01:39:17,713 [der.py] => do not weight align student!
2025-02-05 01:39:22,292 [der.py] => darknet eval: 
2025-02-05 01:39:22,292 [der.py] => CNN top1 curve: 81.36
2025-02-05 01:39:22,292 [der.py] => CNN top5 curve: 98.11
2025-02-05 01:39:22,293 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 01:39:56,843 [der.py] => Exemplar size: 750
2025-02-05 01:39:56,843 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-02-05 01:39:56,843 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-02-05 01:39:56,843 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-02-05 01:39:56,843 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-02-05 01:39:56,843 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-02-05 01:39:56,844 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-02-05 01:39:56,844 [trainer.py] => All params: 42091068
2025-02-05 01:39:56,845 [trainer.py] => Trainable params: 21049456
2025-02-05 01:39:56,999 [der.py] => Learning on 25-35
2025-02-05 01:39:57,000 [der.py] => All params: 42093638
2025-02-05 01:39:57,000 [der.py] => Trainable params: 21052026
2025-02-05 01:53:01,351 [der.py] => Task 2, Epoch 150/150 => Loss 0.011, Loss_clf 0.006, Loss_aux 0.005, Train_accy 100.00
2025-02-05 01:53:15,629 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.251,  Train_accy 45.92, Test_accy 57.27
2025-02-05 01:53:24,533 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.916,  Train_accy 68.06
2025-02-05 01:53:33,405 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.789,  Train_accy 76.14
2025-02-05 01:53:42,257 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.724,  Train_accy 80.85
2025-02-05 01:53:51,352 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.685,  Train_accy 83.52
2025-02-05 01:54:06,039 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.653,  Train_accy 85.41, Test_accy 64.62
2025-02-05 01:54:14,920 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.635,  Train_accy 86.00
2025-02-05 01:54:23,765 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.621,  Train_accy 87.19
2025-02-05 01:54:32,695 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.600,  Train_accy 88.24
2025-02-05 01:54:41,580 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.595,  Train_accy 88.18
2025-02-05 01:54:56,047 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.578,  Train_accy 89.66, Test_accy 69.84
2025-02-05 01:55:04,835 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.564,  Train_accy 90.42
2025-02-05 01:55:13,771 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.558,  Train_accy 90.97
2025-02-05 01:55:22,617 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.558,  Train_accy 89.96
2025-02-05 01:55:31,434 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.552,  Train_accy 91.31
2025-02-05 01:55:45,850 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.546,  Train_accy 91.76, Test_accy 68.90
2025-02-05 01:55:54,935 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.541,  Train_accy 92.04
2025-02-05 01:56:04,041 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.535,  Train_accy 92.16
2025-02-05 01:56:12,915 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.533,  Train_accy 91.70
2025-02-05 01:56:21,903 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.524,  Train_accy 92.93
2025-02-05 01:56:36,139 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.527,  Train_accy 92.97, Test_accy 70.06
2025-02-05 01:56:45,342 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.527,  Train_accy 92.20
2025-02-05 01:56:54,271 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.525,  Train_accy 92.42
2025-02-05 01:57:03,282 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.517,  Train_accy 92.93
2025-02-05 01:57:12,146 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.511,  Train_accy 93.60
2025-02-05 01:57:26,616 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.508,  Train_accy 93.43, Test_accy 72.33
2025-02-05 01:57:35,502 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.504,  Train_accy 93.64
2025-02-05 01:57:44,365 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.502,  Train_accy 93.88
2025-02-05 01:57:53,331 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.503,  Train_accy 93.37
2025-02-05 01:58:02,388 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.500,  Train_accy 93.92
2025-02-05 01:58:16,801 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.501,  Train_accy 93.98, Test_accy 72.00
2025-02-05 01:58:25,747 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.500,  Train_accy 93.52
2025-02-05 01:58:34,726 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.495,  Train_accy 94.06
2025-02-05 01:58:43,559 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.495,  Train_accy 94.20
2025-02-05 01:58:52,487 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.492,  Train_accy 94.10
2025-02-05 01:59:06,877 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.493,  Train_accy 94.00, Test_accy 72.37
2025-02-05 01:59:15,748 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.490,  Train_accy 93.74
2025-02-05 01:59:24,867 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.490,  Train_accy 94.16
2025-02-05 01:59:33,935 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.487,  Train_accy 94.32
2025-02-05 01:59:42,908 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.484,  Train_accy 94.30
2025-02-05 01:59:57,167 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.490,  Train_accy 93.98, Test_accy 73.35
2025-02-05 02:00:06,163 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.484,  Train_accy 94.79
2025-02-05 02:00:15,131 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.485,  Train_accy 94.55
2025-02-05 02:00:24,038 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.485,  Train_accy 94.36
2025-02-05 02:00:33,009 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.481,  Train_accy 94.30
2025-02-05 02:00:47,407 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.481,  Train_accy 94.85, Test_accy 73.40
2025-02-05 02:00:56,345 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.481,  Train_accy 94.22
2025-02-05 02:01:05,184 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.480,  Train_accy 94.67
2025-02-05 02:01:14,147 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.481,  Train_accy 94.26
2025-02-05 02:01:23,001 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.476,  Train_accy 94.81
2025-02-05 02:01:37,250 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.475,  Train_accy 94.51, Test_accy 73.49
2025-02-05 02:01:46,087 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.478,  Train_accy 94.69
2025-02-05 02:01:55,109 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.479,  Train_accy 94.48
2025-02-05 02:02:04,031 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.472,  Train_accy 94.97
2025-02-05 02:02:13,154 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.475,  Train_accy 94.67
2025-02-05 02:02:27,480 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.473,  Train_accy 94.95, Test_accy 74.17
2025-02-05 02:02:36,320 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.471,  Train_accy 95.31
2025-02-05 02:02:45,359 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.474,  Train_accy 94.67
2025-02-05 02:02:54,189 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.473,  Train_accy 95.17
2025-02-05 02:03:03,277 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.469,  Train_accy 94.95
2025-02-05 02:03:17,606 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.471,  Train_accy 94.61, Test_accy 74.05
2025-02-05 02:03:26,527 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.468,  Train_accy 95.19
2025-02-05 02:03:35,585 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.475,  Train_accy 94.79
2025-02-05 02:03:44,415 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.467,  Train_accy 95.23
2025-02-05 02:03:53,360 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.468,  Train_accy 95.07
2025-02-05 02:04:07,739 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.467,  Train_accy 95.07, Test_accy 74.21
2025-02-05 02:04:16,640 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.467,  Train_accy 95.27
2025-02-05 02:04:25,457 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.466,  Train_accy 95.15
2025-02-05 02:04:34,439 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.464,  Train_accy 95.05
2025-02-05 02:04:43,262 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.462,  Train_accy 94.99
2025-02-05 02:04:57,832 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.466,  Train_accy 95.15, Test_accy 74.19
2025-02-05 02:05:06,690 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.465,  Train_accy 95.41
2025-02-05 02:05:15,553 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.467,  Train_accy 95.47
2025-02-05 02:05:24,482 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.461,  Train_accy 95.52
2025-02-05 02:05:33,325 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.464,  Train_accy 94.91
2025-02-05 02:05:48,021 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.463,  Train_accy 95.29, Test_accy 74.10
2025-02-05 02:05:56,823 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.463,  Train_accy 94.97
2025-02-05 02:06:05,801 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.461,  Train_accy 95.78
2025-02-05 02:06:14,696 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.463,  Train_accy 95.21
2025-02-05 02:06:23,678 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.461,  Train_accy 95.27
2025-02-05 02:06:38,019 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.460,  Train_accy 95.29, Test_accy 73.83
2025-02-05 02:06:47,093 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.461,  Train_accy 95.25
2025-02-05 02:06:55,916 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.455,  Train_accy 95.56
2025-02-05 02:07:04,798 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.456,  Train_accy 95.49
2025-02-05 02:07:13,823 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.460,  Train_accy 95.72
2025-02-05 02:07:21,778 [der.py] => Task 2, Epoch 150/150 => Loss 0.012, Loss_clf 0.006, Loss_aux 0.006, Train_accy 100.00
2025-02-05 02:07:28,245 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.458,  Train_accy 95.31, Test_accy 74.37
2025-02-05 02:07:37,250 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.455,  Train_accy 95.41
2025-02-05 02:07:39,274 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.268,  Train_accy 45.27, Test_accy 56.60
2025-02-05 02:07:46,108 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.457,  Train_accy 95.33
2025-02-05 02:07:49,884 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.934,  Train_accy 67.37
2025-02-05 02:07:55,053 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.456,  Train_accy 95.60
2025-02-05 02:08:00,602 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.812,  Train_accy 74.91
2025-02-05 02:08:03,887 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.457,  Train_accy 95.72
2025-02-05 02:08:11,270 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.745,  Train_accy 79.88
2025-02-05 02:08:18,161 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.454,  Train_accy 95.19, Test_accy 74.32
2025-02-05 02:08:22,084 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.708,  Train_accy 82.67
2025-02-05 02:08:27,015 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.456,  Train_accy 95.37
2025-02-05 02:08:35,867 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.456,  Train_accy 95.35
2025-02-05 02:08:39,514 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.681,  Train_accy 84.48, Test_accy 65.98
2025-02-05 02:08:44,939 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.454,  Train_accy 95.45
2025-02-05 02:08:50,196 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.661,  Train_accy 84.83
2025-02-05 02:08:53,818 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.454,  Train_accy 95.58
2025-02-05 02:09:00,888 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.646,  Train_accy 86.36
2025-02-05 02:09:08,173 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.454,  Train_accy 95.58, Test_accy 74.89
2025-02-05 02:09:11,645 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.634,  Train_accy 87.13
2025-02-05 02:09:16,986 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.453,  Train_accy 95.76
2025-02-05 02:09:22,446 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.623,  Train_accy 87.47
2025-02-05 02:09:25,930 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.454,  Train_accy 95.58
2025-02-05 02:09:34,767 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.451,  Train_accy 95.64
2025-02-05 02:09:39,591 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.610,  Train_accy 88.22, Test_accy 70.67
2025-02-05 02:09:43,777 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.452,  Train_accy 95.56
2025-02-05 02:09:50,228 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.597,  Train_accy 89.05
2025-02-05 02:09:58,114 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.455,  Train_accy 95.66, Test_accy 74.56
2025-02-05 02:10:01,046 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.590,  Train_accy 90.06
2025-02-05 02:10:07,013 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.456,  Train_accy 95.23
2025-02-05 02:10:11,684 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.589,  Train_accy 89.47
2025-02-05 02:10:15,877 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.455,  Train_accy 95.74
2025-02-05 02:10:22,403 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.581,  Train_accy 90.63
2025-02-05 02:10:24,732 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.452,  Train_accy 95.56
2025-02-05 02:10:33,634 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.451,  Train_accy 95.72
2025-02-05 02:10:39,714 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.578,  Train_accy 90.24, Test_accy 70.03
2025-02-05 02:10:48,188 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.452,  Train_accy 95.76, Test_accy 74.67
2025-02-05 02:10:50,569 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.574,  Train_accy 90.79
2025-02-05 02:10:56,969 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.453,  Train_accy 95.76
2025-02-05 02:11:01,278 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.567,  Train_accy 90.87
2025-02-05 02:11:05,815 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.451,  Train_accy 95.86
2025-02-05 02:11:12,031 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.563,  Train_accy 90.83
2025-02-05 02:11:14,724 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.454,  Train_accy 95.41
2025-02-05 02:11:22,715 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.557,  Train_accy 91.78
2025-02-05 02:11:23,606 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.452,  Train_accy 95.70
2025-02-05 02:11:38,062 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.452,  Train_accy 95.76, Test_accy 74.65
2025-02-05 02:11:40,242 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.565,  Train_accy 91.94, Test_accy 70.84
2025-02-05 02:11:46,912 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.452,  Train_accy 95.70
2025-02-05 02:11:51,048 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.561,  Train_accy 91.60
2025-02-05 02:11:55,827 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.451,  Train_accy 95.72
2025-02-05 02:12:01,753 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.556,  Train_accy 91.49
2025-02-05 02:12:04,686 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.450,  Train_accy 95.82
2025-02-05 02:12:12,449 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.549,  Train_accy 91.72
2025-02-05 02:12:13,497 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.452,  Train_accy 95.58
2025-02-05 02:12:23,001 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.547,  Train_accy 92.26
2025-02-05 02:12:27,918 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.451,  Train_accy 95.49, Test_accy 74.79
2025-02-05 02:12:36,717 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.452,  Train_accy 95.49
2025-02-05 02:12:40,583 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.543,  Train_accy 92.02, Test_accy 73.57
2025-02-05 02:12:45,751 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.452,  Train_accy 95.76
2025-02-05 02:12:51,272 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.537,  Train_accy 92.48
2025-02-05 02:12:54,561 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.452,  Train_accy 95.84
2025-02-05 02:13:01,905 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.536,  Train_accy 92.59
2025-02-05 02:13:03,487 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.454,  Train_accy 95.47
2025-02-05 02:13:12,672 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.537,  Train_accy 91.84
2025-02-05 02:13:17,772 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.452,  Train_accy 95.62, Test_accy 74.67
2025-02-05 02:13:23,736 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.533,  Train_accy 92.59
2025-02-05 02:13:26,710 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.450,  Train_accy 95.62
2025-02-05 02:13:35,585 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.453,  Train_accy 95.43
2025-02-05 02:13:40,895 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.535,  Train_accy 93.23, Test_accy 72.87
2025-02-05 02:13:44,680 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.453,  Train_accy 95.33
2025-02-05 02:13:51,653 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.533,  Train_accy 92.00
2025-02-05 02:13:53,622 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.451,  Train_accy 95.43
2025-02-05 02:14:02,811 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.530,  Train_accy 92.85
2025-02-05 02:14:07,825 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.451,  Train_accy 95.62, Test_accy 74.71
2025-02-05 02:14:13,911 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.532,  Train_accy 92.59
2025-02-05 02:14:16,724 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.453,  Train_accy 95.09
2025-02-05 02:14:24,571 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.527,  Train_accy 92.75
2025-02-05 02:14:25,593 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.452,  Train_accy 95.54
2025-02-05 02:14:34,577 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.452,  Train_accy 95.56
2025-02-05 02:14:41,771 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.527,  Train_accy 92.93, Test_accy 72.94
2025-02-05 02:14:43,542 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.451,  Train_accy 95.52
2025-02-05 02:14:43,542 [der.py] => do not weight align student!
2025-02-05 02:14:48,711 [der.py] => darknet eval: 
2025-02-05 02:14:48,711 [der.py] => CNN top1 curve: 75.03
2025-02-05 02:14:48,711 [der.py] => CNN top5 curve: 96.06
2025-02-05 02:14:48,713 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 02:14:52,706 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.525,  Train_accy 92.71
2025-02-05 02:15:03,176 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.524,  Train_accy 92.79
2025-02-05 02:15:13,739 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.522,  Train_accy 92.93
2025-02-05 02:15:24,400 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.521,  Train_accy 93.09
2025-02-05 02:15:33,853 [der.py] => Exemplar size: 1050
2025-02-05 02:15:33,853 [trainer.py] => CNN: {'total': 79.33, '0': 88.89, '1': 59.44, '2': 82.22, '3': 63.89, '4': 77.22, '5': 41.67, '6': 63.89, '7': 53.33, '8': 40.0, '9': 50.0, '10': 90.0, '11': 93.89, '12': 75.0, '13': 65.0, '14': 63.89, '15': 94.44, '16': 99.44, '17': 97.22, '18': 93.89, '19': 96.11, '20': 96.67, '21': 92.22, '22': 94.44, '23': 84.44, '24': 85.0, '25': 81.11, '26': 81.67, '27': 86.11, '28': 68.89, '29': 78.89, '30': 85.0, '31': 86.11, '32': 96.67, '33': 83.33, 'old': 77.69, 'new': 83.44}
2025-02-05 02:15:33,853 [trainer.py] => NME: {'total': 75.76, '0': 84.44, '1': 55.56, '2': 70.56, '3': 59.44, '4': 77.78, '5': 37.22, '6': 54.44, '7': 53.89, '8': 45.56, '9': 56.67, '10': 91.67, '11': 90.56, '12': 68.33, '13': 55.56, '14': 58.89, '15': 90.56, '16': 91.67, '17': 93.33, '18': 87.78, '19': 90.56, '20': 93.89, '21': 87.78, '22': 82.78, '23': 67.22, '24': 63.89, '25': 84.44, '26': 94.44, '27': 87.78, '28': 66.11, '29': 81.11, '30': 83.89, '31': 86.67, '32': 95.0, '33': 77.78, 'old': 72.4, 'new': 84.17}
2025-02-05 02:15:33,853 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.33]
2025-02-05 02:15:33,853 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.83]
2025-02-05 02:15:33,853 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.76]
2025-02-05 02:15:33,853 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.05]

2025-02-05 02:15:33,854 [trainer.py] => All params: 42093638
2025-02-05 02:15:33,854 [trainer.py] => Trainable params: 21052026
2025-02-05 02:15:33,992 [der.py] => Learning on 35-45
2025-02-05 02:15:33,993 [der.py] => All params: 42096208
2025-02-05 02:15:33,993 [der.py] => Trainable params: 21054596
2025-02-05 02:15:41,683 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.523,  Train_accy 92.97, Test_accy 74.06
2025-02-05 02:15:52,421 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.516,  Train_accy 93.35
2025-02-05 02:16:03,076 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.520,  Train_accy 93.58
2025-02-05 02:16:13,777 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.519,  Train_accy 93.03
2025-02-05 02:16:24,379 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.515,  Train_accy 93.09
2025-02-05 02:16:41,877 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.516,  Train_accy 93.01, Test_accy 73.57
2025-02-05 02:16:52,565 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.516,  Train_accy 93.29
2025-02-05 02:17:03,163 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.513,  Train_accy 93.56
2025-02-05 02:17:13,865 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.513,  Train_accy 93.27
2025-02-05 02:17:24,607 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.510,  Train_accy 93.60
2025-02-05 02:17:41,846 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.510,  Train_accy 93.68, Test_accy 73.71
2025-02-05 02:17:52,590 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.513,  Train_accy 93.86
2025-02-05 02:18:03,260 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.513,  Train_accy 93.43
2025-02-05 02:18:14,026 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.507,  Train_accy 93.47
2025-02-05 02:18:24,675 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.508,  Train_accy 93.43
2025-02-05 02:18:41,970 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.509,  Train_accy 93.94, Test_accy 74.06
2025-02-05 02:18:52,650 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.505,  Train_accy 93.80
2025-02-05 02:19:03,444 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.508,  Train_accy 93.80
2025-02-05 02:19:14,128 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.508,  Train_accy 93.84
2025-02-05 02:19:24,759 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.505,  Train_accy 93.78
2025-02-05 02:19:41,909 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.506,  Train_accy 93.47, Test_accy 74.00
2025-02-05 02:19:52,911 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.504,  Train_accy 93.90
2025-02-05 02:20:03,617 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.510,  Train_accy 94.30
2025-02-05 02:20:14,313 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.502,  Train_accy 93.94
2025-02-05 02:20:25,002 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.501,  Train_accy 93.66
2025-02-05 02:20:42,434 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.501,  Train_accy 93.90, Test_accy 74.78
2025-02-05 02:20:53,235 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.501,  Train_accy 94.14
2025-02-05 02:21:03,863 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.500,  Train_accy 93.94
2025-02-05 02:21:14,534 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.499,  Train_accy 93.84
2025-02-05 02:21:25,144 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.497,  Train_accy 93.78
2025-02-05 02:21:42,883 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.501,  Train_accy 94.46, Test_accy 74.29
2025-02-05 02:21:53,534 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.499,  Train_accy 94.02
2025-02-05 02:22:04,231 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.499,  Train_accy 94.02
2025-02-05 02:22:14,827 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.495,  Train_accy 94.42
2025-02-05 02:22:25,619 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.497,  Train_accy 93.82
2025-02-05 02:22:42,897 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.497,  Train_accy 94.42, Test_accy 74.21
2025-02-05 02:22:53,540 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.496,  Train_accy 94.02
2025-02-05 02:23:04,327 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.495,  Train_accy 94.00
2025-02-05 02:23:15,157 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.497,  Train_accy 94.00
2025-02-05 02:23:25,831 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.493,  Train_accy 94.46
2025-02-05 02:23:42,945 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.496,  Train_accy 93.92, Test_accy 73.87
2025-02-05 02:23:53,750 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.495,  Train_accy 94.53
2025-02-05 02:24:04,536 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.489,  Train_accy 94.51
2025-02-05 02:24:15,112 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.490,  Train_accy 94.40
2025-02-05 02:24:25,867 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.494,  Train_accy 94.10
2025-02-05 02:24:43,252 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.493,  Train_accy 94.16, Test_accy 74.05
2025-02-05 02:24:54,190 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.490,  Train_accy 94.40
2025-02-05 02:25:04,710 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.491,  Train_accy 94.67
2025-02-05 02:25:15,391 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.491,  Train_accy 94.18
2025-02-05 02:25:26,041 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.492,  Train_accy 94.38
2025-02-05 02:25:43,505 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.488,  Train_accy 94.26, Test_accy 74.76
2025-02-05 02:25:54,210 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.490,  Train_accy 94.24
2025-02-05 02:26:04,976 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.491,  Train_accy 94.46
2025-02-05 02:26:15,575 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.489,  Train_accy 94.16
2025-02-05 02:26:26,237 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.488,  Train_accy 94.65
2025-02-05 02:26:43,422 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.489,  Train_accy 94.04, Test_accy 74.92
2025-02-05 02:26:54,130 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.487,  Train_accy 94.40
2025-02-05 02:27:04,711 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.487,  Train_accy 94.48
2025-02-05 02:27:15,865 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.486,  Train_accy 94.44
2025-02-05 02:27:26,705 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.487,  Train_accy 94.97
2025-02-05 02:27:43,943 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.489,  Train_accy 94.53, Test_accy 75.14
2025-02-05 02:27:54,651 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.489,  Train_accy 94.83
2025-02-05 02:28:05,843 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.489,  Train_accy 94.73
2025-02-05 02:28:16,630 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.487,  Train_accy 94.51
2025-02-05 02:28:27,258 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.486,  Train_accy 94.48
2025-02-05 02:28:44,561 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.485,  Train_accy 94.46, Test_accy 74.95
2025-02-05 02:28:55,180 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.487,  Train_accy 94.34
2025-02-05 02:29:05,709 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.486,  Train_accy 94.44
2025-02-05 02:29:16,237 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.489,  Train_accy 94.36
2025-02-05 02:29:26,696 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.486,  Train_accy 94.36
2025-02-05 02:29:43,702 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.486,  Train_accy 94.34, Test_accy 74.97
2025-02-05 02:29:54,189 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.487,  Train_accy 94.79
2025-02-05 02:30:04,731 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.485,  Train_accy 94.42
2025-02-05 02:30:15,279 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.483,  Train_accy 94.67
2025-02-05 02:30:25,785 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.486,  Train_accy 94.59
2025-02-05 02:30:42,800 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.486,  Train_accy 94.79, Test_accy 74.87
2025-02-05 02:30:53,300 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.486,  Train_accy 94.55
2025-02-05 02:31:03,866 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.486,  Train_accy 94.55
2025-02-05 02:31:14,479 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.487,  Train_accy 94.51
2025-02-05 02:31:25,025 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.487,  Train_accy 94.18
2025-02-05 02:31:41,810 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.486,  Train_accy 94.65, Test_accy 74.89
2025-02-05 02:31:52,375 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.485,  Train_accy 94.53
2025-02-05 02:32:02,946 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.488,  Train_accy 94.36
2025-02-05 02:32:13,448 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.487,  Train_accy 94.36
2025-02-05 02:32:24,032 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.486,  Train_accy 94.28
2025-02-05 02:32:41,136 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.485,  Train_accy 94.61, Test_accy 75.21
2025-02-05 02:32:51,740 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.487,  Train_accy 94.04
2025-02-05 02:33:02,246 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.486,  Train_accy 94.69
2025-02-05 02:33:12,812 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.486,  Train_accy 94.48
2025-02-05 02:33:23,289 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.485,  Train_accy 94.51
2025-02-05 02:33:23,290 [der.py] => do not weight align student!
2025-02-05 02:33:28,886 [der.py] => darknet eval: 
2025-02-05 02:33:28,886 [der.py] => CNN top1 curve: 75.0
2025-02-05 02:33:28,886 [der.py] => CNN top5 curve: 96.05
2025-02-05 02:33:28,887 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 02:34:10,399 [der.py] => Exemplar size: 1050
2025-02-05 02:34:10,399 [trainer.py] => CNN: {'total': 78.4, '0': 87.78, '1': 58.89, '2': 80.56, '3': 61.11, '4': 73.33, '5': 40.0, '6': 62.22, '7': 51.11, '8': 38.33, '9': 49.44, '10': 90.0, '11': 94.44, '12': 73.33, '13': 63.33, '14': 61.67, '15': 95.0, '16': 99.44, '17': 96.11, '18': 93.33, '19': 96.67, '20': 97.22, '21': 93.33, '22': 94.44, '23': 83.89, '24': 80.0, '25': 82.78, '26': 82.22, '27': 83.33, '28': 67.22, '29': 80.0, '30': 86.11, '31': 83.33, '32': 96.67, '33': 80.56, 'old': 76.6, 'new': 82.89}
2025-02-05 02:34:10,399 [trainer.py] => NME: {'total': 75.71, '0': 86.11, '1': 58.33, '2': 73.89, '3': 61.11, '4': 75.56, '5': 36.67, '6': 50.0, '7': 56.67, '8': 43.89, '9': 56.67, '10': 91.11, '11': 95.56, '12': 67.78, '13': 55.0, '14': 58.33, '15': 87.78, '16': 94.44, '17': 92.78, '18': 88.89, '19': 91.11, '20': 92.78, '21': 92.22, '22': 82.78, '23': 62.22, '24': 65.56, '25': 83.89, '26': 93.89, '27': 88.33, '28': 61.67, '29': 79.44, '30': 86.11, '31': 83.33, '32': 97.22, '33': 75.56, 'old': 72.69, 'new': 83.28}
2025-02-05 02:34:10,400 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.4]
2025-02-05 02:34:10,400 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.62]
2025-02-05 02:34:10,400 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.71]
2025-02-05 02:34:10,400 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.62]

2025-02-05 02:34:10,400 [trainer.py] => All params: 42093638
2025-02-05 02:34:10,401 [trainer.py] => Trainable params: 21052026
2025-02-05 02:34:10,547 [der.py] => Learning on 35-45
2025-02-05 02:34:10,548 [der.py] => All params: 42096208
2025-02-05 02:34:10,548 [der.py] => Trainable params: 21054596
2025-02-05 02:39:59,497 [der.py] => Task 3, Epoch 150/150 => Loss 0.147, Loss_clf 0.080, Loss_aux 0.067, Train_accy 99.90
2025-02-05 02:40:15,859 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.967,  Train_accy 45.79, Test_accy 46.33
2025-02-05 02:40:25,611 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.724,  Train_accy 56.78
2025-02-05 02:40:34,987 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.569,  Train_accy 62.88
2025-02-05 02:40:44,464 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.506,  Train_accy 65.24
2025-02-05 02:40:53,830 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.517,  Train_accy 66.40
2025-02-05 02:41:09,912 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.525,  Train_accy 67.31, Test_accy 56.09
2025-02-05 02:41:19,300 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.492,  Train_accy 67.70
2025-02-05 02:41:28,689 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.419,  Train_accy 69.92
2025-02-05 02:41:38,169 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.418,  Train_accy 70.36
2025-02-05 02:41:47,554 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.434,  Train_accy 70.72
2025-02-05 02:42:03,937 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.397,  Train_accy 71.52, Test_accy 58.12
2025-02-05 02:42:13,507 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.398,  Train_accy 72.86
2025-02-05 02:42:22,908 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.424,  Train_accy 71.12
2025-02-05 02:42:32,593 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.397,  Train_accy 72.04
2025-02-05 02:42:42,156 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.365,  Train_accy 72.34
2025-02-05 02:42:58,483 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.346,  Train_accy 72.53, Test_accy 61.33
2025-02-05 02:43:07,938 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.394,  Train_accy 72.10
2025-02-05 02:43:17,555 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.375,  Train_accy 73.09
2025-02-05 02:43:27,185 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.346,  Train_accy 73.64
2025-02-05 02:43:36,575 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.365,  Train_accy 73.07
2025-02-05 02:43:52,775 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.365,  Train_accy 74.04, Test_accy 62.40
2025-02-05 02:44:02,057 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.415,  Train_accy 71.71
2025-02-05 02:44:11,511 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.358,  Train_accy 73.81
2025-02-05 02:44:20,889 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.351,  Train_accy 74.10
2025-02-05 02:44:30,325 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.345,  Train_accy 73.26
2025-02-05 02:44:46,343 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.353,  Train_accy 74.36, Test_accy 64.10
2025-02-05 02:44:55,819 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.307,  Train_accy 74.67
2025-02-05 02:45:05,220 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.342,  Train_accy 74.06
2025-02-05 02:45:14,863 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.344,  Train_accy 74.44
2025-02-05 02:45:24,346 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.330,  Train_accy 74.84
2025-02-05 02:45:41,355 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.316,  Train_accy 74.76, Test_accy 60.16
2025-02-05 02:45:51,258 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.327,  Train_accy 74.78
2025-02-05 02:46:00,814 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.301,  Train_accy 74.78
2025-02-05 02:46:10,350 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.300,  Train_accy 74.61
2025-02-05 02:46:19,805 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.332,  Train_accy 73.54
2025-02-05 02:46:35,803 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.312,  Train_accy 75.01, Test_accy 63.62
2025-02-05 02:46:45,242 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.332,  Train_accy 74.59
2025-02-05 02:46:54,637 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.315,  Train_accy 74.86
2025-02-05 02:47:04,431 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.314,  Train_accy 75.37
2025-02-05 02:47:14,098 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.299,  Train_accy 74.74
2025-02-05 02:47:30,052 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.303,  Train_accy 75.24, Test_accy 63.79
2025-02-05 02:47:39,376 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.302,  Train_accy 75.12
2025-02-05 02:47:48,870 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.315,  Train_accy 75.31
2025-02-05 02:47:58,205 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.298,  Train_accy 75.47
2025-02-05 02:48:07,683 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.303,  Train_accy 74.82
2025-02-05 02:48:23,890 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.307,  Train_accy 75.01, Test_accy 61.48
2025-02-05 02:48:33,428 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.296,  Train_accy 75.28
2025-02-05 02:48:42,803 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.289,  Train_accy 75.45
2025-02-05 02:48:52,219 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.312,  Train_accy 75.30
2025-02-05 02:49:01,868 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.294,  Train_accy 75.01
2025-02-05 02:49:18,476 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.295,  Train_accy 75.49, Test_accy 55.17
2025-02-05 02:49:28,127 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.282,  Train_accy 75.68
2025-02-05 02:49:37,703 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.291,  Train_accy 75.70
2025-02-05 02:49:47,131 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.302,  Train_accy 75.41
2025-02-05 02:49:56,566 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.274,  Train_accy 75.77
2025-02-05 02:50:13,328 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.268,  Train_accy 75.79, Test_accy 60.73
2025-02-05 02:50:22,913 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.292,  Train_accy 75.68
2025-02-05 02:50:32,269 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.284,  Train_accy 75.73
2025-02-05 02:50:41,624 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.273,  Train_accy 75.94
2025-02-05 02:50:51,141 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.296,  Train_accy 75.85
2025-02-05 02:51:07,426 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.288,  Train_accy 75.35, Test_accy 63.93
2025-02-05 02:51:16,829 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.280,  Train_accy 75.73
2025-02-05 02:51:26,410 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.273,  Train_accy 75.85
2025-02-05 02:51:35,947 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.288,  Train_accy 75.45
2025-02-05 02:51:45,418 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.267,  Train_accy 75.70
2025-02-05 02:52:01,951 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.276,  Train_accy 76.00, Test_accy 61.31
2025-02-05 02:52:11,313 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.292,  Train_accy 75.66
2025-02-05 02:52:20,750 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.273,  Train_accy 75.35
2025-02-05 02:52:30,157 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.258,  Train_accy 76.13
2025-02-05 02:52:39,618 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.278,  Train_accy 75.39
2025-02-05 02:52:55,673 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.257,  Train_accy 75.85, Test_accy 63.72
2025-02-05 02:53:05,180 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.273,  Train_accy 75.35
2025-02-05 02:53:14,524 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.263,  Train_accy 76.02
2025-02-05 02:53:24,037 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.250,  Train_accy 76.04
2025-02-05 02:53:33,421 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.284,  Train_accy 76.23
2025-02-05 02:53:49,344 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.267,  Train_accy 75.54, Test_accy 59.28
2025-02-05 02:53:58,808 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.266,  Train_accy 76.80
2025-02-05 02:54:08,341 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.257,  Train_accy 76.55
2025-02-05 02:54:17,764 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.273,  Train_accy 75.54
2025-02-05 02:54:27,175 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.289,  Train_accy 75.70
2025-02-05 02:54:43,105 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.274,  Train_accy 75.58, Test_accy 64.27
2025-02-05 02:54:52,589 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.248,  Train_accy 75.37
2025-02-05 02:55:02,216 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.260,  Train_accy 76.44
2025-02-05 02:55:11,880 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.257,  Train_accy 76.13
2025-02-05 02:55:21,523 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.255,  Train_accy 75.87
2025-02-05 02:55:37,647 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.273,  Train_accy 76.50, Test_accy 65.38
2025-02-05 02:55:47,193 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.263,  Train_accy 75.62
2025-02-05 02:55:56,814 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.251,  Train_accy 76.51
2025-02-05 02:56:06,444 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.244,  Train_accy 76.29
2025-02-05 02:56:16,016 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.251,  Train_accy 75.98
2025-02-05 02:56:32,523 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.264,  Train_accy 75.75, Test_accy 65.42
2025-02-05 02:56:41,854 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.236,  Train_accy 76.17
2025-02-05 02:56:51,377 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.253,  Train_accy 76.25
2025-02-05 02:57:00,928 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.259,  Train_accy 75.68
2025-02-05 02:57:10,426 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.261,  Train_accy 76.11
2025-02-05 02:57:26,426 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.256,  Train_accy 76.02, Test_accy 65.28
2025-02-05 02:57:35,961 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.256,  Train_accy 76.44
2025-02-05 02:57:45,379 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.246,  Train_accy 77.03
2025-02-05 02:57:55,032 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.256,  Train_accy 75.94
2025-02-05 02:58:04,326 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.252,  Train_accy 76.04
2025-02-05 02:58:20,282 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.256,  Train_accy 76.46, Test_accy 63.25
2025-02-05 02:58:29,645 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.258,  Train_accy 75.64
2025-02-05 02:58:39,142 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.257,  Train_accy 76.67
2025-02-05 02:58:48,575 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.263,  Train_accy 76.15
2025-02-05 02:58:58,028 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.257,  Train_accy 76.11
2025-02-05 02:59:13,987 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.253,  Train_accy 76.02, Test_accy 65.69
2025-02-05 02:59:23,439 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.258,  Train_accy 76.72
2025-02-05 02:59:32,809 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.246,  Train_accy 76.25
2025-02-05 02:59:42,239 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.251,  Train_accy 75.81
2025-02-05 02:59:51,634 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.247,  Train_accy 75.92
2025-02-05 03:00:07,632 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.242,  Train_accy 76.42, Test_accy 60.74
2025-02-05 03:00:16,954 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.245,  Train_accy 76.44
2025-02-05 03:00:26,394 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.249,  Train_accy 75.89
2025-02-05 03:00:35,745 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.235,  Train_accy 75.77
2025-02-05 03:00:45,219 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.240,  Train_accy 75.96
2025-02-05 03:01:01,360 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.236,  Train_accy 76.95, Test_accy 64.57
2025-02-05 03:01:10,956 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.246,  Train_accy 76.04
2025-02-05 03:01:20,352 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.260,  Train_accy 76.36
2025-02-05 03:01:29,802 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.259,  Train_accy 76.69
2025-02-05 03:01:39,182 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.236,  Train_accy 75.92
2025-02-05 03:01:55,337 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.253,  Train_accy 76.40, Test_accy 65.62
2025-02-05 03:02:04,646 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.250,  Train_accy 76.36
2025-02-05 03:02:14,016 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.232,  Train_accy 76.40
2025-02-05 03:02:23,381 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.235,  Train_accy 76.55
2025-02-05 03:02:32,674 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.255,  Train_accy 76.10
2025-02-05 03:02:48,863 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.247,  Train_accy 76.67, Test_accy 65.15
2025-02-05 03:02:58,233 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.249,  Train_accy 76.46
2025-02-05 03:03:07,716 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.235,  Train_accy 75.96
2025-02-05 03:03:17,181 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.246,  Train_accy 76.74
2025-02-05 03:03:23,534 [der.py] => Task 3, Epoch 150/150 => Loss 0.211, Loss_clf 0.144, Loss_aux 0.067, Train_accy 99.92
2025-02-05 03:03:26,709 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.253,  Train_accy 76.17
2025-02-05 03:03:26,709 [der.py] => do not weight align student!
2025-02-05 03:03:32,939 [der.py] => darknet eval: 
2025-02-05 03:03:32,939 [der.py] => CNN top1 curve: 61.63
2025-02-05 03:03:32,939 [der.py] => CNN top5 curve: 91.15
2025-02-05 03:03:32,945 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 03:03:42,570 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.938,  Train_accy 46.21, Test_accy 40.60
2025-02-05 03:03:53,508 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.510,  Train_accy 60.95
2025-02-05 03:04:04,562 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.372,  Train_accy 67.03
2025-02-05 03:04:15,735 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.303,  Train_accy 69.87
2025-02-05 03:04:26,938 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.301,  Train_accy 72.15
2025-02-05 03:04:27,989 [der.py] => Exemplar size: 1350
2025-02-05 03:04:27,989 [trainer.py] => CNN: {'total': 71.11, '0': 84.44, '1': 46.67, '2': 64.44, '3': 57.22, '4': 70.56, '5': 25.0, '6': 53.33, '7': 46.11, '8': 27.78, '9': 48.89, '10': 84.44, '11': 88.89, '12': 61.11, '13': 60.56, '14': 48.89, '15': 96.11, '16': 87.22, '17': 86.67, '18': 75.56, '19': 82.78, '20': 85.56, '21': 85.0, '22': 81.67, '23': 61.11, '24': 54.44, '25': 83.89, '26': 89.44, '27': 88.33, '28': 70.56, '29': 82.78, '30': 86.67, '31': 81.67, '32': 97.22, '33': 82.78, '34': 83.89, '35': 79.44, '36': 91.67, '37': 32.78, '38': 14.44, '39': 77.22, '40': 58.89, '41': 92.78, '42': 98.89, '43': 96.11, 'old': 71.76, 'new': 68.83}
2025-02-05 03:04:27,989 [trainer.py] => NME: {'total': 71.67, '0': 76.67, '1': 50.56, '2': 57.78, '3': 43.33, '4': 66.11, '5': 29.44, '6': 52.22, '7': 51.67, '8': 31.67, '9': 57.22, '10': 88.33, '11': 81.11, '12': 63.33, '13': 55.56, '14': 57.78, '15': 91.11, '16': 83.33, '17': 79.44, '18': 76.11, '19': 83.33, '20': 84.44, '21': 75.56, '22': 72.78, '23': 58.89, '24': 49.44, '25': 68.33, '26': 83.33, '27': 73.89, '28': 58.33, '29': 69.44, '30': 73.89, '31': 73.33, '32': 84.44, '33': 57.78, '34': 73.33, '35': 96.11, '36': 93.89, '37': 69.44, '38': 95.0, '39': 92.78, '40': 77.22, '41': 96.11, '42': 99.44, '43': 95.0, 'old': 66.67, 'new': 89.17}
2025-02-05 03:04:27,989 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.33, 71.11]
2025-02-05 03:04:27,989 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.83, 94.52]
2025-02-05 03:04:27,989 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.76, 71.67]
2025-02-05 03:04:27,989 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.05, 95.17]

2025-02-05 03:04:27,990 [trainer.py] => All params: 42096208
2025-02-05 03:04:27,990 [trainer.py] => Trainable params: 21054596
2025-02-05 03:04:28,138 [der.py] => Learning on 45-55
2025-02-05 03:04:28,139 [der.py] => All params: 42098778
2025-02-05 03:04:28,139 [der.py] => Trainable params: 21057166
2025-02-05 03:04:46,082 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.293,  Train_accy 72.51, Test_accy 45.01
2025-02-05 03:04:57,136 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.243,  Train_accy 71.89
2025-02-05 03:05:08,293 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.195,  Train_accy 75.03
2025-02-05 03:05:19,390 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.167,  Train_accy 75.49
2025-02-05 03:05:30,490 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.204,  Train_accy 76.30
2025-02-05 03:05:49,568 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.165,  Train_accy 76.76, Test_accy 55.53
2025-02-05 03:06:00,675 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.163,  Train_accy 77.35
2025-02-05 03:06:11,848 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.177,  Train_accy 76.25
2025-02-05 03:06:22,977 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.136,  Train_accy 77.52
2025-02-05 03:06:34,221 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.138,  Train_accy 77.41
2025-02-05 03:06:53,065 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.095,  Train_accy 77.54, Test_accy 59.70
2025-02-05 03:07:04,153 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.158,  Train_accy 76.63
2025-02-05 03:07:15,323 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.135,  Train_accy 77.35
2025-02-05 03:07:26,547 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.118,  Train_accy 78.55
2025-02-05 03:07:37,708 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.121,  Train_accy 78.13
2025-02-05 03:07:56,531 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.119,  Train_accy 79.09, Test_accy 60.53
2025-02-05 03:08:07,630 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.162,  Train_accy 76.90
2025-02-05 03:08:18,867 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.110,  Train_accy 78.97
2025-02-05 03:08:30,119 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.089,  Train_accy 79.58
2025-02-05 03:08:41,225 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.090,  Train_accy 79.26
2025-02-05 03:09:00,105 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.091,  Train_accy 79.47, Test_accy 62.60
2025-02-05 03:09:11,402 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.064,  Train_accy 79.92
2025-02-05 03:09:22,545 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.103,  Train_accy 79.58
2025-02-05 03:09:33,607 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.081,  Train_accy 80.04
2025-02-05 03:09:44,757 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.068,  Train_accy 79.89
2025-02-05 03:10:03,957 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.049,  Train_accy 80.65, Test_accy 59.64
2025-02-05 03:10:15,016 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.064,  Train_accy 80.21
2025-02-05 03:10:26,105 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.044,  Train_accy 80.40
2025-02-05 03:10:37,263 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.043,  Train_accy 79.92
2025-02-05 03:10:48,494 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.081,  Train_accy 78.78
2025-02-05 03:11:07,589 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.051,  Train_accy 80.36, Test_accy 62.48
2025-02-05 03:11:18,650 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.064,  Train_accy 80.08
2025-02-05 03:11:29,731 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.074,  Train_accy 79.77
2025-02-05 03:11:40,846 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.058,  Train_accy 79.89
2025-02-05 03:11:52,133 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.057,  Train_accy 80.46
2025-02-05 03:12:11,211 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.059,  Train_accy 80.76, Test_accy 61.46
2025-02-05 03:12:22,323 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.041,  Train_accy 80.08
2025-02-05 03:12:33,469 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.054,  Train_accy 80.72
2025-02-05 03:12:44,724 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.065,  Train_accy 80.51
2025-02-05 03:12:55,877 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.055,  Train_accy 80.46
2025-02-05 03:13:14,933 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.055,  Train_accy 80.02, Test_accy 62.83
2025-02-05 03:13:25,975 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.047,  Train_accy 80.38
2025-02-05 03:13:37,170 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.021,  Train_accy 80.82
2025-02-05 03:13:48,302 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.067,  Train_accy 79.96
2025-02-05 03:13:59,392 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.038,  Train_accy 81.09
2025-02-05 03:14:18,387 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.038,  Train_accy 81.24, Test_accy 58.81
2025-02-05 03:14:29,697 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.024,  Train_accy 80.65
2025-02-05 03:14:40,874 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.043,  Train_accy 80.63
2025-02-05 03:14:52,012 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.044,  Train_accy 80.34
2025-02-05 03:15:03,164 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.027,  Train_accy 80.86
2025-02-05 03:15:22,350 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.019,  Train_accy 81.12, Test_accy 63.67
2025-02-05 03:15:33,375 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.046,  Train_accy 80.95
2025-02-05 03:15:44,454 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.036,  Train_accy 81.14
2025-02-05 03:15:55,598 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.030,  Train_accy 81.22
2025-02-05 03:16:06,718 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.031,  Train_accy 80.93
2025-02-05 03:16:25,581 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.037,  Train_accy 80.59, Test_accy 64.89
2025-02-05 03:16:36,659 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.030,  Train_accy 80.48
2025-02-05 03:16:47,797 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.017,  Train_accy 80.51
2025-02-05 03:16:58,900 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.036,  Train_accy 81.12
2025-02-05 03:17:10,120 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.018,  Train_accy 81.16
2025-02-05 03:17:28,941 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.020,  Train_accy 80.93, Test_accy 66.72
2025-02-05 03:17:40,034 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.041,  Train_accy 81.22
2025-02-05 03:17:51,176 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.023,  Train_accy 80.61
2025-02-05 03:18:02,366 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.008,  Train_accy 80.95
2025-02-05 03:18:13,402 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.027,  Train_accy 81.37
2025-02-05 03:18:32,355 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.005,  Train_accy 80.80, Test_accy 65.37
2025-02-05 03:18:43,478 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.018,  Train_accy 80.90
2025-02-05 03:18:54,788 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.013,  Train_accy 81.09
2025-02-05 03:19:05,901 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 0.997,  Train_accy 81.37
2025-02-05 03:19:17,024 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.031,  Train_accy 81.54
2025-02-05 03:19:36,324 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.016,  Train_accy 81.10, Test_accy 61.74
2025-02-05 03:19:47,551 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.015,  Train_accy 81.37
2025-02-05 03:19:58,631 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.011,  Train_accy 81.35
2025-02-05 03:20:09,749 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.019,  Train_accy 80.93
2025-02-05 03:20:20,861 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.035,  Train_accy 81.16
2025-02-05 03:20:39,949 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.017,  Train_accy 81.26, Test_accy 65.07
2025-02-05 03:20:51,045 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 0.990,  Train_accy 81.07
2025-02-05 03:21:02,236 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.013,  Train_accy 81.09
2025-02-05 03:21:13,298 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.001,  Train_accy 81.10
2025-02-05 03:21:24,466 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 0.990,  Train_accy 81.37
2025-02-05 03:21:43,463 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.024,  Train_accy 81.49, Test_accy 65.43
2025-02-05 03:21:54,566 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.013,  Train_accy 80.93
2025-02-05 03:22:05,609 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 0.998,  Train_accy 81.73
2025-02-05 03:22:16,838 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 0.990,  Train_accy 81.41
2025-02-05 03:22:27,947 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 0.995,  Train_accy 80.99
2025-02-05 03:22:46,871 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.011,  Train_accy 81.37, Test_accy 65.81
2025-02-05 03:22:57,960 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.980,  Train_accy 80.91
2025-02-05 03:23:09,167 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.003,  Train_accy 81.30
2025-02-05 03:23:20,331 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.003,  Train_accy 81.01
2025-02-05 03:23:31,483 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 0.997,  Train_accy 81.22
2025-02-05 03:23:50,288 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 0.988,  Train_accy 81.66, Test_accy 65.42
2025-02-05 03:24:01,429 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 0.985,  Train_accy 81.35
2025-02-05 03:24:12,631 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.005,  Train_accy 81.26
2025-02-05 03:24:23,852 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.010,  Train_accy 81.14
2025-02-05 03:24:35,019 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.005,  Train_accy 81.16
2025-02-05 03:24:54,734 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 0.998,  Train_accy 81.47, Test_accy 65.25
2025-02-05 03:25:06,011 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.006,  Train_accy 81.20
2025-02-05 03:25:17,270 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.009,  Train_accy 81.60
2025-02-05 03:25:28,655 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.017,  Train_accy 81.71
2025-02-05 03:25:39,962 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.010,  Train_accy 81.56
2025-02-05 03:25:59,540 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.003,  Train_accy 81.12, Test_accy 65.67
2025-02-05 03:26:10,844 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.011,  Train_accy 81.28
2025-02-05 03:26:22,156 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 0.984,  Train_accy 81.41
2025-02-05 03:26:33,492 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.000,  Train_accy 81.22
2025-02-05 03:26:45,032 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 0.996,  Train_accy 81.52
2025-02-05 03:27:04,479 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.000,  Train_accy 81.49, Test_accy 65.68
2025-02-05 03:27:15,846 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 0.992,  Train_accy 81.66
2025-02-05 03:27:27,200 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 0.996,  Train_accy 80.55
2025-02-05 03:27:38,574 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 0.997,  Train_accy 81.49
2025-02-05 03:27:49,798 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.984,  Train_accy 81.68
2025-02-05 03:28:09,079 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.984,  Train_accy 81.68, Test_accy 65.73
2025-02-05 03:28:20,417 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 0.990,  Train_accy 81.49
2025-02-05 03:28:31,803 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.009,  Train_accy 81.35
2025-02-05 03:28:43,019 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.007,  Train_accy 81.41
2025-02-05 03:28:54,383 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 0.978,  Train_accy 81.47
2025-02-05 03:29:13,820 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 0.996,  Train_accy 81.52, Test_accy 65.80
2025-02-05 03:29:25,175 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 0.987,  Train_accy 81.68
2025-02-05 03:29:36,407 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.979,  Train_accy 81.01
2025-02-05 03:29:47,740 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.982,  Train_accy 81.73
2025-02-05 03:29:58,935 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 0.998,  Train_accy 81.31
2025-02-05 03:30:18,515 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 0.995,  Train_accy 81.56, Test_accy 66.06
2025-02-05 03:30:29,822 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 0.995,  Train_accy 81.50
2025-02-05 03:30:40,867 [der.py] => Task 4, Epoch 150/150 => Loss 0.022, Loss_clf 0.014, Loss_aux 0.008, Train_accy 100.00
2025-02-05 03:30:41,066 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.981,  Train_accy 81.47
2025-02-05 03:30:52,409 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 0.996,  Train_accy 81.58
2025-02-05 03:30:58,619 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.866,  Train_accy 34.16, Test_accy 58.70
2025-02-05 03:31:03,997 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 0.988,  Train_accy 81.26
2025-02-05 03:31:03,998 [der.py] => do not weight align student!
2025-02-05 03:31:08,391 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.623,  Train_accy 52.56
2025-02-05 03:31:11,042 [der.py] => darknet eval: 
2025-02-05 03:31:11,043 [der.py] => CNN top1 curve: 63.46
2025-02-05 03:31:11,043 [der.py] => CNN top5 curve: 91.31
2025-02-05 03:31:11,044 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 03:31:18,153 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.510,  Train_accy 61.15
2025-02-05 03:31:27,709 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.442,  Train_accy 68.31
2025-02-05 03:31:37,415 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.400,  Train_accy 72.47
2025-02-05 03:31:54,959 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.366,  Train_accy 75.50, Test_accy 60.38
2025-02-05 03:32:03,443 [der.py] => Exemplar size: 1350
2025-02-05 03:32:03,443 [trainer.py] => CNN: {'total': 72.0, '0': 80.56, '1': 55.0, '2': 69.44, '3': 47.22, '4': 68.89, '5': 18.89, '6': 54.44, '7': 43.89, '8': 31.67, '9': 51.67, '10': 77.22, '11': 88.33, '12': 63.89, '13': 55.0, '14': 50.0, '15': 92.22, '16': 90.0, '17': 91.67, '18': 83.33, '19': 82.78, '20': 88.33, '21': 86.11, '22': 79.44, '23': 65.0, '24': 63.33, '25': 80.56, '26': 89.44, '27': 87.22, '28': 66.67, '29': 83.33, '30': 85.56, '31': 85.0, '32': 87.22, '33': 76.67, '34': 83.89, '35': 85.56, '36': 95.0, '37': 30.0, '38': 9.44, '39': 94.44, '40': 77.22, '41': 95.56, '42': 99.44, '43': 93.89, 'old': 71.54, 'new': 73.61}
2025-02-05 03:32:03,443 [trainer.py] => NME: {'total': 71.9, '0': 69.44, '1': 51.11, '2': 68.89, '3': 41.11, '4': 62.22, '5': 33.33, '6': 51.11, '7': 51.11, '8': 31.11, '9': 60.0, '10': 88.33, '11': 87.78, '12': 62.22, '13': 52.78, '14': 55.56, '15': 88.33, '16': 83.89, '17': 88.33, '18': 77.22, '19': 85.0, '20': 84.44, '21': 79.44, '22': 68.89, '23': 60.56, '24': 48.33, '25': 65.0, '26': 80.56, '27': 74.44, '28': 60.0, '29': 71.67, '30': 72.78, '31': 80.56, '32': 78.33, '33': 60.56, '34': 75.0, '35': 95.56, '36': 88.89, '37': 69.44, '38': 95.56, '39': 95.0, '40': 80.56, '41': 90.56, '42': 100.0, '43': 94.44, 'old': 67.13, 'new': 88.61}
2025-02-05 03:32:03,443 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.4, 72.0]
2025-02-05 03:32:03,443 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.62, 94.19]
2025-02-05 03:32:03,443 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.71, 71.9]
2025-02-05 03:32:03,443 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.62, 95.26]

2025-02-05 03:32:03,444 [trainer.py] => All params: 42096208
2025-02-05 03:32:03,445 [trainer.py] => Trainable params: 21054596
2025-02-05 03:32:03,584 [der.py] => Learning on 45-55
2025-02-05 03:32:03,585 [der.py] => All params: 42098778
2025-02-05 03:32:03,585 [der.py] => Trainable params: 21057166
2025-02-05 03:32:05,109 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.346,  Train_accy 76.97
2025-02-05 03:32:14,855 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.323,  Train_accy 79.51
2025-02-05 03:32:24,914 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.308,  Train_accy 80.92
2025-02-05 03:32:34,651 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.299,  Train_accy 82.04
2025-02-05 03:32:52,362 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.288,  Train_accy 82.56, Test_accy 64.02
2025-02-05 03:33:02,168 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.285,  Train_accy 84.23
2025-02-05 03:33:12,180 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.270,  Train_accy 84.36
2025-02-05 03:33:22,071 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.265,  Train_accy 85.03
2025-02-05 03:33:32,037 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.260,  Train_accy 84.97
2025-02-05 03:33:49,840 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.258,  Train_accy 86.38, Test_accy 65.27
2025-02-05 03:33:59,569 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.254,  Train_accy 85.98
2025-02-05 03:34:09,368 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.246,  Train_accy 86.76
2025-02-05 03:34:19,119 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.247,  Train_accy 86.79
2025-02-05 03:34:28,961 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.244,  Train_accy 86.88
2025-02-05 03:34:46,703 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.239,  Train_accy 87.69, Test_accy 64.48
2025-02-05 03:34:56,602 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.234,  Train_accy 87.84
2025-02-05 03:35:06,421 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.230,  Train_accy 88.05
2025-02-05 03:35:16,272 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.229,  Train_accy 88.47
2025-02-05 03:35:26,115 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.228,  Train_accy 88.04
2025-02-05 03:35:43,907 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.227,  Train_accy 88.88, Test_accy 64.86
2025-02-05 03:35:53,637 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.225,  Train_accy 88.77
2025-02-05 03:36:03,488 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.219,  Train_accy 88.38
2025-02-05 03:36:13,351 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.215,  Train_accy 88.95
2025-02-05 03:36:23,216 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.213,  Train_accy 89.50
2025-02-05 03:36:41,024 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.219,  Train_accy 88.90, Test_accy 65.32
2025-02-05 03:36:50,919 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.215,  Train_accy 89.46
2025-02-05 03:37:00,650 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.210,  Train_accy 90.09
2025-02-05 03:37:10,487 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.212,  Train_accy 90.07
2025-02-05 03:37:20,250 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.203,  Train_accy 90.34
2025-02-05 03:37:37,966 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.206,  Train_accy 89.60, Test_accy 66.11
2025-02-05 03:37:47,848 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.206,  Train_accy 90.18
2025-02-05 03:37:57,787 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.200,  Train_accy 90.40
2025-02-05 03:38:07,568 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.199,  Train_accy 90.07
2025-02-05 03:38:17,410 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.200,  Train_accy 90.25
2025-02-05 03:38:34,948 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.198,  Train_accy 90.67, Test_accy 66.47
2025-02-05 03:38:44,882 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.195,  Train_accy 90.43
2025-02-05 03:38:54,646 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.202,  Train_accy 91.14
2025-02-05 03:39:04,491 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.197,  Train_accy 90.83
2025-02-05 03:39:14,352 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.196,  Train_accy 90.59
2025-02-05 03:39:32,437 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.195,  Train_accy 91.19, Test_accy 66.55
2025-02-05 03:39:42,335 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.193,  Train_accy 91.50
2025-02-05 03:39:52,114 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.195,  Train_accy 90.83
2025-02-05 03:40:02,104 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.194,  Train_accy 91.33
2025-02-05 03:40:12,109 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.189,  Train_accy 91.71
2025-02-05 03:40:30,104 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.189,  Train_accy 91.48, Test_accy 66.48
2025-02-05 03:40:39,874 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.190,  Train_accy 91.44
2025-02-05 03:40:49,802 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.189,  Train_accy 91.05
2025-02-05 03:40:59,647 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.181,  Train_accy 91.59
2025-02-05 03:41:09,443 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.185,  Train_accy 91.48
2025-02-05 03:41:27,064 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.186,  Train_accy 92.00, Test_accy 66.64
2025-02-05 03:41:36,993 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.185,  Train_accy 91.68
2025-02-05 03:41:46,872 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.182,  Train_accy 91.71
2025-02-05 03:41:57,118 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.181,  Train_accy 91.14
2025-02-05 03:42:06,893 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.186,  Train_accy 91.21
2025-02-05 03:42:24,825 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.184,  Train_accy 92.11, Test_accy 66.78
2025-02-05 03:42:34,658 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.179,  Train_accy 91.82
2025-02-05 03:42:44,523 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.179,  Train_accy 91.93
2025-02-05 03:42:54,316 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.182,  Train_accy 91.78
2025-02-05 03:43:04,312 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.177,  Train_accy 92.04
2025-02-05 03:43:22,044 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.178,  Train_accy 92.00, Test_accy 67.33
2025-02-05 03:43:31,859 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.179,  Train_accy 91.95
2025-02-05 03:43:41,630 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.175,  Train_accy 92.09
2025-02-05 03:43:51,494 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.173,  Train_accy 92.05
2025-02-05 03:44:01,360 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.175,  Train_accy 92.14
2025-02-05 03:44:19,065 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.173,  Train_accy 91.91, Test_accy 67.17
2025-02-05 03:44:28,885 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.175,  Train_accy 92.54
2025-02-05 03:44:38,880 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.175,  Train_accy 92.00
2025-02-05 03:44:48,747 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.175,  Train_accy 92.27
2025-02-05 03:44:58,686 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.173,  Train_accy 92.25
2025-02-05 03:45:16,627 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.170,  Train_accy 92.31, Test_accy 67.49
2025-02-05 03:45:26,497 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.172,  Train_accy 92.09
2025-02-05 03:45:36,362 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.169,  Train_accy 92.52
2025-02-05 03:45:46,489 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.172,  Train_accy 92.59
2025-02-05 03:45:56,374 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.172,  Train_accy 92.65
2025-02-05 03:46:14,961 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.171,  Train_accy 92.45, Test_accy 66.94
2025-02-05 03:46:24,852 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.173,  Train_accy 92.34
2025-02-05 03:46:34,780 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.165,  Train_accy 92.50
2025-02-05 03:46:44,672 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.169,  Train_accy 92.32
2025-02-05 03:46:54,624 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.172,  Train_accy 92.77
2025-02-05 03:47:12,816 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.169,  Train_accy 92.77, Test_accy 66.99
2025-02-05 03:47:22,642 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.172,  Train_accy 92.56
2025-02-05 03:47:32,600 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.170,  Train_accy 92.54
2025-02-05 03:47:42,424 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.170,  Train_accy 92.65
2025-02-05 03:47:52,276 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.165,  Train_accy 92.97
2025-02-05 03:48:09,751 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.169,  Train_accy 92.95, Test_accy 66.80
2025-02-05 03:48:19,713 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.165,  Train_accy 92.76
2025-02-05 03:48:29,499 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.165,  Train_accy 92.95
2025-02-05 03:48:39,430 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.165,  Train_accy 92.65
2025-02-05 03:48:49,200 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.166,  Train_accy 92.92
2025-02-05 03:49:06,907 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.165,  Train_accy 93.01, Test_accy 67.14
2025-02-05 03:49:16,777 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.166,  Train_accy 92.36
2025-02-05 03:49:26,725 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.167,  Train_accy 92.65
2025-02-05 03:49:36,597 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.165,  Train_accy 92.45
2025-02-05 03:49:46,554 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.165,  Train_accy 92.77
2025-02-05 03:50:04,035 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.165,  Train_accy 93.06, Test_accy 67.28
2025-02-05 03:50:13,887 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.165,  Train_accy 92.97
2025-02-05 03:50:23,719 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.163,  Train_accy 92.70
2025-02-05 03:50:33,654 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.160,  Train_accy 93.01
2025-02-05 03:50:43,515 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.164,  Train_accy 92.72
2025-02-05 03:51:01,120 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.162,  Train_accy 92.52, Test_accy 67.21
2025-02-05 03:51:10,965 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.163,  Train_accy 92.94
2025-02-05 03:51:20,858 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.165,  Train_accy 92.61
2025-02-05 03:51:30,618 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.163,  Train_accy 92.95
2025-02-05 03:51:40,494 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.165,  Train_accy 93.12
2025-02-05 03:51:58,129 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.164,  Train_accy 92.76, Test_accy 67.56
2025-02-05 03:52:08,009 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.162,  Train_accy 93.01
2025-02-05 03:52:17,897 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.160,  Train_accy 93.12
2025-02-05 03:52:27,750 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.162,  Train_accy 92.81
2025-02-05 03:52:37,683 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.164,  Train_accy 93.06
2025-02-05 03:52:55,564 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.159,  Train_accy 92.72, Test_accy 67.44
2025-02-05 03:53:05,509 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.158,  Train_accy 93.15
2025-02-05 03:53:15,351 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.159,  Train_accy 93.28
2025-02-05 03:53:25,156 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.160,  Train_accy 93.12
2025-02-05 03:53:35,119 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.164,  Train_accy 92.95
2025-02-05 03:53:52,823 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.161,  Train_accy 92.85, Test_accy 67.47
2025-02-05 03:54:02,624 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.162,  Train_accy 93.28
2025-02-05 03:54:12,514 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.160,  Train_accy 92.97
2025-02-05 03:54:22,401 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.163,  Train_accy 93.08
2025-02-05 03:54:32,208 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.163,  Train_accy 93.15
2025-02-05 03:54:49,957 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.162,  Train_accy 92.88, Test_accy 67.20
2025-02-05 03:54:59,822 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.161,  Train_accy 92.99
2025-02-05 03:55:09,641 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.158,  Train_accy 93.23
2025-02-05 03:55:19,461 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.161,  Train_accy 93.01
2025-02-05 03:55:29,251 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.160,  Train_accy 93.15
2025-02-05 03:55:29,252 [der.py] => do not weight align student!
2025-02-05 03:55:36,719 [der.py] => darknet eval: 
2025-02-05 03:55:36,719 [der.py] => CNN top1 curve: 67.65
2025-02-05 03:55:36,719 [der.py] => CNN top5 curve: 92.21
2025-02-05 03:55:36,721 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 03:56:41,488 [der.py] => Exemplar size: 1650
2025-02-05 03:56:41,488 [trainer.py] => CNN: {'total': 70.33, '0': 66.11, '1': 51.11, '2': 53.89, '3': 32.22, '4': 62.78, '5': 33.33, '6': 57.22, '7': 51.67, '8': 33.33, '9': 51.67, '10': 80.0, '11': 67.22, '12': 55.0, '13': 52.78, '14': 59.44, '15': 81.67, '16': 81.67, '17': 81.67, '18': 68.33, '19': 78.89, '20': 80.56, '21': 68.33, '22': 77.78, '23': 56.11, '24': 60.56, '25': 70.56, '26': 70.56, '27': 68.89, '28': 41.67, '29': 51.67, '30': 77.22, '31': 71.67, '32': 82.22, '33': 45.56, '34': 61.67, '35': 94.44, '36': 92.22, '37': 67.78, '38': 92.22, '39': 94.44, '40': 80.0, '41': 95.0, '42': 96.67, '43': 98.33, '44': 76.67, '45': 87.78, '46': 82.22, '47': 80.0, '48': 77.22, '49': 78.89, '50': 75.0, '51': 79.44, '52': 77.22, '53': 75.56, 'old': 68.28, 'new': 79.56}
2025-02-05 03:56:41,489 [trainer.py] => NME: {'total': 64.33, '0': 62.78, '1': 44.44, '2': 48.33, '3': 25.56, '4': 60.56, '5': 34.44, '6': 51.11, '7': 53.89, '8': 30.0, '9': 51.11, '10': 76.67, '11': 78.89, '12': 56.67, '13': 52.22, '14': 55.56, '15': 71.67, '16': 76.11, '17': 83.33, '18': 73.33, '19': 75.56, '20': 76.67, '21': 70.56, '22': 62.22, '23': 49.44, '24': 48.33, '25': 53.33, '26': 61.67, '27': 51.67, '28': 36.67, '29': 42.78, '30': 67.78, '31': 60.0, '32': 72.78, '33': 35.56, '34': 66.67, '35': 80.0, '36': 84.44, '37': 47.22, '38': 84.44, '39': 77.22, '40': 43.33, '41': 87.78, '42': 91.11, '43': 85.0, '44': 54.44, '45': 86.11, '46': 85.56, '47': 81.11, '48': 86.67, '49': 72.22, '50': 71.11, '51': 76.67, '52': 78.89, '53': 71.67, 'old': 61.19, 'new': 78.5}
2025-02-05 03:56:41,489 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.33, 71.11, 70.33]
2025-02-05 03:56:41,489 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.83, 94.52, 93.09]
2025-02-05 03:56:41,489 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.76, 71.67, 64.33]
2025-02-05 03:56:41,489 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.05, 95.17, 92.32]

2025-02-05 04:03:35,147 [der.py] => Task 4, Epoch 150/150 => Loss 0.020, Loss_clf 0.013, Loss_aux 0.007, Train_accy 99.98
2025-02-05 04:03:56,142 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.873,  Train_accy 32.29, Test_accy 57.03
2025-02-05 04:04:07,810 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.643,  Train_accy 48.14
2025-02-05 04:04:19,308 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.525,  Train_accy 58.27
2025-02-05 04:04:30,890 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.455,  Train_accy 66.02
2025-02-05 04:04:42,434 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.408,  Train_accy 71.89
2025-02-05 04:05:03,491 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.375,  Train_accy 74.16, Test_accy 61.04
2025-02-05 04:05:15,152 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.347,  Train_accy 77.33
2025-02-05 04:05:26,591 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.325,  Train_accy 79.68
2025-02-05 04:05:38,029 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.312,  Train_accy 80.56
2025-02-05 04:05:49,719 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.305,  Train_accy 81.24
2025-02-05 04:06:10,336 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.297,  Train_accy 82.38, Test_accy 62.86
2025-02-05 04:06:21,838 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.289,  Train_accy 83.03
2025-02-05 04:06:33,401 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.268,  Train_accy 85.17
2025-02-05 04:06:44,951 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.274,  Train_accy 84.58
2025-02-05 04:06:56,444 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.265,  Train_accy 84.95
2025-02-05 04:07:17,006 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.258,  Train_accy 86.40, Test_accy 64.57
2025-02-05 04:07:28,478 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.256,  Train_accy 86.27
2025-02-05 04:07:40,058 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.255,  Train_accy 86.70
2025-02-05 04:07:51,557 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.249,  Train_accy 87.26
2025-02-05 04:08:03,017 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.243,  Train_accy 87.41
2025-02-05 04:08:23,947 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.238,  Train_accy 88.00, Test_accy 65.42
2025-02-05 04:08:35,387 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.233,  Train_accy 88.22
2025-02-05 04:08:46,937 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.234,  Train_accy 87.84
2025-02-05 04:08:58,367 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.235,  Train_accy 88.65
2025-02-05 04:09:09,861 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.229,  Train_accy 88.90
2025-02-05 04:09:30,280 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.226,  Train_accy 88.94, Test_accy 65.46
2025-02-05 04:09:41,755 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.227,  Train_accy 88.95
2025-02-05 04:09:53,209 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.225,  Train_accy 88.65
2025-02-05 04:10:04,662 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.220,  Train_accy 88.94
2025-02-05 04:10:16,163 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.216,  Train_accy 90.34
2025-02-05 04:10:36,526 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.222,  Train_accy 89.17, Test_accy 65.70
2025-02-05 04:10:47,940 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.216,  Train_accy 89.95
2025-02-05 04:10:59,570 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.211,  Train_accy 90.22
2025-02-05 04:11:11,098 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.213,  Train_accy 90.07
2025-02-05 04:11:22,717 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.207,  Train_accy 90.67
2025-02-05 04:11:43,226 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.208,  Train_accy 90.23, Test_accy 66.41
2025-02-05 04:11:54,689 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.208,  Train_accy 91.06
2025-02-05 04:12:06,112 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.201,  Train_accy 90.83
2025-02-05 04:12:17,672 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.200,  Train_accy 90.65
2025-02-05 04:12:29,172 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.199,  Train_accy 91.01
2025-02-05 04:12:50,150 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.199,  Train_accy 91.06, Test_accy 66.13
2025-02-05 04:13:01,578 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.196,  Train_accy 90.45
2025-02-05 04:13:13,065 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.203,  Train_accy 91.08
2025-02-05 04:13:24,533 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.198,  Train_accy 91.01
2025-02-05 04:13:36,163 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.198,  Train_accy 91.46
2025-02-05 04:13:56,892 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.196,  Train_accy 91.84, Test_accy 66.76
2025-02-05 04:14:08,360 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.196,  Train_accy 91.53
2025-02-05 04:14:19,825 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.198,  Train_accy 91.41
2025-02-05 04:14:31,288 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.194,  Train_accy 90.97
2025-02-05 04:14:42,719 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.192,  Train_accy 91.62
2025-02-05 04:15:03,496 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.194,  Train_accy 92.41, Test_accy 66.28
2025-02-05 04:15:14,995 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.192,  Train_accy 91.80
2025-02-05 04:15:26,496 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.190,  Train_accy 92.13
2025-02-05 04:15:38,093 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.183,  Train_accy 91.84
2025-02-05 04:15:49,499 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.186,  Train_accy 92.29
2025-02-05 04:16:10,087 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.187,  Train_accy 91.64, Test_accy 66.25
2025-02-05 04:16:21,488 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.186,  Train_accy 91.57
2025-02-05 04:16:32,993 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.185,  Train_accy 92.36
2025-02-05 04:16:44,432 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.184,  Train_accy 91.77
2025-02-05 04:16:55,948 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.186,  Train_accy 91.69
2025-02-05 04:17:16,579 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.187,  Train_accy 92.34, Test_accy 66.73
2025-02-05 04:17:28,093 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.183,  Train_accy 92.27
2025-02-05 04:17:39,591 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.182,  Train_accy 92.56
2025-02-05 04:17:51,106 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.184,  Train_accy 92.52
2025-02-05 04:18:02,559 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.179,  Train_accy 92.74
2025-02-05 04:18:23,216 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.178,  Train_accy 92.31, Test_accy 67.64
2025-02-05 04:18:34,650 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.179,  Train_accy 92.31
2025-02-05 04:18:46,152 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.174,  Train_accy 92.95
2025-02-05 04:18:57,635 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.175,  Train_accy 92.43
2025-02-05 04:19:09,074 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.179,  Train_accy 92.56
2025-02-05 04:19:29,652 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.173,  Train_accy 92.25, Test_accy 67.71
2025-02-05 04:19:41,103 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.177,  Train_accy 93.06
2025-02-05 04:19:52,546 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.173,  Train_accy 92.70
2025-02-05 04:20:04,025 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.175,  Train_accy 92.77
2025-02-05 04:20:15,500 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.173,  Train_accy 92.97
2025-02-05 04:20:36,168 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.172,  Train_accy 92.86, Test_accy 67.37
2025-02-05 04:20:47,586 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.173,  Train_accy 92.74
2025-02-05 04:20:59,028 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.173,  Train_accy 92.61
2025-02-05 04:21:10,446 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.171,  Train_accy 92.90
2025-02-05 04:21:22,113 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.176,  Train_accy 92.45
2025-02-05 04:21:42,877 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.170,  Train_accy 93.32, Test_accy 67.44
2025-02-05 04:21:54,390 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.173,  Train_accy 92.58
2025-02-05 04:22:05,837 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.168,  Train_accy 93.21
2025-02-05 04:22:17,296 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.169,  Train_accy 93.17
2025-02-05 04:22:28,847 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.172,  Train_accy 93.33
2025-02-05 04:22:49,471 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.169,  Train_accy 93.23, Test_accy 67.52
2025-02-05 04:23:01,049 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.170,  Train_accy 92.99
2025-02-05 04:23:12,582 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.168,  Train_accy 93.41
2025-02-05 04:23:23,997 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.173,  Train_accy 93.33
2025-02-05 04:23:35,460 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.168,  Train_accy 93.23
2025-02-05 04:23:55,977 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.167,  Train_accy 93.44, Test_accy 67.38
2025-02-05 04:24:07,335 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.168,  Train_accy 93.39
2025-02-05 04:24:18,800 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.166,  Train_accy 93.14
2025-02-05 04:24:30,203 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.169,  Train_accy 93.51
2025-02-05 04:24:41,651 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.167,  Train_accy 93.06
2025-02-05 04:25:01,996 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.167,  Train_accy 93.23, Test_accy 67.96
2025-02-05 04:25:13,571 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.165,  Train_accy 92.86
2025-02-05 04:25:25,075 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.168,  Train_accy 92.94
2025-02-05 04:25:36,637 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.166,  Train_accy 93.86
2025-02-05 04:25:48,104 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.163,  Train_accy 93.53
2025-02-05 04:26:08,709 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.165,  Train_accy 93.48, Test_accy 67.93
2025-02-05 04:26:20,258 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.165,  Train_accy 93.53
2025-02-05 04:26:31,740 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.165,  Train_accy 93.69
2025-02-05 04:26:43,330 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.160,  Train_accy 93.28
2025-02-05 04:26:54,787 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.164,  Train_accy 93.33
2025-02-05 04:27:15,292 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.161,  Train_accy 93.93, Test_accy 67.99
2025-02-05 04:27:26,715 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.164,  Train_accy 93.15
2025-02-05 04:27:38,211 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.167,  Train_accy 93.19
2025-02-05 04:27:49,720 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.164,  Train_accy 93.60
2025-02-05 04:28:01,225 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.163,  Train_accy 93.62
2025-02-05 04:28:21,886 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.163,  Train_accy 93.80, Test_accy 67.98
2025-02-05 04:28:33,368 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.162,  Train_accy 93.26
2025-02-05 04:28:44,810 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.161,  Train_accy 93.84
2025-02-05 04:28:56,296 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.161,  Train_accy 93.89
2025-02-05 04:29:07,812 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.163,  Train_accy 93.84
2025-02-05 04:29:28,325 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.160,  Train_accy 93.57, Test_accy 67.88
2025-02-05 04:29:39,730 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.160,  Train_accy 93.44
2025-02-05 04:29:51,236 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.160,  Train_accy 93.60
2025-02-05 04:30:02,681 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.162,  Train_accy 93.82
2025-02-05 04:30:14,108 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.165,  Train_accy 93.59
2025-02-05 04:30:34,546 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.160,  Train_accy 93.19, Test_accy 68.07
2025-02-05 04:30:46,046 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.163,  Train_accy 93.32
2025-02-05 04:30:57,512 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.161,  Train_accy 93.78
2025-02-05 04:31:09,018 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.163,  Train_accy 93.69
2025-02-05 04:31:20,448 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.161,  Train_accy 93.68
2025-02-05 04:31:41,723 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.160,  Train_accy 93.50, Test_accy 67.88
2025-02-05 04:31:53,171 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.160,  Train_accy 93.42
2025-02-05 04:32:04,795 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.160,  Train_accy 93.48
2025-02-05 04:32:16,350 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.165,  Train_accy 93.51
2025-02-05 04:32:27,914 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.161,  Train_accy 93.98
2025-02-05 04:32:27,914 [der.py] => do not weight align student!
2025-02-05 04:32:35,736 [der.py] => darknet eval: 
2025-02-05 04:32:35,736 [der.py] => CNN top1 curve: 67.84
2025-02-05 04:32:35,736 [der.py] => CNN top5 curve: 91.3
2025-02-05 04:32:35,737 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 04:33:31,979 [der.py] => Exemplar size: 1650
2025-02-05 04:33:31,979 [trainer.py] => CNN: {'total': 70.09, '0': 66.67, '1': 58.33, '2': 57.78, '3': 23.33, '4': 62.22, '5': 35.56, '6': 53.89, '7': 43.89, '8': 33.33, '9': 49.44, '10': 86.67, '11': 70.0, '12': 55.56, '13': 50.0, '14': 58.33, '15': 80.56, '16': 84.44, '17': 76.11, '18': 70.0, '19': 79.44, '20': 84.44, '21': 75.0, '22': 72.22, '23': 61.67, '24': 64.44, '25': 59.44, '26': 72.78, '27': 72.78, '28': 41.67, '29': 59.44, '30': 71.67, '31': 74.44, '32': 67.22, '33': 37.78, '34': 61.11, '35': 95.0, '36': 92.22, '37': 66.67, '38': 88.33, '39': 97.78, '40': 83.89, '41': 96.67, '42': 95.0, '43': 93.33, '44': 74.44, '45': 91.11, '46': 82.22, '47': 77.22, '48': 80.56, '49': 77.78, '50': 75.56, '51': 81.11, '52': 78.89, '53': 75.56, 'old': 67.89, 'new': 80.0}
2025-02-05 04:33:31,979 [trainer.py] => NME: {'total': 64.32, '0': 61.67, '1': 53.33, '2': 53.33, '3': 21.11, '4': 61.67, '5': 33.89, '6': 47.22, '7': 51.11, '8': 32.78, '9': 55.56, '10': 79.44, '11': 76.67, '12': 53.89, '13': 48.89, '14': 53.89, '15': 77.22, '16': 81.11, '17': 77.78, '18': 76.11, '19': 72.22, '20': 76.67, '21': 65.56, '22': 71.11, '23': 53.33, '24': 52.22, '25': 44.44, '26': 66.67, '27': 54.44, '28': 38.89, '29': 46.67, '30': 62.78, '31': 64.44, '32': 59.44, '33': 32.22, '34': 57.22, '35': 87.78, '36': 82.22, '37': 35.56, '38': 77.22, '39': 90.0, '40': 55.56, '41': 93.33, '42': 93.89, '43': 88.89, '44': 52.78, '45': 85.56, '46': 81.67, '47': 78.33, '48': 81.67, '49': 73.33, '50': 67.78, '51': 81.11, '52': 75.0, '53': 72.78, 'old': 61.6, 'new': 76.56}
2025-02-05 04:33:31,979 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.4, 72.0, 70.09]
2025-02-05 04:33:31,979 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.62, 94.19, 92.28]
2025-02-05 04:33:31,979 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.71, 71.9, 64.32]
2025-02-05 04:33:31,979 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.62, 95.26, 91.98]

2025-02-05 12:40:17,528 [trainer.py] => 实验名称:BKD*0.01对比实验
2025-02-05 12:40:17,529 [trainer.py] => config: ./exps/der.json
2025-02-05 12:40:17,529 [trainer.py] => experiment_name: 实验名称:BKD*0.01对比实验
2025-02-05 12:40:17,529 [trainer.py] => prefix: reproduce
2025-02-05 12:40:17,529 [trainer.py] => dataset: xrfdataset
2025-02-05 12:40:17,529 [trainer.py] => memory_size: 1650
2025-02-05 12:40:17,529 [trainer.py] => memory_per_class: 30
2025-02-05 12:40:17,529 [trainer.py] => fixed_memory: True
2025-02-05 12:40:17,529 [trainer.py] => shuffle: True
2025-02-05 12:40:17,529 [trainer.py] => init_cls: 15
2025-02-05 12:40:17,529 [trainer.py] => increment: 10
2025-02-05 12:40:17,529 [trainer.py] => model_name: der
2025-02-05 12:40:17,529 [trainer.py] => compression_epochs: 130
2025-02-05 12:40:17,529 [trainer.py] => compression_lr: 0.1
2025-02-05 12:40:17,529 [trainer.py] => is_student_wa: False
2025-02-05 12:40:17,529 [trainer.py] => wa_value: 1
2025-02-05 12:40:17,529 [trainer.py] => T: 2
2025-02-05 12:40:17,529 [trainer.py] => convnet_type: unet
2025-02-05 12:40:17,529 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2025-02-05 12:40:17,529 [trainer.py] => seed: 1993
2025-02-05 12:40:17,541 [data.py] => 加载完毕XRF原始数据集
2025-02-05 12:40:17,546 [data.py] => 加载完毕XRF原始数据集
2025-02-05 12:40:17,547 [trainer.py] => All params: 0
2025-02-05 12:40:17,547 [trainer.py] => Trainable params: 0
2025-02-05 12:40:17,715 [der.py] => Learning on 0-15
2025-02-05 12:40:17,715 [der.py] => All params: 21045611
2025-02-05 12:40:17,716 [der.py] => Trainable params: 21045611
2025-02-05 13:01:04,545 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-05 13:01:04,546 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 13:01:28,384 [der.py] => Exemplar size: 450
2025-02-05 13:01:28,384 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-05 13:01:28,384 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-05 13:01:28,384 [trainer.py] => CNN top1 curve: [89.44]
2025-02-05 13:01:28,385 [trainer.py] => CNN top5 curve: [98.93]
2025-02-05 13:01:28,385 [trainer.py] => NME top1 curve: [88.22]
2025-02-05 13:01:28,385 [trainer.py] => NME top5 curve: [98.81]

2025-02-05 13:01:28,385 [trainer.py] => All params: 21045611
2025-02-05 13:01:28,386 [trainer.py] => Trainable params: 21045611
2025-02-05 13:01:28,537 [der.py] => Learning on 15-25
2025-02-05 13:01:28,538 [der.py] => All params: 42091068
2025-02-05 13:01:28,538 [der.py] => Trainable params: 21049456
2025-02-05 13:01:28,635 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-05 13:01:28,635 [der.py] => per cls weights : [1.21616069 1.21616069 1.21616069 1.21616069 1.21616069 1.21616069
 1.21616069 1.21616069 1.21616069 1.21616069 1.21616069 1.21616069
 1.21616069 1.21616069 1.21616069 0.67575897 0.67575897 0.67575897
 0.67575897 0.67575897 0.67575897 0.67575897 0.67575897 0.67575897
 0.67575897]
2025-02-05 13:22:01,608 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-02-05 13:22:14,347 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.107,  Train_accy 44.75, Test_accy 52.49
2025-02-05 13:22:22,655 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.585,  Train_accy 70.04
2025-02-05 13:22:30,938 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.401,  Train_accy 79.01
2025-02-05 13:22:39,428 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.279,  Train_accy 85.66
2025-02-05 13:22:47,727 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.222,  Train_accy 88.02
2025-02-05 13:23:00,417 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.181,  Train_accy 90.92, Test_accy 74.80
2025-02-05 13:23:08,747 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.157,  Train_accy 91.10
2025-02-05 13:23:17,118 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.117,  Train_accy 94.06
2025-02-05 13:23:25,515 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.106,  Train_accy 94.30
2025-02-05 13:23:33,934 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.102,  Train_accy 94.34
2025-02-05 13:23:46,373 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.078,  Train_accy 95.59, Test_accy 77.11
2025-02-05 13:23:54,653 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.069,  Train_accy 95.87
2025-02-05 13:24:02,937 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.058,  Train_accy 96.15
2025-02-05 13:24:11,361 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.054,  Train_accy 96.49
2025-02-05 13:24:19,735 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.051,  Train_accy 96.43
2025-02-05 13:24:32,179 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.060,  Train_accy 95.83, Test_accy 77.38
2025-02-05 13:24:40,456 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.048,  Train_accy 96.71
2025-02-05 13:24:48,907 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.043,  Train_accy 96.49
2025-02-05 13:24:57,213 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.039,  Train_accy 97.35
2025-02-05 13:25:05,509 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.041,  Train_accy 96.88
2025-02-05 13:25:17,958 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.029,  Train_accy 97.20, Test_accy 79.87
2025-02-05 13:25:26,228 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.027,  Train_accy 97.10
2025-02-05 13:25:34,603 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.022,  Train_accy 97.55
2025-02-05 13:25:42,900 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.021,  Train_accy 97.25
2025-02-05 13:25:51,237 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.019,  Train_accy 97.18
2025-02-05 13:26:03,773 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.017,  Train_accy 97.42, Test_accy 80.91
2025-02-05 13:26:12,107 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.017,  Train_accy 97.40
2025-02-05 13:26:20,499 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.012,  Train_accy 97.59
2025-02-05 13:26:28,801 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.009,  Train_accy 97.44
2025-02-05 13:26:37,115 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.012,  Train_accy 97.42
2025-02-05 13:26:49,673 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.012,  Train_accy 97.29, Test_accy 80.33
2025-02-05 13:26:58,314 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.014,  Train_accy 97.44
2025-02-05 13:27:06,668 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.004,  Train_accy 97.63
2025-02-05 13:27:14,949 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.002,  Train_accy 97.74
2025-02-05 13:27:23,334 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.002,  Train_accy 97.57
2025-02-05 13:27:35,738 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.002,  Train_accy 97.87, Test_accy 81.27
2025-02-05 13:27:44,039 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.001,  Train_accy 97.55
2025-02-05 13:27:52,373 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.005,  Train_accy 97.33
2025-02-05 13:28:00,662 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.004,  Train_accy 97.57
2025-02-05 13:28:08,989 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 0.998,  Train_accy 97.78
2025-02-05 13:28:21,476 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 0.996,  Train_accy 97.53, Test_accy 81.24
2025-02-05 13:28:29,840 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 0.999,  Train_accy 97.59
2025-02-05 13:28:38,239 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.002,  Train_accy 97.48
2025-02-05 13:28:46,499 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 0.991,  Train_accy 97.66
2025-02-05 13:28:54,909 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 0.991,  Train_accy 97.83
2025-02-05 13:29:07,298 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 0.997,  Train_accy 97.89, Test_accy 80.87
2025-02-05 13:29:15,569 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 0.995,  Train_accy 97.25
2025-02-05 13:29:23,933 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 0.991,  Train_accy 97.83
2025-02-05 13:29:32,242 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 0.996,  Train_accy 97.85
2025-02-05 13:29:40,596 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 0.995,  Train_accy 98.04
2025-02-05 13:29:52,996 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 0.993,  Train_accy 97.55, Test_accy 80.84
2025-02-05 13:30:01,312 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 0.994,  Train_accy 97.51
2025-02-05 13:30:09,596 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 0.992,  Train_accy 97.53
2025-02-05 13:30:17,855 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 0.994,  Train_accy 97.85
2025-02-05 13:30:26,259 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 0.993,  Train_accy 97.38
2025-02-05 13:30:38,727 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.986,  Train_accy 97.83, Test_accy 82.27
2025-02-05 13:30:47,110 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.984,  Train_accy 97.85
2025-02-05 13:30:55,462 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 0.987,  Train_accy 97.68
2025-02-05 13:31:03,723 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.986,  Train_accy 98.02
2025-02-05 13:31:12,188 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.983,  Train_accy 98.09
2025-02-05 13:31:24,569 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.980,  Train_accy 97.74, Test_accy 81.51
2025-02-05 13:31:33,026 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.984,  Train_accy 97.85
2025-02-05 13:31:41,736 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.985,  Train_accy 97.94
2025-02-05 13:31:49,963 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.986,  Train_accy 97.89
2025-02-05 13:31:58,391 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.981,  Train_accy 97.91
2025-02-05 13:32:11,660 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.980,  Train_accy 97.66, Test_accy 81.60
2025-02-05 13:32:20,247 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.981,  Train_accy 97.85
2025-02-05 13:32:28,861 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.984,  Train_accy 97.72
2025-02-05 13:32:37,384 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.984,  Train_accy 98.22
2025-02-05 13:32:45,858 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.984,  Train_accy 97.87
2025-02-05 13:32:58,809 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.981,  Train_accy 97.68, Test_accy 81.69
2025-02-05 13:33:07,483 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.982,  Train_accy 98.13
2025-02-05 13:33:16,150 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.978,  Train_accy 98.11
2025-02-05 13:33:24,759 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.984,  Train_accy 97.74
2025-02-05 13:33:33,459 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.978,  Train_accy 98.06
2025-02-05 13:33:46,753 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.979,  Train_accy 97.83, Test_accy 81.16
2025-02-05 13:33:55,383 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.981,  Train_accy 98.00
2025-02-05 13:34:04,087 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.977,  Train_accy 97.89
2025-02-05 13:34:12,879 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.977,  Train_accy 98.28
2025-02-05 13:34:21,566 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.980,  Train_accy 98.00
2025-02-05 13:34:34,709 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.976,  Train_accy 98.11, Test_accy 81.56
2025-02-05 13:34:43,448 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.981,  Train_accy 97.94
2025-02-05 13:34:52,213 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.979,  Train_accy 97.98
2025-02-05 13:35:00,850 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.977,  Train_accy 97.85
2025-02-05 13:35:09,412 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.975,  Train_accy 97.89
2025-02-05 13:35:22,733 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.972,  Train_accy 98.13, Test_accy 81.96
2025-02-05 13:35:31,331 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.976,  Train_accy 97.98
2025-02-05 13:35:40,060 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.978,  Train_accy 97.74
2025-02-05 13:35:48,825 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.976,  Train_accy 98.17
2025-02-05 13:35:57,520 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.975,  Train_accy 97.78
2025-02-05 13:36:10,948 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.975,  Train_accy 97.74, Test_accy 81.62
2025-02-05 13:36:19,604 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.975,  Train_accy 98.06
2025-02-05 13:36:28,269 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.973,  Train_accy 98.17
2025-02-05 13:36:37,133 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.974,  Train_accy 98.30
2025-02-05 13:36:45,839 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.976,  Train_accy 98.06
2025-02-05 13:36:59,196 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.972,  Train_accy 97.85, Test_accy 82.02
2025-02-05 13:37:07,874 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.974,  Train_accy 98.00
2025-02-05 13:37:16,658 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.973,  Train_accy 98.04
2025-02-05 13:37:25,344 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.972,  Train_accy 98.00
2025-02-05 13:37:34,026 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.978,  Train_accy 97.98
2025-02-05 13:37:47,297 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.974,  Train_accy 97.74, Test_accy 81.87
2025-02-05 13:37:55,728 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.974,  Train_accy 97.94
2025-02-05 13:38:04,523 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.971,  Train_accy 98.17
2025-02-05 13:38:13,195 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.971,  Train_accy 98.09
2025-02-05 13:38:21,900 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.972,  Train_accy 97.94
2025-02-05 13:38:35,065 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.969,  Train_accy 98.15, Test_accy 82.00
2025-02-05 13:38:43,702 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.969,  Train_accy 97.91
2025-02-05 13:38:52,500 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.975,  Train_accy 98.02
2025-02-05 13:39:01,151 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.969,  Train_accy 98.02
2025-02-05 13:39:09,906 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.973,  Train_accy 97.94
2025-02-05 13:39:23,097 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.972,  Train_accy 98.06, Test_accy 81.73
2025-02-05 13:39:31,770 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.971,  Train_accy 98.06
2025-02-05 13:39:40,592 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.971,  Train_accy 98.09
2025-02-05 13:39:49,238 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.972,  Train_accy 98.24
2025-02-05 13:39:57,994 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.971,  Train_accy 98.06
2025-02-05 13:40:10,839 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.971,  Train_accy 98.15, Test_accy 82.04
2025-02-05 13:40:19,534 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.969,  Train_accy 98.02
2025-02-05 13:40:28,288 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.970,  Train_accy 98.02
2025-02-05 13:40:36,692 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.972,  Train_accy 98.19
2025-02-05 13:40:45,522 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.972,  Train_accy 98.15
2025-02-05 13:40:58,681 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.972,  Train_accy 98.17, Test_accy 81.91
2025-02-05 13:41:07,306 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.973,  Train_accy 98.11
2025-02-05 13:41:15,875 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.970,  Train_accy 98.09
2025-02-05 13:41:24,583 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.968,  Train_accy 98.00
2025-02-05 13:41:33,383 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.969,  Train_accy 97.94
2025-02-05 13:41:46,361 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.967,  Train_accy 98.39, Test_accy 81.76
2025-02-05 13:41:55,081 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.972,  Train_accy 98.04
2025-02-05 13:42:03,673 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.972,  Train_accy 98.06
2025-02-05 13:42:12,432 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.968,  Train_accy 98.17
2025-02-05 13:42:21,230 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.968,  Train_accy 98.15
2025-02-05 13:42:21,231 [der.py] => do not weight align student!
2025-02-05 13:42:25,624 [der.py] => darknet eval: 
2025-02-05 13:42:25,624 [der.py] => CNN top1 curve: 81.69
2025-02-05 13:42:25,624 [der.py] => CNN top5 curve: 98.07
2025-02-05 13:42:25,626 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 13:42:57,718 [der.py] => Exemplar size: 750
2025-02-05 13:42:57,718 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-02-05 13:42:57,718 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-02-05 13:42:57,719 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-02-05 13:42:57,719 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-02-05 13:42:57,719 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-02-05 13:42:57,719 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-02-05 13:42:57,720 [trainer.py] => All params: 42091068
2025-02-05 13:42:57,722 [trainer.py] => Trainable params: 21049456
2025-02-05 13:42:57,880 [der.py] => Learning on 25-35
2025-02-05 13:42:57,881 [der.py] => All params: 42093638
2025-02-05 13:42:57,882 [der.py] => Trainable params: 21052026
2025-02-05 13:42:57,995 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-05 13:42:57,996 [der.py] => per cls weights : [1.14541936 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936
 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936
 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936
 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936 1.14541936
 1.14541936 0.63645159 0.63645159 0.63645159 0.63645159 0.63645159
 0.63645159 0.63645159 0.63645159 0.63645159 0.63645159]
2025-02-05 14:05:34,322 [der.py] => Task 2, Epoch 150/150 => Loss 0.012, Loss_clf 0.006, Loss_aux 0.006, Train_accy 100.00
2025-02-05 14:05:48,769 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.250,  Train_accy 45.64, Test_accy 56.24
2025-02-05 14:05:57,607 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.914,  Train_accy 68.00
2025-02-05 14:06:06,558 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.784,  Train_accy 76.71
2025-02-05 14:06:15,268 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.719,  Train_accy 81.64
2025-02-05 14:06:24,091 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.688,  Train_accy 83.68
2025-02-05 14:06:38,334 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.655,  Train_accy 84.97, Test_accy 63.33
2025-02-05 14:06:47,274 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.626,  Train_accy 87.21
2025-02-05 14:06:56,107 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.614,  Train_accy 88.10
2025-02-05 14:07:04,969 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.602,  Train_accy 88.34
2025-02-05 14:07:13,700 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.596,  Train_accy 89.13
2025-02-05 14:07:28,028 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.581,  Train_accy 89.86, Test_accy 70.00
2025-02-05 14:07:36,875 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.570,  Train_accy 90.97
2025-02-05 14:07:45,718 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.563,  Train_accy 91.11
2025-02-05 14:07:54,623 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.563,  Train_accy 90.22
2025-02-05 14:08:03,421 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.552,  Train_accy 91.76
2025-02-05 14:08:17,729 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.546,  Train_accy 91.78, Test_accy 68.92
2025-02-05 14:08:26,524 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.543,  Train_accy 91.98
2025-02-05 14:08:35,463 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.543,  Train_accy 91.84
2025-02-05 14:08:44,303 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.535,  Train_accy 92.65
2025-02-05 14:08:53,081 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.527,  Train_accy 92.99
2025-02-05 14:09:07,525 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.531,  Train_accy 93.11, Test_accy 70.92
2025-02-05 14:09:16,361 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.530,  Train_accy 92.59
2025-02-05 14:09:25,231 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.529,  Train_accy 92.59
2025-02-05 14:09:34,034 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.520,  Train_accy 93.25
2025-02-05 14:09:42,871 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.516,  Train_accy 93.98
2025-02-05 14:09:57,238 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.514,  Train_accy 93.17, Test_accy 72.97
2025-02-05 14:10:06,111 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.507,  Train_accy 93.76
2025-02-05 14:10:14,908 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.506,  Train_accy 94.30
2025-02-05 14:10:23,691 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.506,  Train_accy 93.92
2025-02-05 14:10:32,646 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.504,  Train_accy 94.14
2025-02-05 14:10:47,144 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.505,  Train_accy 94.08, Test_accy 72.73
2025-02-05 14:10:56,101 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.503,  Train_accy 94.08
2025-02-05 14:11:04,957 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.500,  Train_accy 94.08
2025-02-05 14:11:13,866 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.499,  Train_accy 94.24
2025-02-05 14:11:22,669 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.496,  Train_accy 94.02
2025-02-05 14:11:37,153 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.497,  Train_accy 94.30, Test_accy 73.03
2025-02-05 14:11:45,984 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.493,  Train_accy 94.67
2025-02-05 14:11:54,928 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.493,  Train_accy 94.20
2025-02-05 14:12:03,884 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.489,  Train_accy 94.67
2025-02-05 14:12:12,691 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.487,  Train_accy 94.87
2025-02-05 14:12:26,938 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.492,  Train_accy 94.38, Test_accy 73.35
2025-02-05 14:12:35,736 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.486,  Train_accy 94.83
2025-02-05 14:12:44,664 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.488,  Train_accy 94.57
2025-02-05 14:12:53,478 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.487,  Train_accy 94.28
2025-02-05 14:13:02,250 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.483,  Train_accy 94.61
2025-02-05 14:13:16,587 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.484,  Train_accy 94.61, Test_accy 72.92
2025-02-05 14:13:25,529 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.485,  Train_accy 94.79
2025-02-05 14:13:34,371 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.482,  Train_accy 94.57
2025-02-05 14:13:43,266 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.483,  Train_accy 94.59
2025-02-05 14:13:52,265 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.479,  Train_accy 94.87
2025-02-05 14:14:06,600 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.478,  Train_accy 94.97, Test_accy 73.79
2025-02-05 14:14:15,609 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.482,  Train_accy 94.71
2025-02-05 14:14:24,468 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.482,  Train_accy 94.30
2025-02-05 14:14:33,353 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.475,  Train_accy 95.49
2025-02-05 14:14:42,379 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.477,  Train_accy 94.67
2025-02-05 14:14:57,027 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.476,  Train_accy 94.93, Test_accy 73.76
2025-02-05 14:15:05,916 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.475,  Train_accy 95.21
2025-02-05 14:15:14,708 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.477,  Train_accy 95.09
2025-02-05 14:15:23,638 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.477,  Train_accy 95.35
2025-02-05 14:15:32,603 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.473,  Train_accy 95.27
2025-02-05 14:15:47,290 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.474,  Train_accy 95.05, Test_accy 73.71
2025-02-05 14:15:56,323 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.472,  Train_accy 95.11
2025-02-05 14:16:05,247 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.478,  Train_accy 95.19
2025-02-05 14:16:14,030 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.470,  Train_accy 95.49
2025-02-05 14:16:22,941 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.470,  Train_accy 94.51
2025-02-05 14:16:37,416 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.469,  Train_accy 95.19, Test_accy 74.14
2025-02-05 14:16:46,222 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.470,  Train_accy 95.58
2025-02-05 14:16:55,190 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.469,  Train_accy 95.56
2025-02-05 14:17:04,041 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.469,  Train_accy 95.17
2025-02-05 14:17:12,990 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.466,  Train_accy 95.58
2025-02-05 14:17:27,365 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.470,  Train_accy 95.19, Test_accy 74.40
2025-02-05 14:17:36,251 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.469,  Train_accy 95.17
2025-02-05 14:17:45,125 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.469,  Train_accy 95.60
2025-02-05 14:17:53,980 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.464,  Train_accy 96.18
2025-02-05 14:18:02,954 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.467,  Train_accy 95.07
2025-02-05 14:18:17,142 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.466,  Train_accy 95.09, Test_accy 73.98
2025-02-05 14:18:26,096 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.466,  Train_accy 95.47
2025-02-05 14:18:34,886 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.464,  Train_accy 95.39
2025-02-05 14:18:43,780 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.465,  Train_accy 95.70
2025-02-05 14:18:52,682 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.463,  Train_accy 95.62
2025-02-05 14:19:06,937 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.463,  Train_accy 95.33, Test_accy 74.14
2025-02-05 14:19:15,847 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.464,  Train_accy 95.66
2025-02-05 14:19:24,709 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.458,  Train_accy 95.58
2025-02-05 14:19:33,733 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.459,  Train_accy 95.66
2025-02-05 14:19:42,834 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.464,  Train_accy 95.70
2025-02-05 14:19:57,369 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.461,  Train_accy 95.70, Test_accy 74.48
2025-02-05 14:20:06,196 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.459,  Train_accy 95.58
2025-02-05 14:20:14,998 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.460,  Train_accy 95.92
2025-02-05 14:20:23,734 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.460,  Train_accy 95.64
2025-02-05 14:20:32,668 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.460,  Train_accy 95.84
2025-02-05 14:20:46,808 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.458,  Train_accy 95.58, Test_accy 74.56
2025-02-05 14:20:55,591 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.458,  Train_accy 95.76
2025-02-05 14:21:04,434 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.459,  Train_accy 95.54
2025-02-05 14:21:13,207 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.458,  Train_accy 95.60
2025-02-05 14:21:22,095 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.457,  Train_accy 95.86
2025-02-05 14:21:36,308 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.458,  Train_accy 95.72, Test_accy 74.83
2025-02-05 14:21:45,098 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.456,  Train_accy 95.70
2025-02-05 14:21:53,875 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.457,  Train_accy 95.62
2025-02-05 14:22:02,701 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.455,  Train_accy 95.60
2025-02-05 14:22:11,862 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.456,  Train_accy 95.94
2025-02-05 14:22:26,439 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.458,  Train_accy 95.74, Test_accy 74.73
2025-02-05 14:22:35,339 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.458,  Train_accy 95.88
2025-02-05 14:22:44,193 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.458,  Train_accy 95.82
2025-02-05 14:22:53,086 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.456,  Train_accy 95.43
2025-02-05 14:23:01,926 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.455,  Train_accy 95.82
2025-02-05 14:23:16,521 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.456,  Train_accy 95.78, Test_accy 75.16
2025-02-05 14:23:25,323 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.456,  Train_accy 95.56
2025-02-05 14:23:34,160 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.455,  Train_accy 96.08
2025-02-05 14:23:43,096 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.458,  Train_accy 95.66
2025-02-05 14:23:51,957 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.455,  Train_accy 95.98
2025-02-05 14:24:06,630 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.456,  Train_accy 95.82, Test_accy 74.79
2025-02-05 14:24:15,522 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.455,  Train_accy 95.60
2025-02-05 14:24:24,598 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.454,  Train_accy 95.94
2025-02-05 14:24:33,531 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.452,  Train_accy 95.92
2025-02-05 14:24:42,554 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.455,  Train_accy 95.92
2025-02-05 14:24:57,108 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.454,  Train_accy 96.08, Test_accy 74.90
2025-02-05 14:25:06,127 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.455,  Train_accy 95.76
2025-02-05 14:25:15,021 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.455,  Train_accy 95.86
2025-02-05 14:25:23,945 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.455,  Train_accy 95.84
2025-02-05 14:25:32,974 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.456,  Train_accy 95.47
2025-02-05 14:25:47,660 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.454,  Train_accy 96.06, Test_accy 75.02
2025-02-05 14:25:56,645 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.454,  Train_accy 95.56
2025-02-05 14:26:05,518 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.455,  Train_accy 95.96
2025-02-05 14:26:14,356 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.456,  Train_accy 95.70
2025-02-05 14:26:23,240 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.455,  Train_accy 95.52
2025-02-05 14:26:37,460 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.454,  Train_accy 95.74, Test_accy 74.97
2025-02-05 14:26:46,449 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.456,  Train_accy 95.56
2025-02-05 14:26:55,346 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.455,  Train_accy 95.70
2025-02-05 14:27:04,215 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.455,  Train_accy 95.86
2025-02-05 14:27:13,131 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.454,  Train_accy 96.02
2025-02-05 14:27:13,132 [der.py] => do not weight align student!
2025-02-05 14:27:18,622 [der.py] => darknet eval: 
2025-02-05 14:27:18,622 [der.py] => CNN top1 curve: 75.08
2025-02-05 14:27:18,623 [der.py] => CNN top5 curve: 95.78
2025-02-05 14:27:18,625 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 14:27:58,699 [der.py] => Exemplar size: 1050
2025-02-05 14:27:58,699 [trainer.py] => CNN: {'total': 78.87, '0': 84.44, '1': 58.33, '2': 80.56, '3': 61.11, '4': 76.11, '5': 40.56, '6': 62.22, '7': 53.33, '8': 39.44, '9': 48.33, '10': 91.11, '11': 95.0, '12': 71.11, '13': 68.33, '14': 66.11, '15': 93.33, '16': 98.33, '17': 96.67, '18': 95.0, '19': 97.22, '20': 96.67, '21': 91.67, '22': 92.22, '23': 87.22, '24': 80.56, '25': 84.44, '26': 84.44, '27': 83.33, '28': 71.67, '29': 79.44, '30': 84.44, '31': 84.44, '32': 96.11, '33': 78.89, 'old': 77.0, 'new': 83.56}
2025-02-05 14:27:58,699 [trainer.py] => NME: {'total': 75.92, '0': 85.0, '1': 62.78, '2': 71.11, '3': 56.11, '4': 74.44, '5': 42.22, '6': 52.78, '7': 57.22, '8': 48.89, '9': 57.78, '10': 90.56, '11': 94.44, '12': 70.56, '13': 55.0, '14': 55.0, '15': 90.56, '16': 94.44, '17': 90.0, '18': 91.67, '19': 91.11, '20': 92.22, '21': 87.78, '22': 81.67, '23': 65.0, '24': 57.78, '25': 86.67, '26': 94.44, '27': 86.67, '28': 67.22, '29': 80.0, '30': 85.0, '31': 88.89, '32': 96.67, '33': 71.67, 'old': 72.64, 'new': 84.11}
2025-02-05 14:27:58,699 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.87]
2025-02-05 14:27:58,699 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.7]
2025-02-05 14:27:58,699 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.92]
2025-02-05 14:27:58,699 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.97]

2025-02-05 14:27:58,700 [trainer.py] => All params: 42093638
2025-02-05 14:27:58,701 [trainer.py] => Trainable params: 21052026
2025-02-05 14:27:58,840 [der.py] => Learning on 35-45
2025-02-05 14:27:58,841 [der.py] => All params: 42096208
2025-02-05 14:27:58,842 [der.py] => Trainable params: 21054596
2025-02-05 14:27:58,972 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-05 14:27:58,973 [der.py] => per cls weights : [1.10956336 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336
 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336
 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336
 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336
 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336
 1.10956336 1.10956336 1.10956336 1.10956336 1.10956336 0.61652823
 0.61652823 0.61652823 0.61652823 0.61652823 0.61652823 0.61652823
 0.61652823 0.61652823 0.61652823]
2025-02-05 14:54:29,905 [der.py] => Task 3, Epoch 150/150 => Loss 0.132, Loss_clf 0.070, Loss_aux 0.062, Train_accy 99.92
2025-02-05 14:54:46,514 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.958,  Train_accy 46.27, Test_accy 41.60
2025-02-05 14:54:55,816 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.526,  Train_accy 63.24
2025-02-05 14:55:05,249 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.392,  Train_accy 69.62
2025-02-05 14:55:14,584 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.354,  Train_accy 70.15
2025-02-05 14:55:23,932 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.310,  Train_accy 73.05
2025-02-05 14:55:40,129 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.326,  Train_accy 73.33, Test_accy 54.07
2025-02-05 14:55:49,567 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.271,  Train_accy 73.64
2025-02-05 14:55:58,846 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.220,  Train_accy 76.02
2025-02-05 14:56:08,187 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.193,  Train_accy 77.20
2025-02-05 14:56:17,514 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.207,  Train_accy 76.93
2025-02-05 14:56:33,848 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.189,  Train_accy 77.56, Test_accy 55.58
2025-02-05 14:56:43,231 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.187,  Train_accy 78.53
2025-02-05 14:56:52,619 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.182,  Train_accy 77.71
2025-02-05 14:57:01,948 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.163,  Train_accy 79.98
2025-02-05 14:57:11,305 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.128,  Train_accy 79.45
2025-02-05 14:57:27,512 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.103,  Train_accy 79.62, Test_accy 61.72
2025-02-05 14:57:36,939 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.189,  Train_accy 78.34
2025-02-05 14:57:46,352 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.143,  Train_accy 79.60
2025-02-05 14:57:55,708 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.109,  Train_accy 80.86
2025-02-05 14:58:05,122 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.113,  Train_accy 80.46
2025-02-05 14:58:21,437 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.117,  Train_accy 80.99, Test_accy 61.23
2025-02-05 14:58:30,829 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.171,  Train_accy 78.30
2025-02-05 14:58:40,223 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.107,  Train_accy 80.59
2025-02-05 14:58:49,759 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.118,  Train_accy 80.38
2025-02-05 14:58:59,075 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.105,  Train_accy 80.15
2025-02-05 14:59:15,137 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.114,  Train_accy 81.09, Test_accy 63.79
2025-02-05 14:59:24,488 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.064,  Train_accy 81.50
2025-02-05 14:59:33,918 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.108,  Train_accy 81.49
2025-02-05 14:59:43,270 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.090,  Train_accy 81.87
2025-02-05 14:59:52,689 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.075,  Train_accy 81.50
2025-02-05 15:00:08,799 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.074,  Train_accy 81.87, Test_accy 61.65
2025-02-05 15:00:18,408 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.086,  Train_accy 81.64
2025-02-05 15:00:27,752 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.061,  Train_accy 82.15
2025-02-05 15:00:37,284 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.054,  Train_accy 81.07
2025-02-05 15:00:46,697 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.080,  Train_accy 81.30
2025-02-05 15:01:03,112 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.063,  Train_accy 82.06, Test_accy 62.99
2025-02-05 15:01:12,494 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.082,  Train_accy 81.98
2025-02-05 15:01:21,811 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.069,  Train_accy 81.90
2025-02-05 15:01:31,359 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.077,  Train_accy 81.68
2025-02-05 15:01:40,739 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.065,  Train_accy 82.72
2025-02-05 15:01:57,061 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.078,  Train_accy 82.17, Test_accy 62.94
2025-02-05 15:02:06,426 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.055,  Train_accy 82.04
2025-02-05 15:02:15,914 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.071,  Train_accy 82.08
2025-02-05 15:02:25,290 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.067,  Train_accy 82.36
2025-02-05 15:02:34,750 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.060,  Train_accy 82.15
2025-02-05 15:02:50,935 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.068,  Train_accy 81.68, Test_accy 64.20
2025-02-05 15:03:00,325 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.063,  Train_accy 82.30
2025-02-05 15:03:09,734 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.041,  Train_accy 82.51
2025-02-05 15:03:19,165 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.077,  Train_accy 81.89
2025-02-05 15:03:28,602 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.052,  Train_accy 82.40
2025-02-05 15:03:45,019 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.051,  Train_accy 82.69, Test_accy 54.32
2025-02-05 15:03:54,704 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.037,  Train_accy 82.76
2025-02-05 15:04:04,200 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.042,  Train_accy 82.38
2025-02-05 15:04:13,549 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.051,  Train_accy 82.40
2025-02-05 15:04:22,995 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.036,  Train_accy 82.61
2025-02-05 15:04:39,041 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.020,  Train_accy 82.80, Test_accy 64.81
2025-02-05 15:04:48,476 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.059,  Train_accy 82.42
2025-02-05 15:04:57,861 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.043,  Train_accy 82.82
2025-02-05 15:05:07,267 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.036,  Train_accy 82.61
2025-02-05 15:05:16,625 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.042,  Train_accy 82.48
2025-02-05 15:05:32,932 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.041,  Train_accy 82.25, Test_accy 65.93
2025-02-05 15:05:42,234 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.042,  Train_accy 82.38
2025-02-05 15:05:51,729 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.017,  Train_accy 82.29
2025-02-05 15:06:01,084 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.048,  Train_accy 82.76
2025-02-05 15:06:10,408 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.030,  Train_accy 82.99
2025-02-05 15:06:26,735 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.027,  Train_accy 82.84, Test_accy 65.46
2025-02-05 15:06:36,225 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.051,  Train_accy 82.86
2025-02-05 15:06:45,649 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.038,  Train_accy 82.50
2025-02-05 15:06:55,027 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.020,  Train_accy 82.57
2025-02-05 15:07:04,491 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.047,  Train_accy 82.93
2025-02-05 15:07:20,770 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.014,  Train_accy 82.91, Test_accy 66.36
2025-02-05 15:07:30,263 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.033,  Train_accy 82.99
2025-02-05 15:07:39,750 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.025,  Train_accy 83.18
2025-02-05 15:07:49,324 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.000,  Train_accy 82.76
2025-02-05 15:07:58,729 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.052,  Train_accy 82.90
2025-02-05 15:08:14,894 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.019,  Train_accy 82.90, Test_accy 60.81
2025-02-05 15:08:24,277 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.029,  Train_accy 83.10
2025-02-05 15:08:33,672 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.019,  Train_accy 83.43
2025-02-05 15:08:43,135 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.046,  Train_accy 83.12
2025-02-05 15:08:52,718 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.036,  Train_accy 82.72
2025-02-05 15:09:08,917 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.032,  Train_accy 82.84, Test_accy 65.06
2025-02-05 15:09:18,228 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.011,  Train_accy 82.76
2025-02-05 15:09:27,505 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.026,  Train_accy 83.45
2025-02-05 15:09:36,869 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.022,  Train_accy 83.12
2025-02-05 15:09:46,158 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.015,  Train_accy 83.18
2025-02-05 15:10:02,273 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.030,  Train_accy 83.26, Test_accy 66.47
2025-02-05 15:10:11,572 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.021,  Train_accy 82.91
2025-02-05 15:10:20,916 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.011,  Train_accy 83.58
2025-02-05 15:10:30,313 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.001,  Train_accy 82.88
2025-02-05 15:10:39,599 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.003,  Train_accy 83.22
2025-02-05 15:10:55,573 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.032,  Train_accy 83.28, Test_accy 66.33
2025-02-05 15:11:05,151 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 0.996,  Train_accy 83.12
2025-02-05 15:11:14,936 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.023,  Train_accy 83.03
2025-02-05 15:11:24,662 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.020,  Train_accy 82.38
2025-02-05 15:11:34,110 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.011,  Train_accy 82.90
2025-02-05 15:11:50,281 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.007,  Train_accy 83.30, Test_accy 65.59
2025-02-05 15:11:59,785 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.009,  Train_accy 83.64
2025-02-05 15:12:09,147 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.012,  Train_accy 83.85
2025-02-05 15:12:18,612 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.020,  Train_accy 83.01
2025-02-05 15:12:27,954 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.021,  Train_accy 82.67
2025-02-05 15:12:44,312 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.016,  Train_accy 83.16, Test_accy 65.78
2025-02-05 15:12:53,724 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.018,  Train_accy 83.14
2025-02-05 15:13:03,157 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.019,  Train_accy 82.91
2025-02-05 15:13:12,480 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.023,  Train_accy 83.01
2025-02-05 15:13:21,886 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.014,  Train_accy 82.99
2025-02-05 15:13:38,039 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.012,  Train_accy 82.91, Test_accy 65.91
2025-02-05 15:13:47,496 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.024,  Train_accy 83.41
2025-02-05 15:13:56,814 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.015,  Train_accy 83.81
2025-02-05 15:14:06,238 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.008,  Train_accy 83.03
2025-02-05 15:14:15,663 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.011,  Train_accy 83.30
2025-02-05 15:14:32,136 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.019,  Train_accy 83.28, Test_accy 64.81
2025-02-05 15:14:41,481 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.007,  Train_accy 83.09
2025-02-05 15:14:50,888 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.009,  Train_accy 82.86
2025-02-05 15:15:00,278 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.006,  Train_accy 83.24
2025-02-05 15:15:09,617 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 0.995,  Train_accy 82.93
2025-02-05 15:15:25,785 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 0.999,  Train_accy 83.10, Test_accy 65.80
2025-02-05 15:15:35,190 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.007,  Train_accy 82.99
2025-02-05 15:15:44,577 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.012,  Train_accy 83.52
2025-02-05 15:15:53,914 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.031,  Train_accy 82.99
2025-02-05 15:16:03,388 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.000,  Train_accy 83.24
2025-02-05 15:16:19,611 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.014,  Train_accy 82.91, Test_accy 66.36
2025-02-05 15:16:28,987 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.004,  Train_accy 83.39
2025-02-05 15:16:38,603 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 0.992,  Train_accy 83.24
2025-02-05 15:16:48,147 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 0.995,  Train_accy 83.09
2025-02-05 15:16:57,509 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.008,  Train_accy 83.24
2025-02-05 15:17:13,782 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.008,  Train_accy 83.07, Test_accy 66.30
2025-02-05 15:17:23,166 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.006,  Train_accy 83.24
2025-02-05 15:17:32,697 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 0.997,  Train_accy 83.64
2025-02-05 15:17:42,154 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.008,  Train_accy 82.99
2025-02-05 15:17:51,631 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.007,  Train_accy 83.14
2025-02-05 15:17:51,632 [der.py] => do not weight align student!
2025-02-05 15:17:58,127 [der.py] => darknet eval: 
2025-02-05 15:17:58,127 [der.py] => CNN top1 curve: 64.86
2025-02-05 15:17:58,127 [der.py] => CNN top5 curve: 91.64
2025-02-05 15:17:58,129 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 15:18:46,386 [der.py] => Exemplar size: 1350
2025-02-05 15:18:46,386 [trainer.py] => CNN: {'total': 71.83, '0': 78.89, '1': 47.22, '2': 61.11, '3': 56.11, '4': 67.22, '5': 19.44, '6': 53.89, '7': 43.33, '8': 28.89, '9': 50.56, '10': 68.33, '11': 88.33, '12': 58.33, '13': 52.78, '14': 50.0, '15': 92.22, '16': 87.22, '17': 88.89, '18': 83.89, '19': 82.22, '20': 89.44, '21': 80.56, '22': 82.22, '23': 66.11, '24': 53.89, '25': 85.56, '26': 91.11, '27': 87.22, '28': 72.78, '29': 84.44, '30': 87.78, '31': 83.89, '32': 90.56, '33': 80.0, '34': 85.0, '35': 92.22, '36': 97.22, '37': 47.78, '38': 10.0, '39': 72.22, '40': 77.22, '41': 96.11, '42': 98.89, '43': 94.44, 'old': 70.84, 'new': 75.28}
2025-02-05 15:18:46,386 [trainer.py] => NME: {'total': 72.14, '0': 67.22, '1': 53.33, '2': 61.11, '3': 41.11, '4': 65.0, '5': 28.33, '6': 50.56, '7': 53.33, '8': 32.78, '9': 60.0, '10': 87.22, '11': 85.0, '12': 63.33, '13': 55.0, '14': 57.22, '15': 90.0, '16': 83.89, '17': 86.11, '18': 82.22, '19': 88.89, '20': 85.0, '21': 75.0, '22': 72.22, '23': 58.89, '24': 47.78, '25': 64.44, '26': 85.0, '27': 77.22, '28': 64.44, '29': 72.22, '30': 70.56, '31': 78.33, '32': 84.44, '33': 56.11, '34': 71.67, '35': 97.22, '36': 91.67, '37': 72.22, '38': 93.89, '39': 90.0, '40': 79.44, '41': 95.0, '42': 97.78, '43': 97.22, 'old': 67.29, 'new': 89.11}
2025-02-05 15:18:46,386 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.87, 71.83]
2025-02-05 15:18:46,386 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.7, 94.49]
2025-02-05 15:18:46,386 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.92, 72.14]
2025-02-05 15:18:46,386 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.97, 95.26]

2025-02-05 15:18:46,387 [trainer.py] => All params: 42096208
2025-02-05 15:18:46,387 [trainer.py] => Trainable params: 21054596
2025-02-05 15:18:46,523 [der.py] => Learning on 45-55
2025-02-05 15:18:46,524 [der.py] => All params: 42098778
2025-02-05 15:18:46,524 [der.py] => Trainable params: 21057166
2025-02-05 15:18:46,660 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-05 15:18:46,661 [der.py] => per cls weights : [1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189 1.08789189
 1.08789189 1.08789189 1.08789189 0.60448649 0.60448649 0.60448649
 0.60448649 0.60448649 0.60448649 0.60448649 0.60448649 0.60448649
 0.60448649]
2025-02-05 15:45:27,708 [der.py] => Task 4, Epoch 150/150 => Loss 0.021, Loss_clf 0.013, Loss_aux 0.008, Train_accy 99.96
2025-02-05 15:45:45,914 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.855,  Train_accy 33.35, Test_accy 57.03
2025-02-05 15:45:55,646 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.616,  Train_accy 51.32
2025-02-05 15:46:05,494 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.500,  Train_accy 60.90
2025-02-05 15:46:15,411 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.424,  Train_accy 68.41
2025-02-05 15:46:25,241 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.377,  Train_accy 72.32
2025-02-05 15:46:43,144 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.342,  Train_accy 76.45, Test_accy 60.95
2025-02-05 15:46:52,919 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.323,  Train_accy 77.93
2025-02-05 15:47:02,714 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.298,  Train_accy 79.93
2025-02-05 15:47:12,468 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.286,  Train_accy 81.14
2025-02-05 15:47:22,218 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.278,  Train_accy 82.40
2025-02-05 15:47:40,166 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.264,  Train_accy 83.57, Test_accy 63.27
2025-02-05 15:47:50,052 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.260,  Train_accy 84.29
2025-02-05 15:47:59,827 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.242,  Train_accy 85.37
2025-02-05 15:48:09,646 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.243,  Train_accy 85.46
2025-02-05 15:48:19,608 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.236,  Train_accy 86.02
2025-02-05 15:48:37,461 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.225,  Train_accy 86.74, Test_accy 64.57
2025-02-05 15:48:47,227 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.228,  Train_accy 86.52
2025-02-05 15:48:57,234 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.227,  Train_accy 86.90
2025-02-05 15:49:07,133 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.223,  Train_accy 87.44
2025-02-05 15:49:17,313 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.216,  Train_accy 88.11
2025-02-05 15:49:35,300 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.207,  Train_accy 88.34, Test_accy 64.56
2025-02-05 15:49:45,148 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.208,  Train_accy 88.52
2025-02-05 15:49:54,976 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.207,  Train_accy 88.65
2025-02-05 15:50:04,792 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.204,  Train_accy 89.64
2025-02-05 15:50:14,525 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.204,  Train_accy 89.33
2025-02-05 15:50:32,393 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.197,  Train_accy 89.50, Test_accy 66.35
2025-02-05 15:50:42,150 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.196,  Train_accy 90.22
2025-02-05 15:50:52,146 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.197,  Train_accy 89.69
2025-02-05 15:51:02,183 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.191,  Train_accy 89.66
2025-02-05 15:51:12,111 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.187,  Train_accy 90.34
2025-02-05 15:51:30,064 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.194,  Train_accy 90.16, Test_accy 66.27
2025-02-05 15:51:39,905 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.188,  Train_accy 90.50
2025-02-05 15:51:49,745 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.183,  Train_accy 91.03
2025-02-05 15:51:59,591 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.187,  Train_accy 90.81
2025-02-05 15:52:09,388 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.181,  Train_accy 91.01
2025-02-05 15:52:27,337 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.183,  Train_accy 90.83, Test_accy 66.19
2025-02-05 15:52:37,136 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.176,  Train_accy 91.24
2025-02-05 15:52:47,113 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.176,  Train_accy 91.46
2025-02-05 15:52:56,919 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.174,  Train_accy 91.57
2025-02-05 15:53:06,856 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.172,  Train_accy 91.28
2025-02-05 15:53:24,893 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.173,  Train_accy 91.23, Test_accy 66.40
2025-02-05 15:53:34,743 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.168,  Train_accy 91.39
2025-02-05 15:53:44,552 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.176,  Train_accy 91.46
2025-02-05 15:53:54,563 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.171,  Train_accy 91.30
2025-02-05 15:54:04,442 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.169,  Train_accy 91.89
2025-02-05 15:54:22,451 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.166,  Train_accy 92.16, Test_accy 67.03
2025-02-05 15:54:32,459 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.165,  Train_accy 92.36
2025-02-05 15:54:42,299 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.170,  Train_accy 91.75
2025-02-05 15:54:52,474 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.169,  Train_accy 92.02
2025-02-05 15:55:02,309 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.163,  Train_accy 91.69
2025-02-05 15:55:20,941 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.165,  Train_accy 92.13, Test_accy 67.23
2025-02-05 15:55:30,802 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.163,  Train_accy 91.93
2025-02-05 15:55:40,626 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.163,  Train_accy 92.20
2025-02-05 15:55:50,402 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.157,  Train_accy 92.22
2025-02-05 15:56:00,278 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.157,  Train_accy 92.65
2025-02-05 15:56:18,245 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.159,  Train_accy 92.43, Test_accy 66.57
2025-02-05 15:56:28,121 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.160,  Train_accy 91.96
2025-02-05 15:56:37,877 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.159,  Train_accy 92.34
2025-02-05 15:56:47,731 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.154,  Train_accy 92.68
2025-02-05 15:56:57,564 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.157,  Train_accy 92.41
2025-02-05 15:57:15,475 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.159,  Train_accy 92.97, Test_accy 67.29
2025-02-05 15:57:25,296 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.155,  Train_accy 92.63
2025-02-05 15:57:35,390 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.150,  Train_accy 92.70
2025-02-05 15:57:45,298 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.157,  Train_accy 92.49
2025-02-05 15:57:55,331 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.152,  Train_accy 93.33
2025-02-05 15:58:13,482 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.151,  Train_accy 92.34, Test_accy 67.40
2025-02-05 15:58:23,369 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.152,  Train_accy 92.67
2025-02-05 15:58:33,239 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.148,  Train_accy 93.08
2025-02-05 15:58:43,483 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.147,  Train_accy 93.68
2025-02-05 15:58:53,382 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.151,  Train_accy 93.32
2025-02-05 15:59:11,429 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.145,  Train_accy 92.47, Test_accy 67.26
2025-02-05 15:59:21,287 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.147,  Train_accy 92.94
2025-02-05 15:59:31,082 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.147,  Train_accy 92.47
2025-02-05 15:59:40,970 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.147,  Train_accy 93.19
2025-02-05 15:59:50,893 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.143,  Train_accy 93.48
2025-02-05 16:00:08,873 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.142,  Train_accy 92.99, Test_accy 67.53
2025-02-05 16:00:18,642 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.146,  Train_accy 93.39
2025-02-05 16:00:28,515 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.144,  Train_accy 93.26
2025-02-05 16:00:38,507 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.147,  Train_accy 93.32
2025-02-05 16:00:48,646 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.146,  Train_accy 93.48
2025-02-05 16:01:06,556 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.143,  Train_accy 93.53, Test_accy 67.49
2025-02-05 16:01:16,444 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.146,  Train_accy 93.39
2025-02-05 16:01:26,171 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.142,  Train_accy 93.28
2025-02-05 16:01:35,996 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.140,  Train_accy 93.42
2025-02-05 16:01:45,798 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.144,  Train_accy 93.82
2025-02-05 16:02:03,643 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.139,  Train_accy 93.55, Test_accy 67.96
2025-02-05 16:02:13,429 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.143,  Train_accy 93.14
2025-02-05 16:02:23,323 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.141,  Train_accy 93.69
2025-02-05 16:02:33,093 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.144,  Train_accy 93.41
2025-02-05 16:02:42,866 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.138,  Train_accy 93.80
2025-02-05 16:03:00,751 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.142,  Train_accy 93.80, Test_accy 67.63
2025-02-05 16:03:10,615 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.140,  Train_accy 93.98
2025-02-05 16:03:20,430 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.138,  Train_accy 93.57
2025-02-05 16:03:30,456 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.140,  Train_accy 93.53
2025-02-05 16:03:40,406 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.140,  Train_accy 93.46
2025-02-05 16:03:58,385 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.137,  Train_accy 93.51, Test_accy 68.07
2025-02-05 16:04:08,310 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.139,  Train_accy 93.48
2025-02-05 16:04:18,212 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.139,  Train_accy 93.71
2025-02-05 16:04:28,262 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.139,  Train_accy 93.84
2025-02-05 16:04:38,092 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.137,  Train_accy 93.66
2025-02-05 16:04:55,834 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.139,  Train_accy 93.50, Test_accy 68.18
2025-02-05 16:05:05,784 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.137,  Train_accy 93.91
2025-02-05 16:05:15,576 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.136,  Train_accy 93.86
2025-02-05 16:05:25,402 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.132,  Train_accy 93.60
2025-02-05 16:05:35,174 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.137,  Train_accy 93.82
2025-02-05 16:05:53,091 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.134,  Train_accy 93.77, Test_accy 67.82
2025-02-05 16:06:02,866 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.137,  Train_accy 93.80
2025-02-05 16:06:12,705 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.139,  Train_accy 93.87
2025-02-05 16:06:22,551 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.136,  Train_accy 93.73
2025-02-05 16:06:32,395 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.137,  Train_accy 93.91
2025-02-05 16:06:50,293 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.138,  Train_accy 93.87, Test_accy 68.18
2025-02-05 16:06:59,998 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.134,  Train_accy 93.95
2025-02-05 16:07:09,737 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.133,  Train_accy 93.73
2025-02-05 16:07:19,646 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.133,  Train_accy 93.98
2025-02-05 16:07:29,422 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.133,  Train_accy 93.77
2025-02-05 16:07:47,530 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.132,  Train_accy 93.66, Test_accy 67.76
2025-02-05 16:07:57,666 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.131,  Train_accy 94.00
2025-02-05 16:08:07,544 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.133,  Train_accy 93.69
2025-02-05 16:08:17,429 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.132,  Train_accy 93.41
2025-02-05 16:08:27,358 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.135,  Train_accy 93.68
2025-02-05 16:08:45,497 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.133,  Train_accy 93.69, Test_accy 68.00
2025-02-05 16:08:55,324 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.136,  Train_accy 93.77
2025-02-05 16:09:05,202 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.133,  Train_accy 93.73
2025-02-05 16:09:14,937 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.136,  Train_accy 93.89
2025-02-05 16:09:24,720 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.134,  Train_accy 93.80
2025-02-05 16:09:42,916 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.133,  Train_accy 93.84, Test_accy 67.92
2025-02-05 16:09:52,755 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.133,  Train_accy 93.87
2025-02-05 16:10:02,581 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.130,  Train_accy 94.34
2025-02-05 16:10:12,461 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.135,  Train_accy 93.80
2025-02-05 16:10:22,230 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.131,  Train_accy 94.09
2025-02-05 16:10:22,231 [der.py] => do not weight align student!
2025-02-05 16:10:29,970 [der.py] => darknet eval: 
2025-02-05 16:10:29,970 [der.py] => CNN top1 curve: 67.56
2025-02-05 16:10:29,970 [der.py] => CNN top5 curve: 91.93
2025-02-05 16:10:29,971 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-05 16:11:26,346 [der.py] => Exemplar size: 1650
2025-02-05 16:11:26,347 [trainer.py] => CNN: {'total': 69.46, '0': 71.11, '1': 53.89, '2': 58.33, '3': 33.89, '4': 64.44, '5': 27.78, '6': 50.56, '7': 41.67, '8': 36.67, '9': 51.67, '10': 78.33, '11': 80.56, '12': 60.0, '13': 50.0, '14': 58.33, '15': 76.67, '16': 80.0, '17': 75.0, '18': 68.89, '19': 68.89, '20': 83.33, '21': 71.67, '22': 78.33, '23': 56.67, '24': 57.22, '25': 57.78, '26': 66.11, '27': 68.33, '28': 52.22, '29': 61.67, '30': 71.11, '31': 69.44, '32': 77.22, '33': 46.67, '34': 47.22, '35': 97.22, '36': 96.11, '37': 68.89, '38': 88.33, '39': 91.67, '40': 82.78, '41': 96.11, '42': 94.44, '43': 97.22, '44': 72.22, '45': 82.22, '46': 82.78, '47': 80.0, '48': 82.22, '49': 76.11, '50': 73.33, '51': 79.44, '52': 76.11, '53': 75.0, 'old': 67.48, 'new': 78.39}
2025-02-05 16:11:26,347 [trainer.py] => NME: {'total': 63.44, '0': 60.56, '1': 49.44, '2': 55.0, '3': 27.78, '4': 58.89, '5': 29.44, '6': 45.56, '7': 50.0, '8': 33.89, '9': 58.89, '10': 76.67, '11': 86.11, '12': 60.0, '13': 45.0, '14': 53.89, '15': 71.11, '16': 77.22, '17': 76.67, '18': 58.89, '19': 67.22, '20': 70.0, '21': 68.89, '22': 71.67, '23': 50.0, '24': 42.78, '25': 43.89, '26': 57.22, '27': 55.56, '28': 41.67, '29': 46.67, '30': 61.11, '31': 63.33, '32': 53.89, '33': 36.67, '34': 55.56, '35': 83.89, '36': 86.11, '37': 45.56, '38': 79.44, '39': 69.44, '40': 62.22, '41': 90.56, '42': 97.22, '43': 95.0, '44': 48.89, '45': 87.78, '46': 83.89, '47': 83.89, '48': 81.11, '49': 71.11, '50': 67.78, '51': 73.89, '52': 75.56, '53': 68.33, 'old': 60.43, 'new': 77.0}
2025-02-05 16:11:26,347 [trainer.py] => CNN top1 curve: [89.44, 88.07, 78.87, 71.83, 69.46]
2025-02-05 16:11:26,347 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.7, 94.49, 92.58]
2025-02-05 16:11:26,347 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.92, 72.14, 63.44]
2025-02-05 16:11:26,347 [trainer.py] => NME top5 curve: [98.81, 98.51, 96.97, 95.26, 91.76]

2025-02-16 17:35:15,090 [trainer.py] => 实验名称:auxloss对比实验
2025-02-16 17:35:15,123 [trainer.py] => config: ./exps/der.json
2025-02-16 17:35:15,123 [trainer.py] => experiment_name: 实验名称:auxloss对比实验
2025-02-16 17:35:15,123 [trainer.py] => prefix: reproduce
2025-02-16 17:35:15,123 [trainer.py] => dataset: xrfdataset
2025-02-16 17:35:15,123 [trainer.py] => memory_size: 1650
2025-02-16 17:35:15,123 [trainer.py] => memory_per_class: 30
2025-02-16 17:35:15,123 [trainer.py] => fixed_memory: True
2025-02-16 17:35:15,123 [trainer.py] => shuffle: True
2025-02-16 17:35:15,123 [trainer.py] => init_cls: 15
2025-02-16 17:35:15,124 [trainer.py] => increment: 10
2025-02-16 17:35:15,124 [trainer.py] => model_name: der
2025-02-16 17:35:15,124 [trainer.py] => compression_epochs: 130
2025-02-16 17:35:15,124 [trainer.py] => compression_lr: 0.1
2025-02-16 17:35:15,124 [trainer.py] => is_student_wa: False
2025-02-16 17:35:15,124 [trainer.py] => wa_value: 1
2025-02-16 17:35:15,124 [trainer.py] => T: 2
2025-02-16 17:35:15,124 [trainer.py] => convnet_type: unet
2025-02-16 17:35:15,124 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-02-16 17:35:15,124 [trainer.py] => seed: 1993
2025-02-16 17:35:15,177 [data.py] => 加载完毕XRF原始数据集
2025-02-16 17:35:15,198 [data.py] => 加载完毕XRF原始数据集
2025-02-16 17:35:15,199 [trainer.py] => All params: 0
2025-02-16 17:35:15,199 [trainer.py] => Trainable params: 0
2025-02-16 17:35:15,413 [der.py] => Learning on 0-15
2025-02-16 17:35:15,413 [der.py] => All params: 21045611
2025-02-16 17:35:15,414 [der.py] => Trainable params: 21045611
2025-02-16 18:10:13,338 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-02-16 18:10:13,369 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 18:10:41,569 [der.py] => Exemplar size: 450
2025-02-16 18:10:41,569 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-02-16 18:10:41,569 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-02-16 18:10:41,569 [trainer.py] => CNN top1 curve: [89.44]
2025-02-16 18:10:41,569 [trainer.py] => CNN top5 curve: [98.93]
2025-02-16 18:10:41,569 [trainer.py] => NME top1 curve: [88.22]
2025-02-16 18:10:41,570 [trainer.py] => NME top5 curve: [98.81]

2025-02-16 18:10:41,570 [trainer.py] => All params: 21045611
2025-02-16 18:10:41,570 [trainer.py] => Trainable params: 21045611
2025-02-16 18:10:41,733 [der.py] => Learning on 15-25
2025-02-16 18:10:41,734 [der.py] => All params: 42091068
2025-02-16 18:10:41,734 [der.py] => Trainable params: 21049456
2025-02-16 18:10:41,810 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 18:10:41,811 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-02-16 18:41:40,069 [der.py] => Task 1, Epoch 150/150 => Loss 0.006, Loss_clf 0.006, Loss_aux 2.320, Train_accy 100.00
2025-02-16 18:41:58,155 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.189,  Train_accy 45.18, Test_accy 56.96
2025-02-16 18:42:10,515 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.659,  Train_accy 71.44
2025-02-16 18:42:23,401 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.497,  Train_accy 79.91
2025-02-16 18:42:35,509 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.392,  Train_accy 86.28
2025-02-16 18:42:48,248 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.339,  Train_accy 88.52
2025-02-16 18:43:07,423 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.301,  Train_accy 90.41, Test_accy 77.36
2025-02-16 18:43:20,219 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.278,  Train_accy 90.99
2025-02-16 18:43:32,666 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.249,  Train_accy 93.40
2025-02-16 18:43:45,193 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.241,  Train_accy 93.68
2025-02-16 18:43:57,684 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.240,  Train_accy 93.18
2025-02-16 18:44:15,373 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.220,  Train_accy 94.77, Test_accy 76.38
2025-02-16 18:44:28,251 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.207,  Train_accy 95.44
2025-02-16 18:44:40,336 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.196,  Train_accy 95.27
2025-02-16 18:44:52,786 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.191,  Train_accy 95.42
2025-02-16 18:45:04,212 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.182,  Train_accy 96.15
2025-02-16 18:45:22,477 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.198,  Train_accy 94.95, Test_accy 77.98
2025-02-16 18:45:34,882 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.189,  Train_accy 95.81
2025-02-16 18:45:47,018 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.180,  Train_accy 95.48
2025-02-16 18:45:59,220 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.179,  Train_accy 96.04
2025-02-16 18:46:12,132 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.181,  Train_accy 96.00
2025-02-16 18:46:30,011 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.169,  Train_accy 96.49, Test_accy 79.84
2025-02-16 18:46:42,064 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.164,  Train_accy 96.45
2025-02-16 18:46:54,429 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.161,  Train_accy 96.56
2025-02-16 18:47:07,389 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.163,  Train_accy 96.58
2025-02-16 18:47:19,407 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.160,  Train_accy 96.58
2025-02-16 18:47:37,883 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.152,  Train_accy 97.05, Test_accy 80.29
2025-02-16 18:47:50,171 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.154,  Train_accy 96.62
2025-02-16 18:48:03,098 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.150,  Train_accy 96.80
2025-02-16 18:48:15,141 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.147,  Train_accy 97.03
2025-02-16 18:48:27,645 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.150,  Train_accy 97.03
2025-02-16 18:48:45,935 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.151,  Train_accy 97.18, Test_accy 80.44
2025-02-16 18:48:57,958 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.150,  Train_accy 96.71
2025-02-16 18:49:10,029 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.145,  Train_accy 97.33
2025-02-16 18:49:22,567 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.138,  Train_accy 97.46
2025-02-16 18:49:35,301 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.138,  Train_accy 97.01
2025-02-16 18:49:53,262 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.138,  Train_accy 97.31, Test_accy 80.76
2025-02-16 18:50:05,563 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.139,  Train_accy 97.14
2025-02-16 18:50:18,083 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.144,  Train_accy 97.08
2025-02-16 18:50:30,253 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.137,  Train_accy 97.18
2025-02-16 18:50:42,548 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.134,  Train_accy 97.51
2025-02-16 18:51:01,088 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.133,  Train_accy 97.35, Test_accy 81.49
2025-02-16 18:51:13,810 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.135,  Train_accy 97.27
2025-02-16 18:51:25,905 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.139,  Train_accy 97.18
2025-02-16 18:51:38,694 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.129,  Train_accy 97.42
2025-02-16 18:51:51,589 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.130,  Train_accy 97.48
2025-02-16 18:52:08,812 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.135,  Train_accy 97.10, Test_accy 81.80
2025-02-16 18:52:20,975 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.132,  Train_accy 97.29
2025-02-16 18:52:33,651 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.128,  Train_accy 97.40
2025-02-16 18:52:46,520 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.131,  Train_accy 97.51
2025-02-16 18:52:57,825 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.134,  Train_accy 97.23
2025-02-16 18:53:16,344 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.130,  Train_accy 96.99, Test_accy 80.69
2025-02-16 18:53:28,962 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.130,  Train_accy 96.99
2025-02-16 18:53:41,411 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.129,  Train_accy 97.46
2025-02-16 18:53:53,545 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.131,  Train_accy 97.46
2025-02-16 18:54:06,331 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.127,  Train_accy 97.42
2025-02-16 18:54:24,348 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.122,  Train_accy 97.38, Test_accy 82.02
2025-02-16 18:54:36,313 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.122,  Train_accy 97.57
2025-02-16 18:54:48,622 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.124,  Train_accy 97.48
2025-02-16 18:55:01,422 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.121,  Train_accy 97.61
2025-02-16 18:55:13,266 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.119,  Train_accy 97.89
2025-02-16 18:55:31,145 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.116,  Train_accy 97.59, Test_accy 81.64
2025-02-16 18:55:43,357 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.122,  Train_accy 97.12
2025-02-16 18:55:56,129 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.119,  Train_accy 97.78
2025-02-16 18:56:07,467 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.123,  Train_accy 97.76
2025-02-16 18:56:20,001 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.118,  Train_accy 97.27
2025-02-16 18:56:38,060 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.117,  Train_accy 97.35, Test_accy 81.04
2025-02-16 18:56:49,908 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.120,  Train_accy 97.38
2025-02-16 18:57:01,956 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.119,  Train_accy 97.44
2025-02-16 18:57:14,603 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.119,  Train_accy 97.53
2025-02-16 18:57:27,102 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.120,  Train_accy 97.33
2025-02-16 18:57:44,532 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.119,  Train_accy 97.53, Test_accy 81.33
2025-02-16 18:57:57,005 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.117,  Train_accy 97.83
2025-02-16 18:58:09,792 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.114,  Train_accy 97.89
2025-02-16 18:58:21,887 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.119,  Train_accy 97.46
2025-02-16 18:58:34,055 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.115,  Train_accy 97.51
2025-02-16 18:58:52,431 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.115,  Train_accy 97.33, Test_accy 81.40
2025-02-16 18:59:04,920 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.117,  Train_accy 97.76
2025-02-16 18:59:16,632 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.115,  Train_accy 97.91
2025-02-16 18:59:29,365 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.114,  Train_accy 97.74
2025-02-16 18:59:42,004 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.115,  Train_accy 97.44
2025-02-16 18:59:59,720 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.114,  Train_accy 97.46, Test_accy 81.36
2025-02-16 19:00:11,985 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.117,  Train_accy 97.63
2025-02-16 19:00:24,429 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.113,  Train_accy 97.74
2025-02-16 19:00:36,599 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.114,  Train_accy 97.66
2025-02-16 19:00:48,366 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.109,  Train_accy 97.85
2025-02-16 19:01:06,607 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.108,  Train_accy 97.96, Test_accy 81.93
2025-02-16 19:01:19,916 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.110,  Train_accy 97.53
2025-02-16 19:01:32,793 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.115,  Train_accy 97.48
2025-02-16 19:01:45,062 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.113,  Train_accy 97.74
2025-02-16 19:01:57,741 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.112,  Train_accy 97.55
2025-02-16 19:02:16,158 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.112,  Train_accy 97.48, Test_accy 81.67
2025-02-16 19:02:28,200 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.111,  Train_accy 97.72
2025-02-16 19:02:40,661 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.109,  Train_accy 97.89
2025-02-16 19:02:53,487 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.110,  Train_accy 97.98
2025-02-16 19:03:06,058 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.112,  Train_accy 97.78
2025-02-16 19:03:23,659 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.108,  Train_accy 97.53, Test_accy 81.91
2025-02-16 19:03:36,435 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.109,  Train_accy 97.81
2025-02-16 19:03:48,848 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.108,  Train_accy 97.66
2025-02-16 19:04:01,772 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.106,  Train_accy 97.66
2025-02-16 19:04:12,974 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.112,  Train_accy 97.53
2025-02-16 19:04:31,224 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.109,  Train_accy 97.78, Test_accy 81.84
2025-02-16 19:04:43,975 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.108,  Train_accy 97.55
2025-02-16 19:04:56,493 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.107,  Train_accy 97.70
2025-02-16 19:05:08,931 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.108,  Train_accy 97.76
2025-02-16 19:05:21,657 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.108,  Train_accy 97.46
2025-02-16 19:05:40,468 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.107,  Train_accy 97.85, Test_accy 81.51
2025-02-16 19:05:52,129 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.106,  Train_accy 97.81
2025-02-16 19:06:05,346 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.110,  Train_accy 97.66
2025-02-16 19:06:18,109 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.105,  Train_accy 97.85
2025-02-16 19:06:31,381 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.109,  Train_accy 97.94
2025-02-16 19:06:48,917 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.107,  Train_accy 97.76, Test_accy 81.82
2025-02-16 19:07:01,696 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.105,  Train_accy 97.94
2025-02-16 19:07:14,812 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.107,  Train_accy 97.61
2025-02-16 19:07:27,440 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.108,  Train_accy 97.91
2025-02-16 19:07:39,578 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.107,  Train_accy 97.81
2025-02-16 19:07:58,091 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.109,  Train_accy 97.61, Test_accy 82.29
2025-02-16 19:08:10,358 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.106,  Train_accy 97.59
2025-02-16 19:08:22,419 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.105,  Train_accy 97.89
2025-02-16 19:08:34,749 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.108,  Train_accy 97.83
2025-02-16 19:08:47,618 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.108,  Train_accy 97.72
2025-02-16 19:09:05,750 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.107,  Train_accy 97.72, Test_accy 82.04
2025-02-16 19:09:17,167 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.109,  Train_accy 97.81
2025-02-16 19:09:29,899 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.104,  Train_accy 97.66
2025-02-16 19:09:42,163 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.105,  Train_accy 98.06
2025-02-16 19:09:55,138 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.106,  Train_accy 97.81
2025-02-16 19:10:12,095 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.102,  Train_accy 97.83, Test_accy 82.04
2025-02-16 19:10:24,797 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.108,  Train_accy 97.72
2025-02-16 19:10:38,033 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.107,  Train_accy 97.59
2025-02-16 19:10:50,148 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.104,  Train_accy 97.72
2025-02-16 19:11:02,234 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.105,  Train_accy 97.78
2025-02-16 19:11:02,235 [der.py] => do not weight align student!
2025-02-16 19:11:07,141 [der.py] => darknet eval: 
2025-02-16 19:11:07,142 [der.py] => CNN top1 curve: 82.02
2025-02-16 19:11:07,142 [der.py] => CNN top5 curve: 98.07
2025-02-16 19:11:07,144 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 19:11:42,541 [der.py] => Exemplar size: 750
2025-02-16 19:11:42,541 [trainer.py] => CNN: {'total': 87.89, '0': 88.33, '1': 86.11, '2': 95.56, '3': 81.67, '4': 92.78, '5': 71.67, '6': 76.11, '7': 74.44, '8': 65.0, '9': 65.56, '10': 96.11, '11': 100.0, '12': 88.33, '13': 87.78, '14': 87.78, '15': 96.67, '16': 97.22, '17': 97.78, '18': 95.0, '19': 95.56, '20': 97.22, '21': 91.67, '22': 88.89, '23': 90.0, 'old': 83.81, 'new': 94.0}
2025-02-16 19:11:42,541 [trainer.py] => NME: {'total': 85.53, '0': 85.56, '1': 85.56, '2': 94.44, '3': 81.11, '4': 91.67, '5': 70.0, '6': 65.0, '7': 58.89, '8': 60.0, '9': 67.22, '10': 97.22, '11': 100.0, '12': 87.78, '13': 83.33, '14': 85.0, '15': 93.33, '16': 97.78, '17': 93.33, '18': 94.44, '19': 93.89, '20': 95.0, '21': 97.22, '22': 87.22, '23': 85.56, 'old': 80.85, 'new': 92.56}
2025-02-16 19:11:42,541 [trainer.py] => CNN top1 curve: [89.44, 87.89]
2025-02-16 19:11:42,541 [trainer.py] => CNN top5 curve: [98.93, 98.71]
2025-02-16 19:11:42,541 [trainer.py] => NME top1 curve: [88.22, 85.53]
2025-02-16 19:11:42,541 [trainer.py] => NME top5 curve: [98.81, 98.64]

2025-02-16 19:11:42,542 [trainer.py] => All params: 42091068
2025-02-16 19:11:42,542 [trainer.py] => Trainable params: 21049456
2025-02-16 19:11:42,696 [der.py] => Learning on 25-35
2025-02-16 19:11:42,697 [der.py] => All params: 42093638
2025-02-16 19:11:42,697 [der.py] => Trainable params: 21052026
2025-02-16 19:11:42,808 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 19:11:42,808 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-02-16 19:45:59,447 [der.py] => Task 2, Epoch 150/150 => Loss 0.008, Loss_clf 0.008, Loss_aux 2.389, Train_accy 100.00
2025-02-16 19:46:21,279 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.338,  Train_accy 46.02, Test_accy 55.65
2025-02-16 19:46:35,115 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.023,  Train_accy 67.56
2025-02-16 19:46:48,702 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.916,  Train_accy 74.61
2025-02-16 19:47:01,044 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.854,  Train_accy 79.31
2025-02-16 19:47:14,338 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.826,  Train_accy 82.00
2025-02-16 19:47:36,050 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.793,  Train_accy 83.66, Test_accy 66.43
2025-02-16 19:47:49,709 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.778,  Train_accy 84.87
2025-02-16 19:48:03,747 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.764,  Train_accy 85.31
2025-02-16 19:48:17,821 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.742,  Train_accy 86.57
2025-02-16 19:48:31,086 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.741,  Train_accy 87.39
2025-02-16 19:48:51,688 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.729,  Train_accy 87.60, Test_accy 71.29
2025-02-16 19:49:05,133 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.715,  Train_accy 88.85
2025-02-16 19:49:18,821 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.707,  Train_accy 89.21
2025-02-16 19:49:31,762 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.706,  Train_accy 89.60
2025-02-16 19:49:44,816 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.697,  Train_accy 90.10
2025-02-16 19:50:06,460 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.693,  Train_accy 90.18, Test_accy 71.67
2025-02-16 19:50:19,827 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.692,  Train_accy 90.06
2025-02-16 19:50:32,185 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.686,  Train_accy 90.61
2025-02-16 19:50:46,251 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.685,  Train_accy 90.22
2025-02-16 19:50:59,535 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.678,  Train_accy 90.69
2025-02-16 19:51:20,925 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.680,  Train_accy 90.83, Test_accy 72.02
2025-02-16 19:51:34,149 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.679,  Train_accy 91.01
2025-02-16 19:51:48,600 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.674,  Train_accy 91.64
2025-02-16 19:52:02,042 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.671,  Train_accy 91.86
2025-02-16 19:52:15,052 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.666,  Train_accy 91.74
2025-02-16 19:52:36,141 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.662,  Train_accy 91.78, Test_accy 73.16
2025-02-16 19:52:49,937 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.657,  Train_accy 92.36
2025-02-16 19:53:03,062 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.656,  Train_accy 92.22
2025-02-16 19:53:15,862 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.659,  Train_accy 91.78
2025-02-16 19:53:29,571 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.657,  Train_accy 92.10
2025-02-16 19:53:51,704 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.659,  Train_accy 92.34, Test_accy 72.60
2025-02-16 19:54:04,152 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.656,  Train_accy 92.38
2025-02-16 19:54:17,707 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.651,  Train_accy 92.87
2025-02-16 19:54:30,999 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.648,  Train_accy 92.81
2025-02-16 19:54:44,578 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.648,  Train_accy 92.87
2025-02-16 19:55:05,519 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.646,  Train_accy 92.93, Test_accy 73.62
2025-02-16 19:55:19,914 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.645,  Train_accy 92.83
2025-02-16 19:55:33,247 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.646,  Train_accy 92.67
2025-02-16 19:55:46,492 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.642,  Train_accy 93.11
2025-02-16 19:55:59,716 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.642,  Train_accy 92.95
2025-02-16 19:56:21,174 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.644,  Train_accy 92.55, Test_accy 73.16
2025-02-16 19:56:34,442 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.638,  Train_accy 93.43
2025-02-16 19:56:47,320 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.639,  Train_accy 92.85
2025-02-16 19:57:00,927 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.638,  Train_accy 93.62
2025-02-16 19:57:15,081 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.636,  Train_accy 93.25
2025-02-16 19:57:36,928 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.636,  Train_accy 93.41, Test_accy 73.63
2025-02-16 19:57:51,219 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.639,  Train_accy 93.21
2025-02-16 19:58:05,236 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.637,  Train_accy 93.37
2025-02-16 19:58:18,856 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.637,  Train_accy 93.58
2025-02-16 19:58:31,527 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.631,  Train_accy 93.09
2025-02-16 19:58:52,485 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.630,  Train_accy 93.41, Test_accy 73.95
2025-02-16 19:59:06,797 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.632,  Train_accy 93.39
2025-02-16 19:59:20,229 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.632,  Train_accy 93.33
2025-02-16 19:59:33,632 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.628,  Train_accy 93.84
2025-02-16 19:59:47,440 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.629,  Train_accy 93.49
2025-02-16 20:00:10,491 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.627,  Train_accy 94.08, Test_accy 74.11
2025-02-16 20:00:23,723 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.626,  Train_accy 93.82
2025-02-16 20:00:37,458 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.628,  Train_accy 93.39
2025-02-16 20:00:51,596 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.626,  Train_accy 93.96
2025-02-16 20:01:04,988 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.625,  Train_accy 93.58
2025-02-16 20:01:26,091 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.626,  Train_accy 93.74, Test_accy 73.84
2025-02-16 20:01:39,631 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.624,  Train_accy 93.96
2025-02-16 20:01:53,571 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.631,  Train_accy 93.35
2025-02-16 20:02:07,006 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.620,  Train_accy 94.18
2025-02-16 20:02:19,779 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.622,  Train_accy 93.41
2025-02-16 20:02:41,450 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.622,  Train_accy 93.94, Test_accy 74.22
2025-02-16 20:02:54,760 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.623,  Train_accy 93.72
2025-02-16 20:03:07,739 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.621,  Train_accy 94.36
2025-02-16 20:03:21,149 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.621,  Train_accy 94.08
2025-02-16 20:03:35,111 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.618,  Train_accy 93.47
2025-02-16 20:03:57,256 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.623,  Train_accy 94.16, Test_accy 74.27
2025-02-16 20:04:11,190 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.621,  Train_accy 93.96
2025-02-16 20:04:25,030 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.620,  Train_accy 94.08
2025-02-16 20:04:39,814 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.616,  Train_accy 94.12
2025-02-16 20:04:53,706 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.619,  Train_accy 93.96
2025-02-16 20:05:14,667 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.618,  Train_accy 94.12, Test_accy 73.83
2025-02-16 20:05:28,476 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.619,  Train_accy 94.30
2025-02-16 20:05:41,965 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.614,  Train_accy 94.57
2025-02-16 20:05:54,745 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.617,  Train_accy 94.26
2025-02-16 20:06:07,889 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.612,  Train_accy 94.16
2025-02-16 20:06:29,389 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.615,  Train_accy 94.00, Test_accy 74.33
2025-02-16 20:06:42,827 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.616,  Train_accy 94.65
2025-02-16 20:06:55,457 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.610,  Train_accy 94.42
2025-02-16 20:07:09,599 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.612,  Train_accy 94.73
2025-02-16 20:07:23,193 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.613,  Train_accy 94.46
2025-02-16 20:07:44,248 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.613,  Train_accy 93.43, Test_accy 74.86
2025-02-16 20:07:57,434 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.611,  Train_accy 94.57
2025-02-16 20:08:11,453 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.611,  Train_accy 94.69
2025-02-16 20:08:25,100 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.610,  Train_accy 94.36
2025-02-16 20:08:38,277 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.612,  Train_accy 94.00
2025-02-16 20:08:59,540 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.610,  Train_accy 94.44, Test_accy 74.27
2025-02-16 20:09:13,048 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.611,  Train_accy 94.12
2025-02-16 20:09:26,734 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.611,  Train_accy 94.59
2025-02-16 20:09:39,061 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.609,  Train_accy 94.61
2025-02-16 20:09:53,455 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.609,  Train_accy 94.53
2025-02-16 20:10:15,566 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.609,  Train_accy 94.02, Test_accy 74.73
2025-02-16 20:10:28,889 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.609,  Train_accy 94.65
2025-02-16 20:10:42,123 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.609,  Train_accy 94.48
2025-02-16 20:10:55,387 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.607,  Train_accy 94.61
2025-02-16 20:11:09,149 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.608,  Train_accy 94.53
2025-02-16 20:11:29,465 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.609,  Train_accy 94.55, Test_accy 74.98
2025-02-16 20:11:43,825 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.609,  Train_accy 94.20
2025-02-16 20:11:57,255 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.608,  Train_accy 94.61
2025-02-16 20:12:11,154 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.606,  Train_accy 94.57
2025-02-16 20:12:23,198 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.606,  Train_accy 94.63
2025-02-16 20:12:44,956 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.608,  Train_accy 94.34, Test_accy 74.63
2025-02-16 20:12:58,378 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.607,  Train_accy 94.48
2025-02-16 20:13:11,323 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.606,  Train_accy 94.93
2025-02-16 20:13:24,071 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.610,  Train_accy 94.04
2025-02-16 20:13:37,123 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.606,  Train_accy 94.83
2025-02-16 20:13:57,907 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.608,  Train_accy 94.81, Test_accy 74.76
2025-02-16 20:14:10,007 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.607,  Train_accy 94.38
2025-02-16 20:14:23,582 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.605,  Train_accy 94.97
2025-02-16 20:14:37,108 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.605,  Train_accy 94.75
2025-02-16 20:14:50,484 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.606,  Train_accy 94.59
2025-02-16 20:15:10,320 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.607,  Train_accy 94.77, Test_accy 74.79
2025-02-16 20:15:23,611 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.606,  Train_accy 94.32
2025-02-16 20:15:37,279 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.606,  Train_accy 94.53
2025-02-16 20:15:50,444 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.607,  Train_accy 94.34
2025-02-16 20:16:03,223 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.607,  Train_accy 94.59
2025-02-16 20:16:24,098 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.606,  Train_accy 95.47, Test_accy 74.68
2025-02-16 20:16:37,981 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.605,  Train_accy 94.83
2025-02-16 20:16:50,142 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.607,  Train_accy 94.44
2025-02-16 20:17:03,964 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.606,  Train_accy 94.77
2025-02-16 20:17:17,564 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.605,  Train_accy 93.84
2025-02-16 20:17:38,878 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.604,  Train_accy 94.81, Test_accy 74.90
2025-02-16 20:17:51,735 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.605,  Train_accy 94.61
2025-02-16 20:18:04,949 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.608,  Train_accy 94.44
2025-02-16 20:18:18,722 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.606,  Train_accy 94.51
2025-02-16 20:18:31,882 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.605,  Train_accy 94.83
2025-02-16 20:18:31,882 [der.py] => do not weight align student!
2025-02-16 20:18:41,599 [der.py] => darknet eval: 
2025-02-16 20:18:41,599 [der.py] => CNN top1 curve: 74.63
2025-02-16 20:18:41,599 [der.py] => CNN top5 curve: 95.56
2025-02-16 20:18:41,601 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 20:19:27,001 [der.py] => Exemplar size: 1050
2025-02-16 20:19:27,001 [trainer.py] => CNN: {'total': 78.48, '0': 88.33, '1': 61.67, '2': 80.0, '3': 61.11, '4': 81.11, '5': 37.78, '6': 66.67, '7': 48.33, '8': 34.44, '9': 55.0, '10': 90.56, '11': 93.33, '12': 73.33, '13': 71.11, '14': 66.11, '15': 94.44, '16': 98.89, '17': 96.67, '18': 91.11, '19': 95.0, '20': 95.56, '21': 91.67, '22': 91.11, '23': 80.0, '24': 72.78, '25': 82.78, '26': 79.44, '27': 82.78, '28': 78.89, '29': 77.78, '30': 84.44, '31': 86.67, '32': 96.11, '33': 81.67, 'old': 76.64, 'new': 83.06}
2025-02-16 20:19:27,001 [trainer.py] => NME: {'total': 75.95, '0': 81.11, '1': 66.11, '2': 74.44, '3': 59.44, '4': 81.67, '5': 41.67, '6': 56.11, '7': 56.11, '8': 42.22, '9': 66.67, '10': 92.22, '11': 90.56, '12': 70.56, '13': 66.67, '14': 65.56, '15': 90.0, '16': 93.89, '17': 91.67, '18': 90.0, '19': 92.22, '20': 95.0, '21': 91.11, '22': 82.22, '23': 65.56, '24': 54.44, '25': 80.0, '26': 84.44, '27': 83.33, '28': 70.56, '29': 77.78, '30': 80.56, '31': 85.0, '32': 90.56, '33': 73.89, 'old': 74.29, 'new': 80.11}
2025-02-16 20:19:27,001 [trainer.py] => CNN top1 curve: [89.44, 87.89, 78.48]
2025-02-16 20:19:27,001 [trainer.py] => CNN top5 curve: [98.93, 98.71, 96.17]
2025-02-16 20:19:27,002 [trainer.py] => NME top1 curve: [88.22, 85.53, 75.95]
2025-02-16 20:19:27,002 [trainer.py] => NME top5 curve: [98.81, 98.64, 96.32]

2025-02-16 20:19:27,002 [trainer.py] => All params: 42093638
2025-02-16 20:19:27,003 [trainer.py] => Trainable params: 21052026
2025-02-16 20:19:27,187 [der.py] => Learning on 35-45
2025-02-16 20:19:27,188 [der.py] => All params: 42096208
2025-02-16 20:19:27,189 [der.py] => Trainable params: 21054596
2025-02-16 20:19:27,294 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 20:19:27,294 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-02-16 20:50:17,949 [der.py] => Task 3, Epoch 150/150 => Loss 0.076, Loss_clf 0.076, Loss_aux 2.380, Train_accy 99.90
2025-02-16 20:50:36,670 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.171,  Train_accy 43.30, Test_accy 48.73
2025-02-16 20:50:47,692 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.948,  Train_accy 53.60
2025-02-16 20:50:58,645 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.857,  Train_accy 57.54
2025-02-16 20:51:09,593 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.815,  Train_accy 59.83
2025-02-16 20:51:20,514 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.812,  Train_accy 60.57
2025-02-16 20:51:39,413 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.826,  Train_accy 60.93, Test_accy 53.81
2025-02-16 20:51:50,419 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.773,  Train_accy 61.79
2025-02-16 20:52:01,511 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.742,  Train_accy 62.93
2025-02-16 20:52:12,512 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.743,  Train_accy 63.66
2025-02-16 20:52:23,696 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.742,  Train_accy 64.30
2025-02-16 20:52:42,356 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.726,  Train_accy 64.10, Test_accy 59.62
2025-02-16 20:52:53,463 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.724,  Train_accy 65.14
2025-02-16 20:53:04,454 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.727,  Train_accy 64.15
2025-02-16 20:53:15,473 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.718,  Train_accy 65.24
2025-02-16 20:53:26,523 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.710,  Train_accy 65.33
2025-02-16 20:53:45,476 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.690,  Train_accy 65.89, Test_accy 61.44
2025-02-16 20:53:56,481 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.717,  Train_accy 65.18
2025-02-16 20:54:07,473 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.700,  Train_accy 65.83
2025-02-16 20:54:18,631 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.690,  Train_accy 65.87
2025-02-16 20:54:29,655 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.682,  Train_accy 66.46
2025-02-16 20:54:48,366 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.691,  Train_accy 66.23, Test_accy 61.27
2025-02-16 20:54:59,332 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.737,  Train_accy 64.76
2025-02-16 20:55:10,391 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.684,  Train_accy 66.50
2025-02-16 20:55:21,690 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.687,  Train_accy 66.65
2025-02-16 20:55:32,727 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.690,  Train_accy 66.17
2025-02-16 20:55:51,139 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.689,  Train_accy 66.78, Test_accy 61.37
2025-02-16 20:56:02,077 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.660,  Train_accy 67.26
2025-02-16 20:56:12,991 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.670,  Train_accy 67.64
2025-02-16 20:56:24,033 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.674,  Train_accy 67.47
2025-02-16 20:56:34,928 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.672,  Train_accy 67.09
2025-02-16 20:56:53,442 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.656,  Train_accy 67.45, Test_accy 60.51
2025-02-16 20:57:04,383 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.667,  Train_accy 67.01
2025-02-16 20:57:15,515 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.646,  Train_accy 67.54
2025-02-16 20:57:26,508 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.651,  Train_accy 67.49
2025-02-16 20:57:37,489 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.678,  Train_accy 66.48
2025-02-16 20:57:56,393 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.644,  Train_accy 68.36, Test_accy 61.56
2025-02-16 20:58:07,457 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.662,  Train_accy 67.85
2025-02-16 20:58:18,460 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.666,  Train_accy 67.16
2025-02-16 20:58:29,589 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.678,  Train_accy 66.50
2025-02-16 20:58:40,694 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.653,  Train_accy 67.90
2025-02-16 20:58:59,962 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.652,  Train_accy 68.29, Test_accy 62.93
2025-02-16 20:59:11,418 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.651,  Train_accy 67.56
2025-02-16 20:59:22,648 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.662,  Train_accy 68.02
2025-02-16 20:59:33,810 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.650,  Train_accy 68.40
2025-02-16 20:59:44,910 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.656,  Train_accy 68.10
2025-02-16 21:00:03,984 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.646,  Train_accy 67.87, Test_accy 62.86
2025-02-16 21:00:15,166 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.642,  Train_accy 68.44
2025-02-16 21:00:26,316 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.644,  Train_accy 68.30
2025-02-16 21:00:37,511 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.643,  Train_accy 68.06
2025-02-16 21:00:48,732 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.644,  Train_accy 68.34
2025-02-16 21:01:07,913 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.630,  Train_accy 68.59, Test_accy 56.23
2025-02-16 21:01:19,041 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.637,  Train_accy 68.32
2025-02-16 21:01:30,174 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.629,  Train_accy 68.19
2025-02-16 21:01:41,365 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.636,  Train_accy 68.67
2025-02-16 21:01:52,534 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.630,  Train_accy 69.05
2025-02-16 21:02:11,582 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.625,  Train_accy 68.55, Test_accy 62.93
2025-02-16 21:02:22,684 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.638,  Train_accy 68.99
2025-02-16 21:02:33,886 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.631,  Train_accy 68.55
2025-02-16 21:02:45,329 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.627,  Train_accy 69.03
2025-02-16 21:02:56,501 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.626,  Train_accy 68.95
2025-02-16 21:03:15,509 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.645,  Train_accy 67.56, Test_accy 63.96
2025-02-16 21:03:26,820 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.623,  Train_accy 69.09
2025-02-16 21:03:37,902 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.629,  Train_accy 67.89
2025-02-16 21:03:49,132 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.632,  Train_accy 68.53
2025-02-16 21:04:00,240 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.618,  Train_accy 68.88
2025-02-16 21:04:19,058 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.650,  Train_accy 68.34, Test_accy 62.77
2025-02-16 21:04:30,123 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.636,  Train_accy 68.84
2025-02-16 21:04:41,476 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.620,  Train_accy 68.34
2025-02-16 21:04:52,661 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.618,  Train_accy 68.57
2025-02-16 21:05:03,892 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.626,  Train_accy 68.78
2025-02-16 21:05:23,095 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.613,  Train_accy 69.54, Test_accy 64.25
2025-02-16 21:05:34,333 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.617,  Train_accy 68.74
2025-02-16 21:05:45,560 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.621,  Train_accy 69.10
2025-02-16 21:05:56,863 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.610,  Train_accy 68.61
2025-02-16 21:06:08,119 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.628,  Train_accy 68.95
2025-02-16 21:06:27,553 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.617,  Train_accy 68.86, Test_accy 61.89
2025-02-16 21:06:39,133 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.605,  Train_accy 69.73
2025-02-16 21:06:50,433 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.613,  Train_accy 69.07
2025-02-16 21:07:01,584 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.619,  Train_accy 68.74
2025-02-16 21:07:12,833 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.640,  Train_accy 68.78
2025-02-16 21:07:31,958 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.618,  Train_accy 68.59, Test_accy 63.47
2025-02-16 21:07:43,168 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.600,  Train_accy 68.55
2025-02-16 21:07:54,267 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.611,  Train_accy 69.20
2025-02-16 21:08:05,431 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.613,  Train_accy 68.74
2025-02-16 21:08:16,791 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.613,  Train_accy 70.02
2025-02-16 21:08:36,195 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.628,  Train_accy 69.45, Test_accy 64.40
2025-02-16 21:08:47,441 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.612,  Train_accy 68.82
2025-02-16 21:08:58,564 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.620,  Train_accy 69.24
2025-02-16 21:09:09,859 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.607,  Train_accy 69.49
2025-02-16 21:09:21,158 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.616,  Train_accy 68.91
2025-02-16 21:09:40,328 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.612,  Train_accy 68.78, Test_accy 64.79
2025-02-16 21:09:51,411 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.601,  Train_accy 68.78
2025-02-16 21:10:02,660 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.603,  Train_accy 69.35
2025-02-16 21:10:14,105 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.616,  Train_accy 68.27
2025-02-16 21:10:25,420 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.608,  Train_accy 69.35
2025-02-16 21:10:44,601 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.603,  Train_accy 69.41, Test_accy 63.19
2025-02-16 21:10:55,811 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.608,  Train_accy 69.35
2025-02-16 21:11:07,009 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.605,  Train_accy 69.56
2025-02-16 21:11:18,254 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.614,  Train_accy 69.12
2025-02-16 21:11:29,487 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.603,  Train_accy 68.63
2025-02-16 21:11:48,491 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.612,  Train_accy 69.20, Test_accy 64.05
2025-02-16 21:11:59,675 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.610,  Train_accy 69.33
2025-02-16 21:12:11,232 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.599,  Train_accy 68.69
2025-02-16 21:12:22,420 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.619,  Train_accy 69.03
2025-02-16 21:12:33,565 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.612,  Train_accy 69.33
2025-02-16 21:12:52,418 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.602,  Train_accy 69.03, Test_accy 64.21
2025-02-16 21:13:03,584 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.604,  Train_accy 69.41
2025-02-16 21:13:14,732 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.599,  Train_accy 69.31
2025-02-16 21:13:25,902 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.602,  Train_accy 69.12
2025-02-16 21:13:36,955 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.600,  Train_accy 69.39
2025-02-16 21:13:55,863 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.603,  Train_accy 69.56, Test_accy 63.75
2025-02-16 21:14:07,276 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.598,  Train_accy 69.10
2025-02-16 21:14:18,446 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.599,  Train_accy 68.93
2025-02-16 21:14:29,571 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.598,  Train_accy 68.93
2025-02-16 21:14:40,712 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.600,  Train_accy 69.64
2025-02-16 21:14:59,889 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.600,  Train_accy 69.77, Test_accy 63.67
2025-02-16 21:15:11,147 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.601,  Train_accy 69.85
2025-02-16 21:15:22,264 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.618,  Train_accy 69.31
2025-02-16 21:15:33,379 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.602,  Train_accy 69.14
2025-02-16 21:15:44,554 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.599,  Train_accy 69.37
2025-02-16 21:16:03,626 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.605,  Train_accy 69.18, Test_accy 64.63
2025-02-16 21:16:15,158 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.596,  Train_accy 69.22
2025-02-16 21:16:26,342 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.600,  Train_accy 69.22
2025-02-16 21:16:37,636 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.594,  Train_accy 69.39
2025-02-16 21:16:48,977 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.610,  Train_accy 69.33
2025-02-16 21:17:08,121 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.597,  Train_accy 69.20, Test_accy 64.02
2025-02-16 21:17:19,256 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.602,  Train_accy 69.24
2025-02-16 21:17:30,439 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.599,  Train_accy 69.16
2025-02-16 21:17:41,752 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.595,  Train_accy 69.49
2025-02-16 21:17:53,015 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.600,  Train_accy 69.30
2025-02-16 21:17:53,016 [der.py] => do not weight align student!
2025-02-16 21:18:00,213 [der.py] => darknet eval: 
2025-02-16 21:18:00,213 [der.py] => CNN top1 curve: 64.37
2025-02-16 21:18:00,214 [der.py] => CNN top5 curve: 91.51
2025-02-16 21:18:00,215 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 21:18:52,161 [der.py] => Exemplar size: 1350
2025-02-16 21:18:52,161 [trainer.py] => CNN: {'total': 70.67, '0': 77.78, '1': 48.89, '2': 76.11, '3': 47.78, '4': 75.56, '5': 28.33, '6': 55.0, '7': 55.56, '8': 37.78, '9': 52.78, '10': 82.78, '11': 85.0, '12': 59.44, '13': 61.67, '14': 47.78, '15': 89.44, '16': 83.89, '17': 89.44, '18': 82.22, '19': 78.89, '20': 88.89, '21': 84.44, '22': 78.89, '23': 65.0, '24': 51.11, '25': 86.67, '26': 86.11, '27': 83.89, '28': 76.11, '29': 84.44, '30': 87.78, '31': 86.11, '32': 97.22, '33': 78.33, '34': 80.0, '35': 79.44, '36': 85.56, '37': 33.33, '38': 4.44, '39': 72.78, '40': 49.44, '41': 85.56, '42': 85.0, '43': 91.67, 'old': 72.32, 'new': 64.89}
2025-02-16 21:18:52,161 [trainer.py] => NME: {'total': 68.38, '0': 55.56, '1': 55.0, '2': 67.78, '3': 41.11, '4': 73.89, '5': 36.11, '6': 48.89, '7': 51.67, '8': 37.22, '9': 58.89, '10': 86.11, '11': 79.44, '12': 65.0, '13': 54.44, '14': 58.33, '15': 83.89, '16': 82.78, '17': 88.89, '18': 80.56, '19': 82.78, '20': 87.78, '21': 78.33, '22': 74.44, '23': 57.22, '24': 46.67, '25': 70.0, '26': 78.33, '27': 77.22, '28': 66.67, '29': 78.33, '30': 72.78, '31': 73.89, '32': 78.33, '33': 45.56, '34': 70.56, '35': 83.89, '36': 84.44, '37': 52.22, '38': 85.56, '39': 78.33, '40': 55.0, '41': 74.44, '42': 85.56, '43': 78.33, 'old': 66.98, 'new': 73.28}
2025-02-16 21:18:52,161 [trainer.py] => CNN top1 curve: [89.44, 87.89, 78.48, 70.67]
2025-02-16 21:18:52,161 [trainer.py] => CNN top5 curve: [98.93, 98.71, 96.17, 93.74]
2025-02-16 21:18:52,161 [trainer.py] => NME top1 curve: [88.22, 85.53, 75.95, 68.38]
2025-02-16 21:18:52,161 [trainer.py] => NME top5 curve: [98.81, 98.64, 96.32, 93.59]

2025-02-16 21:18:52,162 [trainer.py] => All params: 42096208
2025-02-16 21:18:52,163 [trainer.py] => Trainable params: 21054596
2025-02-16 21:18:52,307 [der.py] => Learning on 45-55
2025-02-16 21:18:52,308 [der.py] => All params: 42098778
2025-02-16 21:18:52,308 [der.py] => Trainable params: 21057166
2025-02-16 21:18:52,417 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-02-16 21:18:52,418 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-02-16 21:50:45,029 [der.py] => Task 4, Epoch 150/150 => Loss 0.014, Loss_clf 0.014, Loss_aux 2.453, Train_accy 99.98
2025-02-16 21:51:08,216 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.973,  Train_accy 32.05, Test_accy 56.08
2025-02-16 21:51:20,071 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.727,  Train_accy 47.08
2025-02-16 21:51:31,804 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.629,  Train_accy 57.23
2025-02-16 21:51:43,956 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.566,  Train_accy 64.43
2025-02-16 21:51:55,713 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.532,  Train_accy 68.59
2025-02-16 21:52:16,904 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.498,  Train_accy 73.35, Test_accy 59.37
2025-02-16 21:52:28,684 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.476,  Train_accy 75.33
2025-02-16 21:52:40,427 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.456,  Train_accy 77.42
2025-02-16 21:52:52,339 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.442,  Train_accy 79.08
2025-02-16 21:53:04,171 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.432,  Train_accy 80.07
2025-02-16 21:53:25,290 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.428,  Train_accy 80.52, Test_accy 62.10
2025-02-16 21:53:36,968 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.420,  Train_accy 81.98
2025-02-16 21:53:48,797 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.402,  Train_accy 82.61
2025-02-16 21:54:00,580 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.403,  Train_accy 82.63
2025-02-16 21:54:12,412 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.400,  Train_accy 83.44
2025-02-16 21:54:33,738 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.392,  Train_accy 84.04, Test_accy 63.34
2025-02-16 21:54:45,722 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.394,  Train_accy 84.77
2025-02-16 21:54:57,528 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.388,  Train_accy 85.08
2025-02-16 21:55:09,307 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.382,  Train_accy 85.82
2025-02-16 21:55:21,085 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.381,  Train_accy 85.82
2025-02-16 21:55:42,593 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.377,  Train_accy 85.77, Test_accy 64.23
2025-02-16 21:55:54,388 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.373,  Train_accy 85.95
2025-02-16 21:56:06,261 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.372,  Train_accy 86.13
2025-02-16 21:56:17,983 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.370,  Train_accy 86.74
2025-02-16 21:56:29,991 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.366,  Train_accy 86.70
2025-02-16 21:56:51,267 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.360,  Train_accy 86.90, Test_accy 64.02
2025-02-16 21:57:03,087 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.360,  Train_accy 87.55
2025-02-16 21:57:14,853 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.358,  Train_accy 86.95
2025-02-16 21:57:26,636 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.352,  Train_accy 87.93
2025-02-16 21:57:38,342 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.351,  Train_accy 87.12
2025-02-16 21:57:59,346 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.357,  Train_accy 87.64, Test_accy 64.91
2025-02-16 21:58:11,039 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.355,  Train_accy 88.09
2025-02-16 21:58:22,916 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.349,  Train_accy 88.11
2025-02-16 21:58:34,752 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.348,  Train_accy 87.91
2025-02-16 21:58:46,547 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.341,  Train_accy 88.27
2025-02-16 21:59:07,530 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.344,  Train_accy 89.17, Test_accy 65.12
2025-02-16 21:59:19,301 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.344,  Train_accy 88.94
2025-02-16 21:59:31,026 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.340,  Train_accy 88.99
2025-02-16 21:59:42,863 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.338,  Train_accy 89.37
2025-02-16 21:59:54,535 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.338,  Train_accy 88.77
2025-02-16 22:00:15,774 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.333,  Train_accy 89.59, Test_accy 65.46
2025-02-16 22:00:27,784 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.332,  Train_accy 89.69
2025-02-16 22:00:39,556 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.335,  Train_accy 90.13
2025-02-16 22:00:51,272 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.332,  Train_accy 89.93
2025-02-16 22:01:03,085 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.334,  Train_accy 89.68
2025-02-16 22:01:24,046 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.331,  Train_accy 90.09, Test_accy 64.79
2025-02-16 22:01:35,735 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.328,  Train_accy 90.09
2025-02-16 22:01:47,331 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.333,  Train_accy 89.57
2025-02-16 22:01:59,228 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.331,  Train_accy 90.14
2025-02-16 22:02:11,170 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.327,  Train_accy 90.36
2025-02-16 22:02:32,493 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.327,  Train_accy 89.91, Test_accy 64.91
2025-02-16 22:02:44,240 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.326,  Train_accy 90.05
2025-02-16 22:02:55,966 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.325,  Train_accy 90.49
2025-02-16 22:03:07,731 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.318,  Train_accy 90.41
2025-02-16 22:03:19,575 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.321,  Train_accy 90.47
2025-02-16 22:03:40,653 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.324,  Train_accy 90.41, Test_accy 65.12
2025-02-16 22:03:52,537 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.324,  Train_accy 90.23
2025-02-16 22:04:04,502 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.320,  Train_accy 90.40
2025-02-16 22:04:16,190 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.318,  Train_accy 90.90
2025-02-16 22:04:27,981 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.319,  Train_accy 90.77
2025-02-16 22:04:49,046 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.323,  Train_accy 90.92, Test_accy 65.29
2025-02-16 22:05:00,924 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.317,  Train_accy 90.97
2025-02-16 22:05:12,653 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.317,  Train_accy 90.18
2025-02-16 22:05:24,485 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.319,  Train_accy 90.79
2025-02-16 22:05:36,140 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.313,  Train_accy 91.41
2025-02-16 22:05:57,570 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.315,  Train_accy 90.85, Test_accy 66.25
2025-02-16 22:06:09,247 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.316,  Train_accy 90.67
2025-02-16 22:06:21,308 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.310,  Train_accy 91.33
2025-02-16 22:06:32,995 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.311,  Train_accy 91.50
2025-02-16 22:06:44,911 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.315,  Train_accy 91.06
2025-02-16 22:07:06,200 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.310,  Train_accy 91.50, Test_accy 65.53
2025-02-16 22:07:17,875 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.310,  Train_accy 90.99
2025-02-16 22:07:29,512 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.308,  Train_accy 91.32
2025-02-16 22:07:41,341 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.311,  Train_accy 91.55
2025-02-16 22:07:53,181 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.310,  Train_accy 91.62
2025-02-16 22:08:14,367 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.308,  Train_accy 91.80, Test_accy 66.10
2025-02-16 22:08:26,366 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.308,  Train_accy 91.08
2025-02-16 22:08:38,233 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.306,  Train_accy 91.91
2025-02-16 22:08:50,103 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.308,  Train_accy 91.84
2025-02-16 22:09:01,963 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.311,  Train_accy 91.32
2025-02-16 22:09:23,280 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.307,  Train_accy 91.51, Test_accy 66.30
2025-02-16 22:09:35,180 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.311,  Train_accy 91.78
2025-02-16 22:09:47,668 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.305,  Train_accy 91.15
2025-02-16 22:10:04,455 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.305,  Train_accy 91.77
2025-02-16 22:10:17,292 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.308,  Train_accy 91.51
2025-02-16 22:10:42,990 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.305,  Train_accy 91.91, Test_accy 66.02
2025-02-16 22:10:54,827 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.306,  Train_accy 91.96
2025-02-16 22:11:09,360 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.305,  Train_accy 91.66
2025-02-16 22:11:25,342 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.306,  Train_accy 91.80
2025-02-16 22:11:38,033 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.301,  Train_accy 91.66
2025-02-16 22:12:04,982 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.304,  Train_accy 92.14, Test_accy 65.87
2025-02-16 22:12:20,012 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.304,  Train_accy 92.09
2025-02-16 22:12:35,277 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.303,  Train_accy 91.50
2025-02-16 22:12:50,807 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.302,  Train_accy 91.69
2025-02-16 22:13:06,040 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.300,  Train_accy 91.68
2025-02-16 22:13:32,859 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.303,  Train_accy 91.82, Test_accy 65.96
2025-02-16 22:13:47,359 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.301,  Train_accy 92.00
2025-02-16 22:13:59,116 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.304,  Train_accy 92.04
2025-02-16 22:14:10,886 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.301,  Train_accy 92.18
2025-02-16 22:14:22,551 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.303,  Train_accy 92.43
2025-02-16 22:14:44,759 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.302,  Train_accy 91.91, Test_accy 66.21
2025-02-16 22:14:56,416 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.302,  Train_accy 92.13
2025-02-16 22:15:10,158 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.300,  Train_accy 92.41
2025-02-16 22:15:25,642 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.299,  Train_accy 92.13
2025-02-16 22:15:42,214 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.300,  Train_accy 91.98
2025-02-16 22:16:10,302 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.299,  Train_accy 91.78, Test_accy 65.95
2025-02-16 22:16:26,965 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.300,  Train_accy 92.63
2025-02-16 22:16:43,550 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.304,  Train_accy 91.59
2025-02-16 22:17:00,364 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.301,  Train_accy 92.61
2025-02-16 22:17:17,239 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.301,  Train_accy 91.93
2025-02-16 22:17:45,289 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.299,  Train_accy 92.20, Test_accy 66.47
2025-02-16 22:18:00,929 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.299,  Train_accy 91.91
2025-02-16 22:18:12,789 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.297,  Train_accy 92.65
2025-02-16 22:18:26,101 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.296,  Train_accy 92.27
2025-02-16 22:18:38,048 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.300,  Train_accy 92.41
2025-02-16 22:19:03,140 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.296,  Train_accy 92.63, Test_accy 66.33
2025-02-16 22:19:19,784 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.296,  Train_accy 91.84
2025-02-16 22:19:36,612 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.297,  Train_accy 92.47
2025-02-16 22:19:53,319 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.299,  Train_accy 92.09
2025-02-16 22:20:10,018 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.300,  Train_accy 92.04
2025-02-16 22:20:51,128 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.296,  Train_accy 92.52, Test_accy 66.28
2025-02-16 22:21:08,276 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.299,  Train_accy 91.77
2025-02-16 22:21:25,265 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.296,  Train_accy 92.43
2025-02-16 22:21:37,527 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.301,  Train_accy 92.02
2025-02-16 22:21:51,803 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.301,  Train_accy 91.87
2025-02-16 22:22:17,731 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.297,  Train_accy 92.34, Test_accy 65.83
2025-02-16 22:22:34,501 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.297,  Train_accy 91.95
2025-02-16 22:22:51,184 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.295,  Train_accy 92.41
2025-02-16 22:23:07,994 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.299,  Train_accy 92.14
2025-02-16 22:23:24,676 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.293,  Train_accy 92.54
2025-02-16 22:23:24,677 [der.py] => do not weight align student!
2025-02-16 22:23:33,778 [der.py] => darknet eval: 
2025-02-16 22:23:33,778 [der.py] => CNN top1 curve: 66.15
2025-02-16 22:23:33,779 [der.py] => CNN top5 curve: 91.17
2025-02-16 22:23:33,781 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-02-16 22:24:34,592 [der.py] => Exemplar size: 1650
2025-02-16 22:24:34,593 [trainer.py] => CNN: {'total': 69.96, '0': 71.67, '1': 55.0, '2': 63.33, '3': 30.0, '4': 61.67, '5': 36.11, '6': 52.22, '7': 42.22, '8': 40.56, '9': 54.44, '10': 81.67, '11': 67.78, '12': 54.44, '13': 47.78, '14': 57.22, '15': 78.33, '16': 77.22, '17': 82.78, '18': 73.33, '19': 72.78, '20': 85.56, '21': 73.89, '22': 77.22, '23': 58.33, '24': 55.0, '25': 70.0, '26': 72.22, '27': 76.11, '28': 50.56, '29': 70.56, '30': 67.22, '31': 70.56, '32': 77.78, '33': 52.22, '34': 62.22, '35': 91.67, '36': 86.67, '37': 64.44, '38': 85.0, '39': 97.22, '40': 73.33, '41': 93.33, '42': 97.22, '43': 96.11, '44': 71.67, '45': 83.33, '46': 79.44, '47': 75.0, '48': 81.11, '49': 71.11, '50': 65.56, '51': 77.78, '52': 80.56, '53': 80.56, 'old': 68.37, 'new': 77.11}
2025-02-16 22:24:34,593 [trainer.py] => NME: {'total': 63.46, '0': 63.33, '1': 58.89, '2': 52.22, '3': 33.33, '4': 62.22, '5': 40.56, '6': 50.56, '7': 48.33, '8': 40.56, '9': 60.0, '10': 83.89, '11': 76.11, '12': 51.67, '13': 47.22, '14': 47.78, '15': 76.67, '16': 79.44, '17': 81.67, '18': 70.56, '19': 70.0, '20': 85.56, '21': 76.11, '22': 72.22, '23': 44.44, '24': 56.11, '25': 51.67, '26': 68.89, '27': 69.44, '28': 46.11, '29': 52.78, '30': 61.11, '31': 55.56, '32': 72.78, '33': 36.11, '34': 59.44, '35': 77.78, '36': 81.67, '37': 48.33, '38': 66.11, '39': 77.78, '40': 32.78, '41': 80.0, '42': 86.11, '43': 86.67, '44': 40.0, '45': 81.11, '46': 76.11, '47': 77.22, '48': 75.0, '49': 61.11, '50': 58.89, '51': 70.56, '52': 72.78, '53': 70.56, 'old': 61.79, 'new': 71.0}
2025-02-16 22:24:34,593 [trainer.py] => CNN top1 curve: [89.44, 87.89, 78.48, 70.67, 69.96]
2025-02-16 22:24:34,593 [trainer.py] => CNN top5 curve: [98.93, 98.71, 96.17, 93.74, 92.15]
2025-02-16 22:24:34,593 [trainer.py] => NME top1 curve: [88.22, 85.53, 75.95, 68.38, 63.46]
2025-02-16 22:24:34,593 [trainer.py] => NME top5 curve: [98.81, 98.64, 96.32, 93.59, 91.45]

2025-04-22 12:36:47,035 [trainer.py] => 实验名称:CIL实验
2025-04-22 12:36:47,052 [trainer.py] => config: ./exps/der.json
2025-04-22 12:36:47,052 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 12:36:47,052 [trainer.py] => prefix: reproduce
2025-04-22 12:36:47,052 [trainer.py] => dataset: xrfdataset
2025-04-22 12:36:47,052 [trainer.py] => memory_size: 1650
2025-04-22 12:36:47,052 [trainer.py] => memory_per_class: 30
2025-04-22 12:36:47,052 [trainer.py] => fixed_memory: True
2025-04-22 12:36:47,052 [trainer.py] => shuffle: True
2025-04-22 12:36:47,052 [trainer.py] => init_cls: 15
2025-04-22 12:36:47,052 [trainer.py] => increment: 10
2025-04-22 12:36:47,052 [trainer.py] => model_name: der
2025-04-22 12:36:47,052 [trainer.py] => compression_epochs: 130
2025-04-22 12:36:47,052 [trainer.py] => compression_lr: 0.1
2025-04-22 12:36:47,052 [trainer.py] => is_student_wa: False
2025-04-22 12:36:47,052 [trainer.py] => wa_value: 1
2025-04-22 12:36:47,052 [trainer.py] => T: 2
2025-04-22 12:36:47,052 [trainer.py] => convnet_type: unet
2025-04-22 12:36:47,053 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-04-22 12:36:47,053 [trainer.py] => seed: 1993
2025-04-22 12:36:47,082 [data.py] => 加载完毕XRF原始数据集
2025-04-22 12:36:47,129 [data.py] => 加载完毕XRF原始数据集
2025-04-22 12:36:47,129 [trainer.py] => All params: 0
2025-04-22 12:36:47,129 [trainer.py] => Trainable params: 0
2025-04-22 12:36:47,306 [der.py] => Learning on 0-15
2025-04-22 12:36:47,307 [der.py] => All params: 21045611
2025-04-22 12:36:47,307 [der.py] => Trainable params: 21045611
2025-04-22 13:04:45,519 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-04-22 13:04:45,533 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 13:05:13,917 [der.py] => Exemplar size: 450
2025-04-22 13:05:13,918 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-04-22 13:05:13,918 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-04-22 13:05:13,918 [trainer.py] => CNN top1 curve: [89.44]
2025-04-22 13:05:13,918 [trainer.py] => CNN top5 curve: [98.93]
2025-04-22 13:05:13,918 [trainer.py] => NME top1 curve: [88.22]
2025-04-22 13:05:13,918 [trainer.py] => NME top5 curve: [98.81]

2025-04-22 13:05:13,918 [trainer.py] => All params: 21045611
2025-04-22 13:05:13,919 [trainer.py] => Trainable params: 21045611
2025-04-22 13:05:14,106 [der.py] => Learning on 15-25
2025-04-22 13:05:14,107 [der.py] => All params: 42091068
2025-04-22 13:05:14,108 [der.py] => Trainable params: 21049456
2025-04-22 13:05:14,191 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 13:05:14,191 [der.py] => per cls weights : [1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105 1.54892105
 1.54892105 1.54892105 1.54892105 0.17661843 0.17661843 0.17661843
 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843 0.17661843
 0.17661843]
2025-04-22 13:33:52,543 [der.py] => Task 1, Epoch 150/150 => Loss 0.006, Loss_clf 0.006, Loss_aux 2.320, Train_accy 100.00
2025-04-22 13:34:09,640 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.315,  Train_accy 27.78, Test_accy 61.58
2025-04-22 13:34:20,989 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.985,  Train_accy 45.01
2025-04-22 13:34:32,515 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.871,  Train_accy 53.01
2025-04-22 13:34:43,888 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.785,  Train_accy 60.73
2025-04-22 13:34:55,455 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.742,  Train_accy 62.58
2025-04-22 13:35:12,570 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.712,  Train_accy 66.00, Test_accy 72.13
2025-04-22 13:35:23,990 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.689,  Train_accy 66.73
2025-04-22 13:35:35,602 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.664,  Train_accy 69.89
2025-04-22 13:35:46,767 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.652,  Train_accy 70.90
2025-04-22 13:35:58,253 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.648,  Train_accy 70.00
2025-04-22 13:36:15,575 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.629,  Train_accy 72.69, Test_accy 71.56
2025-04-22 13:36:26,729 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.621,  Train_accy 72.37
2025-04-22 13:36:38,200 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.609,  Train_accy 73.44
2025-04-22 13:36:49,591 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.604,  Train_accy 73.42
2025-04-22 13:37:01,292 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.592,  Train_accy 74.49
2025-04-22 13:37:18,393 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.610,  Train_accy 72.88, Test_accy 72.84
2025-04-22 13:37:29,832 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.598,  Train_accy 73.59
2025-04-22 13:37:41,111 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.589,  Train_accy 74.37
2025-04-22 13:37:52,704 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.585,  Train_accy 74.60
2025-04-22 13:38:04,182 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.593,  Train_accy 74.00
2025-04-22 13:38:21,370 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.582,  Train_accy 75.29, Test_accy 75.47
2025-04-22 13:38:32,845 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.575,  Train_accy 74.88
2025-04-22 13:38:43,958 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.571,  Train_accy 75.78
2025-04-22 13:38:55,494 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.571,  Train_accy 74.56
2025-04-22 13:39:06,938 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.577,  Train_accy 75.29
2025-04-22 13:39:23,612 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.562,  Train_accy 75.78, Test_accy 74.24
2025-04-22 13:39:35,224 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.562,  Train_accy 75.87
2025-04-22 13:39:46,793 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.556,  Train_accy 75.96
2025-04-22 13:39:58,199 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.554,  Train_accy 75.72
2025-04-22 13:40:09,772 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.557,  Train_accy 76.15
2025-04-22 13:40:26,310 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.560,  Train_accy 75.33, Test_accy 74.64
2025-04-22 13:40:37,630 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.559,  Train_accy 75.70
2025-04-22 13:40:49,251 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.552,  Train_accy 75.89
2025-04-22 13:41:00,721 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.544,  Train_accy 76.24
2025-04-22 13:41:12,065 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.545,  Train_accy 76.11
2025-04-22 13:41:28,529 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.547,  Train_accy 76.67, Test_accy 76.07
2025-04-22 13:41:39,915 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.547,  Train_accy 76.86
2025-04-22 13:41:51,126 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.551,  Train_accy 77.03
2025-04-22 13:42:02,780 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.543,  Train_accy 75.87
2025-04-22 13:42:14,157 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.539,  Train_accy 76.97
2025-04-22 13:42:31,299 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.538,  Train_accy 76.45, Test_accy 76.13
2025-04-22 13:42:42,567 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.539,  Train_accy 76.15
2025-04-22 13:42:53,821 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.544,  Train_accy 76.77
2025-04-22 13:43:05,143 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.534,  Train_accy 76.32
2025-04-22 13:43:16,420 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.535,  Train_accy 76.32
2025-04-22 13:43:33,124 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.540,  Train_accy 76.97, Test_accy 75.98
2025-04-22 13:43:44,440 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.535,  Train_accy 76.84
2025-04-22 13:43:55,913 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.532,  Train_accy 76.65
2025-04-22 13:44:07,448 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.535,  Train_accy 76.15
2025-04-22 13:44:18,984 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.540,  Train_accy 77.05
2025-04-22 13:44:35,997 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.532,  Train_accy 77.44, Test_accy 75.09
2025-04-22 13:44:47,412 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.534,  Train_accy 76.97
2025-04-22 13:44:58,863 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.533,  Train_accy 76.45
2025-04-22 13:45:10,372 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.533,  Train_accy 77.20
2025-04-22 13:45:21,857 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.530,  Train_accy 77.27
2025-04-22 13:45:38,852 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 1.525,  Train_accy 77.16, Test_accy 76.69
2025-04-22 13:45:49,823 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 1.524,  Train_accy 77.42
2025-04-22 13:46:01,214 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.527,  Train_accy 77.12
2025-04-22 13:46:12,366 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 1.525,  Train_accy 77.53
2025-04-22 13:46:23,630 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 1.523,  Train_accy 77.74
2025-04-22 13:46:47,589 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 1.520,  Train_accy 77.05, Test_accy 76.38
2025-04-22 13:46:59,238 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 1.526,  Train_accy 77.16
2025-04-22 13:47:10,626 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 1.523,  Train_accy 76.80
2025-04-22 13:47:22,034 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 1.526,  Train_accy 77.20
2025-04-22 13:47:33,452 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 1.519,  Train_accy 76.97
2025-04-22 13:47:57,847 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 1.517,  Train_accy 77.46, Test_accy 76.33
2025-04-22 13:48:09,435 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 1.524,  Train_accy 77.27
2025-04-22 13:48:20,641 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 1.522,  Train_accy 76.95
2025-04-22 13:48:31,901 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 1.522,  Train_accy 78.39
2025-04-22 13:48:43,129 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 1.522,  Train_accy 77.63
2025-04-22 13:49:44,702 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 1.519,  Train_accy 77.59, Test_accy 76.24
2025-04-22 13:49:56,097 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 1.518,  Train_accy 77.29
2025-04-22 13:50:07,389 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 1.516,  Train_accy 77.01
2025-04-22 13:50:18,753 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 1.521,  Train_accy 78.02
2025-04-22 13:50:30,011 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 1.515,  Train_accy 77.72
2025-04-22 13:51:16,439 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 1.514,  Train_accy 77.51, Test_accy 76.49
2025-04-22 13:51:27,653 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 1.517,  Train_accy 77.91
2025-04-22 13:51:38,851 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 1.517,  Train_accy 77.31
2025-04-22 13:51:50,065 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 1.516,  Train_accy 77.94
2025-04-22 13:52:01,235 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 1.516,  Train_accy 77.85
2025-04-22 13:52:41,442 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 1.515,  Train_accy 78.73, Test_accy 75.93
2025-04-22 13:52:52,204 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 1.517,  Train_accy 77.51
2025-04-22 13:53:03,597 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 1.513,  Train_accy 77.63
2025-04-22 13:53:14,966 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 1.515,  Train_accy 78.06
2025-04-22 13:53:25,971 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 1.509,  Train_accy 77.55
2025-04-22 13:53:59,330 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 1.509,  Train_accy 77.59, Test_accy 76.47
2025-04-22 13:54:10,708 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 1.510,  Train_accy 78.11
2025-04-22 13:54:22,133 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 1.514,  Train_accy 77.61
2025-04-22 13:54:33,607 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 1.514,  Train_accy 77.94
2025-04-22 13:54:44,915 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 1.511,  Train_accy 77.70
2025-04-22 13:55:01,695 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 1.513,  Train_accy 77.72, Test_accy 76.56
2025-04-22 13:55:13,131 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 1.513,  Train_accy 78.02
2025-04-22 13:55:24,298 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 1.509,  Train_accy 78.02
2025-04-22 13:55:35,554 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 1.509,  Train_accy 77.31
2025-04-22 13:55:46,866 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 1.508,  Train_accy 77.85
2025-04-22 13:56:03,469 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 1.508,  Train_accy 77.85, Test_accy 76.02
2025-04-22 13:56:14,818 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 1.508,  Train_accy 77.42
2025-04-22 13:56:26,160 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 1.508,  Train_accy 77.76
2025-04-22 13:56:37,512 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 1.505,  Train_accy 77.98
2025-04-22 13:56:48,833 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 1.512,  Train_accy 77.61
2025-04-22 13:57:05,859 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 1.508,  Train_accy 78.45, Test_accy 76.44
2025-04-22 13:57:17,180 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 1.508,  Train_accy 77.61
2025-04-22 13:57:28,665 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 1.509,  Train_accy 78.00
2025-04-22 13:57:39,974 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 1.506,  Train_accy 78.19
2025-04-22 13:57:51,376 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 1.507,  Train_accy 77.33
2025-04-22 13:58:08,342 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 1.507,  Train_accy 78.67, Test_accy 76.40
2025-04-22 13:58:19,697 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 1.505,  Train_accy 77.51
2025-04-22 13:58:31,246 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 1.508,  Train_accy 78.45
2025-04-22 13:58:42,608 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 1.504,  Train_accy 78.00
2025-04-22 13:58:53,723 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 1.508,  Train_accy 77.85
2025-04-22 13:59:10,655 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 1.504,  Train_accy 78.43, Test_accy 76.53
2025-04-22 13:59:22,100 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 1.503,  Train_accy 78.32
2025-04-22 13:59:33,494 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 1.505,  Train_accy 77.70
2025-04-22 13:59:44,956 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 1.507,  Train_accy 77.76
2025-04-22 13:59:56,282 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 1.507,  Train_accy 77.35
2025-04-22 14:00:12,907 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 1.507,  Train_accy 77.78, Test_accy 76.91
2025-04-22 14:00:24,063 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 1.505,  Train_accy 78.32
2025-04-22 14:00:35,327 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 1.505,  Train_accy 77.70
2025-04-22 14:00:46,641 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 1.506,  Train_accy 78.37
2025-04-22 14:00:58,161 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 1.505,  Train_accy 78.43
2025-04-22 14:01:14,993 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 1.506,  Train_accy 77.55, Test_accy 76.62
2025-04-22 14:01:26,261 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 1.507,  Train_accy 78.41
2025-04-22 14:01:37,578 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 1.501,  Train_accy 77.94
2025-04-22 14:01:48,871 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 1.503,  Train_accy 77.87
2025-04-22 14:02:00,206 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 1.505,  Train_accy 78.02
2025-04-22 14:02:16,858 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 1.501,  Train_accy 77.76, Test_accy 76.60
2025-04-22 14:02:26,894 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 1.506,  Train_accy 77.81
2025-04-22 14:02:37,102 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 1.506,  Train_accy 77.85
2025-04-22 14:02:47,446 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 1.503,  Train_accy 78.24
2025-04-22 14:02:57,456 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 1.504,  Train_accy 77.63
2025-04-22 14:02:57,457 [der.py] => do not weight align student!
2025-04-22 14:03:02,274 [der.py] => darknet eval: 
2025-04-22 14:03:02,275 [der.py] => CNN top1 curve: 76.89
2025-04-22 14:03:02,275 [der.py] => CNN top5 curve: 98.24
2025-04-22 14:03:02,278 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 14:03:37,863 [der.py] => Exemplar size: 750
2025-04-22 14:03:37,864 [trainer.py] => CNN: {'total': 87.89, '0': 88.33, '1': 86.11, '2': 95.56, '3': 81.67, '4': 92.78, '5': 71.67, '6': 76.11, '7': 74.44, '8': 65.0, '9': 65.56, '10': 96.11, '11': 100.0, '12': 88.33, '13': 87.78, '14': 87.78, '15': 96.67, '16': 97.22, '17': 97.78, '18': 95.0, '19': 95.56, '20': 97.22, '21': 91.67, '22': 88.89, '23': 90.0, 'old': 83.81, 'new': 94.0}
2025-04-22 14:03:37,864 [trainer.py] => NME: {'total': 85.53, '0': 85.56, '1': 85.56, '2': 94.44, '3': 81.11, '4': 91.67, '5': 70.0, '6': 65.0, '7': 58.89, '8': 60.0, '9': 67.22, '10': 97.22, '11': 100.0, '12': 87.78, '13': 83.33, '14': 85.0, '15': 93.33, '16': 97.78, '17': 93.33, '18': 94.44, '19': 93.89, '20': 95.0, '21': 97.22, '22': 87.22, '23': 85.56, 'old': 80.85, 'new': 92.56}
2025-04-22 14:03:37,864 [trainer.py] => CNN top1 curve: [89.44, 87.89]
2025-04-22 14:03:37,864 [trainer.py] => CNN top5 curve: [98.93, 98.71]
2025-04-22 14:03:37,864 [trainer.py] => NME top1 curve: [88.22, 85.53]
2025-04-22 14:03:37,864 [trainer.py] => NME top5 curve: [98.81, 98.64]

2025-04-22 14:03:37,865 [trainer.py] => All params: 42091068
2025-04-22 14:03:37,865 [trainer.py] => Trainable params: 21049456
2025-04-22 14:03:38,041 [der.py] => Learning on 25-35
2025-04-22 14:03:38,042 [der.py] => All params: 42093638
2025-04-22 14:03:38,043 [der.py] => Trainable params: 21052026
2025-04-22 14:03:38,129 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 14:03:38,129 [der.py] => per cls weights : [1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045 1.33893045
 1.33893045 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388
 0.15267388 0.15267388 0.15267388 0.15267388 0.15267388]
2025-04-22 14:38:39,194 [der.py] => Task 2, Epoch 150/150 => Loss 0.010, Loss_clf 0.010, Loss_aux 2.391, Train_accy 99.98
2025-04-22 14:38:59,123 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.422,  Train_accy 20.71, Test_accy 55.60
2025-04-22 14:39:10,987 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 2.276,  Train_accy 26.65
2025-04-22 14:39:22,983 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 2.215,  Train_accy 31.45
2025-04-22 14:39:34,829 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 2.168,  Train_accy 36.87
2025-04-22 14:39:47,012 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 2.151,  Train_accy 39.17
2025-04-22 14:40:05,848 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 2.128,  Train_accy 42.14, Test_accy 61.41
2025-04-22 14:40:17,603 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 2.120,  Train_accy 43.56
2025-04-22 14:40:29,421 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 2.104,  Train_accy 43.92
2025-04-22 14:40:41,575 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 2.092,  Train_accy 45.92
2025-04-22 14:40:53,610 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 2.089,  Train_accy 45.76
2025-04-22 14:41:12,988 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 2.076,  Train_accy 47.03, Test_accy 63.14
2025-04-22 14:41:25,399 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 2.066,  Train_accy 47.33
2025-04-22 14:41:37,457 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 2.060,  Train_accy 48.14
2025-04-22 14:41:49,332 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 2.063,  Train_accy 49.13
2025-04-22 14:42:01,295 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 2.054,  Train_accy 49.05
2025-04-22 14:42:19,951 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 2.052,  Train_accy 48.87, Test_accy 62.11
2025-04-22 14:42:31,912 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 2.053,  Train_accy 49.15
2025-04-22 14:42:44,016 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 2.043,  Train_accy 49.35
2025-04-22 14:42:56,039 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 2.044,  Train_accy 49.80
2025-04-22 14:43:08,168 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 2.040,  Train_accy 50.61
2025-04-22 14:43:27,261 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 2.036,  Train_accy 50.02, Test_accy 63.46
2025-04-22 14:43:39,188 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 2.034,  Train_accy 50.67
2025-04-22 14:43:51,163 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 2.030,  Train_accy 51.01
2025-04-22 14:44:03,163 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 2.029,  Train_accy 50.83
2025-04-22 14:44:15,104 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 2.026,  Train_accy 51.25
2025-04-22 14:44:34,058 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 2.023,  Train_accy 50.75, Test_accy 64.78
2025-04-22 14:44:45,949 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 2.020,  Train_accy 51.47
2025-04-22 14:44:58,114 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 2.017,  Train_accy 51.47
2025-04-22 14:45:10,082 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 2.016,  Train_accy 51.39
2025-04-22 14:45:22,076 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 2.015,  Train_accy 51.43
2025-04-22 14:45:41,353 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 2.015,  Train_accy 52.12, Test_accy 62.57
2025-04-22 14:45:53,140 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 2.015,  Train_accy 51.64
2025-04-22 14:46:05,053 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 2.013,  Train_accy 51.56
2025-04-22 14:46:16,902 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 2.012,  Train_accy 51.84
2025-04-22 14:46:29,259 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 2.011,  Train_accy 52.20
2025-04-22 14:46:48,725 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 2.006,  Train_accy 52.14, Test_accy 64.02
2025-04-22 14:47:00,695 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 2.006,  Train_accy 52.26
2025-04-22 14:47:12,696 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 2.007,  Train_accy 52.53
2025-04-22 14:47:24,735 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 2.004,  Train_accy 51.78
2025-04-22 14:47:36,629 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 2.000,  Train_accy 53.09
2025-04-22 14:47:55,745 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 2.007,  Train_accy 52.38, Test_accy 63.24
2025-04-22 14:48:07,634 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.999,  Train_accy 53.03
2025-04-22 14:48:19,460 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 2.000,  Train_accy 52.91
2025-04-22 14:48:31,690 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 2.001,  Train_accy 52.44
2025-04-22 14:48:43,946 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.997,  Train_accy 52.81
2025-04-22 14:49:03,405 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.998,  Train_accy 51.68, Test_accy 64.24
2025-04-22 14:49:15,295 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.996,  Train_accy 53.39
2025-04-22 14:49:27,468 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.995,  Train_accy 52.63
2025-04-22 14:49:39,376 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.995,  Train_accy 52.79
2025-04-22 14:49:50,950 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.993,  Train_accy 53.13
2025-04-22 14:50:10,003 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.992,  Train_accy 53.35, Test_accy 63.51
2025-04-22 14:50:21,739 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.995,  Train_accy 52.79
2025-04-22 14:50:33,840 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.992,  Train_accy 53.29
2025-04-22 14:50:45,752 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.990,  Train_accy 53.88
2025-04-22 14:50:57,530 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.990,  Train_accy 52.57
2025-04-22 14:51:16,361 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.987,  Train_accy 53.66, Test_accy 64.94
2025-04-22 14:51:28,091 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.986,  Train_accy 53.19
2025-04-22 14:51:40,186 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.992,  Train_accy 52.77
2025-04-22 14:51:52,338 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.987,  Train_accy 53.25
2025-04-22 14:52:04,340 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.989,  Train_accy 52.75
2025-04-22 14:52:23,344 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.987,  Train_accy 53.17, Test_accy 64.10
2025-04-22 14:52:35,060 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.984,  Train_accy 52.75
2025-04-22 14:52:46,757 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.993,  Train_accy 53.07
2025-04-22 14:52:58,521 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.982,  Train_accy 53.78
2025-04-22 14:53:10,389 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.983,  Train_accy 53.05
2025-04-22 14:53:28,992 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.982,  Train_accy 53.66, Test_accy 63.79
2025-04-22 14:53:40,700 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.984,  Train_accy 54.04
2025-04-22 14:53:52,458 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.982,  Train_accy 53.41
2025-04-22 14:54:04,452 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.981,  Train_accy 53.96
2025-04-22 14:54:16,155 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.978,  Train_accy 53.31
2025-04-22 14:54:34,609 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.984,  Train_accy 53.98, Test_accy 64.17
2025-04-22 14:54:46,540 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.982,  Train_accy 52.89
2025-04-22 14:54:58,426 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.980,  Train_accy 53.60
2025-04-22 14:55:10,156 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.975,  Train_accy 54.14
2025-04-22 14:55:21,820 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.980,  Train_accy 53.84
2025-04-22 14:55:40,424 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.978,  Train_accy 55.03, Test_accy 64.13
2025-04-22 14:55:52,147 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.981,  Train_accy 53.09
2025-04-22 14:56:03,807 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.975,  Train_accy 53.37
2025-04-22 14:56:15,369 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.977,  Train_accy 54.44
2025-04-22 14:56:27,080 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.973,  Train_accy 53.94
2025-04-22 14:56:45,552 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.977,  Train_accy 53.13, Test_accy 64.13
2025-04-22 14:56:57,256 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.976,  Train_accy 53.92
2025-04-22 14:57:08,909 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.970,  Train_accy 53.64
2025-04-22 14:57:20,817 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.972,  Train_accy 54.79
2025-04-22 14:57:32,492 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.974,  Train_accy 53.49
2025-04-22 14:57:50,838 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.973,  Train_accy 54.32, Test_accy 64.84
2025-04-22 14:58:02,531 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.970,  Train_accy 53.96
2025-04-22 14:58:14,022 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.971,  Train_accy 54.00
2025-04-22 14:58:25,604 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.969,  Train_accy 53.88
2025-04-22 14:58:37,384 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.971,  Train_accy 54.34
2025-04-22 14:58:55,768 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.969,  Train_accy 53.52, Test_accy 64.87
2025-04-22 14:59:07,460 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.970,  Train_accy 53.92
2025-04-22 14:59:19,208 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.968,  Train_accy 53.47
2025-04-22 14:59:30,790 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.969,  Train_accy 54.73
2025-04-22 14:59:42,336 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.968,  Train_accy 53.94
2025-04-22 15:00:00,804 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.968,  Train_accy 54.57, Test_accy 64.63
2025-04-22 15:00:12,416 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.969,  Train_accy 54.30
2025-04-22 15:00:24,005 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.969,  Train_accy 53.76
2025-04-22 15:00:35,483 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.966,  Train_accy 54.20
2025-04-22 15:00:47,105 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.966,  Train_accy 54.67
2025-04-22 15:01:05,579 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.969,  Train_accy 53.80, Test_accy 65.08
2025-04-22 15:01:17,115 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.970,  Train_accy 53.60
2025-04-22 15:01:28,808 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.969,  Train_accy 54.10
2025-04-22 15:01:40,231 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.966,  Train_accy 54.34
2025-04-22 15:01:51,900 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.965,  Train_accy 53.86
2025-04-22 15:02:10,171 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.968,  Train_accy 54.32, Test_accy 64.65
2025-04-22 15:02:21,698 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.966,  Train_accy 53.11
2025-04-22 15:02:33,336 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.965,  Train_accy 54.24
2025-04-22 15:02:45,110 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.971,  Train_accy 54.44
2025-04-22 15:02:56,779 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.966,  Train_accy 54.06
2025-04-22 15:03:14,826 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.967,  Train_accy 54.81, Test_accy 64.57
2025-04-22 15:03:26,428 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.967,  Train_accy 54.26
2025-04-22 15:03:38,056 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.966,  Train_accy 54.08
2025-04-22 15:03:49,616 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.964,  Train_accy 54.38
2025-04-22 15:04:01,087 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.965,  Train_accy 54.53
2025-04-22 15:04:19,584 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.966,  Train_accy 54.71, Test_accy 64.92
2025-04-22 15:04:31,187 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.965,  Train_accy 54.38
2025-04-22 15:04:42,828 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.966,  Train_accy 54.44
2025-04-22 15:04:54,365 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.967,  Train_accy 53.56
2025-04-22 15:05:06,050 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.966,  Train_accy 53.72
2025-04-22 15:05:24,281 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.966,  Train_accy 53.74, Test_accy 64.84
2025-04-22 15:05:36,101 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.964,  Train_accy 54.18
2025-04-22 15:05:47,517 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.967,  Train_accy 54.36
2025-04-22 15:05:59,052 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.966,  Train_accy 54.75
2025-04-22 15:06:10,720 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.964,  Train_accy 54.20
2025-04-22 15:06:29,004 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.964,  Train_accy 54.42, Test_accy 64.81
2025-04-22 15:06:40,556 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.965,  Train_accy 54.06
2025-04-22 15:06:52,190 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.967,  Train_accy 54.71
2025-04-22 15:07:03,730 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.965,  Train_accy 54.04
2025-04-22 15:07:15,417 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.964,  Train_accy 54.34
2025-04-22 15:07:15,418 [der.py] => do not weight align student!
2025-04-22 15:07:21,380 [der.py] => darknet eval: 
2025-04-22 15:07:21,381 [der.py] => CNN top1 curve: 64.84
2025-04-22 15:07:21,381 [der.py] => CNN top5 curve: 93.97
2025-04-22 15:07:21,383 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 15:08:05,827 [der.py] => Exemplar size: 1050
2025-04-22 15:08:05,827 [trainer.py] => CNN: {'total': 77.65, '0': 88.89, '1': 58.89, '2': 83.33, '3': 63.33, '4': 77.22, '5': 43.33, '6': 68.33, '7': 53.33, '8': 34.44, '9': 55.0, '10': 92.22, '11': 94.44, '12': 68.89, '13': 66.67, '14': 62.78, '15': 94.44, '16': 98.33, '17': 96.67, '18': 88.89, '19': 93.33, '20': 95.56, '21': 91.11, '22': 86.11, '23': 77.22, '24': 66.11, '25': 76.67, '26': 83.89, '27': 81.67, '28': 70.0, '29': 80.56, '30': 82.78, '31': 86.11, '32': 94.44, '33': 80.0, 'old': 75.96, 'new': 81.89}
2025-04-22 15:08:05,827 [trainer.py] => NME: {'total': 74.81, '0': 80.56, '1': 62.78, '2': 78.33, '3': 66.11, '4': 81.67, '5': 40.0, '6': 61.11, '7': 61.67, '8': 40.56, '9': 63.89, '10': 94.44, '11': 94.44, '12': 65.0, '13': 63.33, '14': 58.89, '15': 86.11, '16': 93.33, '17': 88.89, '18': 90.0, '19': 89.44, '20': 94.44, '21': 90.56, '22': 75.0, '23': 63.89, '24': 52.22, '25': 69.44, '26': 86.11, '27': 82.22, '28': 67.22, '29': 78.89, '30': 73.33, '31': 83.89, '32': 91.11, '33': 75.0, 'old': 73.47, 'new': 78.17}
2025-04-22 15:08:05,827 [trainer.py] => CNN top1 curve: [89.44, 87.89, 77.65]
2025-04-22 15:08:05,827 [trainer.py] => CNN top5 curve: [98.93, 98.71, 96.05]
2025-04-22 15:08:05,827 [trainer.py] => NME top1 curve: [88.22, 85.53, 74.81]
2025-04-22 15:08:05,827 [trainer.py] => NME top5 curve: [98.81, 98.64, 96.21]

2025-04-22 15:08:05,828 [trainer.py] => All params: 42093638
2025-04-22 15:08:05,828 [trainer.py] => Trainable params: 21052026
2025-04-22 15:08:05,976 [der.py] => Learning on 35-45
2025-04-22 15:08:05,977 [der.py] => All params: 42096208
2025-04-22 15:08:05,978 [der.py] => Trainable params: 21054596
2025-04-22 15:08:06,073 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 15:08:06,074 [der.py] => per cls weights : [1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  1.2451485
 1.2451485  1.2451485  1.2451485  1.2451485  1.2451485  0.14198023
 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023 0.14198023
 0.14198023 0.14198023 0.14198023]
2025-04-22 15:42:02,515 [der.py] => Task 3, Epoch 150/150 => Loss 0.022, Loss_clf 0.022, Loss_aux 2.380, Train_accy 99.96
2025-04-22 15:42:22,864 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 2.271,  Train_accy 31.49, Test_accy 47.64
2025-04-22 15:42:35,197 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 2.151,  Train_accy 36.69
2025-04-22 15:42:47,423 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 2.051,  Train_accy 40.44
2025-04-22 15:42:59,568 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 2.013,  Train_accy 41.35
2025-04-22 15:43:11,784 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.994,  Train_accy 43.31
2025-04-22 15:43:32,196 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 2.017,  Train_accy 42.48, Test_accy 49.17
2025-04-22 15:43:44,406 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.948,  Train_accy 43.90
2025-04-22 15:43:56,725 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.944,  Train_accy 44.27
2025-04-22 15:44:08,992 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.940,  Train_accy 44.23
2025-04-22 15:44:21,303 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.952,  Train_accy 45.28
2025-04-22 15:44:41,646 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.930,  Train_accy 45.12, Test_accy 53.27
2025-04-22 15:44:53,835 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.929,  Train_accy 45.77
2025-04-22 15:45:05,967 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.923,  Train_accy 46.32
2025-04-22 15:45:18,147 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.921,  Train_accy 45.62
2025-04-22 15:45:29,485 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.904,  Train_accy 46.88
2025-04-22 15:45:48,351 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.903,  Train_accy 46.23, Test_accy 55.46
2025-04-22 15:45:59,487 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.924,  Train_accy 46.25
2025-04-22 15:46:10,618 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.911,  Train_accy 46.69
2025-04-22 15:46:21,756 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.901,  Train_accy 46.90
2025-04-22 15:46:32,732 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.884,  Train_accy 46.69
2025-04-22 15:46:52,510 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.916,  Train_accy 46.11, Test_accy 55.88
2025-04-22 15:47:04,962 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.922,  Train_accy 46.48
2025-04-22 15:47:17,459 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.898,  Train_accy 46.72
2025-04-22 15:47:30,048 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.891,  Train_accy 47.16
2025-04-22 15:47:42,469 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.897,  Train_accy 47.09
2025-04-22 15:48:03,380 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.886,  Train_accy 47.18, Test_accy 56.62
2025-04-22 15:48:15,770 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.881,  Train_accy 47.26
2025-04-22 15:48:28,210 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.873,  Train_accy 47.68
2025-04-22 15:48:40,735 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.883,  Train_accy 47.50
2025-04-22 15:48:53,158 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.866,  Train_accy 47.14
2025-04-22 15:49:13,896 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.857,  Train_accy 47.03, Test_accy 56.81
2025-04-22 15:49:26,453 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.868,  Train_accy 47.56
2025-04-22 15:49:38,901 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.860,  Train_accy 47.37
2025-04-22 15:49:51,403 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.861,  Train_accy 47.56
2025-04-22 15:50:03,967 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.870,  Train_accy 47.37
2025-04-22 15:50:24,646 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.855,  Train_accy 47.83, Test_accy 56.52
2025-04-22 15:50:37,267 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.865,  Train_accy 47.98
2025-04-22 15:50:49,842 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.877,  Train_accy 47.60
2025-04-22 15:51:02,335 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.872,  Train_accy 47.85
2025-04-22 15:51:14,886 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.861,  Train_accy 47.85
2025-04-22 15:51:35,806 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.851,  Train_accy 47.58, Test_accy 58.75
2025-04-22 15:51:48,261 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.863,  Train_accy 47.90
2025-04-22 15:52:00,807 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.860,  Train_accy 47.90
2025-04-22 15:52:13,140 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.853,  Train_accy 48.44
2025-04-22 15:52:25,779 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.860,  Train_accy 48.15
2025-04-22 15:52:46,539 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.856,  Train_accy 47.98, Test_accy 55.88
2025-04-22 15:52:59,120 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.846,  Train_accy 48.50
2025-04-22 15:53:11,484 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.842,  Train_accy 47.43
2025-04-22 15:53:24,095 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.855,  Train_accy 48.06
2025-04-22 15:53:36,557 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.853,  Train_accy 47.89
2025-04-22 15:53:57,279 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.838,  Train_accy 47.83, Test_accy 52.00
2025-04-22 15:54:09,742 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.856,  Train_accy 48.00
2025-04-22 15:54:22,328 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.852,  Train_accy 48.46
2025-04-22 15:54:35,013 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.837,  Train_accy 48.21
2025-04-22 15:54:47,948 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.839,  Train_accy 48.11
2025-04-22 15:55:09,017 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.834,  Train_accy 48.08, Test_accy 57.88
2025-04-22 15:55:21,640 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.838,  Train_accy 48.70
2025-04-22 15:55:34,507 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.840,  Train_accy 47.96
2025-04-22 15:55:47,047 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.832,  Train_accy 48.40
2025-04-22 15:55:59,583 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.818,  Train_accy 48.86
2025-04-22 15:56:20,509 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.850,  Train_accy 47.58, Test_accy 58.04
2025-04-22 15:56:33,052 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.826,  Train_accy 48.55
2025-04-22 15:56:45,823 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.841,  Train_accy 48.06
2025-04-22 15:56:58,569 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.834,  Train_accy 49.24
2025-04-22 15:57:11,231 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.822,  Train_accy 48.23
2025-04-22 15:57:32,875 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.839,  Train_accy 48.67, Test_accy 56.83
2025-04-22 15:57:45,400 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.838,  Train_accy 48.80
2025-04-22 15:57:57,972 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.825,  Train_accy 48.15
2025-04-22 15:58:10,138 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.830,  Train_accy 47.96
2025-04-22 15:58:22,627 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.832,  Train_accy 48.99
2025-04-22 15:58:43,297 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.812,  Train_accy 48.36, Test_accy 57.04
2025-04-22 15:58:55,355 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.829,  Train_accy 48.93
2025-04-22 15:59:07,456 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.826,  Train_accy 48.93
2025-04-22 15:59:19,592 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.812,  Train_accy 48.69
2025-04-22 15:59:31,888 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.831,  Train_accy 48.70
2025-04-22 15:59:52,939 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.817,  Train_accy 48.67, Test_accy 55.04
2025-04-22 16:00:04,958 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.810,  Train_accy 48.51
2025-04-22 16:00:16,872 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.819,  Train_accy 48.40
2025-04-22 16:00:28,630 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.814,  Train_accy 49.07
2025-04-22 16:00:40,367 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.837,  Train_accy 48.48
2025-04-22 16:01:00,744 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.825,  Train_accy 48.19, Test_accy 58.36
2025-04-22 16:01:12,559 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.809,  Train_accy 48.30
2025-04-22 16:01:24,505 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.811,  Train_accy 49.39
2025-04-22 16:01:36,307 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.821,  Train_accy 48.44
2025-04-22 16:01:48,232 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.817,  Train_accy 48.86
2025-04-22 16:02:08,534 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.816,  Train_accy 48.50, Test_accy 59.00
2025-04-22 16:02:20,324 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.822,  Train_accy 48.67
2025-04-22 16:02:32,043 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.812,  Train_accy 48.63
2025-04-22 16:02:43,906 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.802,  Train_accy 49.03
2025-04-22 16:02:55,755 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.801,  Train_accy 48.40
2025-04-22 16:03:16,051 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.810,  Train_accy 48.10, Test_accy 59.63
2025-04-22 16:03:27,693 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.796,  Train_accy 48.55
2025-04-22 16:03:39,558 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.802,  Train_accy 48.53
2025-04-22 16:03:51,362 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.813,  Train_accy 48.78
2025-04-22 16:04:03,145 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.814,  Train_accy 48.72
2025-04-22 16:04:23,580 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.812,  Train_accy 48.32, Test_accy 58.16
2025-04-22 16:04:35,319 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.819,  Train_accy 48.86
2025-04-22 16:04:47,160 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.798,  Train_accy 49.31
2025-04-22 16:04:58,871 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.795,  Train_accy 48.65
2025-04-22 16:05:10,757 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.807,  Train_accy 48.50
2025-04-22 16:05:31,322 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.809,  Train_accy 48.72, Test_accy 58.21
2025-04-22 16:05:43,197 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.796,  Train_accy 48.25
2025-04-22 16:05:55,017 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.810,  Train_accy 48.46
2025-04-22 16:06:07,018 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.813,  Train_accy 48.65
2025-04-22 16:06:18,838 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.812,  Train_accy 48.69
2025-04-22 16:06:39,263 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.792,  Train_accy 48.44, Test_accy 58.73
2025-04-22 16:06:51,082 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.809,  Train_accy 48.61
2025-04-22 16:07:02,880 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.808,  Train_accy 48.53
2025-04-22 16:07:14,812 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.806,  Train_accy 48.65
2025-04-22 16:07:26,511 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.798,  Train_accy 48.86
2025-04-22 16:07:46,740 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.808,  Train_accy 48.78, Test_accy 56.90
2025-04-22 16:07:58,677 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.800,  Train_accy 49.03
2025-04-22 16:08:10,689 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.804,  Train_accy 48.50
2025-04-22 16:08:22,487 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.805,  Train_accy 48.86
2025-04-22 16:08:34,254 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.803,  Train_accy 49.50
2025-04-22 16:08:54,569 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.803,  Train_accy 49.16, Test_accy 59.64
2025-04-22 16:09:06,566 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.803,  Train_accy 49.12
2025-04-22 16:09:18,412 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.812,  Train_accy 49.28
2025-04-22 16:09:30,322 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.791,  Train_accy 49.16
2025-04-22 16:09:42,223 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.807,  Train_accy 48.93
2025-04-22 16:10:03,004 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.801,  Train_accy 49.20, Test_accy 59.27
2025-04-22 16:10:14,907 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.795,  Train_accy 49.30
2025-04-22 16:10:27,016 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.800,  Train_accy 48.88
2025-04-22 16:10:38,838 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.796,  Train_accy 49.16
2025-04-22 16:10:50,603 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.813,  Train_accy 49.05
2025-04-22 16:11:11,102 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.798,  Train_accy 49.10, Test_accy 59.02
2025-04-22 16:11:23,088 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.805,  Train_accy 49.24
2025-04-22 16:11:35,023 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.792,  Train_accy 48.55
2025-04-22 16:11:46,912 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.798,  Train_accy 49.60
2025-04-22 16:11:58,890 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.809,  Train_accy 48.84
2025-04-22 16:11:58,890 [der.py] => do not weight align student!
2025-04-22 16:12:06,292 [der.py] => darknet eval: 
2025-04-22 16:12:06,293 [der.py] => CNN top1 curve: 57.28
2025-04-22 16:12:06,293 [der.py] => CNN top5 curve: 86.99
2025-04-22 16:12:06,294 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 16:13:10,752 [der.py] => Exemplar size: 1350
2025-04-22 16:13:10,753 [trainer.py] => CNN: {'total': 70.01, '0': 86.11, '1': 47.78, '2': 68.33, '3': 48.33, '4': 73.33, '5': 33.33, '6': 62.22, '7': 47.22, '8': 31.67, '9': 52.78, '10': 83.89, '11': 94.44, '12': 63.89, '13': 59.44, '14': 47.22, '15': 92.78, '16': 83.33, '17': 88.89, '18': 86.67, '19': 79.44, '20': 92.22, '21': 82.22, '22': 78.33, '23': 53.89, '24': 48.33, '25': 76.67, '26': 85.56, '27': 73.89, '28': 68.89, '29': 84.44, '30': 84.44, '31': 78.89, '32': 70.0, '33': 77.78, '34': 73.33, '35': 91.11, '36': 88.33, '37': 38.33, '38': 7.78, '39': 84.44, '40': 52.22, '41': 88.33, '42': 93.89, '43': 89.44, 'old': 70.29, 'new': 69.06}
2025-04-22 16:13:10,753 [trainer.py] => NME: {'total': 67.02, '0': 65.56, '1': 52.78, '2': 62.78, '3': 38.89, '4': 66.11, '5': 37.22, '6': 56.67, '7': 50.0, '8': 32.78, '9': 57.78, '10': 84.44, '11': 82.22, '12': 64.44, '13': 56.11, '14': 55.0, '15': 82.78, '16': 82.78, '17': 87.78, '18': 77.22, '19': 86.67, '20': 85.56, '21': 71.11, '22': 74.44, '23': 51.67, '24': 47.78, '25': 55.0, '26': 73.89, '27': 66.67, '28': 57.22, '29': 63.89, '30': 58.33, '31': 73.33, '32': 77.78, '33': 37.78, '34': 65.56, '35': 95.56, '36': 90.56, '37': 51.67, '38': 85.56, '39': 80.0, '40': 53.89, '41': 83.89, '42': 92.22, '43': 91.11, 'old': 64.0, 'new': 77.61}
2025-04-22 16:13:10,753 [trainer.py] => CNN top1 curve: [89.44, 87.89, 77.65, 70.01]
2025-04-22 16:13:10,753 [trainer.py] => CNN top5 curve: [98.93, 98.71, 96.05, 93.67]
2025-04-22 16:13:10,753 [trainer.py] => NME top1 curve: [88.22, 85.53, 74.81, 67.02]
2025-04-22 16:13:10,753 [trainer.py] => NME top5 curve: [98.81, 98.64, 96.21, 93.79]

2025-04-22 16:13:10,754 [trainer.py] => All params: 42096208
2025-04-22 16:13:10,754 [trainer.py] => Trainable params: 21054596
2025-04-22 16:13:10,947 [der.py] => Learning on 45-55
2025-04-22 16:13:10,948 [der.py] => All params: 42098778
2025-04-22 16:13:10,949 [der.py] => Trainable params: 21057166
2025-04-22 16:13:11,100 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 16:13:11,101 [der.py] => per cls weights : [1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736 1.19201736
 1.19201736 1.19201736 1.19201736 0.13592186 0.13592186 0.13592186
 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186 0.13592186
 0.13592186]
2025-04-22 16:20:42,456 [trainer.py] => 实验名称:CIL实验
2025-04-22 16:20:42,481 [trainer.py] => config: ./exps/der.json
2025-04-22 16:20:42,481 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 16:20:42,481 [trainer.py] => prefix: reproduce
2025-04-22 16:20:42,481 [trainer.py] => dataset: xrfdataset
2025-04-22 16:20:42,481 [trainer.py] => memory_size: 1650
2025-04-22 16:20:42,481 [trainer.py] => memory_per_class: 30
2025-04-22 16:20:42,481 [trainer.py] => fixed_memory: True
2025-04-22 16:20:42,482 [trainer.py] => shuffle: True
2025-04-22 16:20:42,482 [trainer.py] => init_cls: 15
2025-04-22 16:20:42,482 [trainer.py] => increment: 10
2025-04-22 16:20:42,482 [trainer.py] => model_name: der
2025-04-22 16:20:42,482 [trainer.py] => compression_epochs: 130
2025-04-22 16:20:42,482 [trainer.py] => compression_lr: 0.1
2025-04-22 16:20:42,482 [trainer.py] => is_student_wa: False
2025-04-22 16:20:42,482 [trainer.py] => wa_value: 1
2025-04-22 16:20:42,482 [trainer.py] => T: 2
2025-04-22 16:20:42,482 [trainer.py] => convnet_type: unet
2025-04-22 16:20:42,482 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-04-22 16:20:42,482 [trainer.py] => seed: 1993
2025-04-22 16:20:42,510 [data.py] => 加载完毕XRF原始数据集
2025-04-22 16:20:42,532 [data.py] => 加载完毕XRF原始数据集
2025-04-22 16:20:42,532 [trainer.py] => All params: 0
2025-04-22 16:20:42,532 [trainer.py] => Trainable params: 0
2025-04-22 16:20:42,732 [der.py] => Learning on 0-15
2025-04-22 16:20:42,733 [der.py] => All params: 21045611
2025-04-22 16:20:42,733 [der.py] => Trainable params: 21045611
2025-04-22 16:27:47,356 [trainer.py] => 实验名称:CIL实验
2025-04-22 16:27:47,358 [trainer.py] => config: ./exps/der.json
2025-04-22 16:27:47,359 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 16:27:47,359 [trainer.py] => prefix: reproduce
2025-04-22 16:27:47,359 [trainer.py] => dataset: xrfdataset
2025-04-22 16:27:47,359 [trainer.py] => memory_size: 1650
2025-04-22 16:27:47,359 [trainer.py] => memory_per_class: 30
2025-04-22 16:27:47,359 [trainer.py] => fixed_memory: True
2025-04-22 16:27:47,359 [trainer.py] => shuffle: True
2025-04-22 16:27:47,359 [trainer.py] => init_cls: 15
2025-04-22 16:27:47,359 [trainer.py] => increment: 10
2025-04-22 16:27:47,359 [trainer.py] => model_name: der
2025-04-22 16:27:47,359 [trainer.py] => compression_epochs: 1
2025-04-22 16:27:47,359 [trainer.py] => compression_lr: 0.1
2025-04-22 16:27:47,359 [trainer.py] => is_student_wa: False
2025-04-22 16:27:47,359 [trainer.py] => wa_value: 1
2025-04-22 16:27:47,359 [trainer.py] => T: 2
2025-04-22 16:27:47,359 [trainer.py] => convnet_type: unet
2025-04-22 16:27:47,359 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-04-22 16:27:47,359 [trainer.py] => seed: 1993
2025-04-22 16:27:47,375 [data.py] => 加载完毕XRF原始数据集
2025-04-22 16:27:47,382 [data.py] => 加载完毕XRF原始数据集
2025-04-22 16:27:47,382 [trainer.py] => All params: 0
2025-04-22 16:27:47,382 [trainer.py] => Trainable params: 0
2025-04-22 16:27:47,581 [der.py] => Learning on 0-15
2025-04-22 16:27:47,582 [der.py] => All params: 21045611
2025-04-22 16:27:47,582 [der.py] => Trainable params: 21045611
2025-04-22 16:28:05,929 [der.py] => Task 0, Epoch 1/1 => Loss 2.524, Train_accy 14.41, Test_accy 15.48
2025-04-22 16:28:05,929 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 16:28:32,734 [der.py] => Exemplar size: 450
2025-04-22 16:28:32,734 [trainer.py] => CNN: {'total': 15.48, '0': 56.11, '1': 0.0, '2': 0.56, '3': 0.0, '4': 0.0, '5': 49.44, '6': 0.0, '7': 0.0, '8': 2.22, '9': 8.89, '10': 40.0, '11': 43.33, '12': 1.11, '13': 0.56, 'old': 0, 'new': 15.48}
2025-04-22 16:28:32,734 [trainer.py] => NME: {'total': 18.81, '0': 45.56, '1': 2.22, '2': 5.0, '3': 12.78, '4': 23.89, '5': 8.89, '6': 2.22, '7': 13.33, '8': 33.89, '9': 15.0, '10': 14.44, '11': 50.56, '12': 3.33, '13': 18.89, 'old': 0, 'new': 18.81}
2025-04-22 16:28:32,734 [trainer.py] => CNN top1 curve: [15.48]
2025-04-22 16:28:32,734 [trainer.py] => CNN top5 curve: [57.56]
2025-04-22 16:28:32,734 [trainer.py] => NME top1 curve: [18.81]
2025-04-22 16:28:32,734 [trainer.py] => NME top5 curve: [64.56]

2025-04-22 16:28:32,735 [trainer.py] => All params: 21045611
2025-04-22 16:28:32,735 [trainer.py] => Trainable params: 21045611
2025-04-22 16:28:32,947 [der.py] => Learning on 15-25
2025-04-22 16:28:32,948 [der.py] => All params: 42091068
2025-04-22 16:28:32,948 [der.py] => Trainable params: 21049456
2025-04-22 16:28:33,043 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 16:28:33,044 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-04-22 16:29:27,529 [trainer.py] => 实验名称:CIL实验
2025-04-22 16:29:27,530 [trainer.py] => config: ./exps/der.json
2025-04-22 16:29:27,530 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 16:29:27,530 [trainer.py] => prefix: reproduce
2025-04-22 16:29:27,530 [trainer.py] => dataset: xrfdataset
2025-04-22 16:29:27,530 [trainer.py] => memory_size: 1650
2025-04-22 16:29:27,530 [trainer.py] => memory_per_class: 30
2025-04-22 16:29:27,530 [trainer.py] => fixed_memory: True
2025-04-22 16:29:27,530 [trainer.py] => shuffle: True
2025-04-22 16:29:27,530 [trainer.py] => init_cls: 15
2025-04-22 16:29:27,530 [trainer.py] => increment: 10
2025-04-22 16:29:27,530 [trainer.py] => model_name: der
2025-04-22 16:29:27,530 [trainer.py] => compression_epochs: 130
2025-04-22 16:29:27,530 [trainer.py] => compression_lr: 0.1
2025-04-22 16:29:27,530 [trainer.py] => is_student_wa: False
2025-04-22 16:29:27,530 [trainer.py] => wa_value: 1
2025-04-22 16:29:27,530 [trainer.py] => T: 2
2025-04-22 16:29:27,530 [trainer.py] => convnet_type: unet
2025-04-22 16:29:27,530 [trainer.py] => device: [device(type='cuda', index=2), device(type='cuda', index=3)]
2025-04-22 16:29:27,530 [trainer.py] => seed: 1993
2025-04-22 16:29:27,547 [data.py] => 加载完毕XRF原始数据集
2025-04-22 16:29:27,554 [data.py] => 加载完毕XRF原始数据集
2025-04-22 16:29:27,554 [trainer.py] => All params: 0
2025-04-22 16:29:27,555 [trainer.py] => Trainable params: 0
2025-04-22 16:29:27,758 [der.py] => Learning on 0-15
2025-04-22 16:29:27,759 [der.py] => All params: 21045611
2025-04-22 16:29:27,759 [der.py] => Trainable params: 21045611
2025-04-22 16:55:37,741 [der.py] => Task 0, Epoch 150/150 => Loss 0.025, Train_accy 99.68
2025-04-22 16:55:37,742 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 16:56:10,784 [der.py] => Exemplar size: 450
2025-04-22 16:56:10,785 [trainer.py] => CNN: {'total': 89.44, '0': 98.89, '1': 92.78, '2': 96.67, '3': 86.11, '4': 93.89, '5': 81.67, '6': 80.56, '7': 89.44, '8': 91.11, '9': 61.11, '10': 97.78, '11': 100.0, '12': 90.0, '13': 88.33, 'old': 0, 'new': 89.44}
2025-04-22 16:56:10,785 [trainer.py] => NME: {'total': 88.22, '0': 98.33, '1': 91.67, '2': 95.0, '3': 84.44, '4': 91.67, '5': 78.33, '6': 69.44, '7': 90.56, '8': 93.89, '9': 65.56, '10': 97.78, '11': 100.0, '12': 88.33, '13': 86.11, 'old': 0, 'new': 88.22}
2025-04-22 16:56:10,785 [trainer.py] => CNN top1 curve: [89.44]
2025-04-22 16:56:10,785 [trainer.py] => CNN top5 curve: [98.93]
2025-04-22 16:56:10,785 [trainer.py] => NME top1 curve: [88.22]
2025-04-22 16:56:10,785 [trainer.py] => NME top5 curve: [98.81]

2025-04-22 16:56:10,786 [trainer.py] => All params: 21045611
2025-04-22 16:56:10,786 [trainer.py] => Trainable params: 21045611
2025-04-22 16:56:10,981 [der.py] => Learning on 15-25
2025-04-22 16:56:10,982 [der.py] => All params: 42091068
2025-04-22 16:56:10,982 [der.py] => Trainable params: 21049456
2025-04-22 16:56:11,085 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 16:56:11,086 [der.py] => per cls weights : [1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753 1.23409753
 1.23409753 1.23409753 1.23409753 0.64885371 0.64885371 0.64885371
 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371 0.64885371
 0.64885371]
2025-04-22 17:23:36,123 [der.py] => Task 1, Epoch 150/150 => Loss 0.010, Loss_clf 0.004, Loss_aux 0.006, Train_accy 100.00
2025-04-22 17:23:52,242 [der.py] => SNet: Task 1, Epoch 1/130 => Loss 2.114,  Train_accy 44.77, Test_accy 53.31
2025-04-22 17:24:02,654 [der.py] => SNet: Task 1, Epoch 2/130 => Loss 1.597,  Train_accy 70.13
2025-04-22 17:24:13,049 [der.py] => SNet: Task 1, Epoch 3/130 => Loss 1.414,  Train_accy 78.67
2025-04-22 17:24:23,250 [der.py] => SNet: Task 1, Epoch 4/130 => Loss 1.294,  Train_accy 85.48
2025-04-22 17:24:33,502 [der.py] => SNet: Task 1, Epoch 5/130 => Loss 1.236,  Train_accy 87.48
2025-04-22 17:24:49,039 [der.py] => SNet: Task 1, Epoch 6/130 => Loss 1.191,  Train_accy 91.01, Test_accy 74.33
2025-04-22 17:24:59,315 [der.py] => SNet: Task 1, Epoch 7/130 => Loss 1.169,  Train_accy 90.99
2025-04-22 17:25:09,603 [der.py] => SNet: Task 1, Epoch 8/130 => Loss 1.132,  Train_accy 93.89
2025-04-22 17:25:20,059 [der.py] => SNet: Task 1, Epoch 9/130 => Loss 1.119,  Train_accy 94.02
2025-04-22 17:25:30,191 [der.py] => SNet: Task 1, Epoch 10/130 => Loss 1.115,  Train_accy 94.02
2025-04-22 17:25:45,803 [der.py] => SNet: Task 1, Epoch 11/130 => Loss 1.094,  Train_accy 95.40, Test_accy 76.44
2025-04-22 17:25:56,064 [der.py] => SNet: Task 1, Epoch 12/130 => Loss 1.083,  Train_accy 95.44
2025-04-22 17:26:06,416 [der.py] => SNet: Task 1, Epoch 13/130 => Loss 1.071,  Train_accy 95.74
2025-04-22 17:26:16,911 [der.py] => SNet: Task 1, Epoch 14/130 => Loss 1.068,  Train_accy 96.02
2025-04-22 17:26:27,209 [der.py] => SNet: Task 1, Epoch 15/130 => Loss 1.064,  Train_accy 96.19
2025-04-22 17:26:42,849 [der.py] => SNet: Task 1, Epoch 16/130 => Loss 1.073,  Train_accy 95.76, Test_accy 78.04
2025-04-22 17:26:53,143 [der.py] => SNet: Task 1, Epoch 17/130 => Loss 1.062,  Train_accy 96.04
2025-04-22 17:27:03,625 [der.py] => SNet: Task 1, Epoch 18/130 => Loss 1.058,  Train_accy 96.13
2025-04-22 17:27:13,950 [der.py] => SNet: Task 1, Epoch 19/130 => Loss 1.053,  Train_accy 96.92
2025-04-22 17:27:24,253 [der.py] => SNet: Task 1, Epoch 20/130 => Loss 1.055,  Train_accy 96.69
2025-04-22 17:27:40,119 [der.py] => SNet: Task 1, Epoch 21/130 => Loss 1.042,  Train_accy 97.01, Test_accy 80.24
2025-04-22 17:27:50,419 [der.py] => SNet: Task 1, Epoch 22/130 => Loss 1.041,  Train_accy 96.90
2025-04-22 17:28:00,698 [der.py] => SNet: Task 1, Epoch 23/130 => Loss 1.037,  Train_accy 97.18
2025-04-22 17:28:11,333 [der.py] => SNet: Task 1, Epoch 24/130 => Loss 1.036,  Train_accy 97.14
2025-04-22 17:28:21,568 [der.py] => SNet: Task 1, Epoch 25/130 => Loss 1.033,  Train_accy 97.23
2025-04-22 17:28:37,387 [der.py] => SNet: Task 1, Epoch 26/130 => Loss 1.030,  Train_accy 97.12, Test_accy 80.44
2025-04-22 17:28:47,645 [der.py] => SNet: Task 1, Epoch 27/130 => Loss 1.031,  Train_accy 97.23
2025-04-22 17:28:57,970 [der.py] => SNet: Task 1, Epoch 28/130 => Loss 1.026,  Train_accy 97.33
2025-04-22 17:29:08,374 [der.py] => SNet: Task 1, Epoch 29/130 => Loss 1.025,  Train_accy 97.20
2025-04-22 17:29:18,788 [der.py] => SNet: Task 1, Epoch 30/130 => Loss 1.026,  Train_accy 97.18
2025-04-22 17:29:34,701 [der.py] => SNet: Task 1, Epoch 31/130 => Loss 1.026,  Train_accy 97.03, Test_accy 80.40
2025-04-22 17:29:44,998 [der.py] => SNet: Task 1, Epoch 32/130 => Loss 1.029,  Train_accy 97.10
2025-04-22 17:29:55,606 [der.py] => SNet: Task 1, Epoch 33/130 => Loss 1.019,  Train_accy 97.46
2025-04-22 17:30:06,458 [der.py] => SNet: Task 1, Epoch 34/130 => Loss 1.016,  Train_accy 97.63
2025-04-22 17:30:18,734 [der.py] => SNet: Task 1, Epoch 35/130 => Loss 1.016,  Train_accy 97.31
2025-04-22 17:30:36,742 [der.py] => SNet: Task 1, Epoch 36/130 => Loss 1.016,  Train_accy 97.63, Test_accy 80.91
2025-04-22 17:30:48,804 [der.py] => SNet: Task 1, Epoch 37/130 => Loss 1.015,  Train_accy 97.40
2025-04-22 17:31:00,924 [der.py] => SNet: Task 1, Epoch 38/130 => Loss 1.019,  Train_accy 97.16
2025-04-22 17:31:11,290 [der.py] => SNet: Task 1, Epoch 39/130 => Loss 1.017,  Train_accy 97.51
2025-04-22 17:31:21,713 [der.py] => SNet: Task 1, Epoch 40/130 => Loss 1.012,  Train_accy 97.78
2025-04-22 17:31:37,486 [der.py] => SNet: Task 1, Epoch 41/130 => Loss 1.010,  Train_accy 97.55, Test_accy 81.13
2025-04-22 17:31:47,834 [der.py] => SNet: Task 1, Epoch 42/130 => Loss 1.013,  Train_accy 97.59
2025-04-22 17:31:58,113 [der.py] => SNet: Task 1, Epoch 43/130 => Loss 1.015,  Train_accy 97.10
2025-04-22 17:32:08,618 [der.py] => SNet: Task 1, Epoch 44/130 => Loss 1.005,  Train_accy 97.40
2025-04-22 17:32:18,932 [der.py] => SNet: Task 1, Epoch 45/130 => Loss 1.005,  Train_accy 97.68
2025-04-22 17:32:34,341 [der.py] => SNet: Task 1, Epoch 46/130 => Loss 1.011,  Train_accy 97.70, Test_accy 80.93
2025-04-22 17:32:44,554 [der.py] => SNet: Task 1, Epoch 47/130 => Loss 1.010,  Train_accy 97.01
2025-04-22 17:32:54,880 [der.py] => SNet: Task 1, Epoch 48/130 => Loss 1.004,  Train_accy 97.66
2025-04-22 17:33:05,459 [der.py] => SNet: Task 1, Epoch 49/130 => Loss 1.009,  Train_accy 97.78
2025-04-22 17:33:15,750 [der.py] => SNet: Task 1, Epoch 50/130 => Loss 1.009,  Train_accy 97.94
2025-04-22 17:33:30,904 [der.py] => SNet: Task 1, Epoch 51/130 => Loss 1.007,  Train_accy 97.42, Test_accy 81.18
2025-04-22 17:33:41,084 [der.py] => SNet: Task 1, Epoch 52/130 => Loss 1.007,  Train_accy 97.44
2025-04-22 17:33:51,652 [der.py] => SNet: Task 1, Epoch 53/130 => Loss 1.006,  Train_accy 97.48
2025-04-22 17:34:04,283 [der.py] => SNet: Task 1, Epoch 54/130 => Loss 1.008,  Train_accy 97.70
2025-04-22 17:34:16,786 [der.py] => SNet: Task 1, Epoch 55/130 => Loss 1.006,  Train_accy 97.46
2025-04-22 17:34:35,692 [der.py] => SNet: Task 1, Epoch 56/130 => Loss 0.999,  Train_accy 97.57, Test_accy 81.84
2025-04-22 17:34:48,783 [der.py] => SNet: Task 1, Epoch 57/130 => Loss 0.997,  Train_accy 97.74
2025-04-22 17:34:59,473 [der.py] => SNet: Task 1, Epoch 58/130 => Loss 1.000,  Train_accy 97.59
2025-04-22 17:35:09,964 [der.py] => SNet: Task 1, Epoch 59/130 => Loss 0.999,  Train_accy 97.81
2025-04-22 17:35:20,339 [der.py] => SNet: Task 1, Epoch 60/130 => Loss 0.997,  Train_accy 97.68
2025-04-22 17:35:35,756 [der.py] => SNet: Task 1, Epoch 61/130 => Loss 0.994,  Train_accy 97.66, Test_accy 81.09
2025-04-22 17:35:45,986 [der.py] => SNet: Task 1, Epoch 62/130 => Loss 0.998,  Train_accy 97.70
2025-04-22 17:35:56,417 [der.py] => SNet: Task 1, Epoch 63/130 => Loss 0.998,  Train_accy 97.66
2025-04-22 17:36:07,057 [der.py] => SNet: Task 1, Epoch 64/130 => Loss 0.999,  Train_accy 97.57
2025-04-22 17:36:17,304 [der.py] => SNet: Task 1, Epoch 65/130 => Loss 0.994,  Train_accy 97.85
2025-04-22 17:36:33,189 [der.py] => SNet: Task 1, Epoch 66/130 => Loss 0.993,  Train_accy 97.38, Test_accy 81.24
2025-04-22 17:36:44,820 [der.py] => SNet: Task 1, Epoch 67/130 => Loss 0.995,  Train_accy 97.57
2025-04-22 17:36:56,545 [der.py] => SNet: Task 1, Epoch 68/130 => Loss 0.997,  Train_accy 97.51
2025-04-22 17:37:08,499 [der.py] => SNet: Task 1, Epoch 69/130 => Loss 0.997,  Train_accy 98.06
2025-04-22 17:37:20,568 [der.py] => SNet: Task 1, Epoch 70/130 => Loss 0.997,  Train_accy 97.55
2025-04-22 17:37:37,999 [der.py] => SNet: Task 1, Epoch 71/130 => Loss 0.995,  Train_accy 97.66, Test_accy 81.47
2025-04-22 17:37:48,130 [der.py] => SNet: Task 1, Epoch 72/130 => Loss 0.995,  Train_accy 97.91
2025-04-22 17:37:58,497 [der.py] => SNet: Task 1, Epoch 73/130 => Loss 0.991,  Train_accy 97.76
2025-04-22 17:38:08,995 [der.py] => SNet: Task 1, Epoch 74/130 => Loss 0.997,  Train_accy 97.53
2025-04-22 17:38:19,246 [der.py] => SNet: Task 1, Epoch 75/130 => Loss 0.992,  Train_accy 97.94
2025-04-22 17:38:35,040 [der.py] => SNet: Task 1, Epoch 76/130 => Loss 0.993,  Train_accy 97.51, Test_accy 81.09
2025-04-22 17:38:46,453 [der.py] => SNet: Task 1, Epoch 77/130 => Loss 0.995,  Train_accy 97.91
2025-04-22 17:38:58,466 [der.py] => SNet: Task 1, Epoch 78/130 => Loss 0.991,  Train_accy 97.74
2025-04-22 17:39:10,586 [der.py] => SNet: Task 1, Epoch 79/130 => Loss 0.991,  Train_accy 98.11
2025-04-22 17:39:23,087 [der.py] => SNet: Task 1, Epoch 80/130 => Loss 0.994,  Train_accy 97.72
2025-04-22 17:39:39,579 [der.py] => SNet: Task 1, Epoch 81/130 => Loss 0.990,  Train_accy 97.83, Test_accy 81.44
2025-04-22 17:39:49,859 [der.py] => SNet: Task 1, Epoch 82/130 => Loss 0.995,  Train_accy 97.66
2025-04-22 17:39:59,981 [der.py] => SNet: Task 1, Epoch 83/130 => Loss 0.993,  Train_accy 97.55
2025-04-22 17:40:10,488 [der.py] => SNet: Task 1, Epoch 84/130 => Loss 0.990,  Train_accy 97.57
2025-04-22 17:40:21,067 [der.py] => SNet: Task 1, Epoch 85/130 => Loss 0.989,  Train_accy 97.72
2025-04-22 17:40:39,427 [der.py] => SNet: Task 1, Epoch 86/130 => Loss 0.986,  Train_accy 98.06, Test_accy 81.73
2025-04-22 17:40:51,694 [der.py] => SNet: Task 1, Epoch 87/130 => Loss 0.990,  Train_accy 97.74
2025-04-22 17:41:04,052 [der.py] => SNet: Task 1, Epoch 88/130 => Loss 0.992,  Train_accy 97.63
2025-04-22 17:41:16,859 [der.py] => SNet: Task 1, Epoch 89/130 => Loss 0.990,  Train_accy 97.94
2025-04-22 17:41:29,567 [der.py] => SNet: Task 1, Epoch 90/130 => Loss 0.988,  Train_accy 97.63
2025-04-22 17:41:46,024 [der.py] => SNet: Task 1, Epoch 91/130 => Loss 0.989,  Train_accy 97.35, Test_accy 82.31
2025-04-22 17:41:56,570 [der.py] => SNet: Task 1, Epoch 92/130 => Loss 0.988,  Train_accy 98.02
2025-04-22 17:42:06,963 [der.py] => SNet: Task 1, Epoch 93/130 => Loss 0.986,  Train_accy 97.98
2025-04-22 17:42:17,619 [der.py] => SNet: Task 1, Epoch 94/130 => Loss 0.988,  Train_accy 97.91
2025-04-22 17:42:28,484 [der.py] => SNet: Task 1, Epoch 95/130 => Loss 0.989,  Train_accy 97.61
2025-04-22 17:42:44,603 [der.py] => SNet: Task 1, Epoch 96/130 => Loss 0.985,  Train_accy 97.74, Test_accy 81.96
2025-04-22 17:42:55,237 [der.py] => SNet: Task 1, Epoch 97/130 => Loss 0.987,  Train_accy 97.85
2025-04-22 17:43:05,774 [der.py] => SNet: Task 1, Epoch 98/130 => Loss 0.987,  Train_accy 97.96
2025-04-22 17:43:16,678 [der.py] => SNet: Task 1, Epoch 99/130 => Loss 0.985,  Train_accy 97.83
2025-04-22 17:43:27,382 [der.py] => SNet: Task 1, Epoch 100/130 => Loss 0.992,  Train_accy 97.59
2025-04-22 17:43:43,448 [der.py] => SNet: Task 1, Epoch 101/130 => Loss 0.987,  Train_accy 97.61, Test_accy 82.07
2025-04-22 17:43:53,890 [der.py] => SNet: Task 1, Epoch 102/130 => Loss 0.988,  Train_accy 97.70
2025-04-22 17:44:04,688 [der.py] => SNet: Task 1, Epoch 103/130 => Loss 0.985,  Train_accy 98.04
2025-04-22 17:44:15,691 [der.py] => SNet: Task 1, Epoch 104/130 => Loss 0.985,  Train_accy 97.83
2025-04-22 17:44:26,433 [der.py] => SNet: Task 1, Epoch 105/130 => Loss 0.986,  Train_accy 97.72
2025-04-22 17:44:43,010 [der.py] => SNet: Task 1, Epoch 106/130 => Loss 0.982,  Train_accy 98.02, Test_accy 81.73
2025-04-22 17:44:53,926 [der.py] => SNet: Task 1, Epoch 107/130 => Loss 0.983,  Train_accy 97.72
2025-04-22 17:45:04,635 [der.py] => SNet: Task 1, Epoch 108/130 => Loss 0.989,  Train_accy 97.85
2025-04-22 17:45:15,550 [der.py] => SNet: Task 1, Epoch 109/130 => Loss 0.983,  Train_accy 97.85
2025-04-22 17:45:26,349 [der.py] => SNet: Task 1, Epoch 110/130 => Loss 0.987,  Train_accy 97.66
2025-04-22 17:45:43,235 [der.py] => SNet: Task 1, Epoch 111/130 => Loss 0.986,  Train_accy 97.89, Test_accy 81.49
2025-04-22 17:45:53,977 [der.py] => SNet: Task 1, Epoch 112/130 => Loss 0.985,  Train_accy 98.00
2025-04-22 17:46:04,675 [der.py] => SNet: Task 1, Epoch 113/130 => Loss 0.985,  Train_accy 97.81
2025-04-22 17:46:15,568 [der.py] => SNet: Task 1, Epoch 114/130 => Loss 0.985,  Train_accy 97.98
2025-04-22 17:46:26,450 [der.py] => SNet: Task 1, Epoch 115/130 => Loss 0.985,  Train_accy 97.91
2025-04-22 17:46:43,018 [der.py] => SNet: Task 1, Epoch 116/130 => Loss 0.985,  Train_accy 98.02, Test_accy 81.64
2025-04-22 17:46:53,585 [der.py] => SNet: Task 1, Epoch 117/130 => Loss 0.983,  Train_accy 97.81
2025-04-22 17:47:04,217 [der.py] => SNet: Task 1, Epoch 118/130 => Loss 0.984,  Train_accy 97.76
2025-04-22 17:47:15,148 [der.py] => SNet: Task 1, Epoch 119/130 => Loss 0.986,  Train_accy 97.96
2025-04-22 17:47:25,813 [der.py] => SNet: Task 1, Epoch 120/130 => Loss 0.986,  Train_accy 97.91
2025-04-22 17:47:42,512 [der.py] => SNet: Task 1, Epoch 121/130 => Loss 0.985,  Train_accy 97.96, Test_accy 81.98
2025-04-22 17:47:53,287 [der.py] => SNet: Task 1, Epoch 122/130 => Loss 0.987,  Train_accy 98.04
2025-04-22 17:48:04,284 [der.py] => SNet: Task 1, Epoch 123/130 => Loss 0.984,  Train_accy 98.00
2025-04-22 17:48:15,255 [der.py] => SNet: Task 1, Epoch 124/130 => Loss 0.982,  Train_accy 98.04
2025-04-22 17:48:25,891 [der.py] => SNet: Task 1, Epoch 125/130 => Loss 0.983,  Train_accy 97.70
2025-04-22 17:48:42,433 [der.py] => SNet: Task 1, Epoch 126/130 => Loss 0.981,  Train_accy 98.00, Test_accy 81.98
2025-04-22 17:48:53,224 [der.py] => SNet: Task 1, Epoch 127/130 => Loss 0.986,  Train_accy 97.94
2025-04-22 17:49:04,015 [der.py] => SNet: Task 1, Epoch 128/130 => Loss 0.986,  Train_accy 97.87
2025-04-22 17:49:14,929 [der.py] => SNet: Task 1, Epoch 129/130 => Loss 0.981,  Train_accy 97.85
2025-04-22 17:49:25,667 [der.py] => SNet: Task 1, Epoch 130/130 => Loss 0.982,  Train_accy 97.85
2025-04-22 17:49:25,668 [der.py] => do not weight align student!
2025-04-22 17:49:30,973 [der.py] => darknet eval: 
2025-04-22 17:49:30,973 [der.py] => CNN top1 curve: 81.67
2025-04-22 17:49:30,973 [der.py] => CNN top5 curve: 98.11
2025-04-22 17:49:30,974 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 17:50:17,175 [der.py] => Exemplar size: 750
2025-04-22 17:50:17,176 [trainer.py] => CNN: {'total': 88.07, '0': 93.89, '1': 81.11, '2': 93.89, '3': 83.33, '4': 91.67, '5': 68.33, '6': 75.0, '7': 83.33, '8': 65.0, '9': 63.89, '10': 96.67, '11': 99.44, '12': 87.22, '13': 88.89, '14': 86.11, '15': 96.67, '16': 97.78, '17': 97.22, '18': 97.78, '19': 96.11, '20': 98.33, '21': 91.11, '22': 87.78, '23': 86.67, 'old': 83.85, 'new': 94.39}
2025-04-22 17:50:17,176 [trainer.py] => NME: {'total': 84.98, '0': 87.22, '1': 72.78, '2': 91.11, '3': 82.78, '4': 88.89, '5': 64.44, '6': 67.22, '7': 59.44, '8': 57.78, '9': 68.33, '10': 96.67, '11': 100.0, '12': 84.44, '13': 82.78, '14': 82.78, '15': 95.0, '16': 99.44, '17': 94.44, '18': 95.0, '19': 92.22, '20': 95.56, '21': 94.44, '22': 90.0, '23': 89.44, 'old': 79.11, 'new': 93.78}
2025-04-22 17:50:17,176 [trainer.py] => CNN top1 curve: [89.44, 88.07]
2025-04-22 17:50:17,176 [trainer.py] => CNN top5 curve: [98.93, 98.76]
2025-04-22 17:50:17,176 [trainer.py] => NME top1 curve: [88.22, 84.98]
2025-04-22 17:50:17,176 [trainer.py] => NME top5 curve: [98.81, 98.51]

2025-04-22 17:50:17,177 [trainer.py] => All params: 42091068
2025-04-22 17:50:17,178 [trainer.py] => Trainable params: 21049456
2025-04-22 17:50:17,460 [der.py] => Learning on 25-35
2025-04-22 17:50:17,461 [der.py] => All params: 42093638
2025-04-22 17:50:17,461 [der.py] => Trainable params: 21052026
2025-04-22 17:50:17,571 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 17:50:17,572 [der.py] => per cls weights : [1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966 1.15672966
 1.15672966 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586
 0.60817586 0.60817586 0.60817586 0.60817586 0.60817586]
2025-04-22 18:21:35,244 [der.py] => Task 2, Epoch 150/150 => Loss 0.011, Loss_clf 0.006, Loss_aux 0.005, Train_accy 100.00
2025-04-22 18:21:53,993 [der.py] => SNet: Task 2, Epoch 1/130 => Loss 2.251,  Train_accy 45.92, Test_accy 57.27
2025-04-22 18:22:05,264 [der.py] => SNet: Task 2, Epoch 2/130 => Loss 1.916,  Train_accy 68.06
2025-04-22 18:22:16,563 [der.py] => SNet: Task 2, Epoch 3/130 => Loss 1.789,  Train_accy 76.14
2025-04-22 18:22:27,855 [der.py] => SNet: Task 2, Epoch 4/130 => Loss 1.724,  Train_accy 80.85
2025-04-22 18:22:39,218 [der.py] => SNet: Task 2, Epoch 5/130 => Loss 1.685,  Train_accy 83.52
2025-04-22 18:22:57,782 [der.py] => SNet: Task 2, Epoch 6/130 => Loss 1.653,  Train_accy 85.41, Test_accy 64.62
2025-04-22 18:23:09,029 [der.py] => SNet: Task 2, Epoch 7/130 => Loss 1.635,  Train_accy 86.00
2025-04-22 18:23:20,439 [der.py] => SNet: Task 2, Epoch 8/130 => Loss 1.621,  Train_accy 87.19
2025-04-22 18:23:31,687 [der.py] => SNet: Task 2, Epoch 9/130 => Loss 1.600,  Train_accy 88.24
2025-04-22 18:23:43,066 [der.py] => SNet: Task 2, Epoch 10/130 => Loss 1.595,  Train_accy 88.18
2025-04-22 18:24:01,513 [der.py] => SNet: Task 2, Epoch 11/130 => Loss 1.578,  Train_accy 89.66, Test_accy 69.84
2025-04-22 18:24:12,896 [der.py] => SNet: Task 2, Epoch 12/130 => Loss 1.564,  Train_accy 90.42
2025-04-22 18:24:24,305 [der.py] => SNet: Task 2, Epoch 13/130 => Loss 1.558,  Train_accy 90.97
2025-04-22 18:24:35,607 [der.py] => SNet: Task 2, Epoch 14/130 => Loss 1.558,  Train_accy 89.96
2025-04-22 18:24:46,965 [der.py] => SNet: Task 2, Epoch 15/130 => Loss 1.552,  Train_accy 91.31
2025-04-22 18:25:05,306 [der.py] => SNet: Task 2, Epoch 16/130 => Loss 1.546,  Train_accy 91.76, Test_accy 68.90
2025-04-22 18:25:16,708 [der.py] => SNet: Task 2, Epoch 17/130 => Loss 1.541,  Train_accy 92.04
2025-04-22 18:25:28,077 [der.py] => SNet: Task 2, Epoch 18/130 => Loss 1.535,  Train_accy 92.16
2025-04-22 18:25:39,195 [der.py] => SNet: Task 2, Epoch 19/130 => Loss 1.533,  Train_accy 91.70
2025-04-22 18:25:50,557 [der.py] => SNet: Task 2, Epoch 20/130 => Loss 1.524,  Train_accy 92.93
2025-04-22 18:26:09,246 [der.py] => SNet: Task 2, Epoch 21/130 => Loss 1.527,  Train_accy 92.97, Test_accy 70.06
2025-04-22 18:26:20,506 [der.py] => SNet: Task 2, Epoch 22/130 => Loss 1.527,  Train_accy 92.20
2025-04-22 18:26:31,948 [der.py] => SNet: Task 2, Epoch 23/130 => Loss 1.525,  Train_accy 92.42
2025-04-22 18:26:43,248 [der.py] => SNet: Task 2, Epoch 24/130 => Loss 1.517,  Train_accy 92.93
2025-04-22 18:26:54,410 [der.py] => SNet: Task 2, Epoch 25/130 => Loss 1.511,  Train_accy 93.60
2025-04-22 18:27:12,782 [der.py] => SNet: Task 2, Epoch 26/130 => Loss 1.508,  Train_accy 93.43, Test_accy 72.33
2025-04-22 18:27:24,049 [der.py] => SNet: Task 2, Epoch 27/130 => Loss 1.504,  Train_accy 93.64
2025-04-22 18:27:35,234 [der.py] => SNet: Task 2, Epoch 28/130 => Loss 1.502,  Train_accy 93.88
2025-04-22 18:27:46,683 [der.py] => SNet: Task 2, Epoch 29/130 => Loss 1.503,  Train_accy 93.37
2025-04-22 18:27:57,847 [der.py] => SNet: Task 2, Epoch 30/130 => Loss 1.500,  Train_accy 93.92
2025-04-22 18:28:16,345 [der.py] => SNet: Task 2, Epoch 31/130 => Loss 1.501,  Train_accy 93.98, Test_accy 72.00
2025-04-22 18:28:27,484 [der.py] => SNet: Task 2, Epoch 32/130 => Loss 1.500,  Train_accy 93.52
2025-04-22 18:28:38,661 [der.py] => SNet: Task 2, Epoch 33/130 => Loss 1.495,  Train_accy 94.06
2025-04-22 18:28:49,956 [der.py] => SNet: Task 2, Epoch 34/130 => Loss 1.495,  Train_accy 94.20
2025-04-22 18:29:01,222 [der.py] => SNet: Task 2, Epoch 35/130 => Loss 1.492,  Train_accy 94.10
2025-04-22 18:29:19,695 [der.py] => SNet: Task 2, Epoch 36/130 => Loss 1.493,  Train_accy 94.00, Test_accy 72.37
2025-04-22 18:29:30,948 [der.py] => SNet: Task 2, Epoch 37/130 => Loss 1.490,  Train_accy 93.74
2025-04-22 18:29:42,171 [der.py] => SNet: Task 2, Epoch 38/130 => Loss 1.490,  Train_accy 94.16
2025-04-22 18:29:53,467 [der.py] => SNet: Task 2, Epoch 39/130 => Loss 1.487,  Train_accy 94.32
2025-04-22 18:30:04,559 [der.py] => SNet: Task 2, Epoch 40/130 => Loss 1.484,  Train_accy 94.30
2025-04-22 18:30:23,087 [der.py] => SNet: Task 2, Epoch 41/130 => Loss 1.490,  Train_accy 93.98, Test_accy 73.35
2025-04-22 18:30:34,202 [der.py] => SNet: Task 2, Epoch 42/130 => Loss 1.484,  Train_accy 94.79
2025-04-22 18:30:45,411 [der.py] => SNet: Task 2, Epoch 43/130 => Loss 1.485,  Train_accy 94.55
2025-04-22 18:30:56,514 [der.py] => SNet: Task 2, Epoch 44/130 => Loss 1.485,  Train_accy 94.36
2025-04-22 18:31:07,868 [der.py] => SNet: Task 2, Epoch 45/130 => Loss 1.481,  Train_accy 94.30
2025-04-22 18:31:26,221 [der.py] => SNet: Task 2, Epoch 46/130 => Loss 1.481,  Train_accy 94.85, Test_accy 73.40
2025-04-22 18:31:37,492 [der.py] => SNet: Task 2, Epoch 47/130 => Loss 1.481,  Train_accy 94.22
2025-04-22 18:31:48,857 [der.py] => SNet: Task 2, Epoch 48/130 => Loss 1.480,  Train_accy 94.67
2025-04-22 18:32:00,234 [der.py] => SNet: Task 2, Epoch 49/130 => Loss 1.481,  Train_accy 94.26
2025-04-22 18:32:11,667 [der.py] => SNet: Task 2, Epoch 50/130 => Loss 1.476,  Train_accy 94.81
2025-04-22 18:32:30,271 [der.py] => SNet: Task 2, Epoch 51/130 => Loss 1.475,  Train_accy 94.51, Test_accy 73.49
2025-04-22 18:32:41,599 [der.py] => SNet: Task 2, Epoch 52/130 => Loss 1.478,  Train_accy 94.69
2025-04-22 18:32:52,773 [der.py] => SNet: Task 2, Epoch 53/130 => Loss 1.479,  Train_accy 94.48
2025-04-22 18:33:03,930 [der.py] => SNet: Task 2, Epoch 54/130 => Loss 1.472,  Train_accy 94.97
2025-04-22 18:33:15,335 [der.py] => SNet: Task 2, Epoch 55/130 => Loss 1.475,  Train_accy 94.67
2025-04-22 18:33:34,045 [der.py] => SNet: Task 2, Epoch 56/130 => Loss 1.473,  Train_accy 94.95, Test_accy 74.17
2025-04-22 18:33:45,413 [der.py] => SNet: Task 2, Epoch 57/130 => Loss 1.471,  Train_accy 95.31
2025-04-22 18:33:56,593 [der.py] => SNet: Task 2, Epoch 58/130 => Loss 1.474,  Train_accy 94.67
2025-04-22 18:34:07,929 [der.py] => SNet: Task 2, Epoch 59/130 => Loss 1.473,  Train_accy 95.17
2025-04-22 18:34:19,068 [der.py] => SNet: Task 2, Epoch 60/130 => Loss 1.469,  Train_accy 94.95
2025-04-22 18:34:37,454 [der.py] => SNet: Task 2, Epoch 61/130 => Loss 1.471,  Train_accy 94.61, Test_accy 74.05
2025-04-22 18:34:48,865 [der.py] => SNet: Task 2, Epoch 62/130 => Loss 1.468,  Train_accy 95.19
2025-04-22 18:35:00,223 [der.py] => SNet: Task 2, Epoch 63/130 => Loss 1.475,  Train_accy 94.79
2025-04-22 18:35:11,496 [der.py] => SNet: Task 2, Epoch 64/130 => Loss 1.467,  Train_accy 95.23
2025-04-22 18:35:22,839 [der.py] => SNet: Task 2, Epoch 65/130 => Loss 1.468,  Train_accy 95.07
2025-04-22 18:35:41,316 [der.py] => SNet: Task 2, Epoch 66/130 => Loss 1.467,  Train_accy 95.07, Test_accy 74.21
2025-04-22 18:35:52,660 [der.py] => SNet: Task 2, Epoch 67/130 => Loss 1.467,  Train_accy 95.27
2025-04-22 18:36:03,783 [der.py] => SNet: Task 2, Epoch 68/130 => Loss 1.466,  Train_accy 95.15
2025-04-22 18:36:15,033 [der.py] => SNet: Task 2, Epoch 69/130 => Loss 1.464,  Train_accy 95.05
2025-04-22 18:36:26,304 [der.py] => SNet: Task 2, Epoch 70/130 => Loss 1.462,  Train_accy 94.99
2025-04-22 18:36:45,065 [der.py] => SNet: Task 2, Epoch 71/130 => Loss 1.466,  Train_accy 95.15, Test_accy 74.19
2025-04-22 18:36:56,261 [der.py] => SNet: Task 2, Epoch 72/130 => Loss 1.465,  Train_accy 95.41
2025-04-22 18:37:07,645 [der.py] => SNet: Task 2, Epoch 73/130 => Loss 1.467,  Train_accy 95.47
2025-04-22 18:37:18,798 [der.py] => SNet: Task 2, Epoch 74/130 => Loss 1.461,  Train_accy 95.52
2025-04-22 18:37:29,913 [der.py] => SNet: Task 2, Epoch 75/130 => Loss 1.464,  Train_accy 94.91
2025-04-22 18:37:48,206 [der.py] => SNet: Task 2, Epoch 76/130 => Loss 1.463,  Train_accy 95.29, Test_accy 74.10
2025-04-22 18:37:59,309 [der.py] => SNet: Task 2, Epoch 77/130 => Loss 1.463,  Train_accy 94.97
2025-04-22 18:38:10,547 [der.py] => SNet: Task 2, Epoch 78/130 => Loss 1.461,  Train_accy 95.78
2025-04-22 18:38:21,696 [der.py] => SNet: Task 2, Epoch 79/130 => Loss 1.463,  Train_accy 95.21
2025-04-22 18:38:32,911 [der.py] => SNet: Task 2, Epoch 80/130 => Loss 1.461,  Train_accy 95.27
2025-04-22 18:38:51,237 [der.py] => SNet: Task 2, Epoch 81/130 => Loss 1.460,  Train_accy 95.29, Test_accy 73.83
2025-04-22 18:39:02,554 [der.py] => SNet: Task 2, Epoch 82/130 => Loss 1.461,  Train_accy 95.25
2025-04-22 18:39:14,011 [der.py] => SNet: Task 2, Epoch 83/130 => Loss 1.455,  Train_accy 95.56
2025-04-22 18:39:25,363 [der.py] => SNet: Task 2, Epoch 84/130 => Loss 1.456,  Train_accy 95.49
2025-04-22 18:39:36,828 [der.py] => SNet: Task 2, Epoch 85/130 => Loss 1.460,  Train_accy 95.72
2025-04-22 18:39:55,499 [der.py] => SNet: Task 2, Epoch 86/130 => Loss 1.458,  Train_accy 95.31, Test_accy 74.37
2025-04-22 18:40:06,857 [der.py] => SNet: Task 2, Epoch 87/130 => Loss 1.455,  Train_accy 95.41
2025-04-22 18:40:18,274 [der.py] => SNet: Task 2, Epoch 88/130 => Loss 1.457,  Train_accy 95.33
2025-04-22 18:40:29,397 [der.py] => SNet: Task 2, Epoch 89/130 => Loss 1.456,  Train_accy 95.60
2025-04-22 18:40:40,745 [der.py] => SNet: Task 2, Epoch 90/130 => Loss 1.457,  Train_accy 95.72
2025-04-22 18:40:59,509 [der.py] => SNet: Task 2, Epoch 91/130 => Loss 1.454,  Train_accy 95.19, Test_accy 74.32
2025-04-22 18:41:10,683 [der.py] => SNet: Task 2, Epoch 92/130 => Loss 1.456,  Train_accy 95.37
2025-04-22 18:41:21,828 [der.py] => SNet: Task 2, Epoch 93/130 => Loss 1.456,  Train_accy 95.35
2025-04-22 18:41:33,141 [der.py] => SNet: Task 2, Epoch 94/130 => Loss 1.454,  Train_accy 95.45
2025-04-22 18:41:44,438 [der.py] => SNet: Task 2, Epoch 95/130 => Loss 1.454,  Train_accy 95.58
2025-04-22 18:42:02,914 [der.py] => SNet: Task 2, Epoch 96/130 => Loss 1.454,  Train_accy 95.58, Test_accy 74.89
2025-04-22 18:42:14,110 [der.py] => SNet: Task 2, Epoch 97/130 => Loss 1.453,  Train_accy 95.76
2025-04-22 18:42:25,280 [der.py] => SNet: Task 2, Epoch 98/130 => Loss 1.454,  Train_accy 95.58
2025-04-22 18:42:36,485 [der.py] => SNet: Task 2, Epoch 99/130 => Loss 1.451,  Train_accy 95.64
2025-04-22 18:42:47,740 [der.py] => SNet: Task 2, Epoch 100/130 => Loss 1.452,  Train_accy 95.56
2025-04-22 18:43:06,046 [der.py] => SNet: Task 2, Epoch 101/130 => Loss 1.455,  Train_accy 95.66, Test_accy 74.56
2025-04-22 18:43:17,306 [der.py] => SNet: Task 2, Epoch 102/130 => Loss 1.456,  Train_accy 95.23
2025-04-22 18:43:28,543 [der.py] => SNet: Task 2, Epoch 103/130 => Loss 1.455,  Train_accy 95.74
2025-04-22 18:43:39,956 [der.py] => SNet: Task 2, Epoch 104/130 => Loss 1.452,  Train_accy 95.56
2025-04-22 18:43:51,108 [der.py] => SNet: Task 2, Epoch 105/130 => Loss 1.451,  Train_accy 95.72
2025-04-22 18:44:09,583 [der.py] => SNet: Task 2, Epoch 106/130 => Loss 1.452,  Train_accy 95.76, Test_accy 74.67
2025-04-22 18:44:20,685 [der.py] => SNet: Task 2, Epoch 107/130 => Loss 1.453,  Train_accy 95.76
2025-04-22 18:44:32,035 [der.py] => SNet: Task 2, Epoch 108/130 => Loss 1.451,  Train_accy 95.86
2025-04-22 18:44:43,504 [der.py] => SNet: Task 2, Epoch 109/130 => Loss 1.454,  Train_accy 95.41
2025-04-22 18:44:54,651 [der.py] => SNet: Task 2, Epoch 110/130 => Loss 1.452,  Train_accy 95.70
2025-04-22 18:45:13,265 [der.py] => SNet: Task 2, Epoch 111/130 => Loss 1.452,  Train_accy 95.76, Test_accy 74.65
2025-04-22 18:45:24,486 [der.py] => SNet: Task 2, Epoch 112/130 => Loss 1.452,  Train_accy 95.70
2025-04-22 18:45:35,758 [der.py] => SNet: Task 2, Epoch 113/130 => Loss 1.451,  Train_accy 95.72
2025-04-22 18:45:46,978 [der.py] => SNet: Task 2, Epoch 114/130 => Loss 1.450,  Train_accy 95.82
2025-04-22 18:45:58,152 [der.py] => SNet: Task 2, Epoch 115/130 => Loss 1.452,  Train_accy 95.58
2025-04-22 18:46:16,409 [der.py] => SNet: Task 2, Epoch 116/130 => Loss 1.451,  Train_accy 95.49, Test_accy 74.79
2025-04-22 18:46:27,674 [der.py] => SNet: Task 2, Epoch 117/130 => Loss 1.452,  Train_accy 95.49
2025-04-22 18:46:38,985 [der.py] => SNet: Task 2, Epoch 118/130 => Loss 1.452,  Train_accy 95.76
2025-04-22 18:46:50,079 [der.py] => SNet: Task 2, Epoch 119/130 => Loss 1.452,  Train_accy 95.84
2025-04-22 18:47:01,317 [der.py] => SNet: Task 2, Epoch 120/130 => Loss 1.454,  Train_accy 95.47
2025-04-22 18:47:19,612 [der.py] => SNet: Task 2, Epoch 121/130 => Loss 1.452,  Train_accy 95.62, Test_accy 74.67
2025-04-22 18:47:30,746 [der.py] => SNet: Task 2, Epoch 122/130 => Loss 1.450,  Train_accy 95.62
2025-04-22 18:47:41,919 [der.py] => SNet: Task 2, Epoch 123/130 => Loss 1.453,  Train_accy 95.43
2025-04-22 18:47:53,222 [der.py] => SNet: Task 2, Epoch 124/130 => Loss 1.453,  Train_accy 95.33
2025-04-22 18:48:04,497 [der.py] => SNet: Task 2, Epoch 125/130 => Loss 1.451,  Train_accy 95.43
2025-04-22 18:48:23,009 [der.py] => SNet: Task 2, Epoch 126/130 => Loss 1.451,  Train_accy 95.62, Test_accy 74.71
2025-04-22 18:48:34,060 [der.py] => SNet: Task 2, Epoch 127/130 => Loss 1.453,  Train_accy 95.09
2025-04-22 18:48:45,561 [der.py] => SNet: Task 2, Epoch 128/130 => Loss 1.452,  Train_accy 95.54
2025-04-22 18:48:56,735 [der.py] => SNet: Task 2, Epoch 129/130 => Loss 1.452,  Train_accy 95.56
2025-04-22 18:49:08,108 [der.py] => SNet: Task 2, Epoch 130/130 => Loss 1.451,  Train_accy 95.52
2025-04-22 18:49:08,114 [der.py] => do not weight align student!
2025-04-22 18:49:14,459 [der.py] => darknet eval: 
2025-04-22 18:49:14,460 [der.py] => CNN top1 curve: 75.03
2025-04-22 18:49:14,460 [der.py] => CNN top5 curve: 96.06
2025-04-22 18:49:14,461 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 18:50:10,042 [der.py] => Exemplar size: 1050
2025-04-22 18:50:10,045 [trainer.py] => CNN: {'total': 79.33, '0': 88.89, '1': 59.44, '2': 82.22, '3': 63.89, '4': 77.22, '5': 41.67, '6': 63.89, '7': 53.33, '8': 40.0, '9': 50.0, '10': 90.0, '11': 93.89, '12': 75.0, '13': 65.0, '14': 63.89, '15': 94.44, '16': 99.44, '17': 97.22, '18': 93.89, '19': 96.11, '20': 96.67, '21': 92.22, '22': 94.44, '23': 84.44, '24': 85.0, '25': 81.11, '26': 81.67, '27': 86.11, '28': 68.89, '29': 78.89, '30': 85.0, '31': 86.11, '32': 96.67, '33': 83.33, 'old': 77.69, 'new': 83.44}
2025-04-22 18:50:10,045 [trainer.py] => NME: {'total': 75.76, '0': 84.44, '1': 55.56, '2': 70.56, '3': 59.44, '4': 77.78, '5': 37.22, '6': 54.44, '7': 53.89, '8': 45.56, '9': 56.67, '10': 91.67, '11': 90.56, '12': 68.33, '13': 55.56, '14': 58.89, '15': 90.56, '16': 91.67, '17': 93.33, '18': 87.78, '19': 90.56, '20': 93.89, '21': 87.78, '22': 82.78, '23': 67.22, '24': 63.89, '25': 84.44, '26': 94.44, '27': 87.78, '28': 66.11, '29': 81.11, '30': 83.89, '31': 86.67, '32': 95.0, '33': 77.78, 'old': 72.4, 'new': 84.17}
2025-04-22 18:50:10,045 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.33]
2025-04-22 18:50:10,045 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.83]
2025-04-22 18:50:10,045 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.76]
2025-04-22 18:50:10,045 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.05]

2025-04-22 18:50:10,046 [trainer.py] => All params: 42093638
2025-04-22 18:50:10,047 [trainer.py] => Trainable params: 21052026
2025-04-22 18:50:10,232 [der.py] => Learning on 35-45
2025-04-22 18:50:10,238 [der.py] => All params: 42096208
2025-04-22 18:50:10,239 [der.py] => Trainable params: 21054596
2025-04-22 18:50:10,374 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 18:50:10,377 [der.py] => per cls weights : [1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808
 1.11779808 1.11779808 1.11779808 1.11779808 1.11779808 0.58770673
 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673 0.58770673
 0.58770673 0.58770673 0.58770673]
2025-04-22 20:02:43,252 [der.py] => Task 3, Epoch 150/150 => Loss 0.147, Loss_clf 0.080, Loss_aux 0.067, Train_accy 99.90
2025-04-22 20:03:04,854 [der.py] => SNet: Task 3, Epoch 1/130 => Loss 1.967,  Train_accy 45.79, Test_accy 46.33
2025-04-22 20:03:16,832 [der.py] => SNet: Task 3, Epoch 2/130 => Loss 1.724,  Train_accy 56.78
2025-04-22 20:03:28,641 [der.py] => SNet: Task 3, Epoch 3/130 => Loss 1.569,  Train_accy 62.88
2025-04-22 20:03:40,684 [der.py] => SNet: Task 3, Epoch 4/130 => Loss 1.506,  Train_accy 65.24
2025-04-22 20:03:52,596 [der.py] => SNet: Task 3, Epoch 5/130 => Loss 1.517,  Train_accy 66.40
2025-04-22 20:04:13,586 [der.py] => SNet: Task 3, Epoch 6/130 => Loss 1.525,  Train_accy 67.31, Test_accy 56.09
2025-04-22 20:04:25,633 [der.py] => SNet: Task 3, Epoch 7/130 => Loss 1.492,  Train_accy 67.70
2025-04-22 20:04:37,734 [der.py] => SNet: Task 3, Epoch 8/130 => Loss 1.419,  Train_accy 69.92
2025-04-22 20:04:49,584 [der.py] => SNet: Task 3, Epoch 9/130 => Loss 1.418,  Train_accy 70.36
2025-04-22 20:05:01,571 [der.py] => SNet: Task 3, Epoch 10/130 => Loss 1.434,  Train_accy 70.72
2025-04-22 20:05:22,181 [der.py] => SNet: Task 3, Epoch 11/130 => Loss 1.397,  Train_accy 71.52, Test_accy 58.12
2025-04-22 20:05:34,222 [der.py] => SNet: Task 3, Epoch 12/130 => Loss 1.398,  Train_accy 72.86
2025-04-22 20:05:46,072 [der.py] => SNet: Task 3, Epoch 13/130 => Loss 1.424,  Train_accy 71.12
2025-04-22 20:05:57,917 [der.py] => SNet: Task 3, Epoch 14/130 => Loss 1.397,  Train_accy 72.04
2025-04-22 20:06:09,789 [der.py] => SNet: Task 3, Epoch 15/130 => Loss 1.365,  Train_accy 72.34
2025-04-22 20:06:30,928 [der.py] => SNet: Task 3, Epoch 16/130 => Loss 1.346,  Train_accy 72.53, Test_accy 61.33
2025-04-22 20:06:42,640 [der.py] => SNet: Task 3, Epoch 17/130 => Loss 1.394,  Train_accy 72.10
2025-04-22 20:06:54,654 [der.py] => SNet: Task 3, Epoch 18/130 => Loss 1.375,  Train_accy 73.09
2025-04-22 20:07:06,624 [der.py] => SNet: Task 3, Epoch 19/130 => Loss 1.346,  Train_accy 73.64
2025-04-22 20:07:18,558 [der.py] => SNet: Task 3, Epoch 20/130 => Loss 1.365,  Train_accy 73.07
2025-04-22 20:07:39,464 [der.py] => SNet: Task 3, Epoch 21/130 => Loss 1.365,  Train_accy 74.04, Test_accy 62.40
2025-04-22 20:07:51,533 [der.py] => SNet: Task 3, Epoch 22/130 => Loss 1.415,  Train_accy 71.71
2025-04-22 20:08:03,486 [der.py] => SNet: Task 3, Epoch 23/130 => Loss 1.358,  Train_accy 73.81
2025-04-22 20:08:15,620 [der.py] => SNet: Task 3, Epoch 24/130 => Loss 1.351,  Train_accy 74.10
2025-04-22 20:08:27,819 [der.py] => SNet: Task 3, Epoch 25/130 => Loss 1.345,  Train_accy 73.26
2025-04-22 20:08:48,942 [der.py] => SNet: Task 3, Epoch 26/130 => Loss 1.353,  Train_accy 74.36, Test_accy 64.10
2025-04-22 20:09:00,772 [der.py] => SNet: Task 3, Epoch 27/130 => Loss 1.307,  Train_accy 74.67
2025-04-22 20:09:12,708 [der.py] => SNet: Task 3, Epoch 28/130 => Loss 1.342,  Train_accy 74.06
2025-04-22 20:09:24,614 [der.py] => SNet: Task 3, Epoch 29/130 => Loss 1.344,  Train_accy 74.44
2025-04-22 20:09:36,384 [der.py] => SNet: Task 3, Epoch 30/130 => Loss 1.330,  Train_accy 74.84
2025-04-22 20:09:56,891 [der.py] => SNet: Task 3, Epoch 31/130 => Loss 1.316,  Train_accy 74.76, Test_accy 60.16
2025-04-22 20:10:08,596 [der.py] => SNet: Task 3, Epoch 32/130 => Loss 1.327,  Train_accy 74.78
2025-04-22 20:10:20,548 [der.py] => SNet: Task 3, Epoch 33/130 => Loss 1.301,  Train_accy 74.78
2025-04-22 20:10:32,420 [der.py] => SNet: Task 3, Epoch 34/130 => Loss 1.300,  Train_accy 74.61
2025-04-22 20:10:44,254 [der.py] => SNet: Task 3, Epoch 35/130 => Loss 1.332,  Train_accy 73.54
2025-04-22 20:11:05,008 [der.py] => SNet: Task 3, Epoch 36/130 => Loss 1.312,  Train_accy 75.01, Test_accy 63.62
2025-04-22 20:11:16,789 [der.py] => SNet: Task 3, Epoch 37/130 => Loss 1.332,  Train_accy 74.59
2025-04-22 20:11:28,773 [der.py] => SNet: Task 3, Epoch 38/130 => Loss 1.315,  Train_accy 74.86
2025-04-22 20:11:40,598 [der.py] => SNet: Task 3, Epoch 39/130 => Loss 1.314,  Train_accy 75.37
2025-04-22 20:11:52,449 [der.py] => SNet: Task 3, Epoch 40/130 => Loss 1.299,  Train_accy 74.74
2025-04-22 20:12:13,064 [der.py] => SNet: Task 3, Epoch 41/130 => Loss 1.303,  Train_accy 75.24, Test_accy 63.79
2025-04-22 20:12:24,935 [der.py] => SNet: Task 3, Epoch 42/130 => Loss 1.302,  Train_accy 75.12
2025-04-22 20:12:36,806 [der.py] => SNet: Task 3, Epoch 43/130 => Loss 1.315,  Train_accy 75.31
2025-04-22 20:12:48,612 [der.py] => SNet: Task 3, Epoch 44/130 => Loss 1.298,  Train_accy 75.47
2025-04-22 20:13:00,386 [der.py] => SNet: Task 3, Epoch 45/130 => Loss 1.303,  Train_accy 74.82
2025-04-22 20:13:20,955 [der.py] => SNet: Task 3, Epoch 46/130 => Loss 1.307,  Train_accy 75.01, Test_accy 61.48
2025-04-22 20:13:32,919 [der.py] => SNet: Task 3, Epoch 47/130 => Loss 1.296,  Train_accy 75.28
2025-04-22 20:13:44,527 [der.py] => SNet: Task 3, Epoch 48/130 => Loss 1.289,  Train_accy 75.45
2025-04-22 20:13:56,706 [der.py] => SNet: Task 3, Epoch 49/130 => Loss 1.312,  Train_accy 75.30
2025-04-22 20:14:08,409 [der.py] => SNet: Task 3, Epoch 50/130 => Loss 1.294,  Train_accy 75.01
2025-04-22 20:14:28,737 [der.py] => SNet: Task 3, Epoch 51/130 => Loss 1.295,  Train_accy 75.49, Test_accy 55.17
2025-04-22 20:14:40,779 [der.py] => SNet: Task 3, Epoch 52/130 => Loss 1.282,  Train_accy 75.68
2025-04-22 20:14:52,764 [der.py] => SNet: Task 3, Epoch 53/130 => Loss 1.291,  Train_accy 75.70
2025-04-22 20:15:04,561 [der.py] => SNet: Task 3, Epoch 54/130 => Loss 1.302,  Train_accy 75.41
2025-04-22 20:15:16,683 [der.py] => SNet: Task 3, Epoch 55/130 => Loss 1.274,  Train_accy 75.77
2025-04-22 20:15:37,390 [der.py] => SNet: Task 3, Epoch 56/130 => Loss 1.268,  Train_accy 75.79, Test_accy 60.73
2025-04-22 20:15:49,394 [der.py] => SNet: Task 3, Epoch 57/130 => Loss 1.292,  Train_accy 75.68
2025-04-22 20:16:01,106 [der.py] => SNet: Task 3, Epoch 58/130 => Loss 1.284,  Train_accy 75.73
2025-04-22 20:16:13,125 [der.py] => SNet: Task 3, Epoch 59/130 => Loss 1.273,  Train_accy 75.94
2025-04-22 20:16:25,104 [der.py] => SNet: Task 3, Epoch 60/130 => Loss 1.296,  Train_accy 75.85
2025-04-22 20:17:04,529 [der.py] => SNet: Task 3, Epoch 61/130 => Loss 1.288,  Train_accy 75.35, Test_accy 63.93
2025-04-22 20:17:16,701 [der.py] => SNet: Task 3, Epoch 62/130 => Loss 1.280,  Train_accy 75.73
2025-04-22 20:17:28,923 [der.py] => SNet: Task 3, Epoch 63/130 => Loss 1.273,  Train_accy 75.85
2025-04-22 20:17:41,103 [der.py] => SNet: Task 3, Epoch 64/130 => Loss 1.288,  Train_accy 75.45
2025-04-22 20:17:53,169 [der.py] => SNet: Task 3, Epoch 65/130 => Loss 1.267,  Train_accy 75.70
2025-04-22 20:18:14,669 [der.py] => SNet: Task 3, Epoch 66/130 => Loss 1.276,  Train_accy 76.00, Test_accy 61.31
2025-04-22 20:18:26,896 [der.py] => SNet: Task 3, Epoch 67/130 => Loss 1.292,  Train_accy 75.66
2025-04-22 20:18:39,120 [der.py] => SNet: Task 3, Epoch 68/130 => Loss 1.273,  Train_accy 75.35
2025-04-22 20:18:51,109 [der.py] => SNet: Task 3, Epoch 69/130 => Loss 1.258,  Train_accy 76.13
2025-04-22 20:19:03,114 [der.py] => SNet: Task 3, Epoch 70/130 => Loss 1.278,  Train_accy 75.39
2025-04-22 20:19:23,890 [der.py] => SNet: Task 3, Epoch 71/130 => Loss 1.257,  Train_accy 75.85, Test_accy 63.72
2025-04-22 20:19:35,796 [der.py] => SNet: Task 3, Epoch 72/130 => Loss 1.273,  Train_accy 75.35
2025-04-22 20:19:47,751 [der.py] => SNet: Task 3, Epoch 73/130 => Loss 1.263,  Train_accy 76.02
2025-04-22 20:19:59,876 [der.py] => SNet: Task 3, Epoch 74/130 => Loss 1.250,  Train_accy 76.04
2025-04-22 20:20:11,836 [der.py] => SNet: Task 3, Epoch 75/130 => Loss 1.284,  Train_accy 76.23
2025-04-22 20:20:32,313 [der.py] => SNet: Task 3, Epoch 76/130 => Loss 1.267,  Train_accy 75.54, Test_accy 59.28
2025-04-22 20:20:44,504 [der.py] => SNet: Task 3, Epoch 77/130 => Loss 1.266,  Train_accy 76.80
2025-04-22 20:20:56,414 [der.py] => SNet: Task 3, Epoch 78/130 => Loss 1.257,  Train_accy 76.55
2025-04-22 20:21:08,408 [der.py] => SNet: Task 3, Epoch 79/130 => Loss 1.273,  Train_accy 75.54
2025-04-22 20:21:20,203 [der.py] => SNet: Task 3, Epoch 80/130 => Loss 1.289,  Train_accy 75.70
2025-04-22 20:21:41,162 [der.py] => SNet: Task 3, Epoch 81/130 => Loss 1.274,  Train_accy 75.58, Test_accy 64.27
2025-04-22 20:21:53,062 [der.py] => SNet: Task 3, Epoch 82/130 => Loss 1.248,  Train_accy 75.37
2025-04-22 20:22:04,999 [der.py] => SNet: Task 3, Epoch 83/130 => Loss 1.260,  Train_accy 76.44
2025-04-22 20:22:17,072 [der.py] => SNet: Task 3, Epoch 84/130 => Loss 1.257,  Train_accy 76.13
2025-04-22 20:22:28,895 [der.py] => SNet: Task 3, Epoch 85/130 => Loss 1.255,  Train_accy 75.87
2025-04-22 20:22:49,892 [der.py] => SNet: Task 3, Epoch 86/130 => Loss 1.273,  Train_accy 76.50, Test_accy 65.38
2025-04-22 20:23:01,790 [der.py] => SNet: Task 3, Epoch 87/130 => Loss 1.263,  Train_accy 75.62
2025-04-22 20:23:13,756 [der.py] => SNet: Task 3, Epoch 88/130 => Loss 1.251,  Train_accy 76.51
2025-04-22 20:23:25,723 [der.py] => SNet: Task 3, Epoch 89/130 => Loss 1.244,  Train_accy 76.29
2025-04-22 20:23:37,840 [der.py] => SNet: Task 3, Epoch 90/130 => Loss 1.251,  Train_accy 75.98
2025-04-22 20:23:58,623 [der.py] => SNet: Task 3, Epoch 91/130 => Loss 1.264,  Train_accy 75.75, Test_accy 65.42
2025-04-22 20:24:10,489 [der.py] => SNet: Task 3, Epoch 92/130 => Loss 1.236,  Train_accy 76.17
2025-04-22 20:24:22,387 [der.py] => SNet: Task 3, Epoch 93/130 => Loss 1.253,  Train_accy 76.25
2025-04-22 20:24:34,383 [der.py] => SNet: Task 3, Epoch 94/130 => Loss 1.259,  Train_accy 75.68
2025-04-22 20:24:46,195 [der.py] => SNet: Task 3, Epoch 95/130 => Loss 1.261,  Train_accy 76.11
2025-04-22 20:25:06,914 [der.py] => SNet: Task 3, Epoch 96/130 => Loss 1.256,  Train_accy 76.02, Test_accy 65.28
2025-04-22 20:25:19,186 [der.py] => SNet: Task 3, Epoch 97/130 => Loss 1.256,  Train_accy 76.44
2025-04-22 20:25:30,952 [der.py] => SNet: Task 3, Epoch 98/130 => Loss 1.246,  Train_accy 77.03
2025-04-22 20:25:43,065 [der.py] => SNet: Task 3, Epoch 99/130 => Loss 1.256,  Train_accy 75.94
2025-04-22 20:25:54,965 [der.py] => SNet: Task 3, Epoch 100/130 => Loss 1.252,  Train_accy 76.04
2025-04-22 20:26:45,992 [der.py] => SNet: Task 3, Epoch 101/130 => Loss 1.256,  Train_accy 76.46, Test_accy 63.25
2025-04-22 20:26:58,015 [der.py] => SNet: Task 3, Epoch 102/130 => Loss 1.258,  Train_accy 75.64
2025-04-22 20:27:10,200 [der.py] => SNet: Task 3, Epoch 103/130 => Loss 1.257,  Train_accy 76.67
2025-04-22 20:27:22,057 [der.py] => SNet: Task 3, Epoch 104/130 => Loss 1.263,  Train_accy 76.15
2025-04-22 20:27:34,102 [der.py] => SNet: Task 3, Epoch 105/130 => Loss 1.257,  Train_accy 76.11
2025-04-22 20:27:57,816 [der.py] => SNet: Task 3, Epoch 106/130 => Loss 1.253,  Train_accy 76.02, Test_accy 65.69
2025-04-22 20:28:09,835 [der.py] => SNet: Task 3, Epoch 107/130 => Loss 1.258,  Train_accy 76.72
2025-04-22 20:28:21,875 [der.py] => SNet: Task 3, Epoch 108/130 => Loss 1.246,  Train_accy 76.25
2025-04-22 20:28:33,729 [der.py] => SNet: Task 3, Epoch 109/130 => Loss 1.251,  Train_accy 75.81
2025-04-22 20:28:45,660 [der.py] => SNet: Task 3, Epoch 110/130 => Loss 1.247,  Train_accy 75.92
2025-04-22 20:29:11,821 [der.py] => SNet: Task 3, Epoch 111/130 => Loss 1.242,  Train_accy 76.42, Test_accy 60.74
2025-04-22 20:29:23,827 [der.py] => SNet: Task 3, Epoch 112/130 => Loss 1.245,  Train_accy 76.44
2025-04-22 20:29:35,946 [der.py] => SNet: Task 3, Epoch 113/130 => Loss 1.249,  Train_accy 75.89
2025-04-22 20:29:47,868 [der.py] => SNet: Task 3, Epoch 114/130 => Loss 1.235,  Train_accy 75.77
2025-04-22 20:29:59,655 [der.py] => SNet: Task 3, Epoch 115/130 => Loss 1.240,  Train_accy 75.96
2025-04-22 20:30:57,270 [der.py] => SNet: Task 3, Epoch 116/130 => Loss 1.236,  Train_accy 76.95, Test_accy 64.57
2025-04-22 20:31:09,344 [der.py] => SNet: Task 3, Epoch 117/130 => Loss 1.246,  Train_accy 76.04
2025-04-22 20:31:21,421 [der.py] => SNet: Task 3, Epoch 118/130 => Loss 1.260,  Train_accy 76.36
2025-04-22 20:31:33,444 [der.py] => SNet: Task 3, Epoch 119/130 => Loss 1.259,  Train_accy 76.69
2025-04-22 20:31:45,639 [der.py] => SNet: Task 3, Epoch 120/130 => Loss 1.236,  Train_accy 75.92
2025-04-22 20:32:12,895 [der.py] => SNet: Task 3, Epoch 121/130 => Loss 1.253,  Train_accy 76.40, Test_accy 65.62
2025-04-22 20:32:24,888 [der.py] => SNet: Task 3, Epoch 122/130 => Loss 1.250,  Train_accy 76.36
2025-04-22 20:32:36,705 [der.py] => SNet: Task 3, Epoch 123/130 => Loss 1.232,  Train_accy 76.40
2025-04-22 20:32:48,832 [der.py] => SNet: Task 3, Epoch 124/130 => Loss 1.235,  Train_accy 76.55
2025-04-22 20:33:00,542 [der.py] => SNet: Task 3, Epoch 125/130 => Loss 1.255,  Train_accy 76.10
2025-04-22 20:33:22,205 [der.py] => SNet: Task 3, Epoch 126/130 => Loss 1.247,  Train_accy 76.67, Test_accy 65.15
2025-04-22 20:33:34,165 [der.py] => SNet: Task 3, Epoch 127/130 => Loss 1.249,  Train_accy 76.46
2025-04-22 20:33:46,088 [der.py] => SNet: Task 3, Epoch 128/130 => Loss 1.235,  Train_accy 75.96
2025-04-22 20:33:58,053 [der.py] => SNet: Task 3, Epoch 129/130 => Loss 1.246,  Train_accy 76.74
2025-04-22 20:34:09,780 [der.py] => SNet: Task 3, Epoch 130/130 => Loss 1.253,  Train_accy 76.17
2025-04-22 20:34:09,781 [der.py] => do not weight align student!
2025-04-22 20:34:19,526 [der.py] => darknet eval: 
2025-04-22 20:34:19,527 [der.py] => CNN top1 curve: 61.63
2025-04-22 20:34:19,527 [der.py] => CNN top5 curve: 91.15
2025-04-22 20:34:19,528 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 20:35:27,392 [der.py] => Exemplar size: 1350
2025-04-22 20:35:27,394 [trainer.py] => CNN: {'total': 71.11, '0': 84.44, '1': 46.67, '2': 64.44, '3': 57.22, '4': 70.56, '5': 25.0, '6': 53.33, '7': 46.11, '8': 27.78, '9': 48.89, '10': 84.44, '11': 88.89, '12': 61.11, '13': 60.56, '14': 48.89, '15': 96.11, '16': 87.22, '17': 86.67, '18': 75.56, '19': 82.78, '20': 85.56, '21': 85.0, '22': 81.67, '23': 61.11, '24': 54.44, '25': 83.89, '26': 89.44, '27': 88.33, '28': 70.56, '29': 82.78, '30': 86.67, '31': 81.67, '32': 97.22, '33': 82.78, '34': 83.89, '35': 79.44, '36': 91.67, '37': 32.78, '38': 14.44, '39': 77.22, '40': 58.89, '41': 92.78, '42': 98.89, '43': 96.11, 'old': 71.76, 'new': 68.83}
2025-04-22 20:35:27,394 [trainer.py] => NME: {'total': 71.67, '0': 76.67, '1': 50.56, '2': 57.78, '3': 43.33, '4': 66.11, '5': 29.44, '6': 52.22, '7': 51.67, '8': 31.67, '9': 57.22, '10': 88.33, '11': 81.11, '12': 63.33, '13': 55.56, '14': 57.78, '15': 91.11, '16': 83.33, '17': 79.44, '18': 76.11, '19': 83.33, '20': 84.44, '21': 75.56, '22': 72.78, '23': 58.89, '24': 49.44, '25': 68.33, '26': 83.33, '27': 73.89, '28': 58.33, '29': 69.44, '30': 73.89, '31': 73.33, '32': 84.44, '33': 57.78, '34': 73.33, '35': 96.11, '36': 93.89, '37': 69.44, '38': 95.0, '39': 92.78, '40': 77.22, '41': 96.11, '42': 99.44, '43': 95.0, 'old': 66.67, 'new': 89.17}
2025-04-22 20:35:27,394 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.33, 71.11]
2025-04-22 20:35:27,394 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.83, 94.52]
2025-04-22 20:35:27,399 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.76, 71.67]
2025-04-22 20:35:27,399 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.05, 95.17]

2025-04-22 20:35:27,400 [trainer.py] => All params: 42096208
2025-04-22 20:35:27,401 [trainer.py] => Trainable params: 21054596
2025-04-22 20:35:27,702 [der.py] => Learning on 45-55
2025-04-22 20:35:27,703 [der.py] => All params: 42098778
2025-04-22 20:35:27,704 [der.py] => Trainable params: 21057166
2025-04-22 20:35:27,898 [der.py] => cls_num_list: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420]
2025-04-22 20:35:27,929 [der.py] => per cls weights : [1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927 1.09435927
 1.09435927 1.09435927 1.09435927 0.57538327 0.57538327 0.57538327
 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327 0.57538327
 0.57538327]
2025-04-22 21:16:02,694 [der.py] => Task 4, Epoch 150/150 => Loss 0.022, Loss_clf 0.014, Loss_aux 0.008, Train_accy 100.00
2025-04-22 21:16:26,060 [der.py] => SNet: Task 4, Epoch 1/130 => Loss 2.866,  Train_accy 34.16, Test_accy 58.70
2025-04-22 21:16:38,546 [der.py] => SNet: Task 4, Epoch 2/130 => Loss 2.623,  Train_accy 52.56
2025-04-22 21:16:51,012 [der.py] => SNet: Task 4, Epoch 3/130 => Loss 2.510,  Train_accy 61.15
2025-04-22 21:17:03,523 [der.py] => SNet: Task 4, Epoch 4/130 => Loss 2.442,  Train_accy 68.31
2025-04-22 21:17:15,865 [der.py] => SNet: Task 4, Epoch 5/130 => Loss 2.400,  Train_accy 72.47
2025-04-22 21:17:38,750 [der.py] => SNet: Task 4, Epoch 6/130 => Loss 2.366,  Train_accy 75.50, Test_accy 60.38
2025-04-22 21:17:51,059 [der.py] => SNet: Task 4, Epoch 7/130 => Loss 2.346,  Train_accy 76.97
2025-04-22 21:18:03,680 [der.py] => SNet: Task 4, Epoch 8/130 => Loss 2.323,  Train_accy 79.51
2025-04-22 21:18:16,172 [der.py] => SNet: Task 4, Epoch 9/130 => Loss 2.308,  Train_accy 80.92
2025-04-22 21:18:28,606 [der.py] => SNet: Task 4, Epoch 10/130 => Loss 2.299,  Train_accy 82.04
2025-04-22 21:18:51,628 [der.py] => SNet: Task 4, Epoch 11/130 => Loss 2.288,  Train_accy 82.56, Test_accy 64.02
2025-04-22 21:19:04,368 [der.py] => SNet: Task 4, Epoch 12/130 => Loss 2.285,  Train_accy 84.23
2025-04-22 21:19:16,745 [der.py] => SNet: Task 4, Epoch 13/130 => Loss 2.270,  Train_accy 84.36
2025-04-22 21:19:29,264 [der.py] => SNet: Task 4, Epoch 14/130 => Loss 2.265,  Train_accy 85.03
2025-04-22 21:19:41,754 [der.py] => SNet: Task 4, Epoch 15/130 => Loss 2.260,  Train_accy 84.97
2025-04-22 21:20:04,643 [der.py] => SNet: Task 4, Epoch 16/130 => Loss 2.258,  Train_accy 86.38, Test_accy 65.27
2025-04-22 21:20:16,990 [der.py] => SNet: Task 4, Epoch 17/130 => Loss 2.254,  Train_accy 85.98
2025-04-22 21:20:29,610 [der.py] => SNet: Task 4, Epoch 18/130 => Loss 2.246,  Train_accy 86.76
2025-04-22 21:20:42,012 [der.py] => SNet: Task 4, Epoch 19/130 => Loss 2.247,  Train_accy 86.79
2025-04-22 21:20:54,444 [der.py] => SNet: Task 4, Epoch 20/130 => Loss 2.244,  Train_accy 86.88
2025-04-22 21:21:17,437 [der.py] => SNet: Task 4, Epoch 21/130 => Loss 2.239,  Train_accy 87.69, Test_accy 64.48
2025-04-22 21:21:29,834 [der.py] => SNet: Task 4, Epoch 22/130 => Loss 2.234,  Train_accy 87.84
2025-04-22 21:21:42,282 [der.py] => SNet: Task 4, Epoch 23/130 => Loss 2.230,  Train_accy 88.05
2025-04-22 21:21:54,656 [der.py] => SNet: Task 4, Epoch 24/130 => Loss 2.229,  Train_accy 88.47
2025-04-22 21:22:06,990 [der.py] => SNet: Task 4, Epoch 25/130 => Loss 2.228,  Train_accy 88.04
2025-04-22 21:22:29,945 [der.py] => SNet: Task 4, Epoch 26/130 => Loss 2.227,  Train_accy 88.88, Test_accy 64.86
2025-04-22 21:22:42,419 [der.py] => SNet: Task 4, Epoch 27/130 => Loss 2.225,  Train_accy 88.77
2025-04-22 21:22:54,898 [der.py] => SNet: Task 4, Epoch 28/130 => Loss 2.219,  Train_accy 88.38
2025-04-22 21:23:07,744 [der.py] => SNet: Task 4, Epoch 29/130 => Loss 2.215,  Train_accy 88.95
2025-04-22 21:23:20,394 [der.py] => SNet: Task 4, Epoch 30/130 => Loss 2.213,  Train_accy 89.50
2025-04-22 21:23:43,418 [der.py] => SNet: Task 4, Epoch 31/130 => Loss 2.219,  Train_accy 88.90, Test_accy 65.32
2025-04-22 21:23:56,183 [der.py] => SNet: Task 4, Epoch 32/130 => Loss 2.215,  Train_accy 89.46
2025-04-22 21:24:08,637 [der.py] => SNet: Task 4, Epoch 33/130 => Loss 2.210,  Train_accy 90.09
2025-04-22 21:24:20,987 [der.py] => SNet: Task 4, Epoch 34/130 => Loss 2.212,  Train_accy 90.07
2025-04-22 21:24:33,523 [der.py] => SNet: Task 4, Epoch 35/130 => Loss 2.203,  Train_accy 90.34
2025-04-22 21:24:56,552 [der.py] => SNet: Task 4, Epoch 36/130 => Loss 2.206,  Train_accy 89.60, Test_accy 66.11
2025-04-22 21:25:09,229 [der.py] => SNet: Task 4, Epoch 37/130 => Loss 2.206,  Train_accy 90.18
2025-04-22 21:25:21,639 [der.py] => SNet: Task 4, Epoch 38/130 => Loss 2.200,  Train_accy 90.40
2025-04-22 21:25:34,014 [der.py] => SNet: Task 4, Epoch 39/130 => Loss 2.199,  Train_accy 90.07
2025-04-22 21:25:46,376 [der.py] => SNet: Task 4, Epoch 40/130 => Loss 2.200,  Train_accy 90.25
2025-04-22 21:26:09,511 [der.py] => SNet: Task 4, Epoch 41/130 => Loss 2.198,  Train_accy 90.67, Test_accy 66.47
2025-04-22 21:26:21,895 [der.py] => SNet: Task 4, Epoch 42/130 => Loss 2.195,  Train_accy 90.43
2025-04-22 21:26:34,408 [der.py] => SNet: Task 4, Epoch 43/130 => Loss 2.202,  Train_accy 91.14
2025-04-22 21:26:46,769 [der.py] => SNet: Task 4, Epoch 44/130 => Loss 2.197,  Train_accy 90.83
2025-04-22 21:26:59,291 [der.py] => SNet: Task 4, Epoch 45/130 => Loss 2.196,  Train_accy 90.59
2025-04-22 21:27:22,088 [der.py] => SNet: Task 4, Epoch 46/130 => Loss 2.195,  Train_accy 91.19, Test_accy 66.55
2025-04-22 21:27:34,648 [der.py] => SNet: Task 4, Epoch 47/130 => Loss 2.193,  Train_accy 91.50
2025-04-22 21:27:47,236 [der.py] => SNet: Task 4, Epoch 48/130 => Loss 2.195,  Train_accy 90.83
2025-04-22 21:27:59,790 [der.py] => SNet: Task 4, Epoch 49/130 => Loss 2.194,  Train_accy 91.33
2025-04-22 21:28:12,216 [der.py] => SNet: Task 4, Epoch 50/130 => Loss 2.189,  Train_accy 91.71
2025-04-22 21:28:35,294 [der.py] => SNet: Task 4, Epoch 51/130 => Loss 2.189,  Train_accy 91.48, Test_accy 66.48
2025-04-22 21:28:47,777 [der.py] => SNet: Task 4, Epoch 52/130 => Loss 2.190,  Train_accy 91.44
2025-04-22 21:29:00,441 [der.py] => SNet: Task 4, Epoch 53/130 => Loss 2.189,  Train_accy 91.05
2025-04-22 21:29:12,814 [der.py] => SNet: Task 4, Epoch 54/130 => Loss 2.181,  Train_accy 91.59
2025-04-22 21:29:25,419 [der.py] => SNet: Task 4, Epoch 55/130 => Loss 2.185,  Train_accy 91.48
2025-04-22 21:29:48,598 [der.py] => SNet: Task 4, Epoch 56/130 => Loss 2.186,  Train_accy 92.00, Test_accy 66.64
2025-04-22 21:30:01,315 [der.py] => SNet: Task 4, Epoch 57/130 => Loss 2.185,  Train_accy 91.68
2025-04-22 21:30:13,868 [der.py] => SNet: Task 4, Epoch 58/130 => Loss 2.182,  Train_accy 91.71
2025-04-22 21:30:26,454 [der.py] => SNet: Task 4, Epoch 59/130 => Loss 2.181,  Train_accy 91.14
2025-04-22 21:30:39,079 [der.py] => SNet: Task 4, Epoch 60/130 => Loss 2.186,  Train_accy 91.21
2025-04-22 21:31:02,037 [der.py] => SNet: Task 4, Epoch 61/130 => Loss 2.184,  Train_accy 92.11, Test_accy 66.78
2025-04-22 21:31:14,844 [der.py] => SNet: Task 4, Epoch 62/130 => Loss 2.179,  Train_accy 91.82
2025-04-22 21:31:27,151 [der.py] => SNet: Task 4, Epoch 63/130 => Loss 2.179,  Train_accy 91.93
2025-04-22 21:31:39,520 [der.py] => SNet: Task 4, Epoch 64/130 => Loss 2.182,  Train_accy 91.78
2025-04-22 21:31:51,754 [der.py] => SNet: Task 4, Epoch 65/130 => Loss 2.177,  Train_accy 92.04
2025-04-22 21:32:14,497 [der.py] => SNet: Task 4, Epoch 66/130 => Loss 2.178,  Train_accy 92.00, Test_accy 67.33
2025-04-22 21:32:26,837 [der.py] => SNet: Task 4, Epoch 67/130 => Loss 2.179,  Train_accy 91.95
2025-04-22 21:32:39,418 [der.py] => SNet: Task 4, Epoch 68/130 => Loss 2.175,  Train_accy 92.09
2025-04-22 21:32:51,925 [der.py] => SNet: Task 4, Epoch 69/130 => Loss 2.173,  Train_accy 92.05
2025-04-22 21:33:04,526 [der.py] => SNet: Task 4, Epoch 70/130 => Loss 2.175,  Train_accy 92.14
2025-04-22 21:33:27,534 [der.py] => SNet: Task 4, Epoch 71/130 => Loss 2.173,  Train_accy 91.91, Test_accy 67.17
2025-04-22 21:33:40,022 [der.py] => SNet: Task 4, Epoch 72/130 => Loss 2.175,  Train_accy 92.54
2025-04-22 21:33:52,636 [der.py] => SNet: Task 4, Epoch 73/130 => Loss 2.175,  Train_accy 92.00
2025-04-22 21:34:05,408 [der.py] => SNet: Task 4, Epoch 74/130 => Loss 2.175,  Train_accy 92.27
2025-04-22 21:34:17,978 [der.py] => SNet: Task 4, Epoch 75/130 => Loss 2.173,  Train_accy 92.25
2025-04-22 21:34:41,089 [der.py] => SNet: Task 4, Epoch 76/130 => Loss 2.170,  Train_accy 92.31, Test_accy 67.49
2025-04-22 21:34:53,521 [der.py] => SNet: Task 4, Epoch 77/130 => Loss 2.172,  Train_accy 92.09
2025-04-22 21:35:06,142 [der.py] => SNet: Task 4, Epoch 78/130 => Loss 2.169,  Train_accy 92.52
2025-04-22 21:35:18,657 [der.py] => SNet: Task 4, Epoch 79/130 => Loss 2.172,  Train_accy 92.59
2025-04-22 21:35:31,141 [der.py] => SNet: Task 4, Epoch 80/130 => Loss 2.172,  Train_accy 92.65
2025-04-22 21:35:54,046 [der.py] => SNet: Task 4, Epoch 81/130 => Loss 2.171,  Train_accy 92.45, Test_accy 66.94
2025-04-22 21:36:06,620 [der.py] => SNet: Task 4, Epoch 82/130 => Loss 2.173,  Train_accy 92.34
2025-04-22 21:36:19,041 [der.py] => SNet: Task 4, Epoch 83/130 => Loss 2.165,  Train_accy 92.50
2025-04-22 21:36:31,380 [der.py] => SNet: Task 4, Epoch 84/130 => Loss 2.169,  Train_accy 92.32
2025-04-22 21:36:43,939 [der.py] => SNet: Task 4, Epoch 85/130 => Loss 2.172,  Train_accy 92.77
2025-04-22 21:37:06,592 [der.py] => SNet: Task 4, Epoch 86/130 => Loss 2.169,  Train_accy 92.77, Test_accy 66.99
2025-04-22 21:37:18,875 [der.py] => SNet: Task 4, Epoch 87/130 => Loss 2.172,  Train_accy 92.56
2025-04-22 21:37:31,528 [der.py] => SNet: Task 4, Epoch 88/130 => Loss 2.170,  Train_accy 92.54
2025-04-22 21:37:43,970 [der.py] => SNet: Task 4, Epoch 89/130 => Loss 2.170,  Train_accy 92.65
2025-04-22 21:37:56,381 [der.py] => SNet: Task 4, Epoch 90/130 => Loss 2.165,  Train_accy 92.97
2025-04-22 21:38:19,130 [der.py] => SNet: Task 4, Epoch 91/130 => Loss 2.169,  Train_accy 92.95, Test_accy 66.80
2025-04-22 21:38:31,579 [der.py] => SNet: Task 4, Epoch 92/130 => Loss 2.165,  Train_accy 92.76
2025-04-22 21:38:43,987 [der.py] => SNet: Task 4, Epoch 93/130 => Loss 2.165,  Train_accy 92.95
2025-04-22 21:38:56,318 [der.py] => SNet: Task 4, Epoch 94/130 => Loss 2.165,  Train_accy 92.65
2025-04-22 21:39:08,770 [der.py] => SNet: Task 4, Epoch 95/130 => Loss 2.166,  Train_accy 92.92
2025-04-22 21:39:31,478 [der.py] => SNet: Task 4, Epoch 96/130 => Loss 2.165,  Train_accy 93.01, Test_accy 67.14
2025-04-22 21:39:43,853 [der.py] => SNet: Task 4, Epoch 97/130 => Loss 2.166,  Train_accy 92.36
2025-04-22 21:39:56,422 [der.py] => SNet: Task 4, Epoch 98/130 => Loss 2.167,  Train_accy 92.65
2025-04-22 21:40:08,967 [der.py] => SNet: Task 4, Epoch 99/130 => Loss 2.165,  Train_accy 92.45
2025-04-22 21:40:21,458 [der.py] => SNet: Task 4, Epoch 100/130 => Loss 2.165,  Train_accy 92.77
2025-04-22 21:40:44,275 [der.py] => SNet: Task 4, Epoch 101/130 => Loss 2.165,  Train_accy 93.06, Test_accy 67.28
2025-04-22 21:40:56,675 [der.py] => SNet: Task 4, Epoch 102/130 => Loss 2.165,  Train_accy 92.97
2025-04-22 21:41:09,322 [der.py] => SNet: Task 4, Epoch 103/130 => Loss 2.163,  Train_accy 92.70
2025-04-22 21:41:21,909 [der.py] => SNet: Task 4, Epoch 104/130 => Loss 2.160,  Train_accy 93.01
2025-04-22 21:41:34,356 [der.py] => SNet: Task 4, Epoch 105/130 => Loss 2.164,  Train_accy 92.72
2025-04-22 21:41:57,144 [der.py] => SNet: Task 4, Epoch 106/130 => Loss 2.162,  Train_accy 92.52, Test_accy 67.21
2025-04-22 21:42:09,520 [der.py] => SNet: Task 4, Epoch 107/130 => Loss 2.163,  Train_accy 92.94
2025-04-22 21:42:21,965 [der.py] => SNet: Task 4, Epoch 108/130 => Loss 2.165,  Train_accy 92.61
2025-04-22 21:42:34,574 [der.py] => SNet: Task 4, Epoch 109/130 => Loss 2.163,  Train_accy 92.95
2025-04-22 21:42:47,175 [der.py] => SNet: Task 4, Epoch 110/130 => Loss 2.165,  Train_accy 93.12
2025-04-22 21:43:10,526 [der.py] => SNet: Task 4, Epoch 111/130 => Loss 2.164,  Train_accy 92.76, Test_accy 67.56
2025-04-22 21:43:22,849 [der.py] => SNet: Task 4, Epoch 112/130 => Loss 2.162,  Train_accy 93.01
2025-04-22 21:43:35,267 [der.py] => SNet: Task 4, Epoch 113/130 => Loss 2.160,  Train_accy 93.12
2025-04-22 21:43:47,587 [der.py] => SNet: Task 4, Epoch 114/130 => Loss 2.162,  Train_accy 92.81
2025-04-22 21:44:00,108 [der.py] => SNet: Task 4, Epoch 115/130 => Loss 2.164,  Train_accy 93.06
2025-04-22 21:44:23,319 [der.py] => SNet: Task 4, Epoch 116/130 => Loss 2.159,  Train_accy 92.72, Test_accy 67.44
2025-04-22 21:44:35,862 [der.py] => SNet: Task 4, Epoch 117/130 => Loss 2.158,  Train_accy 93.15
2025-04-22 21:44:48,353 [der.py] => SNet: Task 4, Epoch 118/130 => Loss 2.159,  Train_accy 93.28
2025-04-22 21:45:01,086 [der.py] => SNet: Task 4, Epoch 119/130 => Loss 2.160,  Train_accy 93.12
2025-04-22 21:45:13,410 [der.py] => SNet: Task 4, Epoch 120/130 => Loss 2.164,  Train_accy 92.95
2025-04-22 21:45:36,578 [der.py] => SNet: Task 4, Epoch 121/130 => Loss 2.161,  Train_accy 92.85, Test_accy 67.47
2025-04-22 21:45:49,039 [der.py] => SNet: Task 4, Epoch 122/130 => Loss 2.162,  Train_accy 93.28
2025-04-22 21:46:01,495 [der.py] => SNet: Task 4, Epoch 123/130 => Loss 2.160,  Train_accy 92.97
2025-04-22 21:46:13,777 [der.py] => SNet: Task 4, Epoch 124/130 => Loss 2.163,  Train_accy 93.08
2025-04-22 21:46:26,187 [der.py] => SNet: Task 4, Epoch 125/130 => Loss 2.163,  Train_accy 93.15
2025-04-22 21:46:49,447 [der.py] => SNet: Task 4, Epoch 126/130 => Loss 2.162,  Train_accy 92.88, Test_accy 67.20
2025-04-22 21:47:01,977 [der.py] => SNet: Task 4, Epoch 127/130 => Loss 2.161,  Train_accy 92.99
2025-04-22 21:47:14,337 [der.py] => SNet: Task 4, Epoch 128/130 => Loss 2.158,  Train_accy 93.23
2025-04-22 21:47:26,602 [der.py] => SNet: Task 4, Epoch 129/130 => Loss 2.161,  Train_accy 93.01
2025-04-22 21:47:39,150 [der.py] => SNet: Task 4, Epoch 130/130 => Loss 2.160,  Train_accy 93.15
2025-04-22 21:47:39,151 [der.py] => do not weight align student!
2025-04-22 21:47:48,759 [der.py] => darknet eval: 
2025-04-22 21:47:48,759 [der.py] => CNN top1 curve: 67.65
2025-04-22 21:47:48,759 [der.py] => CNN top5 curve: 92.21
2025-04-22 21:47:48,760 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 21:49:07,533 [der.py] => Exemplar size: 1650
2025-04-22 21:49:07,533 [trainer.py] => CNN: {'total': 70.33, '0': 66.11, '1': 51.11, '2': 53.89, '3': 32.22, '4': 62.78, '5': 33.33, '6': 57.22, '7': 51.67, '8': 33.33, '9': 51.67, '10': 80.0, '11': 67.22, '12': 55.0, '13': 52.78, '14': 59.44, '15': 81.67, '16': 81.67, '17': 81.67, '18': 68.33, '19': 78.89, '20': 80.56, '21': 68.33, '22': 77.78, '23': 56.11, '24': 60.56, '25': 70.56, '26': 70.56, '27': 68.89, '28': 41.67, '29': 51.67, '30': 77.22, '31': 71.67, '32': 82.22, '33': 45.56, '34': 61.67, '35': 94.44, '36': 92.22, '37': 67.78, '38': 92.22, '39': 94.44, '40': 80.0, '41': 95.0, '42': 96.67, '43': 98.33, '44': 76.67, '45': 87.78, '46': 82.22, '47': 80.0, '48': 77.22, '49': 78.89, '50': 75.0, '51': 79.44, '52': 77.22, '53': 75.56, 'old': 68.28, 'new': 79.56}
2025-04-22 21:49:07,533 [trainer.py] => NME: {'total': 64.33, '0': 62.78, '1': 44.44, '2': 48.33, '3': 25.56, '4': 60.56, '5': 34.44, '6': 51.11, '7': 53.89, '8': 30.0, '9': 51.11, '10': 76.67, '11': 78.89, '12': 56.67, '13': 52.22, '14': 55.56, '15': 71.67, '16': 76.11, '17': 83.33, '18': 73.33, '19': 75.56, '20': 76.67, '21': 70.56, '22': 62.22, '23': 49.44, '24': 48.33, '25': 53.33, '26': 61.67, '27': 51.67, '28': 36.67, '29': 42.78, '30': 67.78, '31': 60.0, '32': 72.78, '33': 35.56, '34': 66.67, '35': 80.0, '36': 84.44, '37': 47.22, '38': 84.44, '39': 77.22, '40': 43.33, '41': 87.78, '42': 91.11, '43': 85.0, '44': 54.44, '45': 86.11, '46': 85.56, '47': 81.11, '48': 86.67, '49': 72.22, '50': 71.11, '51': 76.67, '52': 78.89, '53': 71.67, 'old': 61.19, 'new': 78.5}
2025-04-22 21:49:07,533 [trainer.py] => CNN top1 curve: [89.44, 88.07, 79.33, 71.11, 70.33]
2025-04-22 21:49:07,533 [trainer.py] => CNN top5 curve: [98.93, 98.76, 96.83, 94.52, 93.09]
2025-04-22 21:49:07,533 [trainer.py] => NME top1 curve: [88.22, 84.98, 75.76, 71.67, 64.33]
2025-04-22 21:49:07,533 [trainer.py] => NME top5 curve: [98.81, 98.51, 97.05, 95.17, 92.32]

