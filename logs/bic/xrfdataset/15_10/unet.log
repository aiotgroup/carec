2024-01-10 23:13:55,143 [trainer.py] => 实验名称:WiFi 测试类交换
2024-01-10 23:13:55,144 [trainer.py] => config: ./exps/bic.json
2024-01-10 23:13:55,144 [trainer.py] => experiment_name: 实验名称:WiFi 测试类交换
2024-01-10 23:13:55,144 [trainer.py] => prefix: reproduce
2024-01-10 23:13:55,144 [trainer.py] => dataset: xrfdataset
2024-01-10 23:13:55,144 [trainer.py] => memory_size: 1650
2024-01-10 23:13:55,144 [trainer.py] => memory_per_class: 30
2024-01-10 23:13:55,144 [trainer.py] => fixed_memory: True
2024-01-10 23:13:55,144 [trainer.py] => shuffle: True
2024-01-10 23:13:55,144 [trainer.py] => init_cls: 15
2024-01-10 23:13:55,144 [trainer.py] => increment: 10
2024-01-10 23:13:55,144 [trainer.py] => model_name: bic
2024-01-10 23:13:55,144 [trainer.py] => convnet_type: unet
2024-01-10 23:13:55,144 [trainer.py] => device: [device(type='cuda', index=2)]
2024-01-10 23:13:55,145 [trainer.py] => seed: 1993
2024-01-10 23:13:55,157 [data.py] => 加载完毕XRF原始数据集
2024-01-10 23:13:55,163 [data.py] => 加载完毕XRF原始数据集
2024-01-10 23:13:55,329 [trainer.py] => All params: 21041612
2024-01-10 23:13:55,329 [trainer.py] => Trainable params: 21041612
2024-01-10 23:13:55,329 [bic.py] => Learning on 0-15
2024-01-10 23:13:55,385 [bic.py] => Parameters of bias layer:
2024-01-10 23:13:55,386 [bic.py] => 0 => 1.000, 0.000
2024-01-10 23:14:14,791 [bic.py] => training => Task 0, Epoch 1/2 => Loss 2.472, Train_accy 14.330, Test_accy 13.560
2024-01-10 23:14:32,846 [bic.py] => training => Task 0, Epoch 2/2 => Loss 2.074, Train_accy 21.290, Test_accy 20.040
2024-01-10 23:14:32,848 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-10 23:14:46,832 [bic.py] => Parameters of bias layer:
2024-01-10 23:14:46,832 [bic.py] => 0 => 1.000, 0.000
2024-01-10 23:14:52,719 [bic.py] => Exemplar size: 450
2024-01-10 23:14:52,915 [trainer.py] => CNN: {'total': 20.04, '0': 49.44, '1': 6.11, '2': 36.11, '3': 5.0, '4': 13.89, '5': 37.22, '6': 0.0, '7': 0.0, '8': 6.67, '9': 39.44, '10': 1.67, '11': 13.33, '12': 21.67, '13': 24.44, 'old': 0, 'new': 20.04}
2024-01-10 23:14:52,916 [trainer.py] => NME: {'total': 26.0, '0': 46.67, '1': 12.78, '2': 30.56, '3': 3.89, '4': 25.56, '5': 15.0, '6': 20.0, '7': 26.67, '8': 30.56, '9': 13.89, '10': 15.56, '11': 66.11, '12': 16.67, '13': 17.78, 'old': 0, 'new': 26.0}
2024-01-10 23:14:52,916 [trainer.py] => CNN top1 curve: [20.04]
2024-01-10 23:14:52,916 [trainer.py] => CNN top5 curve: [67.04]
2024-01-10 23:14:52,916 [trainer.py] => NME top1 curve: [26.0]
2024-01-10 23:14:52,916 [trainer.py] => NME top5 curve: [73.56]

2024-01-10 23:14:52,916 [trainer.py] => All params: 21043549
2024-01-10 23:14:52,916 [trainer.py] => Trainable params: 21043549
2024-01-10 23:14:52,917 [bic.py] => Learning on 15-25
2024-01-10 23:14:53,128 [bic.py] => Stage1 dset: 4375, Stage2 dset: 275
2024-01-10 23:14:53,129 [bic.py] => Lambda: 0.600
2024-01-10 23:14:53,156 [bic.py] => Parameters of bias layer:
2024-01-10 23:14:53,157 [bic.py] => 0 => 1.000, 0.000
2024-01-10 23:14:53,157 [bic.py] => 1 => 1.000, 0.000
2024-01-10 23:15:10,659 [bic.py] => training => Task 1, Epoch 1/2 => Loss 2.462, Train_accy 24.590, Test_accy 10.310
2024-01-10 23:15:29,404 [bic.py] => training => Task 1, Epoch 2/2 => Loss 2.206, Train_accy 33.780, Test_accy 13.960
2024-01-10 23:15:36,504 [bic.py] => bias_correction => Task 1, Epoch 1/2 => Loss 3.179, Train_accy 15.640, Test_accy 14.040
2024-01-10 23:15:44,143 [bic.py] => bias_correction => Task 1, Epoch 2/2 => Loss 3.178, Train_accy 15.640, Test_accy 13.930
2024-01-10 23:15:44,144 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-10 23:16:00,739 [bic.py] => Parameters of bias layer:
2024-01-10 23:16:00,740 [bic.py] => 0 => 1.000, 0.000
2024-01-10 23:16:00,740 [bic.py] => 1 => 1.021, -0.008
2024-01-10 23:16:11,076 [bic.py] => Exemplar size: 750
2024-01-10 23:16:11,377 [trainer.py] => CNN: {'total': 13.93, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 1.11, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 22.22, '16': 23.89, '17': 50.56, '18': 36.11, '19': 0.0, '20': 41.11, '21': 14.44, '22': 68.89, '23': 68.89, 'old': 0.07, 'new': 34.72}
2024-01-10 23:16:11,377 [trainer.py] => NME: {'total': 19.44, '0': 38.89, '1': 3.89, '2': 27.22, '3': 15.0, '4': 33.89, '5': 12.78, '6': 16.67, '7': 22.22, '8': 16.67, '9': 7.78, '10': 30.56, '11': 63.89, '12': 8.33, '13': 23.33, '14': 27.22, '15': 10.0, '16': 11.11, '17': 19.44, '18': 22.22, '19': 10.0, '20': 5.0, '21': 8.89, '22': 21.11, '23': 12.22, 'old': 23.22, 'new': 13.78}
2024-01-10 23:16:11,377 [trainer.py] => CNN top1 curve: [20.04, 13.93]
2024-01-10 23:16:11,377 [trainer.py] => CNN top5 curve: [67.04, 36.73]
2024-01-10 23:16:11,377 [trainer.py] => NME top1 curve: [26.0, 19.44]
2024-01-10 23:16:11,378 [trainer.py] => NME top5 curve: [73.56, 61.36]

2024-01-10 23:16:11,378 [trainer.py] => All params: 21044841
2024-01-10 23:16:11,378 [trainer.py] => Trainable params: 21044841
2024-01-10 23:16:11,379 [bic.py] => Learning on 25-35
2024-01-10 23:16:11,443 [bic.py] => Stage1 dset: 4740, Stage2 dset: 210
2024-01-10 23:16:11,456 [bic.py] => Lambda: 0.714
2024-01-10 23:16:11,549 [bic.py] => Parameters of bias layer:
2024-01-10 23:16:11,550 [bic.py] => 0 => 1.000, 0.000
2024-01-10 23:16:11,550 [bic.py] => 1 => 1.021, -0.008
2024-01-10 23:16:11,550 [bic.py] => 2 => 1.000, 0.000
2024-01-10 23:16:28,516 [trainer.py] => 实验名称:WiFi 测试类交换
2024-01-10 23:16:28,517 [trainer.py] => config: ./exps/bic.json
2024-01-10 23:16:28,517 [trainer.py] => experiment_name: 实验名称:WiFi 测试类交换
2024-01-10 23:16:28,517 [trainer.py] => prefix: reproduce
2024-01-10 23:16:28,517 [trainer.py] => dataset: xrfdataset
2024-01-10 23:16:28,517 [trainer.py] => memory_size: 1650
2024-01-10 23:16:28,517 [trainer.py] => memory_per_class: 30
2024-01-10 23:16:28,517 [trainer.py] => fixed_memory: True
2024-01-10 23:16:28,517 [trainer.py] => shuffle: True
2024-01-10 23:16:28,517 [trainer.py] => init_cls: 15
2024-01-10 23:16:28,517 [trainer.py] => increment: 10
2024-01-10 23:16:28,517 [trainer.py] => model_name: bic
2024-01-10 23:16:28,517 [trainer.py] => convnet_type: unet
2024-01-10 23:16:28,517 [trainer.py] => device: [device(type='cuda', index=2)]
2024-01-10 23:16:28,517 [trainer.py] => seed: 1993
2024-01-10 23:16:28,530 [data.py] => 加载完毕XRF原始数据集
2024-01-10 23:16:28,536 [data.py] => 加载完毕XRF原始数据集
2024-01-10 23:16:28,701 [trainer.py] => All params: 21041612
2024-01-10 23:16:28,701 [trainer.py] => Trainable params: 21041612
2024-01-10 23:16:28,702 [bic.py] => Learning on 0-15
2024-01-10 23:16:28,759 [bic.py] => Parameters of bias layer:
2024-01-10 23:16:28,759 [bic.py] => 0 => 1.000, 0.000
2024-01-10 23:16:52,690 [bic.py] => training => Task 0, Epoch 1/200 => Loss 2.472, Train_accy 14.330, Test_accy 13.560
2024-01-10 23:17:15,303 [bic.py] => training => Task 0, Epoch 2/200 => Loss 2.074, Train_accy 21.290, Test_accy 20.040
2024-01-10 23:17:37,371 [bic.py] => training => Task 0, Epoch 3/200 => Loss 1.831, Train_accy 27.060, Test_accy 26.220
2024-01-10 23:17:58,406 [bic.py] => training => Task 0, Epoch 4/200 => Loss 1.655, Train_accy 41.020, Test_accy 37.040
2024-01-10 23:18:19,565 [bic.py] => training => Task 0, Epoch 5/200 => Loss 1.463, Train_accy 22.790, Test_accy 20.560
2024-01-10 23:18:40,800 [bic.py] => training => Task 0, Epoch 6/200 => Loss 1.348, Train_accy 44.130, Test_accy 40.000
2024-01-10 23:19:02,719 [bic.py] => training => Task 0, Epoch 7/200 => Loss 1.277, Train_accy 42.970, Test_accy 36.630
2024-01-10 23:19:24,161 [bic.py] => training => Task 0, Epoch 8/200 => Loss 1.088, Train_accy 54.290, Test_accy 47.810
2024-01-10 23:19:44,978 [bic.py] => training => Task 0, Epoch 9/200 => Loss 0.982, Train_accy 52.410, Test_accy 44.560
2024-01-10 23:20:13,917 [bic.py] => training => Task 0, Epoch 10/200 => Loss 0.937, Train_accy 63.060, Test_accy 53.930
2024-01-10 23:20:43,424 [bic.py] => training => Task 0, Epoch 11/200 => Loss 0.813, Train_accy 51.600, Test_accy 45.740
2024-01-10 23:21:13,566 [bic.py] => training => Task 0, Epoch 12/200 => Loss 0.775, Train_accy 54.020, Test_accy 46.220
2024-01-10 23:21:45,138 [bic.py] => training => Task 0, Epoch 13/200 => Loss 0.796, Train_accy 64.830, Test_accy 55.560
2024-01-10 23:22:16,973 [bic.py] => training => Task 0, Epoch 14/200 => Loss 0.673, Train_accy 71.950, Test_accy 62.700
2024-01-10 23:22:46,608 [bic.py] => training => Task 0, Epoch 15/200 => Loss 0.613, Train_accy 75.190, Test_accy 63.960
2024-01-10 23:23:16,874 [bic.py] => training => Task 0, Epoch 16/200 => Loss 0.589, Train_accy 65.050, Test_accy 56.930
2024-01-10 23:23:48,324 [bic.py] => training => Task 0, Epoch 17/200 => Loss 0.620, Train_accy 66.950, Test_accy 57.000
2024-01-10 23:24:19,030 [bic.py] => training => Task 0, Epoch 18/200 => Loss 0.547, Train_accy 75.210, Test_accy 64.370
2024-01-10 23:24:49,251 [bic.py] => training => Task 0, Epoch 19/200 => Loss 0.546, Train_accy 68.940, Test_accy 58.330
2024-01-10 23:25:21,966 [bic.py] => training => Task 0, Epoch 20/200 => Loss 0.452, Train_accy 68.170, Test_accy 60.000
2024-01-10 23:25:50,843 [bic.py] => training => Task 0, Epoch 21/200 => Loss 0.515, Train_accy 71.250, Test_accy 60.630
2024-01-10 23:26:20,437 [bic.py] => training => Task 0, Epoch 22/200 => Loss 0.471, Train_accy 75.250, Test_accy 63.110
2024-01-10 23:26:51,619 [bic.py] => training => Task 0, Epoch 23/200 => Loss 0.360, Train_accy 83.920, Test_accy 71.330
2024-01-10 23:27:21,224 [bic.py] => training => Task 0, Epoch 24/200 => Loss 0.375, Train_accy 80.320, Test_accy 67.070
2024-01-10 23:27:51,101 [bic.py] => training => Task 0, Epoch 25/200 => Loss 0.378, Train_accy 81.350, Test_accy 68.930
2024-01-10 23:28:20,861 [bic.py] => training => Task 0, Epoch 26/200 => Loss 0.357, Train_accy 79.560, Test_accy 66.520
2024-01-10 23:28:50,130 [bic.py] => training => Task 0, Epoch 27/200 => Loss 0.401, Train_accy 73.870, Test_accy 63.480
2024-01-10 23:29:19,716 [bic.py] => training => Task 0, Epoch 28/200 => Loss 0.389, Train_accy 81.670, Test_accy 69.930
2024-01-10 23:29:50,816 [bic.py] => training => Task 0, Epoch 29/200 => Loss 0.332, Train_accy 74.290, Test_accy 62.330
2024-01-10 23:30:21,104 [bic.py] => training => Task 0, Epoch 30/200 => Loss 0.366, Train_accy 74.620, Test_accy 64.150
2024-01-10 23:30:50,750 [bic.py] => training => Task 0, Epoch 31/200 => Loss 0.526, Train_accy 78.140, Test_accy 65.670
2024-01-10 23:31:21,319 [bic.py] => training => Task 0, Epoch 32/200 => Loss 0.337, Train_accy 88.630, Test_accy 76.110
2024-01-10 23:31:49,724 [bic.py] => training => Task 0, Epoch 33/200 => Loss 0.351, Train_accy 86.460, Test_accy 73.260
2024-01-10 23:32:19,913 [bic.py] => training => Task 0, Epoch 34/200 => Loss 0.300, Train_accy 80.760, Test_accy 68.560
2024-01-10 23:32:49,885 [bic.py] => training => Task 0, Epoch 35/200 => Loss 0.269, Train_accy 87.210, Test_accy 73.960
2024-01-10 23:33:20,054 [bic.py] => training => Task 0, Epoch 36/200 => Loss 0.298, Train_accy 81.860, Test_accy 67.810
2024-01-10 23:33:50,407 [bic.py] => training => Task 0, Epoch 37/200 => Loss 0.257, Train_accy 87.490, Test_accy 74.560
2024-01-10 23:34:21,934 [bic.py] => training => Task 0, Epoch 38/200 => Loss 0.251, Train_accy 87.050, Test_accy 72.410
2024-01-10 23:34:51,537 [bic.py] => training => Task 0, Epoch 39/200 => Loss 0.361, Train_accy 79.840, Test_accy 66.300
2024-01-10 23:35:22,953 [bic.py] => training => Task 0, Epoch 40/200 => Loss 0.374, Train_accy 86.400, Test_accy 73.440
2024-01-10 23:35:54,627 [bic.py] => training => Task 0, Epoch 41/200 => Loss 0.244, Train_accy 89.440, Test_accy 76.370
2024-01-10 23:36:26,755 [bic.py] => training => Task 0, Epoch 42/200 => Loss 0.232, Train_accy 89.940, Test_accy 76.850
2024-01-10 23:37:00,960 [bic.py] => training => Task 0, Epoch 43/200 => Loss 0.254, Train_accy 83.510, Test_accy 68.850
2024-01-10 23:37:32,996 [bic.py] => training => Task 0, Epoch 44/200 => Loss 0.305, Train_accy 85.830, Test_accy 71.890
2024-01-10 23:38:03,940 [bic.py] => training => Task 0, Epoch 45/200 => Loss 0.295, Train_accy 85.130, Test_accy 71.440
2024-01-10 23:38:37,385 [bic.py] => training => Task 0, Epoch 46/200 => Loss 0.218, Train_accy 92.080, Test_accy 77.410
2024-01-10 23:39:09,522 [bic.py] => training => Task 0, Epoch 47/200 => Loss 0.181, Train_accy 92.080, Test_accy 76.960
2024-01-10 23:39:41,037 [bic.py] => training => Task 0, Epoch 48/200 => Loss 0.208, Train_accy 90.210, Test_accy 76.960
2024-01-10 23:40:14,258 [bic.py] => training => Task 0, Epoch 49/200 => Loss 0.225, Train_accy 87.540, Test_accy 72.000
2024-01-10 23:40:44,209 [bic.py] => training => Task 0, Epoch 50/200 => Loss 0.222, Train_accy 91.270, Test_accy 77.960
2024-01-10 23:41:16,555 [bic.py] => training => Task 0, Epoch 51/200 => Loss 0.230, Train_accy 86.000, Test_accy 71.040
2024-01-10 23:41:49,425 [bic.py] => training => Task 0, Epoch 52/200 => Loss 0.201, Train_accy 84.750, Test_accy 71.070
2024-01-10 23:42:21,581 [bic.py] => training => Task 0, Epoch 53/200 => Loss 0.356, Train_accy 82.920, Test_accy 67.630
2024-01-10 23:42:53,847 [bic.py] => training => Task 0, Epoch 54/200 => Loss 0.241, Train_accy 82.460, Test_accy 69.000
2024-01-10 23:43:24,186 [bic.py] => training => Task 0, Epoch 55/200 => Loss 0.227, Train_accy 89.870, Test_accy 74.370
2024-01-10 23:43:56,222 [bic.py] => training => Task 0, Epoch 56/200 => Loss 0.224, Train_accy 89.080, Test_accy 73.370
2024-01-10 23:44:29,235 [bic.py] => training => Task 0, Epoch 57/200 => Loss 0.201, Train_accy 90.630, Test_accy 76.630
2024-01-10 23:45:01,235 [bic.py] => training => Task 0, Epoch 58/200 => Loss 0.171, Train_accy 93.210, Test_accy 77.810
2024-01-10 23:45:33,878 [bic.py] => training => Task 0, Epoch 59/200 => Loss 0.201, Train_accy 91.860, Test_accy 77.110
2024-01-10 23:46:07,583 [bic.py] => training => Task 0, Epoch 60/200 => Loss 0.209, Train_accy 84.860, Test_accy 71.110
2024-01-10 23:46:40,955 [bic.py] => training => Task 0, Epoch 61/200 => Loss 0.117, Train_accy 97.730, Test_accy 84.220
2024-01-10 23:47:13,582 [bic.py] => training => Task 0, Epoch 62/200 => Loss 0.091, Train_accy 98.140, Test_accy 84.850
2024-01-10 23:47:47,468 [bic.py] => training => Task 0, Epoch 63/200 => Loss 0.077, Train_accy 98.460, Test_accy 85.370
2024-01-10 23:48:19,143 [bic.py] => training => Task 0, Epoch 64/200 => Loss 0.081, Train_accy 98.430, Test_accy 85.590
2024-01-10 23:48:52,456 [bic.py] => training => Task 0, Epoch 65/200 => Loss 0.076, Train_accy 98.560, Test_accy 85.370
2024-01-10 23:49:25,237 [bic.py] => training => Task 0, Epoch 66/200 => Loss 0.071, Train_accy 98.380, Test_accy 85.670
2024-01-10 23:49:58,076 [bic.py] => training => Task 0, Epoch 67/200 => Loss 0.069, Train_accy 98.620, Test_accy 85.630
2024-01-10 23:50:30,810 [bic.py] => training => Task 0, Epoch 68/200 => Loss 0.068, Train_accy 98.680, Test_accy 85.670
2024-01-10 23:51:01,011 [bic.py] => training => Task 0, Epoch 69/200 => Loss 0.067, Train_accy 98.750, Test_accy 85.740
2024-01-10 23:51:31,796 [bic.py] => training => Task 0, Epoch 70/200 => Loss 0.063, Train_accy 98.750, Test_accy 86.220
2024-01-10 23:52:01,189 [bic.py] => training => Task 0, Epoch 71/200 => Loss 0.066, Train_accy 98.760, Test_accy 85.930
2024-01-10 23:52:33,873 [bic.py] => training => Task 0, Epoch 72/200 => Loss 0.066, Train_accy 98.700, Test_accy 85.960
2024-01-10 23:53:05,166 [bic.py] => training => Task 0, Epoch 73/200 => Loss 0.065, Train_accy 98.630, Test_accy 85.960
2024-01-10 23:53:39,645 [bic.py] => training => Task 0, Epoch 74/200 => Loss 0.062, Train_accy 98.920, Test_accy 86.040
2024-01-10 23:54:13,836 [bic.py] => training => Task 0, Epoch 75/200 => Loss 0.059, Train_accy 98.900, Test_accy 85.810
2024-01-10 23:54:42,975 [bic.py] => training => Task 0, Epoch 76/200 => Loss 0.060, Train_accy 99.000, Test_accy 86.220
2024-01-10 23:55:14,489 [bic.py] => training => Task 0, Epoch 77/200 => Loss 0.054, Train_accy 98.890, Test_accy 85.960
2024-01-10 23:55:45,554 [bic.py] => training => Task 0, Epoch 78/200 => Loss 0.054, Train_accy 99.130, Test_accy 86.110
2024-01-10 23:56:16,066 [bic.py] => training => Task 0, Epoch 79/200 => Loss 0.058, Train_accy 98.950, Test_accy 85.560
2024-01-10 23:56:48,969 [bic.py] => training => Task 0, Epoch 80/200 => Loss 0.054, Train_accy 98.900, Test_accy 85.930
2024-01-10 23:57:20,313 [bic.py] => training => Task 0, Epoch 81/200 => Loss 0.055, Train_accy 99.170, Test_accy 86.190
2024-01-10 23:57:50,055 [bic.py] => training => Task 0, Epoch 82/200 => Loss 0.058, Train_accy 99.170, Test_accy 85.960
2024-01-10 23:58:20,618 [bic.py] => training => Task 0, Epoch 83/200 => Loss 0.056, Train_accy 99.080, Test_accy 86.590
2024-01-10 23:58:51,473 [bic.py] => training => Task 0, Epoch 84/200 => Loss 0.055, Train_accy 99.100, Test_accy 85.740
2024-01-10 23:59:22,111 [bic.py] => training => Task 0, Epoch 85/200 => Loss 0.052, Train_accy 99.190, Test_accy 86.300
2024-01-10 23:59:54,232 [bic.py] => training => Task 0, Epoch 86/200 => Loss 0.051, Train_accy 99.270, Test_accy 86.040
2024-01-11 00:00:26,165 [bic.py] => training => Task 0, Epoch 87/200 => Loss 0.050, Train_accy 99.220, Test_accy 86.440
2024-01-11 00:00:56,454 [bic.py] => training => Task 0, Epoch 88/200 => Loss 0.051, Train_accy 99.250, Test_accy 86.150
2024-01-11 00:01:29,318 [bic.py] => training => Task 0, Epoch 89/200 => Loss 0.047, Train_accy 99.270, Test_accy 86.260
2024-01-11 00:02:01,204 [bic.py] => training => Task 0, Epoch 90/200 => Loss 0.048, Train_accy 99.290, Test_accy 86.330
2024-01-11 00:02:35,343 [bic.py] => training => Task 0, Epoch 91/200 => Loss 0.047, Train_accy 99.060, Test_accy 85.780
2024-01-11 00:03:10,388 [bic.py] => training => Task 0, Epoch 92/200 => Loss 0.047, Train_accy 99.330, Test_accy 86.070
2024-01-11 00:03:41,285 [bic.py] => training => Task 0, Epoch 93/200 => Loss 0.049, Train_accy 99.370, Test_accy 86.370
2024-01-11 00:04:11,195 [bic.py] => training => Task 0, Epoch 94/200 => Loss 0.051, Train_accy 99.290, Test_accy 85.930
2024-01-11 00:04:41,853 [bic.py] => training => Task 0, Epoch 95/200 => Loss 0.050, Train_accy 99.410, Test_accy 85.520
2024-01-11 00:05:12,803 [bic.py] => training => Task 0, Epoch 96/200 => Loss 0.045, Train_accy 99.100, Test_accy 85.700
2024-01-11 00:05:44,732 [bic.py] => training => Task 0, Epoch 97/200 => Loss 0.044, Train_accy 99.400, Test_accy 86.330
2024-01-11 00:06:14,528 [bic.py] => training => Task 0, Epoch 98/200 => Loss 0.048, Train_accy 99.250, Test_accy 85.740
2024-01-11 00:06:43,166 [bic.py] => training => Task 0, Epoch 99/200 => Loss 0.050, Train_accy 99.210, Test_accy 85.930
2024-01-11 00:07:13,617 [bic.py] => training => Task 0, Epoch 100/200 => Loss 0.055, Train_accy 99.300, Test_accy 86.190
2024-01-11 00:07:43,340 [bic.py] => training => Task 0, Epoch 101/200 => Loss 0.042, Train_accy 99.400, Test_accy 86.110
2024-01-11 00:08:14,891 [bic.py] => training => Task 0, Epoch 102/200 => Loss 0.044, Train_accy 99.430, Test_accy 86.370
2024-01-11 00:08:44,650 [bic.py] => training => Task 0, Epoch 103/200 => Loss 0.041, Train_accy 99.480, Test_accy 86.070
2024-01-11 00:09:13,905 [bic.py] => training => Task 0, Epoch 104/200 => Loss 0.045, Train_accy 99.380, Test_accy 86.300
2024-01-11 00:09:42,197 [bic.py] => training => Task 0, Epoch 105/200 => Loss 0.042, Train_accy 99.490, Test_accy 86.150
2024-01-11 00:10:10,951 [bic.py] => training => Task 0, Epoch 106/200 => Loss 0.041, Train_accy 99.490, Test_accy 86.070
2024-01-11 00:10:40,315 [bic.py] => training => Task 0, Epoch 107/200 => Loss 0.043, Train_accy 99.490, Test_accy 86.190
2024-01-11 00:11:09,360 [bic.py] => training => Task 0, Epoch 108/200 => Loss 0.042, Train_accy 99.570, Test_accy 86.440
2024-01-11 00:11:38,250 [bic.py] => training => Task 0, Epoch 109/200 => Loss 0.039, Train_accy 99.480, Test_accy 86.000
2024-01-11 00:12:06,745 [bic.py] => training => Task 0, Epoch 110/200 => Loss 0.045, Train_accy 99.520, Test_accy 86.000
2024-01-11 00:12:34,407 [bic.py] => training => Task 0, Epoch 111/200 => Loss 0.041, Train_accy 99.540, Test_accy 86.040
2024-01-11 00:13:01,855 [bic.py] => training => Task 0, Epoch 112/200 => Loss 0.038, Train_accy 99.540, Test_accy 86.110
2024-01-11 00:13:29,774 [bic.py] => training => Task 0, Epoch 113/200 => Loss 0.038, Train_accy 99.440, Test_accy 86.370
2024-01-11 00:13:57,591 [bic.py] => training => Task 0, Epoch 114/200 => Loss 0.038, Train_accy 99.370, Test_accy 86.220
2024-01-11 00:14:27,325 [bic.py] => training => Task 0, Epoch 115/200 => Loss 0.040, Train_accy 99.490, Test_accy 86.410
2024-01-11 00:14:56,231 [bic.py] => training => Task 0, Epoch 116/200 => Loss 0.049, Train_accy 99.560, Test_accy 86.520
2024-01-11 00:15:25,371 [bic.py] => training => Task 0, Epoch 117/200 => Loss 0.042, Train_accy 99.520, Test_accy 86.220
2024-01-11 00:15:54,989 [bic.py] => training => Task 0, Epoch 118/200 => Loss 0.042, Train_accy 99.520, Test_accy 86.260
2024-01-11 00:16:24,397 [bic.py] => training => Task 0, Epoch 119/200 => Loss 0.045, Train_accy 99.620, Test_accy 86.150
2024-01-11 00:16:55,055 [bic.py] => training => Task 0, Epoch 120/200 => Loss 0.038, Train_accy 99.570, Test_accy 86.520
2024-01-11 00:17:24,390 [bic.py] => training => Task 0, Epoch 121/200 => Loss 0.043, Train_accy 99.540, Test_accy 86.300
2024-01-11 00:17:54,512 [bic.py] => training => Task 0, Epoch 122/200 => Loss 0.040, Train_accy 99.480, Test_accy 86.520
2024-01-11 00:18:22,601 [bic.py] => training => Task 0, Epoch 123/200 => Loss 0.038, Train_accy 99.440, Test_accy 86.260
2024-01-11 00:18:52,275 [bic.py] => training => Task 0, Epoch 124/200 => Loss 0.039, Train_accy 99.440, Test_accy 86.590
2024-01-11 00:19:21,770 [bic.py] => training => Task 0, Epoch 125/200 => Loss 0.040, Train_accy 99.410, Test_accy 86.670
2024-01-11 00:19:52,325 [bic.py] => training => Task 0, Epoch 126/200 => Loss 0.038, Train_accy 99.490, Test_accy 86.480
2024-01-11 00:20:21,732 [bic.py] => training => Task 0, Epoch 127/200 => Loss 0.038, Train_accy 99.620, Test_accy 86.560
2024-01-11 00:20:52,156 [bic.py] => training => Task 0, Epoch 128/200 => Loss 0.040, Train_accy 99.540, Test_accy 86.260
2024-01-11 00:21:20,681 [bic.py] => training => Task 0, Epoch 129/200 => Loss 0.041, Train_accy 99.650, Test_accy 86.150
2024-01-11 00:21:52,764 [bic.py] => training => Task 0, Epoch 130/200 => Loss 0.040, Train_accy 99.510, Test_accy 86.370
2024-01-11 00:22:22,940 [bic.py] => training => Task 0, Epoch 131/200 => Loss 0.046, Train_accy 99.560, Test_accy 86.190
2024-01-11 00:22:52,484 [bic.py] => training => Task 0, Epoch 132/200 => Loss 0.038, Train_accy 99.480, Test_accy 86.440
2024-01-11 00:23:21,827 [bic.py] => training => Task 0, Epoch 133/200 => Loss 0.040, Train_accy 99.570, Test_accy 86.220
2024-01-11 00:23:53,730 [bic.py] => training => Task 0, Epoch 134/200 => Loss 0.038, Train_accy 99.560, Test_accy 86.480
2024-01-11 00:24:22,971 [bic.py] => training => Task 0, Epoch 135/200 => Loss 0.038, Train_accy 99.650, Test_accy 86.370
2024-01-11 00:24:52,783 [bic.py] => training => Task 0, Epoch 136/200 => Loss 0.037, Train_accy 99.570, Test_accy 86.330
2024-01-11 00:25:22,378 [bic.py] => training => Task 0, Epoch 137/200 => Loss 0.035, Train_accy 99.620, Test_accy 86.590
2024-01-11 00:25:52,487 [bic.py] => training => Task 0, Epoch 138/200 => Loss 0.039, Train_accy 99.520, Test_accy 86.410
2024-01-11 00:26:22,271 [bic.py] => training => Task 0, Epoch 139/200 => Loss 0.037, Train_accy 99.510, Test_accy 86.110
2024-01-11 00:26:54,498 [bic.py] => training => Task 0, Epoch 140/200 => Loss 0.039, Train_accy 99.510, Test_accy 86.190
2024-01-11 00:27:23,623 [bic.py] => training => Task 0, Epoch 141/200 => Loss 0.040, Train_accy 99.540, Test_accy 86.560
2024-01-11 00:27:53,664 [bic.py] => training => Task 0, Epoch 142/200 => Loss 0.037, Train_accy 99.490, Test_accy 86.370
2024-01-11 00:28:23,688 [bic.py] => training => Task 0, Epoch 143/200 => Loss 0.041, Train_accy 99.590, Test_accy 86.480
2024-01-11 00:28:54,234 [bic.py] => training => Task 0, Epoch 144/200 => Loss 0.040, Train_accy 99.570, Test_accy 86.220
2024-01-11 00:29:24,062 [bic.py] => training => Task 0, Epoch 145/200 => Loss 0.038, Train_accy 99.520, Test_accy 86.440
2024-01-11 00:29:53,057 [bic.py] => training => Task 0, Epoch 146/200 => Loss 0.040, Train_accy 99.560, Test_accy 86.300
2024-01-11 00:30:23,521 [bic.py] => training => Task 0, Epoch 147/200 => Loss 0.038, Train_accy 99.540, Test_accy 86.300
2024-01-11 00:30:51,948 [bic.py] => training => Task 0, Epoch 148/200 => Loss 0.037, Train_accy 99.560, Test_accy 86.480
2024-01-11 00:31:20,620 [bic.py] => training => Task 0, Epoch 149/200 => Loss 0.039, Train_accy 99.560, Test_accy 86.440
2024-01-11 00:31:50,423 [bic.py] => training => Task 0, Epoch 150/200 => Loss 0.034, Train_accy 99.620, Test_accy 86.220
2024-01-11 00:32:19,584 [bic.py] => training => Task 0, Epoch 151/200 => Loss 0.046, Train_accy 99.570, Test_accy 86.670
2024-01-11 00:32:48,514 [bic.py] => training => Task 0, Epoch 152/200 => Loss 0.036, Train_accy 99.540, Test_accy 86.520
2024-01-11 00:33:19,235 [bic.py] => training => Task 0, Epoch 153/200 => Loss 0.038, Train_accy 99.600, Test_accy 86.630
2024-01-11 00:33:46,873 [bic.py] => training => Task 0, Epoch 154/200 => Loss 0.038, Train_accy 99.630, Test_accy 86.480
2024-01-11 00:34:15,820 [bic.py] => training => Task 0, Epoch 155/200 => Loss 0.043, Train_accy 99.590, Test_accy 86.260
2024-01-11 00:34:45,895 [bic.py] => training => Task 0, Epoch 156/200 => Loss 0.036, Train_accy 99.600, Test_accy 86.700
2024-01-11 00:35:15,103 [bic.py] => training => Task 0, Epoch 157/200 => Loss 0.044, Train_accy 99.480, Test_accy 86.480
2024-01-11 00:35:43,938 [bic.py] => training => Task 0, Epoch 158/200 => Loss 0.038, Train_accy 99.570, Test_accy 86.300
2024-01-11 00:36:12,296 [bic.py] => training => Task 0, Epoch 159/200 => Loss 0.040, Train_accy 99.560, Test_accy 86.410
2024-01-11 00:36:40,918 [bic.py] => training => Task 0, Epoch 160/200 => Loss 0.045, Train_accy 99.620, Test_accy 86.300
2024-01-11 00:37:09,754 [bic.py] => training => Task 0, Epoch 161/200 => Loss 0.039, Train_accy 99.560, Test_accy 86.700
2024-01-11 00:37:38,858 [bic.py] => training => Task 0, Epoch 162/200 => Loss 0.039, Train_accy 99.600, Test_accy 86.000
2024-01-11 00:38:08,015 [bic.py] => training => Task 0, Epoch 163/200 => Loss 0.039, Train_accy 99.590, Test_accy 86.700
2024-01-11 00:38:37,286 [bic.py] => training => Task 0, Epoch 164/200 => Loss 0.037, Train_accy 99.560, Test_accy 86.560
2024-01-11 00:39:05,214 [bic.py] => training => Task 0, Epoch 165/200 => Loss 0.038, Train_accy 99.650, Test_accy 86.330
2024-01-11 00:39:34,378 [bic.py] => training => Task 0, Epoch 166/200 => Loss 0.037, Train_accy 99.570, Test_accy 86.330
2024-01-11 00:40:03,744 [bic.py] => training => Task 0, Epoch 167/200 => Loss 0.038, Train_accy 99.590, Test_accy 86.410
2024-01-11 00:40:32,721 [bic.py] => training => Task 0, Epoch 168/200 => Loss 0.037, Train_accy 99.480, Test_accy 86.370
2024-01-11 00:41:02,440 [bic.py] => training => Task 0, Epoch 169/200 => Loss 0.038, Train_accy 99.540, Test_accy 86.480
2024-01-11 00:41:31,171 [bic.py] => training => Task 0, Epoch 170/200 => Loss 0.038, Train_accy 99.480, Test_accy 86.370
2024-01-11 00:41:59,284 [bic.py] => training => Task 0, Epoch 171/200 => Loss 0.035, Train_accy 99.460, Test_accy 86.560
2024-01-11 00:42:27,451 [bic.py] => training => Task 0, Epoch 172/200 => Loss 0.043, Train_accy 99.490, Test_accy 86.410
2024-01-11 00:42:56,849 [bic.py] => training => Task 0, Epoch 173/200 => Loss 0.036, Train_accy 99.570, Test_accy 86.190
2024-01-11 00:43:25,549 [bic.py] => training => Task 0, Epoch 174/200 => Loss 0.037, Train_accy 99.540, Test_accy 86.300
2024-01-11 00:43:53,699 [bic.py] => training => Task 0, Epoch 175/200 => Loss 0.043, Train_accy 99.560, Test_accy 86.480
2024-01-11 00:44:23,677 [bic.py] => training => Task 0, Epoch 176/200 => Loss 0.036, Train_accy 99.600, Test_accy 86.440
2024-01-11 00:44:51,270 [bic.py] => training => Task 0, Epoch 177/200 => Loss 0.036, Train_accy 99.490, Test_accy 86.070
2024-01-11 00:45:19,571 [bic.py] => training => Task 0, Epoch 178/200 => Loss 0.042, Train_accy 99.570, Test_accy 85.960
2024-01-11 00:45:48,427 [bic.py] => training => Task 0, Epoch 179/200 => Loss 0.041, Train_accy 99.590, Test_accy 86.150
2024-01-11 00:46:17,143 [bic.py] => training => Task 0, Epoch 180/200 => Loss 0.039, Train_accy 99.510, Test_accy 86.330
2024-01-11 00:46:46,219 [bic.py] => training => Task 0, Epoch 181/200 => Loss 0.039, Train_accy 99.650, Test_accy 86.370
2024-01-11 00:47:15,427 [bic.py] => training => Task 0, Epoch 182/200 => Loss 0.037, Train_accy 99.520, Test_accy 86.440
2024-01-11 00:47:44,262 [bic.py] => training => Task 0, Epoch 183/200 => Loss 0.040, Train_accy 99.540, Test_accy 86.330
2024-01-11 00:48:11,791 [bic.py] => training => Task 0, Epoch 184/200 => Loss 0.038, Train_accy 99.560, Test_accy 86.260
2024-01-11 00:48:41,455 [bic.py] => training => Task 0, Epoch 185/200 => Loss 0.037, Train_accy 99.630, Test_accy 86.410
2024-01-11 00:49:10,722 [bic.py] => training => Task 0, Epoch 186/200 => Loss 0.036, Train_accy 99.590, Test_accy 86.220
2024-01-11 00:49:39,043 [bic.py] => training => Task 0, Epoch 187/200 => Loss 0.035, Train_accy 99.650, Test_accy 86.520
2024-01-11 00:50:08,541 [bic.py] => training => Task 0, Epoch 188/200 => Loss 0.035, Train_accy 99.480, Test_accy 86.440
2024-01-11 00:50:37,507 [bic.py] => training => Task 0, Epoch 189/200 => Loss 0.043, Train_accy 99.620, Test_accy 86.000
2024-01-11 00:51:05,366 [bic.py] => training => Task 0, Epoch 190/200 => Loss 0.040, Train_accy 99.540, Test_accy 86.330
2024-01-11 00:51:35,487 [bic.py] => training => Task 0, Epoch 191/200 => Loss 0.038, Train_accy 99.630, Test_accy 86.330
2024-01-11 00:52:04,782 [bic.py] => training => Task 0, Epoch 192/200 => Loss 0.039, Train_accy 99.600, Test_accy 86.260
2024-01-11 00:52:34,962 [bic.py] => training => Task 0, Epoch 193/200 => Loss 0.041, Train_accy 99.520, Test_accy 86.590
2024-01-11 00:53:03,845 [bic.py] => training => Task 0, Epoch 194/200 => Loss 0.037, Train_accy 99.590, Test_accy 86.150
2024-01-11 00:53:31,977 [bic.py] => training => Task 0, Epoch 195/200 => Loss 0.037, Train_accy 99.620, Test_accy 86.190
2024-01-11 00:54:01,734 [bic.py] => training => Task 0, Epoch 196/200 => Loss 0.037, Train_accy 99.570, Test_accy 86.520
2024-01-11 00:54:31,825 [bic.py] => training => Task 0, Epoch 197/200 => Loss 0.038, Train_accy 99.560, Test_accy 86.480
2024-01-11 00:55:01,261 [bic.py] => training => Task 0, Epoch 198/200 => Loss 0.040, Train_accy 99.430, Test_accy 86.440
2024-01-11 00:55:30,742 [bic.py] => training => Task 0, Epoch 199/200 => Loss 0.037, Train_accy 99.480, Test_accy 86.190
2024-01-11 00:55:59,554 [bic.py] => training => Task 0, Epoch 200/200 => Loss 0.036, Train_accy 99.520, Test_accy 86.110
2024-01-11 00:55:59,555 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-11 00:56:20,719 [bic.py] => Parameters of bias layer:
2024-01-11 00:56:20,719 [bic.py] => 0 => 1.000, 0.000
2024-01-11 00:56:29,625 [bic.py] => Exemplar size: 450
2024-01-11 00:56:30,140 [trainer.py] => CNN: {'total': 86.11, '0': 98.89, '1': 93.33, '2': 92.78, '3': 86.11, '4': 85.56, '5': 73.89, '6': 58.33, '7': 92.78, '8': 91.11, '9': 58.33, '10': 91.67, '11': 99.44, '12': 87.78, '13': 90.56, 'old': 0, 'new': 86.11}
2024-01-11 00:56:30,141 [trainer.py] => NME: {'total': 84.37, '0': 97.78, '1': 91.11, '2': 92.78, '3': 76.67, '4': 85.0, '5': 78.33, '6': 54.44, '7': 90.56, '8': 83.89, '9': 57.22, '10': 93.33, '11': 100.0, '12': 86.11, '13': 87.22, 'old': 0, 'new': 84.37}
2024-01-11 00:56:30,141 [trainer.py] => CNN top1 curve: [86.11]
2024-01-11 00:56:30,141 [trainer.py] => CNN top5 curve: [97.7]
2024-01-11 00:56:30,141 [trainer.py] => NME top1 curve: [84.37]
2024-01-11 00:56:30,141 [trainer.py] => NME top5 curve: [98.07]

2024-01-11 00:56:30,142 [trainer.py] => All params: 21043549
2024-01-11 00:56:30,143 [trainer.py] => Trainable params: 21043549
2024-01-11 00:56:30,208 [bic.py] => Learning on 15-25
2024-01-11 00:56:30,311 [bic.py] => Stage1 dset: 4375, Stage2 dset: 275
2024-01-11 00:56:30,311 [bic.py] => Lambda: 0.600
2024-01-11 00:56:30,339 [bic.py] => Parameters of bias layer:
2024-01-11 00:56:30,339 [bic.py] => 0 => 1.000, 0.000
2024-01-11 00:56:30,339 [bic.py] => 1 => 1.000, 0.000
2024-01-11 00:56:57,846 [bic.py] => training => Task 1, Epoch 1/200 => Loss 2.145, Train_accy 35.360, Test_accy 20.240
2024-01-11 00:57:22,358 [bic.py] => training => Task 1, Epoch 2/200 => Loss 1.431, Train_accy 48.800, Test_accy 33.820
2024-01-11 00:57:49,449 [bic.py] => training => Task 1, Epoch 3/200 => Loss 1.282, Train_accy 62.350, Test_accy 41.200
2024-01-11 00:58:16,171 [bic.py] => training => Task 1, Epoch 4/200 => Loss 1.167, Train_accy 68.710, Test_accy 44.360
2024-01-11 00:58:41,883 [bic.py] => training => Task 1, Epoch 5/200 => Loss 1.075, Train_accy 78.720, Test_accy 48.730
2024-01-11 00:59:11,179 [bic.py] => training => Task 1, Epoch 6/200 => Loss 1.023, Train_accy 79.450, Test_accy 50.110
2024-01-11 00:59:37,222 [bic.py] => training => Task 1, Epoch 7/200 => Loss 0.968, Train_accy 83.340, Test_accy 51.360
2024-01-11 01:00:04,420 [bic.py] => training => Task 1, Epoch 8/200 => Loss 0.931, Train_accy 87.860, Test_accy 50.160
2024-01-11 01:00:34,021 [bic.py] => training => Task 1, Epoch 9/200 => Loss 0.905, Train_accy 90.100, Test_accy 51.640
2024-01-11 01:01:02,024 [bic.py] => training => Task 1, Epoch 10/200 => Loss 0.898, Train_accy 90.220, Test_accy 52.090
2024-01-11 01:01:29,531 [bic.py] => training => Task 1, Epoch 11/200 => Loss 0.868, Train_accy 91.980, Test_accy 53.090
2024-01-11 01:01:56,988 [bic.py] => training => Task 1, Epoch 12/200 => Loss 0.854, Train_accy 88.070, Test_accy 51.000
2024-01-11 01:02:24,150 [bic.py] => training => Task 1, Epoch 13/200 => Loss 0.825, Train_accy 93.230, Test_accy 52.760
2024-01-11 01:02:52,645 [bic.py] => training => Task 1, Epoch 14/200 => Loss 0.818, Train_accy 93.650, Test_accy 55.020
2024-01-11 01:03:20,506 [bic.py] => training => Task 1, Epoch 15/200 => Loss 0.828, Train_accy 94.150, Test_accy 53.870
2024-01-11 01:03:48,816 [bic.py] => training => Task 1, Epoch 16/200 => Loss 0.822, Train_accy 92.430, Test_accy 50.580
2024-01-11 01:04:17,488 [bic.py] => training => Task 1, Epoch 17/200 => Loss 0.810, Train_accy 94.470, Test_accy 55.360
2024-01-11 01:04:44,720 [bic.py] => training => Task 1, Epoch 18/200 => Loss 0.788, Train_accy 94.150, Test_accy 51.470
2024-01-11 01:05:12,175 [bic.py] => training => Task 1, Epoch 19/200 => Loss 0.816, Train_accy 93.780, Test_accy 54.780
2024-01-11 01:05:40,418 [bic.py] => training => Task 1, Epoch 20/200 => Loss 0.780, Train_accy 97.280, Test_accy 56.220
2024-01-11 01:06:07,447 [bic.py] => training => Task 1, Epoch 21/200 => Loss 0.746, Train_accy 97.490, Test_accy 54.420
2024-01-11 01:06:35,701 [bic.py] => training => Task 1, Epoch 22/200 => Loss 0.752, Train_accy 97.140, Test_accy 53.160
2024-01-11 01:07:04,348 [bic.py] => training => Task 1, Epoch 23/200 => Loss 0.739, Train_accy 93.990, Test_accy 54.380
2024-01-11 01:07:32,791 [bic.py] => training => Task 1, Epoch 24/200 => Loss 0.736, Train_accy 97.970, Test_accy 55.600
2024-01-11 01:08:01,263 [bic.py] => training => Task 1, Epoch 25/200 => Loss 0.729, Train_accy 98.350, Test_accy 56.730
2024-01-11 01:08:30,232 [bic.py] => training => Task 1, Epoch 26/200 => Loss 0.719, Train_accy 98.130, Test_accy 55.270
2024-01-11 01:08:58,064 [bic.py] => training => Task 1, Epoch 27/200 => Loss 0.739, Train_accy 98.060, Test_accy 58.160
2024-01-11 01:09:26,806 [bic.py] => training => Task 1, Epoch 28/200 => Loss 0.735, Train_accy 97.260, Test_accy 56.980
2024-01-11 01:09:54,672 [bic.py] => training => Task 1, Epoch 29/200 => Loss 0.764, Train_accy 96.480, Test_accy 54.090
2024-01-11 01:10:23,048 [bic.py] => training => Task 1, Epoch 30/200 => Loss 0.748, Train_accy 96.460, Test_accy 56.200
2024-01-11 01:10:49,975 [bic.py] => training => Task 1, Epoch 31/200 => Loss 0.761, Train_accy 94.010, Test_accy 53.440
2024-01-11 01:11:18,302 [bic.py] => training => Task 1, Epoch 32/200 => Loss 0.759, Train_accy 97.070, Test_accy 53.890
2024-01-11 01:11:48,359 [bic.py] => training => Task 1, Epoch 33/200 => Loss 0.731, Train_accy 97.460, Test_accy 54.930
2024-01-11 01:12:15,792 [bic.py] => training => Task 1, Epoch 34/200 => Loss 0.728, Train_accy 98.580, Test_accy 55.670
2024-01-11 01:12:44,043 [bic.py] => training => Task 1, Epoch 35/200 => Loss 0.743, Train_accy 98.490, Test_accy 56.710
2024-01-11 01:13:13,113 [bic.py] => training => Task 1, Epoch 36/200 => Loss 0.726, Train_accy 97.670, Test_accy 54.580
2024-01-11 01:13:40,026 [bic.py] => training => Task 1, Epoch 37/200 => Loss 0.714, Train_accy 98.540, Test_accy 57.110
2024-01-11 01:14:08,076 [bic.py] => training => Task 1, Epoch 38/200 => Loss 0.705, Train_accy 98.740, Test_accy 56.440
2024-01-11 01:14:36,373 [bic.py] => training => Task 1, Epoch 39/200 => Loss 0.716, Train_accy 97.810, Test_accy 55.930
2024-01-11 01:15:04,868 [bic.py] => training => Task 1, Epoch 40/200 => Loss 0.732, Train_accy 95.730, Test_accy 52.440
2024-01-11 01:15:33,103 [bic.py] => training => Task 1, Epoch 41/200 => Loss 0.715, Train_accy 97.440, Test_accy 55.400
2024-01-11 01:16:00,964 [bic.py] => training => Task 1, Epoch 42/200 => Loss 0.708, Train_accy 99.150, Test_accy 57.510
2024-01-11 01:16:29,019 [bic.py] => training => Task 1, Epoch 43/200 => Loss 0.709, Train_accy 99.250, Test_accy 56.800
2024-01-11 01:16:58,405 [bic.py] => training => Task 1, Epoch 44/200 => Loss 0.716, Train_accy 97.260, Test_accy 54.040
2024-01-11 01:17:26,890 [bic.py] => training => Task 1, Epoch 45/200 => Loss 0.703, Train_accy 98.900, Test_accy 57.180
2024-01-11 01:17:56,739 [bic.py] => training => Task 1, Epoch 46/200 => Loss 0.743, Train_accy 94.830, Test_accy 49.890
2024-01-11 01:18:24,940 [bic.py] => training => Task 1, Epoch 47/200 => Loss 0.730, Train_accy 98.130, Test_accy 55.760
2024-01-11 01:18:52,470 [bic.py] => training => Task 1, Epoch 48/200 => Loss 0.702, Train_accy 99.680, Test_accy 57.000
2024-01-11 01:19:21,566 [bic.py] => training => Task 1, Epoch 49/200 => Loss 0.703, Train_accy 99.360, Test_accy 57.910
2024-01-11 01:19:52,308 [bic.py] => training => Task 1, Epoch 50/200 => Loss 0.707, Train_accy 99.340, Test_accy 58.240
2024-01-11 01:20:22,420 [bic.py] => training => Task 1, Epoch 51/200 => Loss 0.714, Train_accy 96.300, Test_accy 51.840
2024-01-11 01:20:51,686 [bic.py] => training => Task 1, Epoch 52/200 => Loss 0.721, Train_accy 97.740, Test_accy 53.690
2024-01-11 01:21:20,242 [bic.py] => training => Task 1, Epoch 53/200 => Loss 0.717, Train_accy 99.040, Test_accy 57.780
2024-01-11 01:21:48,136 [bic.py] => training => Task 1, Epoch 54/200 => Loss 0.702, Train_accy 99.700, Test_accy 57.910
2024-01-11 01:22:16,740 [bic.py] => training => Task 1, Epoch 55/200 => Loss 0.704, Train_accy 99.450, Test_accy 58.780
2024-01-11 01:22:44,974 [bic.py] => training => Task 1, Epoch 56/200 => Loss 0.723, Train_accy 96.850, Test_accy 54.840
2024-01-11 01:23:15,051 [bic.py] => training => Task 1, Epoch 57/200 => Loss 0.732, Train_accy 97.440, Test_accy 56.600
2024-01-11 01:23:44,474 [bic.py] => training => Task 1, Epoch 58/200 => Loss 0.735, Train_accy 94.970, Test_accy 51.070
2024-01-11 01:24:12,960 [bic.py] => training => Task 1, Epoch 59/200 => Loss 0.794, Train_accy 90.170, Test_accy 50.580
2024-01-11 01:24:40,052 [bic.py] => training => Task 1, Epoch 60/200 => Loss 0.751, Train_accy 96.550, Test_accy 56.110
2024-01-11 01:25:10,597 [bic.py] => training => Task 1, Epoch 61/200 => Loss 0.698, Train_accy 99.890, Test_accy 59.180
2024-01-11 01:25:38,331 [bic.py] => training => Task 1, Epoch 62/200 => Loss 0.684, Train_accy 99.980, Test_accy 59.620
2024-01-11 01:26:06,553 [bic.py] => training => Task 1, Epoch 63/200 => Loss 0.676, Train_accy 99.930, Test_accy 59.930
2024-01-11 01:26:33,805 [bic.py] => training => Task 1, Epoch 64/200 => Loss 0.676, Train_accy 99.980, Test_accy 60.730
2024-01-11 01:27:01,571 [bic.py] => training => Task 1, Epoch 65/200 => Loss 0.676, Train_accy 99.980, Test_accy 60.090
2024-01-11 01:27:28,861 [bic.py] => training => Task 1, Epoch 66/200 => Loss 0.670, Train_accy 99.980, Test_accy 60.470
2024-01-11 01:27:58,240 [bic.py] => training => Task 1, Epoch 67/200 => Loss 0.669, Train_accy 99.950, Test_accy 60.240
2024-01-11 01:28:26,755 [bic.py] => training => Task 1, Epoch 68/200 => Loss 0.671, Train_accy 99.950, Test_accy 60.330
2024-01-11 01:28:56,113 [bic.py] => training => Task 1, Epoch 69/200 => Loss 0.671, Train_accy 99.980, Test_accy 60.530
2024-01-11 01:29:24,642 [bic.py] => training => Task 1, Epoch 70/200 => Loss 0.671, Train_accy 99.950, Test_accy 60.560
2024-01-11 01:29:52,923 [bic.py] => training => Task 1, Epoch 71/200 => Loss 0.672, Train_accy 99.980, Test_accy 60.580
2024-01-11 01:30:19,908 [bic.py] => training => Task 1, Epoch 72/200 => Loss 0.672, Train_accy 99.980, Test_accy 60.840
2024-01-11 01:30:47,581 [bic.py] => training => Task 1, Epoch 73/200 => Loss 0.675, Train_accy 99.980, Test_accy 60.560
2024-01-11 01:31:14,875 [bic.py] => training => Task 1, Epoch 74/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.690
2024-01-11 01:31:42,375 [bic.py] => training => Task 1, Epoch 75/200 => Loss 0.666, Train_accy 99.980, Test_accy 60.840
2024-01-11 01:32:09,899 [bic.py] => training => Task 1, Epoch 76/200 => Loss 0.667, Train_accy 99.980, Test_accy 60.220
2024-01-11 01:32:38,455 [bic.py] => training => Task 1, Epoch 77/200 => Loss 0.670, Train_accy 100.000, Test_accy 60.930
2024-01-11 01:33:04,986 [bic.py] => training => Task 1, Epoch 78/200 => Loss 0.667, Train_accy 99.980, Test_accy 60.490
2024-01-11 01:33:33,234 [bic.py] => training => Task 1, Epoch 79/200 => Loss 0.671, Train_accy 99.980, Test_accy 60.560
2024-01-11 01:34:02,001 [bic.py] => training => Task 1, Epoch 80/200 => Loss 0.665, Train_accy 100.000, Test_accy 60.180
2024-01-11 01:34:30,588 [bic.py] => training => Task 1, Epoch 81/200 => Loss 0.665, Train_accy 100.000, Test_accy 60.490
2024-01-11 01:34:59,526 [bic.py] => training => Task 1, Epoch 82/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.290
2024-01-11 01:35:27,286 [bic.py] => training => Task 1, Epoch 83/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.670
2024-01-11 01:35:54,863 [bic.py] => training => Task 1, Epoch 84/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.090
2024-01-11 01:36:22,948 [bic.py] => training => Task 1, Epoch 85/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.530
2024-01-11 01:36:50,973 [bic.py] => training => Task 1, Epoch 86/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.160
2024-01-11 01:37:18,474 [bic.py] => training => Task 1, Epoch 87/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.200
2024-01-11 01:37:47,195 [bic.py] => training => Task 1, Epoch 88/200 => Loss 0.661, Train_accy 99.980, Test_accy 60.070
2024-01-11 01:38:15,130 [bic.py] => training => Task 1, Epoch 89/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.620
2024-01-11 01:38:41,520 [bic.py] => training => Task 1, Epoch 90/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.240
2024-01-11 01:39:10,200 [bic.py] => training => Task 1, Epoch 91/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.840
2024-01-11 01:39:37,888 [bic.py] => training => Task 1, Epoch 92/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.090
2024-01-11 01:40:06,364 [bic.py] => training => Task 1, Epoch 93/200 => Loss 0.663, Train_accy 100.000, Test_accy 59.890
2024-01-11 01:40:34,128 [bic.py] => training => Task 1, Epoch 94/200 => Loss 0.662, Train_accy 100.000, Test_accy 59.800
2024-01-11 01:41:01,981 [bic.py] => training => Task 1, Epoch 95/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.420
2024-01-11 01:41:28,503 [bic.py] => training => Task 1, Epoch 96/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.560
2024-01-11 01:41:55,305 [bic.py] => training => Task 1, Epoch 97/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.380
2024-01-11 01:42:23,143 [bic.py] => training => Task 1, Epoch 98/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.600
2024-01-11 01:42:50,798 [bic.py] => training => Task 1, Epoch 99/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.840
2024-01-11 01:43:18,433 [bic.py] => training => Task 1, Epoch 100/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.890
2024-01-11 01:43:45,774 [bic.py] => training => Task 1, Epoch 101/200 => Loss 0.658, Train_accy 100.000, Test_accy 60.290
2024-01-11 01:44:12,978 [bic.py] => training => Task 1, Epoch 102/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.440
2024-01-11 01:44:38,781 [bic.py] => training => Task 1, Epoch 103/200 => Loss 0.670, Train_accy 100.000, Test_accy 60.600
2024-01-11 01:45:07,026 [bic.py] => training => Task 1, Epoch 104/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.670
2024-01-11 01:45:34,336 [bic.py] => training => Task 1, Epoch 105/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.910
2024-01-11 01:46:02,694 [bic.py] => training => Task 1, Epoch 106/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.960
2024-01-11 01:46:30,392 [bic.py] => training => Task 1, Epoch 107/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.640
2024-01-11 01:46:58,090 [bic.py] => training => Task 1, Epoch 108/200 => Loss 0.659, Train_accy 99.980, Test_accy 60.600
2024-01-11 01:47:24,372 [bic.py] => training => Task 1, Epoch 109/200 => Loss 0.667, Train_accy 100.000, Test_accy 61.200
2024-01-11 01:47:52,352 [bic.py] => training => Task 1, Epoch 110/200 => Loss 0.658, Train_accy 100.000, Test_accy 60.730
2024-01-11 01:48:19,531 [bic.py] => training => Task 1, Epoch 111/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.580
2024-01-11 01:48:47,806 [bic.py] => training => Task 1, Epoch 112/200 => Loss 0.665, Train_accy 100.000, Test_accy 60.470
2024-01-11 01:49:14,878 [bic.py] => training => Task 1, Epoch 113/200 => Loss 0.662, Train_accy 99.980, Test_accy 60.640
2024-01-11 01:49:42,500 [bic.py] => training => Task 1, Epoch 114/200 => Loss 0.666, Train_accy 100.000, Test_accy 61.070
2024-01-11 01:50:10,002 [bic.py] => training => Task 1, Epoch 115/200 => Loss 0.670, Train_accy 100.000, Test_accy 60.820
2024-01-11 01:50:38,941 [bic.py] => training => Task 1, Epoch 116/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.870
2024-01-11 01:51:07,179 [bic.py] => training => Task 1, Epoch 117/200 => Loss 0.665, Train_accy 100.000, Test_accy 60.510
2024-01-11 01:51:35,346 [bic.py] => training => Task 1, Epoch 118/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.310
2024-01-11 01:52:02,335 [bic.py] => training => Task 1, Epoch 119/200 => Loss 0.664, Train_accy 100.000, Test_accy 60.510
2024-01-11 01:52:31,448 [bic.py] => training => Task 1, Epoch 120/200 => Loss 0.664, Train_accy 100.000, Test_accy 60.440
2024-01-11 01:52:58,390 [bic.py] => training => Task 1, Epoch 121/200 => Loss 0.660, Train_accy 99.980, Test_accy 60.690
2024-01-11 01:53:25,770 [bic.py] => training => Task 1, Epoch 122/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.800
2024-01-11 01:53:52,307 [bic.py] => training => Task 1, Epoch 123/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.640
2024-01-11 01:54:19,395 [bic.py] => training => Task 1, Epoch 124/200 => Loss 0.661, Train_accy 100.000, Test_accy 61.000
2024-01-11 01:54:46,657 [bic.py] => training => Task 1, Epoch 125/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.670
2024-01-11 01:55:13,552 [bic.py] => training => Task 1, Epoch 126/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.380
2024-01-11 01:55:41,343 [bic.py] => training => Task 1, Epoch 127/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.240
2024-01-11 01:56:08,050 [bic.py] => training => Task 1, Epoch 128/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.620
2024-01-11 01:56:35,284 [bic.py] => training => Task 1, Epoch 129/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.530
2024-01-11 01:57:02,640 [bic.py] => training => Task 1, Epoch 130/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.760
2024-01-11 01:57:30,007 [bic.py] => training => Task 1, Epoch 131/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.470
2024-01-11 01:57:57,319 [bic.py] => training => Task 1, Epoch 132/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.600
2024-01-11 01:58:24,359 [bic.py] => training => Task 1, Epoch 133/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.730
2024-01-11 01:58:50,351 [bic.py] => training => Task 1, Epoch 134/200 => Loss 0.664, Train_accy 100.000, Test_accy 61.000
2024-01-11 01:59:16,980 [bic.py] => training => Task 1, Epoch 135/200 => Loss 0.667, Train_accy 99.980, Test_accy 59.980
2024-01-11 01:59:44,030 [bic.py] => training => Task 1, Epoch 136/200 => Loss 0.659, Train_accy 100.000, Test_accy 61.160
2024-01-11 02:00:11,671 [bic.py] => training => Task 1, Epoch 137/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.560
2024-01-11 02:00:39,109 [bic.py] => training => Task 1, Epoch 138/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.330
2024-01-11 02:01:07,126 [bic.py] => training => Task 1, Epoch 139/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.780
2024-01-11 02:01:33,942 [bic.py] => training => Task 1, Epoch 140/200 => Loss 0.660, Train_accy 100.000, Test_accy 61.110
2024-01-11 02:02:00,690 [bic.py] => training => Task 1, Epoch 141/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.600
2024-01-11 02:02:27,596 [bic.py] => training => Task 1, Epoch 142/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.890
2024-01-11 02:02:55,341 [bic.py] => training => Task 1, Epoch 143/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.910
2024-01-11 02:03:22,776 [bic.py] => training => Task 1, Epoch 144/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.600
2024-01-11 02:03:49,909 [bic.py] => training => Task 1, Epoch 145/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.490
2024-01-11 02:04:16,832 [bic.py] => training => Task 1, Epoch 146/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.290
2024-01-11 02:04:43,249 [bic.py] => training => Task 1, Epoch 147/200 => Loss 0.667, Train_accy 100.000, Test_accy 60.730
2024-01-11 02:05:09,673 [bic.py] => training => Task 1, Epoch 148/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.490
2024-01-11 02:05:36,429 [bic.py] => training => Task 1, Epoch 149/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.560
2024-01-11 02:06:03,450 [bic.py] => training => Task 1, Epoch 150/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.240
2024-01-11 02:06:30,245 [bic.py] => training => Task 1, Epoch 151/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.620
2024-01-11 02:06:57,542 [bic.py] => training => Task 1, Epoch 152/200 => Loss 0.664, Train_accy 100.000, Test_accy 60.530
2024-01-11 02:07:24,321 [bic.py] => training => Task 1, Epoch 153/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.620
2024-01-11 02:07:51,243 [bic.py] => training => Task 1, Epoch 154/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.400
2024-01-11 02:08:17,433 [bic.py] => training => Task 1, Epoch 155/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.690
2024-01-11 02:08:44,986 [bic.py] => training => Task 1, Epoch 156/200 => Loss 0.662, Train_accy 100.000, Test_accy 61.020
2024-01-11 02:09:12,214 [bic.py] => training => Task 1, Epoch 157/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.640
2024-01-11 02:09:40,119 [bic.py] => training => Task 1, Epoch 158/200 => Loss 0.656, Train_accy 100.000, Test_accy 60.290
2024-01-11 02:10:07,298 [bic.py] => training => Task 1, Epoch 159/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.760
2024-01-11 02:10:34,685 [bic.py] => training => Task 1, Epoch 160/200 => Loss 0.658, Train_accy 100.000, Test_accy 60.470
2024-01-11 02:11:00,937 [bic.py] => training => Task 1, Epoch 161/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.780
2024-01-11 02:11:28,238 [bic.py] => training => Task 1, Epoch 162/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.310
2024-01-11 02:11:55,766 [bic.py] => training => Task 1, Epoch 163/200 => Loss 0.657, Train_accy 100.000, Test_accy 60.180
2024-01-11 02:12:22,745 [bic.py] => training => Task 1, Epoch 164/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.870
2024-01-11 02:12:50,344 [bic.py] => training => Task 1, Epoch 165/200 => Loss 0.658, Train_accy 100.000, Test_accy 60.560
2024-01-11 02:13:16,929 [bic.py] => training => Task 1, Epoch 166/200 => Loss 0.656, Train_accy 100.000, Test_accy 60.800
2024-01-11 02:13:43,502 [bic.py] => training => Task 1, Epoch 167/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.870
2024-01-11 02:14:09,216 [bic.py] => training => Task 1, Epoch 168/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.490
2024-01-11 02:14:36,107 [bic.py] => training => Task 1, Epoch 169/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.560
2024-01-11 02:15:02,906 [bic.py] => training => Task 1, Epoch 170/200 => Loss 0.663, Train_accy 100.000, Test_accy 59.910
2024-01-11 02:15:30,523 [bic.py] => training => Task 1, Epoch 171/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.420
2024-01-11 02:15:57,319 [bic.py] => training => Task 1, Epoch 172/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.910
2024-01-11 02:16:24,782 [bic.py] => training => Task 1, Epoch 173/200 => Loss 0.669, Train_accy 100.000, Test_accy 60.510
2024-01-11 02:16:50,262 [bic.py] => training => Task 1, Epoch 174/200 => Loss 0.667, Train_accy 100.000, Test_accy 61.000
2024-01-11 02:17:17,256 [bic.py] => training => Task 1, Epoch 175/200 => Loss 0.659, Train_accy 100.000, Test_accy 60.440
2024-01-11 02:17:45,123 [bic.py] => training => Task 1, Epoch 176/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.800
2024-01-11 02:18:12,157 [bic.py] => training => Task 1, Epoch 177/200 => Loss 0.658, Train_accy 100.000, Test_accy 60.690
2024-01-11 02:18:39,392 [bic.py] => training => Task 1, Epoch 178/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.380
2024-01-11 02:19:06,680 [bic.py] => training => Task 1, Epoch 179/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.200
2024-01-11 02:19:33,890 [bic.py] => training => Task 1, Epoch 180/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.420
2024-01-11 02:20:01,258 [bic.py] => training => Task 1, Epoch 181/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.600
2024-01-11 02:20:28,424 [bic.py] => training => Task 1, Epoch 182/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.510
2024-01-11 02:20:55,312 [bic.py] => training => Task 1, Epoch 183/200 => Loss 0.664, Train_accy 100.000, Test_accy 60.530
2024-01-11 02:21:21,975 [bic.py] => training => Task 1, Epoch 184/200 => Loss 0.658, Train_accy 100.000, Test_accy 60.420
2024-01-11 02:21:47,867 [bic.py] => training => Task 1, Epoch 185/200 => Loss 0.660, Train_accy 99.980, Test_accy 60.620
2024-01-11 02:22:14,097 [bic.py] => training => Task 1, Epoch 186/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.510
2024-01-11 02:22:39,617 [bic.py] => training => Task 1, Epoch 187/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.310
2024-01-11 02:23:05,667 [bic.py] => training => Task 1, Epoch 188/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.800
2024-01-11 02:23:31,310 [bic.py] => training => Task 1, Epoch 189/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.490
2024-01-11 02:23:58,013 [bic.py] => training => Task 1, Epoch 190/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.560
2024-01-11 02:24:25,441 [bic.py] => training => Task 1, Epoch 191/200 => Loss 0.657, Train_accy 99.980, Test_accy 60.490
2024-01-11 02:24:51,441 [bic.py] => training => Task 1, Epoch 192/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.690
2024-01-11 02:25:17,716 [bic.py] => training => Task 1, Epoch 193/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.780
2024-01-11 02:25:45,073 [bic.py] => training => Task 1, Epoch 194/200 => Loss 0.666, Train_accy 100.000, Test_accy 60.110
2024-01-11 02:26:11,383 [bic.py] => training => Task 1, Epoch 195/200 => Loss 0.662, Train_accy 100.000, Test_accy 60.440
2024-01-11 02:26:37,387 [bic.py] => training => Task 1, Epoch 196/200 => Loss 0.660, Train_accy 100.000, Test_accy 60.400
2024-01-11 02:27:04,451 [bic.py] => training => Task 1, Epoch 197/200 => Loss 0.661, Train_accy 100.000, Test_accy 60.200
2024-01-11 02:27:30,601 [bic.py] => training => Task 1, Epoch 198/200 => Loss 0.663, Train_accy 100.000, Test_accy 60.490
2024-01-11 02:27:57,288 [bic.py] => training => Task 1, Epoch 199/200 => Loss 0.665, Train_accy 100.000, Test_accy 60.110
2024-01-11 02:28:24,132 [bic.py] => training => Task 1, Epoch 200/200 => Loss 0.665, Train_accy 99.980, Test_accy 60.470
2024-01-11 02:28:33,070 [bic.py] => bias_correction => Task 1, Epoch 1/200 => Loss 2.841, Train_accy 65.090, Test_accy 65.330
2024-01-11 02:28:43,095 [bic.py] => bias_correction => Task 1, Epoch 2/200 => Loss 2.700, Train_accy 71.270, Test_accy 66.800
2024-01-11 02:28:51,961 [bic.py] => bias_correction => Task 1, Epoch 3/200 => Loss 2.762, Train_accy 66.180, Test_accy 61.220
2024-01-11 02:29:01,160 [bic.py] => bias_correction => Task 1, Epoch 4/200 => Loss 2.803, Train_accy 68.360, Test_accy 65.960
2024-01-11 02:29:10,890 [bic.py] => bias_correction => Task 1, Epoch 5/200 => Loss 2.783, Train_accy 61.820, Test_accy 63.670
2024-01-11 02:29:19,969 [bic.py] => bias_correction => Task 1, Epoch 6/200 => Loss 2.727, Train_accy 65.820, Test_accy 65.040
2024-01-11 02:29:28,744 [bic.py] => bias_correction => Task 1, Epoch 7/200 => Loss 2.698, Train_accy 67.270, Test_accy 63.690
2024-01-11 02:29:37,916 [bic.py] => bias_correction => Task 1, Epoch 8/200 => Loss 2.760, Train_accy 65.090, Test_accy 64.270
2024-01-11 02:29:46,736 [bic.py] => bias_correction => Task 1, Epoch 9/200 => Loss 2.742, Train_accy 64.000, Test_accy 64.600
2024-01-11 02:29:55,629 [bic.py] => bias_correction => Task 1, Epoch 10/200 => Loss 2.735, Train_accy 64.360, Test_accy 64.470
2024-01-11 02:30:04,489 [bic.py] => bias_correction => Task 1, Epoch 11/200 => Loss 2.709, Train_accy 64.000, Test_accy 64.470
2024-01-11 02:30:14,547 [bic.py] => bias_correction => Task 1, Epoch 12/200 => Loss 2.717, Train_accy 65.820, Test_accy 64.000
2024-01-11 02:30:23,220 [bic.py] => bias_correction => Task 1, Epoch 13/200 => Loss 2.739, Train_accy 64.730, Test_accy 64.020
2024-01-11 02:30:31,917 [bic.py] => bias_correction => Task 1, Epoch 14/200 => Loss 2.754, Train_accy 61.450, Test_accy 62.200
2024-01-11 02:30:40,900 [bic.py] => bias_correction => Task 1, Epoch 15/200 => Loss 2.742, Train_accy 62.910, Test_accy 63.690
2024-01-11 02:30:49,802 [bic.py] => bias_correction => Task 1, Epoch 16/200 => Loss 2.773, Train_accy 66.550, Test_accy 62.980
2024-01-11 02:30:58,913 [bic.py] => bias_correction => Task 1, Epoch 17/200 => Loss 2.764, Train_accy 63.640, Test_accy 63.580
2024-01-11 02:31:07,406 [bic.py] => bias_correction => Task 1, Epoch 18/200 => Loss 2.763, Train_accy 57.450, Test_accy 59.400
2024-01-11 02:31:17,390 [bic.py] => bias_correction => Task 1, Epoch 19/200 => Loss 2.749, Train_accy 60.000, Test_accy 60.290
2024-01-11 02:31:26,207 [bic.py] => bias_correction => Task 1, Epoch 20/200 => Loss 2.730, Train_accy 66.180, Test_accy 64.270
2024-01-11 02:31:35,248 [bic.py] => bias_correction => Task 1, Epoch 21/200 => Loss 2.720, Train_accy 65.090, Test_accy 60.360
2024-01-11 02:31:43,905 [bic.py] => bias_correction => Task 1, Epoch 22/200 => Loss 2.757, Train_accy 65.820, Test_accy 63.780
2024-01-11 02:31:52,670 [bic.py] => bias_correction => Task 1, Epoch 23/200 => Loss 2.751, Train_accy 62.180, Test_accy 63.420
2024-01-11 02:32:01,549 [bic.py] => bias_correction => Task 1, Epoch 24/200 => Loss 2.767, Train_accy 63.270, Test_accy 64.220
2024-01-11 02:32:10,636 [bic.py] => bias_correction => Task 1, Epoch 25/200 => Loss 2.690, Train_accy 66.550, Test_accy 63.040
2024-01-11 02:32:20,288 [bic.py] => bias_correction => Task 1, Epoch 26/200 => Loss 2.721, Train_accy 66.180, Test_accy 64.310
2024-01-11 02:32:29,142 [bic.py] => bias_correction => Task 1, Epoch 27/200 => Loss 2.742, Train_accy 65.090, Test_accy 65.510
2024-01-11 02:32:38,152 [bic.py] => bias_correction => Task 1, Epoch 28/200 => Loss 2.756, Train_accy 62.910, Test_accy 64.530
2024-01-11 02:32:46,995 [bic.py] => bias_correction => Task 1, Epoch 29/200 => Loss 2.726, Train_accy 64.360, Test_accy 64.290
2024-01-11 02:32:56,222 [bic.py] => bias_correction => Task 1, Epoch 30/200 => Loss 2.776, Train_accy 66.550, Test_accy 64.730
2024-01-11 02:33:05,690 [bic.py] => bias_correction => Task 1, Epoch 31/200 => Loss 2.774, Train_accy 64.360, Test_accy 59.670
2024-01-11 02:33:15,765 [bic.py] => bias_correction => Task 1, Epoch 32/200 => Loss 2.762, Train_accy 64.730, Test_accy 61.760
2024-01-11 02:33:25,044 [bic.py] => bias_correction => Task 1, Epoch 33/200 => Loss 2.746, Train_accy 62.550, Test_accy 63.560
2024-01-11 02:33:33,846 [bic.py] => bias_correction => Task 1, Epoch 34/200 => Loss 2.756, Train_accy 61.450, Test_accy 63.510
2024-01-11 02:33:43,139 [bic.py] => bias_correction => Task 1, Epoch 35/200 => Loss 2.737, Train_accy 63.640, Test_accy 64.330
2024-01-11 02:33:51,417 [bic.py] => bias_correction => Task 1, Epoch 36/200 => Loss 2.734, Train_accy 65.450, Test_accy 64.110
2024-01-11 02:34:01,032 [bic.py] => bias_correction => Task 1, Epoch 37/200 => Loss 2.749, Train_accy 63.640, Test_accy 64.420
2024-01-11 02:34:09,752 [bic.py] => bias_correction => Task 1, Epoch 38/200 => Loss 2.698, Train_accy 64.360, Test_accy 64.640
2024-01-11 02:34:19,105 [bic.py] => bias_correction => Task 1, Epoch 39/200 => Loss 2.715, Train_accy 66.910, Test_accy 64.710
2024-01-11 02:34:28,261 [bic.py] => bias_correction => Task 1, Epoch 40/200 => Loss 2.678, Train_accy 66.910, Test_accy 64.960
2024-01-11 02:34:37,083 [bic.py] => bias_correction => Task 1, Epoch 41/200 => Loss 2.744, Train_accy 65.450, Test_accy 65.130
2024-01-11 02:34:46,003 [bic.py] => bias_correction => Task 1, Epoch 42/200 => Loss 2.722, Train_accy 65.090, Test_accy 65.070
2024-01-11 02:34:54,909 [bic.py] => bias_correction => Task 1, Epoch 43/200 => Loss 2.696, Train_accy 66.550, Test_accy 65.200
2024-01-11 02:35:03,820 [bic.py] => bias_correction => Task 1, Epoch 44/200 => Loss 2.751, Train_accy 66.180, Test_accy 65.220
2024-01-11 02:35:12,637 [bic.py] => bias_correction => Task 1, Epoch 45/200 => Loss 2.720, Train_accy 64.000, Test_accy 64.580
2024-01-11 02:35:21,928 [bic.py] => bias_correction => Task 1, Epoch 46/200 => Loss 2.729, Train_accy 64.360, Test_accy 65.160
2024-01-11 02:35:31,053 [bic.py] => bias_correction => Task 1, Epoch 47/200 => Loss 2.692, Train_accy 67.270, Test_accy 64.560
2024-01-11 02:35:39,766 [bic.py] => bias_correction => Task 1, Epoch 48/200 => Loss 2.741, Train_accy 63.640, Test_accy 64.290
2024-01-11 02:35:48,537 [bic.py] => bias_correction => Task 1, Epoch 49/200 => Loss 2.701, Train_accy 64.730, Test_accy 64.600
2024-01-11 02:35:57,245 [bic.py] => bias_correction => Task 1, Epoch 50/200 => Loss 2.745, Train_accy 64.730, Test_accy 64.760
2024-01-11 02:36:06,259 [bic.py] => bias_correction => Task 1, Epoch 51/200 => Loss 2.768, Train_accy 64.000, Test_accy 64.270
2024-01-11 02:36:15,192 [bic.py] => bias_correction => Task 1, Epoch 52/200 => Loss 2.754, Train_accy 64.730, Test_accy 64.310
2024-01-11 02:36:25,020 [bic.py] => bias_correction => Task 1, Epoch 53/200 => Loss 2.725, Train_accy 64.730, Test_accy 64.760
2024-01-11 02:36:33,446 [bic.py] => bias_correction => Task 1, Epoch 54/200 => Loss 2.729, Train_accy 66.910, Test_accy 65.510
2024-01-11 02:36:43,042 [bic.py] => bias_correction => Task 1, Epoch 55/200 => Loss 2.737, Train_accy 66.550, Test_accy 64.270
2024-01-11 02:36:51,970 [bic.py] => bias_correction => Task 1, Epoch 56/200 => Loss 2.724, Train_accy 66.910, Test_accy 64.220
2024-01-11 02:37:00,781 [bic.py] => bias_correction => Task 1, Epoch 57/200 => Loss 2.698, Train_accy 67.270, Test_accy 64.690
2024-01-11 02:37:09,409 [bic.py] => bias_correction => Task 1, Epoch 58/200 => Loss 2.696, Train_accy 64.360, Test_accy 65.580
2024-01-11 02:37:18,659 [bic.py] => bias_correction => Task 1, Epoch 59/200 => Loss 2.710, Train_accy 61.820, Test_accy 64.160
2024-01-11 02:37:28,024 [bic.py] => bias_correction => Task 1, Epoch 60/200 => Loss 2.734, Train_accy 63.640, Test_accy 64.780
2024-01-11 02:37:36,960 [bic.py] => bias_correction => Task 1, Epoch 61/200 => Loss 2.755, Train_accy 63.640, Test_accy 64.670
2024-01-11 02:37:45,745 [bic.py] => bias_correction => Task 1, Epoch 62/200 => Loss 2.701, Train_accy 64.730, Test_accy 65.000
2024-01-11 02:37:54,797 [bic.py] => bias_correction => Task 1, Epoch 63/200 => Loss 2.772, Train_accy 65.090, Test_accy 64.980
2024-01-11 02:38:03,478 [bic.py] => bias_correction => Task 1, Epoch 64/200 => Loss 2.752, Train_accy 64.360, Test_accy 64.110
2024-01-11 02:38:12,148 [bic.py] => bias_correction => Task 1, Epoch 65/200 => Loss 2.764, Train_accy 64.000, Test_accy 63.440
2024-01-11 02:38:21,266 [bic.py] => bias_correction => Task 1, Epoch 66/200 => Loss 2.713, Train_accy 65.820, Test_accy 63.420
2024-01-11 02:38:30,935 [bic.py] => bias_correction => Task 1, Epoch 67/200 => Loss 2.661, Train_accy 65.820, Test_accy 63.470
2024-01-11 02:38:40,271 [bic.py] => bias_correction => Task 1, Epoch 68/200 => Loss 2.691, Train_accy 66.180, Test_accy 63.760
2024-01-11 02:38:49,185 [bic.py] => bias_correction => Task 1, Epoch 69/200 => Loss 2.723, Train_accy 66.180, Test_accy 63.910
2024-01-11 02:38:57,992 [bic.py] => bias_correction => Task 1, Epoch 70/200 => Loss 2.768, Train_accy 65.090, Test_accy 63.780
2024-01-11 02:39:06,643 [bic.py] => bias_correction => Task 1, Epoch 71/200 => Loss 2.734, Train_accy 66.180, Test_accy 63.560
2024-01-11 02:39:14,928 [bic.py] => bias_correction => Task 1, Epoch 72/200 => Loss 2.720, Train_accy 66.180, Test_accy 64.580
2024-01-11 02:39:24,187 [bic.py] => bias_correction => Task 1, Epoch 73/200 => Loss 2.703, Train_accy 66.180, Test_accy 64.910
2024-01-11 02:39:33,842 [bic.py] => bias_correction => Task 1, Epoch 74/200 => Loss 2.734, Train_accy 65.090, Test_accy 64.380
2024-01-11 02:39:43,285 [bic.py] => bias_correction => Task 1, Epoch 75/200 => Loss 2.749, Train_accy 64.000, Test_accy 64.240
2024-01-11 02:39:51,958 [bic.py] => bias_correction => Task 1, Epoch 76/200 => Loss 2.748, Train_accy 63.270, Test_accy 64.310
2024-01-11 02:40:00,733 [bic.py] => bias_correction => Task 1, Epoch 77/200 => Loss 2.691, Train_accy 65.450, Test_accy 64.620
2024-01-11 02:40:09,363 [bic.py] => bias_correction => Task 1, Epoch 78/200 => Loss 2.767, Train_accy 65.450, Test_accy 64.560
2024-01-11 02:40:18,376 [bic.py] => bias_correction => Task 1, Epoch 79/200 => Loss 2.702, Train_accy 65.820, Test_accy 64.470
2024-01-11 02:40:27,339 [bic.py] => bias_correction => Task 1, Epoch 80/200 => Loss 2.724, Train_accy 65.090, Test_accy 64.560
2024-01-11 02:40:36,996 [bic.py] => bias_correction => Task 1, Epoch 81/200 => Loss 2.695, Train_accy 66.550, Test_accy 65.310
2024-01-11 02:40:46,158 [bic.py] => bias_correction => Task 1, Epoch 82/200 => Loss 2.714, Train_accy 65.450, Test_accy 64.760
2024-01-11 02:40:54,547 [bic.py] => bias_correction => Task 1, Epoch 83/200 => Loss 2.749, Train_accy 64.360, Test_accy 64.440
2024-01-11 02:41:03,535 [bic.py] => bias_correction => Task 1, Epoch 84/200 => Loss 2.676, Train_accy 65.820, Test_accy 65.160
2024-01-11 02:41:12,277 [bic.py] => bias_correction => Task 1, Epoch 85/200 => Loss 2.711, Train_accy 66.550, Test_accy 65.090
2024-01-11 02:41:21,007 [bic.py] => bias_correction => Task 1, Epoch 86/200 => Loss 2.737, Train_accy 66.910, Test_accy 64.560
2024-01-11 02:41:29,563 [bic.py] => bias_correction => Task 1, Epoch 87/200 => Loss 2.730, Train_accy 66.910, Test_accy 65.020
2024-01-11 02:41:39,103 [bic.py] => bias_correction => Task 1, Epoch 88/200 => Loss 2.732, Train_accy 66.550, Test_accy 64.620
2024-01-11 02:41:48,145 [bic.py] => bias_correction => Task 1, Epoch 89/200 => Loss 2.748, Train_accy 66.910, Test_accy 65.240
2024-01-11 02:41:57,225 [bic.py] => bias_correction => Task 1, Epoch 90/200 => Loss 2.725, Train_accy 66.180, Test_accy 64.070
2024-01-11 02:42:06,239 [bic.py] => bias_correction => Task 1, Epoch 91/200 => Loss 2.708, Train_accy 65.090, Test_accy 64.800
2024-01-11 02:42:14,865 [bic.py] => bias_correction => Task 1, Epoch 92/200 => Loss 2.752, Train_accy 65.450, Test_accy 64.510
2024-01-11 02:42:23,564 [bic.py] => bias_correction => Task 1, Epoch 93/200 => Loss 2.701, Train_accy 66.910, Test_accy 64.380
2024-01-11 02:42:32,359 [bic.py] => bias_correction => Task 1, Epoch 94/200 => Loss 2.772, Train_accy 64.730, Test_accy 63.580
2024-01-11 02:42:42,086 [bic.py] => bias_correction => Task 1, Epoch 95/200 => Loss 2.771, Train_accy 65.090, Test_accy 63.560
2024-01-11 02:42:51,418 [bic.py] => bias_correction => Task 1, Epoch 96/200 => Loss 2.729, Train_accy 65.820, Test_accy 64.220
2024-01-11 02:43:00,253 [bic.py] => bias_correction => Task 1, Epoch 97/200 => Loss 2.754, Train_accy 65.450, Test_accy 64.200
2024-01-11 02:43:09,245 [bic.py] => bias_correction => Task 1, Epoch 98/200 => Loss 2.716, Train_accy 64.730, Test_accy 64.200
2024-01-11 02:43:17,972 [bic.py] => bias_correction => Task 1, Epoch 99/200 => Loss 2.750, Train_accy 65.450, Test_accy 64.290
2024-01-11 02:43:26,709 [bic.py] => bias_correction => Task 1, Epoch 100/200 => Loss 2.699, Train_accy 64.730, Test_accy 64.160
2024-01-11 02:43:35,548 [bic.py] => bias_correction => Task 1, Epoch 101/200 => Loss 2.756, Train_accy 63.270, Test_accy 64.240
2024-01-11 02:43:45,240 [bic.py] => bias_correction => Task 1, Epoch 102/200 => Loss 2.729, Train_accy 65.090, Test_accy 64.020
2024-01-11 02:43:54,168 [bic.py] => bias_correction => Task 1, Epoch 103/200 => Loss 2.701, Train_accy 64.360, Test_accy 64.490
2024-01-11 02:44:02,814 [bic.py] => bias_correction => Task 1, Epoch 104/200 => Loss 2.695, Train_accy 65.820, Test_accy 65.110
2024-01-11 02:44:11,728 [bic.py] => bias_correction => Task 1, Epoch 105/200 => Loss 2.744, Train_accy 65.450, Test_accy 64.870
2024-01-11 02:44:21,054 [bic.py] => bias_correction => Task 1, Epoch 106/200 => Loss 2.756, Train_accy 64.360, Test_accy 64.380
2024-01-11 02:44:30,087 [bic.py] => bias_correction => Task 1, Epoch 107/200 => Loss 2.748, Train_accy 66.180, Test_accy 63.820
2024-01-11 02:44:38,806 [bic.py] => bias_correction => Task 1, Epoch 108/200 => Loss 2.737, Train_accy 64.360, Test_accy 63.000
2024-01-11 02:44:49,715 [bic.py] => bias_correction => Task 1, Epoch 109/200 => Loss 2.728, Train_accy 66.180, Test_accy 63.800
2024-01-11 02:44:58,882 [bic.py] => bias_correction => Task 1, Epoch 110/200 => Loss 2.692, Train_accy 65.450, Test_accy 63.890
2024-01-11 02:45:08,281 [bic.py] => bias_correction => Task 1, Epoch 111/200 => Loss 2.802, Train_accy 66.180, Test_accy 62.980
2024-01-11 02:45:17,419 [bic.py] => bias_correction => Task 1, Epoch 112/200 => Loss 2.695, Train_accy 66.550, Test_accy 64.330
2024-01-11 02:45:26,094 [bic.py] => bias_correction => Task 1, Epoch 113/200 => Loss 2.664, Train_accy 67.640, Test_accy 65.400
2024-01-11 02:45:35,019 [bic.py] => bias_correction => Task 1, Epoch 114/200 => Loss 2.750, Train_accy 67.640, Test_accy 64.730
2024-01-11 02:45:44,055 [bic.py] => bias_correction => Task 1, Epoch 115/200 => Loss 2.745, Train_accy 65.090, Test_accy 64.640
2024-01-11 02:45:53,714 [bic.py] => bias_correction => Task 1, Epoch 116/200 => Loss 2.685, Train_accy 65.450, Test_accy 64.820
2024-01-11 02:46:02,624 [bic.py] => bias_correction => Task 1, Epoch 117/200 => Loss 2.711, Train_accy 65.820, Test_accy 64.530
2024-01-11 02:46:11,470 [bic.py] => bias_correction => Task 1, Epoch 118/200 => Loss 2.682, Train_accy 64.000, Test_accy 64.580
2024-01-11 02:46:20,278 [bic.py] => bias_correction => Task 1, Epoch 119/200 => Loss 2.779, Train_accy 63.270, Test_accy 64.130
2024-01-11 02:46:28,905 [bic.py] => bias_correction => Task 1, Epoch 120/200 => Loss 2.666, Train_accy 64.360, Test_accy 64.110
2024-01-11 02:46:37,368 [bic.py] => bias_correction => Task 1, Epoch 121/200 => Loss 2.715, Train_accy 65.090, Test_accy 64.440
2024-01-11 02:46:45,872 [bic.py] => bias_correction => Task 1, Epoch 122/200 => Loss 2.722, Train_accy 66.910, Test_accy 65.440
2024-01-11 02:46:55,509 [bic.py] => bias_correction => Task 1, Epoch 123/200 => Loss 2.726, Train_accy 65.820, Test_accy 64.440
2024-01-11 02:47:04,151 [bic.py] => bias_correction => Task 1, Epoch 124/200 => Loss 2.719, Train_accy 65.090, Test_accy 64.470
2024-01-11 02:47:12,718 [bic.py] => bias_correction => Task 1, Epoch 125/200 => Loss 2.735, Train_accy 66.910, Test_accy 64.640
2024-01-11 02:47:21,212 [bic.py] => bias_correction => Task 1, Epoch 126/200 => Loss 2.733, Train_accy 66.910, Test_accy 64.780
2024-01-11 02:47:29,386 [bic.py] => bias_correction => Task 1, Epoch 127/200 => Loss 2.736, Train_accy 66.550, Test_accy 64.760
2024-01-11 02:47:38,244 [bic.py] => bias_correction => Task 1, Epoch 128/200 => Loss 2.705, Train_accy 66.550, Test_accy 64.600
2024-01-11 02:47:47,066 [bic.py] => bias_correction => Task 1, Epoch 129/200 => Loss 2.734, Train_accy 64.730, Test_accy 63.690
2024-01-11 02:47:56,470 [bic.py] => bias_correction => Task 1, Epoch 130/200 => Loss 2.672, Train_accy 64.730, Test_accy 64.200
2024-01-11 02:48:05,408 [bic.py] => bias_correction => Task 1, Epoch 131/200 => Loss 2.712, Train_accy 65.090, Test_accy 64.000
2024-01-11 02:48:14,118 [bic.py] => bias_correction => Task 1, Epoch 132/200 => Loss 2.692, Train_accy 64.000, Test_accy 63.820
2024-01-11 02:48:22,713 [bic.py] => bias_correction => Task 1, Epoch 133/200 => Loss 2.755, Train_accy 66.550, Test_accy 64.490
2024-01-11 02:48:31,647 [bic.py] => bias_correction => Task 1, Epoch 134/200 => Loss 2.748, Train_accy 65.450, Test_accy 64.360
2024-01-11 02:48:41,383 [bic.py] => bias_correction => Task 1, Epoch 135/200 => Loss 2.760, Train_accy 64.000, Test_accy 64.910
2024-01-11 02:48:50,162 [bic.py] => bias_correction => Task 1, Epoch 136/200 => Loss 2.726, Train_accy 64.000, Test_accy 64.820
2024-01-11 02:48:59,717 [bic.py] => bias_correction => Task 1, Epoch 137/200 => Loss 2.752, Train_accy 64.730, Test_accy 64.580
2024-01-11 02:49:08,504 [bic.py] => bias_correction => Task 1, Epoch 138/200 => Loss 2.788, Train_accy 64.000, Test_accy 64.330
2024-01-11 02:49:17,417 [bic.py] => bias_correction => Task 1, Epoch 139/200 => Loss 2.724, Train_accy 63.640, Test_accy 64.420
2024-01-11 02:49:26,208 [bic.py] => bias_correction => Task 1, Epoch 140/200 => Loss 2.747, Train_accy 62.910, Test_accy 63.670
2024-01-11 02:49:34,797 [bic.py] => bias_correction => Task 1, Epoch 141/200 => Loss 2.717, Train_accy 65.090, Test_accy 65.040
2024-01-11 02:49:43,648 [bic.py] => bias_correction => Task 1, Epoch 142/200 => Loss 2.717, Train_accy 64.360, Test_accy 64.110
2024-01-11 02:49:52,552 [bic.py] => bias_correction => Task 1, Epoch 143/200 => Loss 2.719, Train_accy 64.000, Test_accy 63.600
2024-01-11 02:50:02,231 [bic.py] => bias_correction => Task 1, Epoch 144/200 => Loss 2.739, Train_accy 65.450, Test_accy 63.780
2024-01-11 02:50:11,456 [bic.py] => bias_correction => Task 1, Epoch 145/200 => Loss 2.730, Train_accy 64.360, Test_accy 63.820
2024-01-11 02:50:20,625 [bic.py] => bias_correction => Task 1, Epoch 146/200 => Loss 2.733, Train_accy 64.730, Test_accy 64.160
2024-01-11 02:50:29,421 [bic.py] => bias_correction => Task 1, Epoch 147/200 => Loss 2.672, Train_accy 65.820, Test_accy 64.840
2024-01-11 02:50:38,549 [bic.py] => bias_correction => Task 1, Epoch 148/200 => Loss 2.726, Train_accy 66.180, Test_accy 65.380
2024-01-11 02:50:47,291 [bic.py] => bias_correction => Task 1, Epoch 149/200 => Loss 2.729, Train_accy 65.450, Test_accy 64.710
2024-01-11 02:50:55,962 [bic.py] => bias_correction => Task 1, Epoch 150/200 => Loss 2.715, Train_accy 65.820, Test_accy 64.560
2024-01-11 02:51:05,479 [bic.py] => bias_correction => Task 1, Epoch 151/200 => Loss 2.732, Train_accy 64.730, Test_accy 64.710
2024-01-11 02:51:14,296 [bic.py] => bias_correction => Task 1, Epoch 152/200 => Loss 2.690, Train_accy 65.090, Test_accy 64.440
2024-01-11 02:51:23,490 [bic.py] => bias_correction => Task 1, Epoch 153/200 => Loss 2.673, Train_accy 64.730, Test_accy 64.910
2024-01-11 02:51:32,565 [bic.py] => bias_correction => Task 1, Epoch 154/200 => Loss 2.697, Train_accy 66.180, Test_accy 65.530
2024-01-11 02:51:41,405 [bic.py] => bias_correction => Task 1, Epoch 155/200 => Loss 2.753, Train_accy 65.090, Test_accy 65.400
2024-01-11 02:51:50,097 [bic.py] => bias_correction => Task 1, Epoch 156/200 => Loss 2.786, Train_accy 64.000, Test_accy 64.360
2024-01-11 02:51:59,571 [bic.py] => bias_correction => Task 1, Epoch 157/200 => Loss 2.746, Train_accy 66.180, Test_accy 64.710
2024-01-11 02:52:09,618 [bic.py] => bias_correction => Task 1, Epoch 158/200 => Loss 2.718, Train_accy 65.820, Test_accy 65.040
2024-01-11 02:52:18,230 [bic.py] => bias_correction => Task 1, Epoch 159/200 => Loss 2.746, Train_accy 65.450, Test_accy 64.510
2024-01-11 02:52:28,065 [bic.py] => bias_correction => Task 1, Epoch 160/200 => Loss 2.723, Train_accy 65.090, Test_accy 64.530
2024-01-11 02:52:36,938 [bic.py] => bias_correction => Task 1, Epoch 161/200 => Loss 2.689, Train_accy 63.270, Test_accy 64.070
2024-01-11 02:52:45,952 [bic.py] => bias_correction => Task 1, Epoch 162/200 => Loss 2.717, Train_accy 63.270, Test_accy 64.360
2024-01-11 02:52:54,673 [bic.py] => bias_correction => Task 1, Epoch 163/200 => Loss 2.726, Train_accy 64.360, Test_accy 64.160
2024-01-11 02:53:03,931 [bic.py] => bias_correction => Task 1, Epoch 164/200 => Loss 2.769, Train_accy 63.640, Test_accy 63.380
2024-01-11 02:53:13,452 [bic.py] => bias_correction => Task 1, Epoch 165/200 => Loss 2.775, Train_accy 63.640, Test_accy 63.200
2024-01-11 02:53:22,117 [bic.py] => bias_correction => Task 1, Epoch 166/200 => Loss 2.750, Train_accy 63.640, Test_accy 63.490
2024-01-11 02:53:30,757 [bic.py] => bias_correction => Task 1, Epoch 167/200 => Loss 2.726, Train_accy 64.000, Test_accy 63.530
2024-01-11 02:53:39,506 [bic.py] => bias_correction => Task 1, Epoch 168/200 => Loss 2.767, Train_accy 64.360, Test_accy 63.330
2024-01-11 02:53:48,394 [bic.py] => bias_correction => Task 1, Epoch 169/200 => Loss 2.704, Train_accy 65.450, Test_accy 64.020
2024-01-11 02:53:57,380 [bic.py] => bias_correction => Task 1, Epoch 170/200 => Loss 2.703, Train_accy 66.180, Test_accy 64.640
2024-01-11 02:54:06,738 [bic.py] => bias_correction => Task 1, Epoch 171/200 => Loss 2.655, Train_accy 65.090, Test_accy 64.800
2024-01-11 02:54:16,479 [bic.py] => bias_correction => Task 1, Epoch 172/200 => Loss 2.721, Train_accy 65.090, Test_accy 64.600
2024-01-11 02:54:26,020 [bic.py] => bias_correction => Task 1, Epoch 173/200 => Loss 2.651, Train_accy 65.450, Test_accy 64.870
2024-01-11 02:54:34,635 [bic.py] => bias_correction => Task 1, Epoch 174/200 => Loss 2.789, Train_accy 64.360, Test_accy 64.470
2024-01-11 02:54:43,472 [bic.py] => bias_correction => Task 1, Epoch 175/200 => Loss 2.735, Train_accy 64.730, Test_accy 64.440
2024-01-11 02:54:52,505 [bic.py] => bias_correction => Task 1, Epoch 176/200 => Loss 2.710, Train_accy 65.820, Test_accy 64.310
2024-01-11 02:55:01,579 [bic.py] => bias_correction => Task 1, Epoch 177/200 => Loss 2.708, Train_accy 65.450, Test_accy 64.510
2024-01-11 02:55:10,587 [bic.py] => bias_correction => Task 1, Epoch 178/200 => Loss 2.698, Train_accy 64.360, Test_accy 64.910
2024-01-11 02:55:19,296 [bic.py] => bias_correction => Task 1, Epoch 179/200 => Loss 2.701, Train_accy 65.820, Test_accy 64.360
2024-01-11 02:55:28,412 [bic.py] => bias_correction => Task 1, Epoch 180/200 => Loss 2.683, Train_accy 63.270, Test_accy 64.690
2024-01-11 02:55:37,069 [bic.py] => bias_correction => Task 1, Epoch 181/200 => Loss 2.673, Train_accy 65.820, Test_accy 65.890
2024-01-11 02:55:45,876 [bic.py] => bias_correction => Task 1, Epoch 182/200 => Loss 2.756, Train_accy 65.820, Test_accy 65.310
2024-01-11 02:55:54,506 [bic.py] => bias_correction => Task 1, Epoch 183/200 => Loss 2.789, Train_accy 66.180, Test_accy 64.760
2024-01-11 02:56:03,380 [bic.py] => bias_correction => Task 1, Epoch 184/200 => Loss 2.721, Train_accy 65.450, Test_accy 64.290
2024-01-11 02:56:12,171 [bic.py] => bias_correction => Task 1, Epoch 185/200 => Loss 2.675, Train_accy 65.450, Test_accy 64.090
2024-01-11 02:56:21,540 [bic.py] => bias_correction => Task 1, Epoch 186/200 => Loss 2.761, Train_accy 64.730, Test_accy 63.600
2024-01-11 02:56:29,998 [bic.py] => bias_correction => Task 1, Epoch 187/200 => Loss 2.730, Train_accy 64.360, Test_accy 63.870
2024-01-11 02:56:38,749 [bic.py] => bias_correction => Task 1, Epoch 188/200 => Loss 2.754, Train_accy 66.550, Test_accy 64.710
2024-01-11 02:56:47,676 [bic.py] => bias_correction => Task 1, Epoch 189/200 => Loss 2.729, Train_accy 65.090, Test_accy 64.780
2024-01-11 02:56:56,762 [bic.py] => bias_correction => Task 1, Epoch 190/200 => Loss 2.726, Train_accy 66.180, Test_accy 64.470
2024-01-11 02:57:05,525 [bic.py] => bias_correction => Task 1, Epoch 191/200 => Loss 2.725, Train_accy 66.180, Test_accy 64.600
2024-01-11 02:57:14,577 [bic.py] => bias_correction => Task 1, Epoch 192/200 => Loss 2.740, Train_accy 66.180, Test_accy 64.220
2024-01-11 02:57:24,520 [bic.py] => bias_correction => Task 1, Epoch 193/200 => Loss 2.759, Train_accy 66.910, Test_accy 64.310
2024-01-11 02:57:33,109 [bic.py] => bias_correction => Task 1, Epoch 194/200 => Loss 2.712, Train_accy 66.180, Test_accy 64.090
2024-01-11 02:57:42,111 [bic.py] => bias_correction => Task 1, Epoch 195/200 => Loss 2.718, Train_accy 66.550, Test_accy 64.380
2024-01-11 02:57:51,425 [bic.py] => bias_correction => Task 1, Epoch 196/200 => Loss 2.696, Train_accy 66.910, Test_accy 64.690
2024-01-11 02:57:59,835 [bic.py] => bias_correction => Task 1, Epoch 197/200 => Loss 2.716, Train_accy 66.910, Test_accy 64.870
2024-01-11 02:58:08,484 [bic.py] => bias_correction => Task 1, Epoch 198/200 => Loss 2.670, Train_accy 66.910, Test_accy 64.620
2024-01-11 02:58:17,005 [bic.py] => bias_correction => Task 1, Epoch 199/200 => Loss 2.728, Train_accy 66.550, Test_accy 64.820
2024-01-11 02:58:26,481 [bic.py] => bias_correction => Task 1, Epoch 200/200 => Loss 2.734, Train_accy 66.550, Test_accy 64.910
2024-01-11 02:58:26,483 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-11 02:58:46,853 [bic.py] => Parameters of bias layer:
2024-01-11 02:58:46,854 [bic.py] => 0 => 1.000, 0.000
2024-01-11 02:58:46,854 [bic.py] => 1 => 0.791, -2.133
2024-01-11 02:58:59,154 [bic.py] => Exemplar size: 750
2024-01-11 02:58:59,717 [trainer.py] => CNN: {'total': 64.91, '0': 79.44, '1': 84.44, '2': 63.33, '3': 37.22, '4': 47.22, '5': 57.22, '6': 26.11, '7': 51.11, '8': 77.78, '9': 36.11, '10': 63.89, '11': 68.33, '12': 55.56, '13': 56.67, '14': 65.0, '15': 92.22, '16': 86.11, '17': 82.78, '18': 84.44, '19': 80.0, '20': 92.22, '21': 78.89, '22': 33.89, '23': 54.44, 'old': 57.96, 'new': 75.33}
2024-01-11 02:58:59,717 [trainer.py] => NME: {'total': 68.27, '0': 80.56, '1': 72.22, '2': 71.11, '3': 41.67, '4': 60.0, '5': 55.56, '6': 32.78, '7': 47.22, '8': 56.67, '9': 43.89, '10': 70.0, '11': 82.78, '12': 60.0, '13': 60.56, '14': 71.11, '15': 86.11, '16': 87.22, '17': 80.56, '18': 75.56, '19': 78.33, '20': 85.56, '21': 71.11, '22': 84.44, '23': 75.56, 'old': 60.41, 'new': 80.06}
2024-01-11 02:58:59,717 [trainer.py] => CNN top1 curve: [86.11, 64.91]
2024-01-11 02:58:59,717 [trainer.py] => CNN top5 curve: [97.7, 93.13]
2024-01-11 02:58:59,718 [trainer.py] => NME top1 curve: [84.37, 68.27]
2024-01-11 02:58:59,718 [trainer.py] => NME top5 curve: [98.07, 95.18]

2024-01-11 02:58:59,719 [trainer.py] => All params: 21044841
2024-01-11 02:58:59,719 [trainer.py] => Trainable params: 21044841
2024-01-11 02:58:59,721 [bic.py] => Learning on 25-35
2024-01-11 02:58:59,765 [bic.py] => Stage1 dset: 4740, Stage2 dset: 210
2024-01-11 02:58:59,765 [bic.py] => Lambda: 0.714
2024-01-11 02:58:59,808 [bic.py] => Parameters of bias layer:
2024-01-11 02:58:59,808 [bic.py] => 0 => 1.000, 0.000
2024-01-11 02:58:59,808 [bic.py] => 1 => 0.791, -2.133
2024-01-11 02:58:59,808 [bic.py] => 2 => 1.000, 0.000
2024-01-11 02:59:29,423 [bic.py] => training => Task 2, Epoch 1/200 => Loss 2.220, Train_accy 39.600, Test_accy 18.140
2024-01-11 02:59:59,872 [bic.py] => training => Task 2, Epoch 2/200 => Loss 1.776, Train_accy 48.270, Test_accy 27.370
2024-01-11 03:00:28,851 [bic.py] => training => Task 2, Epoch 3/200 => Loss 1.845, Train_accy 46.770, Test_accy 24.290
2024-01-11 03:00:57,141 [bic.py] => training => Task 2, Epoch 4/200 => Loss 1.730, Train_accy 61.600, Test_accy 33.220
2024-01-11 03:01:24,575 [bic.py] => training => Task 2, Epoch 5/200 => Loss 1.686, Train_accy 61.560, Test_accy 31.630
2024-01-11 03:01:53,132 [bic.py] => training => Task 2, Epoch 6/200 => Loss 1.618, Train_accy 67.950, Test_accy 33.620
2024-01-11 03:02:22,163 [bic.py] => training => Task 2, Epoch 7/200 => Loss 1.572, Train_accy 74.140, Test_accy 35.220
2024-01-11 03:02:51,122 [bic.py] => training => Task 2, Epoch 8/200 => Loss 1.596, Train_accy 63.730, Test_accy 29.830
2024-01-11 03:03:19,653 [bic.py] => training => Task 2, Epoch 9/200 => Loss 1.601, Train_accy 73.020, Test_accy 35.060
2024-01-11 03:03:48,019 [bic.py] => training => Task 2, Epoch 10/200 => Loss 1.558, Train_accy 70.230, Test_accy 34.570
2024-01-11 03:04:15,441 [bic.py] => training => Task 2, Epoch 11/200 => Loss 1.549, Train_accy 50.000, Test_accy 24.350
2024-01-11 03:04:44,512 [bic.py] => training => Task 2, Epoch 12/200 => Loss 1.636, Train_accy 66.580, Test_accy 29.510
2024-01-11 03:05:12,971 [bic.py] => training => Task 2, Epoch 13/200 => Loss 1.557, Train_accy 79.490, Test_accy 34.940
2024-01-11 03:05:42,011 [bic.py] => training => Task 2, Epoch 14/200 => Loss 1.516, Train_accy 74.700, Test_accy 34.130
2024-01-11 03:06:11,115 [bic.py] => training => Task 2, Epoch 15/200 => Loss 1.559, Train_accy 73.080, Test_accy 35.410
2024-01-11 03:06:39,870 [bic.py] => training => Task 2, Epoch 16/200 => Loss 1.487, Train_accy 79.980, Test_accy 37.560
2024-01-11 03:07:07,969 [bic.py] => training => Task 2, Epoch 17/200 => Loss 1.557, Train_accy 79.660, Test_accy 36.980
2024-01-11 03:07:37,365 [bic.py] => training => Task 2, Epoch 18/200 => Loss 1.462, Train_accy 82.280, Test_accy 39.030
2024-01-11 03:08:06,653 [bic.py] => training => Task 2, Epoch 19/200 => Loss 1.498, Train_accy 78.650, Test_accy 38.920
2024-01-11 03:08:35,825 [bic.py] => training => Task 2, Epoch 20/200 => Loss 1.496, Train_accy 82.490, Test_accy 36.140
2024-01-11 03:09:04,658 [bic.py] => training => Task 2, Epoch 21/200 => Loss 1.580, Train_accy 73.230, Test_accy 37.370
2024-01-11 03:09:33,717 [bic.py] => training => Task 2, Epoch 22/200 => Loss 1.570, Train_accy 72.890, Test_accy 32.760
2024-01-11 03:10:00,890 [bic.py] => training => Task 2, Epoch 23/200 => Loss 1.530, Train_accy 84.430, Test_accy 40.190
2024-01-11 03:10:29,010 [bic.py] => training => Task 2, Epoch 24/200 => Loss 1.489, Train_accy 84.090, Test_accy 40.560
2024-01-11 03:10:57,763 [bic.py] => training => Task 2, Epoch 25/200 => Loss 1.555, Train_accy 77.110, Test_accy 36.680
2024-01-11 03:11:26,601 [bic.py] => training => Task 2, Epoch 26/200 => Loss 1.550, Train_accy 79.830, Test_accy 34.680
2024-01-11 03:11:55,213 [bic.py] => training => Task 2, Epoch 27/200 => Loss 1.528, Train_accy 85.170, Test_accy 38.250
2024-01-11 03:12:24,089 [bic.py] => training => Task 2, Epoch 28/200 => Loss 1.519, Train_accy 80.190, Test_accy 34.780
2024-01-11 03:12:51,847 [bic.py] => training => Task 2, Epoch 29/200 => Loss 1.480, Train_accy 84.810, Test_accy 38.600
2024-01-11 03:13:19,664 [bic.py] => training => Task 2, Epoch 30/200 => Loss 1.465, Train_accy 84.680, Test_accy 40.920
2024-01-11 03:13:48,324 [bic.py] => training => Task 2, Epoch 31/200 => Loss 1.466, Train_accy 84.030, Test_accy 39.190
2024-01-11 03:14:16,783 [bic.py] => training => Task 2, Epoch 32/200 => Loss 1.480, Train_accy 81.750, Test_accy 37.410
2024-01-11 03:14:45,217 [bic.py] => training => Task 2, Epoch 33/200 => Loss 1.497, Train_accy 83.230, Test_accy 39.100
2024-01-11 03:15:13,676 [bic.py] => training => Task 2, Epoch 34/200 => Loss 1.523, Train_accy 82.620, Test_accy 37.830
2024-01-11 03:15:42,599 [bic.py] => training => Task 2, Epoch 35/200 => Loss 1.508, Train_accy 79.830, Test_accy 37.300
2024-01-11 03:16:09,720 [bic.py] => training => Task 2, Epoch 36/200 => Loss 1.474, Train_accy 86.390, Test_accy 41.860
2024-01-11 03:16:38,305 [bic.py] => training => Task 2, Epoch 37/200 => Loss 1.450, Train_accy 84.640, Test_accy 40.460
2024-01-11 03:17:06,838 [bic.py] => training => Task 2, Epoch 38/200 => Loss 1.459, Train_accy 85.000, Test_accy 37.130
2024-01-11 03:17:35,484 [bic.py] => training => Task 2, Epoch 39/200 => Loss 1.469, Train_accy 74.920, Test_accy 34.370
2024-01-11 03:18:03,694 [bic.py] => training => Task 2, Epoch 40/200 => Loss 1.500, Train_accy 71.520, Test_accy 33.870
2024-01-11 03:18:32,410 [bic.py] => training => Task 2, Epoch 41/200 => Loss 1.489, Train_accy 84.890, Test_accy 40.410
2024-01-11 03:18:59,783 [bic.py] => training => Task 2, Epoch 42/200 => Loss 1.452, Train_accy 86.670, Test_accy 39.780
2024-01-11 03:19:27,775 [bic.py] => training => Task 2, Epoch 43/200 => Loss 1.440, Train_accy 90.800, Test_accy 44.170
2024-01-11 03:19:56,345 [bic.py] => training => Task 2, Epoch 44/200 => Loss 1.517, Train_accy 80.320, Test_accy 35.620
2024-01-11 03:20:24,412 [bic.py] => training => Task 2, Epoch 45/200 => Loss 1.469, Train_accy 85.700, Test_accy 40.020
2024-01-11 03:20:52,735 [bic.py] => training => Task 2, Epoch 46/200 => Loss 1.451, Train_accy 86.050, Test_accy 41.860
2024-01-11 03:21:21,519 [bic.py] => training => Task 2, Epoch 47/200 => Loss 1.484, Train_accy 84.090, Test_accy 37.810
2024-01-11 03:21:49,535 [bic.py] => training => Task 2, Epoch 48/200 => Loss 1.449, Train_accy 86.390, Test_accy 42.020
2024-01-11 03:22:17,081 [bic.py] => training => Task 2, Epoch 49/200 => Loss 1.442, Train_accy 90.740, Test_accy 43.250
2024-01-11 03:22:45,330 [bic.py] => training => Task 2, Epoch 50/200 => Loss 1.431, Train_accy 85.460, Test_accy 37.730
2024-01-11 03:23:13,708 [bic.py] => training => Task 2, Epoch 51/200 => Loss 1.442, Train_accy 90.760, Test_accy 45.330
2024-01-11 03:23:42,215 [bic.py] => training => Task 2, Epoch 52/200 => Loss 1.429, Train_accy 88.250, Test_accy 42.030
2024-01-11 03:24:10,818 [bic.py] => training => Task 2, Epoch 53/200 => Loss 1.435, Train_accy 82.930, Test_accy 37.760
2024-01-11 03:24:39,398 [bic.py] => training => Task 2, Epoch 54/200 => Loss 1.440, Train_accy 88.460, Test_accy 43.130
2024-01-11 03:25:08,189 [bic.py] => training => Task 2, Epoch 55/200 => Loss 1.386, Train_accy 85.860, Test_accy 43.400
2024-01-11 03:25:37,213 [bic.py] => training => Task 2, Epoch 56/200 => Loss 1.456, Train_accy 86.540, Test_accy 42.460
2024-01-11 03:26:05,716 [bic.py] => training => Task 2, Epoch 57/200 => Loss 1.473, Train_accy 85.080, Test_accy 39.000
2024-01-11 03:26:33,937 [bic.py] => training => Task 2, Epoch 58/200 => Loss 1.458, Train_accy 90.740, Test_accy 42.920
2024-01-11 03:27:02,121 [bic.py] => training => Task 2, Epoch 59/200 => Loss 1.382, Train_accy 91.080, Test_accy 41.650
2024-01-11 03:27:29,732 [bic.py] => training => Task 2, Epoch 60/200 => Loss 1.378, Train_accy 84.580, Test_accy 39.400
2024-01-11 03:27:56,429 [bic.py] => training => Task 2, Epoch 61/200 => Loss 1.349, Train_accy 95.720, Test_accy 46.590
2024-01-11 03:28:24,411 [bic.py] => training => Task 2, Epoch 62/200 => Loss 1.314, Train_accy 96.330, Test_accy 48.130
2024-01-11 03:28:52,614 [bic.py] => training => Task 2, Epoch 63/200 => Loss 1.297, Train_accy 97.260, Test_accy 49.020
2024-01-11 03:29:21,086 [bic.py] => training => Task 2, Epoch 64/200 => Loss 1.311, Train_accy 97.050, Test_accy 47.830
2024-01-11 03:29:49,596 [bic.py] => training => Task 2, Epoch 65/200 => Loss 1.301, Train_accy 97.030, Test_accy 49.290
2024-01-11 03:30:18,126 [bic.py] => training => Task 2, Epoch 66/200 => Loss 1.299, Train_accy 97.220, Test_accy 48.020
2024-01-11 03:30:46,108 [bic.py] => training => Task 2, Epoch 67/200 => Loss 1.312, Train_accy 97.190, Test_accy 48.490
2024-01-11 03:31:13,251 [bic.py] => training => Task 2, Epoch 68/200 => Loss 1.309, Train_accy 97.090, Test_accy 48.590
2024-01-11 03:31:41,549 [bic.py] => training => Task 2, Epoch 69/200 => Loss 1.316, Train_accy 96.620, Test_accy 47.430
2024-01-11 03:32:09,958 [bic.py] => training => Task 2, Epoch 70/200 => Loss 1.302, Train_accy 97.260, Test_accy 48.210
2024-01-11 03:32:38,806 [bic.py] => training => Task 2, Epoch 71/200 => Loss 1.305, Train_accy 97.130, Test_accy 47.710
2024-01-11 03:33:07,164 [bic.py] => training => Task 2, Epoch 72/200 => Loss 1.303, Train_accy 97.360, Test_accy 49.110
2024-01-11 03:33:35,444 [bic.py] => training => Task 2, Epoch 73/200 => Loss 1.312, Train_accy 97.430, Test_accy 49.100
2024-01-11 03:34:02,498 [bic.py] => training => Task 2, Epoch 74/200 => Loss 1.305, Train_accy 97.760, Test_accy 49.440
2024-01-11 03:34:30,873 [bic.py] => training => Task 2, Epoch 75/200 => Loss 1.294, Train_accy 97.410, Test_accy 48.080
2024-01-11 03:34:59,076 [bic.py] => training => Task 2, Epoch 76/200 => Loss 1.298, Train_accy 97.470, Test_accy 49.250
2024-01-11 03:35:26,905 [bic.py] => training => Task 2, Epoch 77/200 => Loss 1.305, Train_accy 97.810, Test_accy 48.520
2024-01-11 03:35:55,446 [bic.py] => training => Task 2, Epoch 78/200 => Loss 1.305, Train_accy 97.570, Test_accy 49.220
2024-01-11 03:36:24,203 [bic.py] => training => Task 2, Epoch 79/200 => Loss 1.310, Train_accy 97.890, Test_accy 49.570
2024-01-11 03:36:51,845 [bic.py] => training => Task 2, Epoch 80/200 => Loss 1.285, Train_accy 97.680, Test_accy 49.400
2024-01-11 03:37:18,965 [bic.py] => training => Task 2, Epoch 81/200 => Loss 1.281, Train_accy 97.830, Test_accy 49.370
2024-01-11 03:37:46,773 [bic.py] => training => Task 2, Epoch 82/200 => Loss 1.310, Train_accy 97.780, Test_accy 48.270
2024-01-11 03:38:15,173 [bic.py] => training => Task 2, Epoch 83/200 => Loss 1.329, Train_accy 97.620, Test_accy 47.890
2024-01-11 03:38:43,850 [bic.py] => training => Task 2, Epoch 84/200 => Loss 1.304, Train_accy 97.930, Test_accy 49.110
2024-01-11 03:39:12,359 [bic.py] => training => Task 2, Epoch 85/200 => Loss 1.278, Train_accy 97.700, Test_accy 49.920
2024-01-11 03:39:40,770 [bic.py] => training => Task 2, Epoch 86/200 => Loss 1.290, Train_accy 97.780, Test_accy 48.460
2024-01-11 03:40:07,272 [bic.py] => training => Task 2, Epoch 87/200 => Loss 1.284, Train_accy 97.660, Test_accy 49.000
2024-01-11 03:40:35,718 [bic.py] => training => Task 2, Epoch 88/200 => Loss 1.282, Train_accy 98.190, Test_accy 49.000
2024-01-11 03:41:04,826 [bic.py] => training => Task 2, Epoch 89/200 => Loss 1.282, Train_accy 98.210, Test_accy 48.920
2024-01-11 03:41:33,558 [bic.py] => training => Task 2, Epoch 90/200 => Loss 1.300, Train_accy 98.540, Test_accy 49.510
2024-01-11 03:42:02,019 [bic.py] => training => Task 2, Epoch 91/200 => Loss 1.286, Train_accy 97.870, Test_accy 48.890
2024-01-11 03:42:30,206 [bic.py] => training => Task 2, Epoch 92/200 => Loss 1.271, Train_accy 98.080, Test_accy 49.330
2024-01-11 03:42:58,121 [bic.py] => training => Task 2, Epoch 93/200 => Loss 1.300, Train_accy 98.060, Test_accy 49.670
2024-01-11 03:43:26,705 [bic.py] => training => Task 2, Epoch 94/200 => Loss 1.304, Train_accy 97.910, Test_accy 49.020
2024-01-11 03:43:55,029 [bic.py] => training => Task 2, Epoch 95/200 => Loss 1.277, Train_accy 98.140, Test_accy 49.100
2024-01-11 03:44:23,521 [bic.py] => training => Task 2, Epoch 96/200 => Loss 1.301, Train_accy 98.400, Test_accy 49.000
2024-01-11 03:44:51,375 [bic.py] => training => Task 2, Epoch 97/200 => Loss 1.309, Train_accy 97.590, Test_accy 48.440
2024-01-11 03:45:19,526 [bic.py] => training => Task 2, Epoch 98/200 => Loss 1.283, Train_accy 98.060, Test_accy 48.560
2024-01-11 03:45:48,745 [bic.py] => training => Task 2, Epoch 99/200 => Loss 1.282, Train_accy 98.230, Test_accy 48.900
2024-01-11 03:46:16,125 [bic.py] => training => Task 2, Epoch 100/200 => Loss 1.277, Train_accy 98.160, Test_accy 49.300
2024-01-11 03:46:44,096 [bic.py] => training => Task 2, Epoch 101/200 => Loss 1.270, Train_accy 98.210, Test_accy 48.970
2024-01-11 03:47:12,212 [bic.py] => training => Task 2, Epoch 102/200 => Loss 1.272, Train_accy 97.890, Test_accy 48.600
2024-01-11 03:47:40,855 [bic.py] => training => Task 2, Epoch 103/200 => Loss 1.268, Train_accy 98.420, Test_accy 49.560
2024-01-11 03:48:08,673 [bic.py] => training => Task 2, Epoch 104/200 => Loss 1.271, Train_accy 98.210, Test_accy 49.730
2024-01-11 03:48:36,582 [bic.py] => training => Task 2, Epoch 105/200 => Loss 1.279, Train_accy 98.460, Test_accy 49.430
2024-01-11 03:49:02,865 [bic.py] => training => Task 2, Epoch 106/200 => Loss 1.276, Train_accy 98.270, Test_accy 48.970
2024-01-11 03:49:30,745 [bic.py] => training => Task 2, Epoch 107/200 => Loss 1.297, Train_accy 98.420, Test_accy 48.980
2024-01-11 03:49:58,700 [bic.py] => training => Task 2, Epoch 108/200 => Loss 1.272, Train_accy 98.380, Test_accy 49.540
2024-01-11 03:50:27,550 [bic.py] => training => Task 2, Epoch 109/200 => Loss 1.259, Train_accy 98.270, Test_accy 50.270
2024-01-11 03:50:55,625 [bic.py] => training => Task 2, Epoch 110/200 => Loss 1.277, Train_accy 98.310, Test_accy 49.940
2024-01-11 03:51:24,061 [bic.py] => training => Task 2, Epoch 111/200 => Loss 1.266, Train_accy 98.140, Test_accy 48.950
2024-01-11 03:51:51,249 [bic.py] => training => Task 2, Epoch 112/200 => Loss 1.275, Train_accy 98.460, Test_accy 49.400
2024-01-11 03:52:18,067 [bic.py] => training => Task 2, Epoch 113/200 => Loss 1.270, Train_accy 98.230, Test_accy 49.290
2024-01-11 03:52:46,053 [bic.py] => training => Task 2, Epoch 114/200 => Loss 1.298, Train_accy 98.460, Test_accy 50.030
2024-01-11 03:53:13,631 [bic.py] => training => Task 2, Epoch 115/200 => Loss 1.289, Train_accy 98.400, Test_accy 49.430
2024-01-11 03:53:42,188 [bic.py] => training => Task 2, Epoch 116/200 => Loss 1.271, Train_accy 98.100, Test_accy 49.020
2024-01-11 03:54:10,362 [bic.py] => training => Task 2, Epoch 117/200 => Loss 1.266, Train_accy 98.500, Test_accy 49.670
2024-01-11 03:54:38,241 [bic.py] => training => Task 2, Epoch 118/200 => Loss 1.285, Train_accy 98.210, Test_accy 49.110
2024-01-11 03:55:04,474 [bic.py] => training => Task 2, Epoch 119/200 => Loss 1.278, Train_accy 98.590, Test_accy 49.380
2024-01-11 03:55:32,712 [bic.py] => training => Task 2, Epoch 120/200 => Loss 1.294, Train_accy 98.120, Test_accy 48.790
2024-01-11 03:56:00,959 [bic.py] => training => Task 2, Epoch 121/200 => Loss 1.271, Train_accy 98.500, Test_accy 49.730
2024-01-11 03:56:28,767 [bic.py] => training => Task 2, Epoch 122/200 => Loss 1.287, Train_accy 98.060, Test_accy 49.220
2024-01-11 03:56:57,244 [bic.py] => training => Task 2, Epoch 123/200 => Loss 1.262, Train_accy 98.350, Test_accy 49.430
2024-01-11 03:57:25,585 [bic.py] => training => Task 2, Epoch 124/200 => Loss 1.277, Train_accy 98.270, Test_accy 49.210
2024-01-11 03:57:53,710 [bic.py] => training => Task 2, Epoch 125/200 => Loss 1.293, Train_accy 98.420, Test_accy 49.220
2024-01-11 03:58:20,601 [bic.py] => training => Task 2, Epoch 126/200 => Loss 1.259, Train_accy 98.310, Test_accy 49.900
2024-01-11 03:58:48,582 [bic.py] => training => Task 2, Epoch 127/200 => Loss 1.266, Train_accy 98.140, Test_accy 49.190
2024-01-11 03:59:17,005 [bic.py] => training => Task 2, Epoch 128/200 => Loss 1.274, Train_accy 98.520, Test_accy 49.440
2024-01-11 03:59:44,969 [bic.py] => training => Task 2, Epoch 129/200 => Loss 1.284, Train_accy 98.570, Test_accy 50.250
2024-01-11 04:00:12,989 [bic.py] => training => Task 2, Epoch 130/200 => Loss 1.283, Train_accy 98.460, Test_accy 48.940
2024-01-11 04:00:40,661 [bic.py] => training => Task 2, Epoch 131/200 => Loss 1.270, Train_accy 98.230, Test_accy 49.710
2024-01-11 04:01:06,964 [bic.py] => training => Task 2, Epoch 132/200 => Loss 1.279, Train_accy 98.440, Test_accy 49.750
2024-01-11 04:01:35,137 [bic.py] => training => Task 2, Epoch 133/200 => Loss 1.285, Train_accy 98.040, Test_accy 49.970
2024-01-11 04:02:03,429 [bic.py] => training => Task 2, Epoch 134/200 => Loss 1.266, Train_accy 98.540, Test_accy 50.510
2024-01-11 04:02:32,094 [bic.py] => training => Task 2, Epoch 135/200 => Loss 1.269, Train_accy 98.570, Test_accy 50.300
2024-01-11 04:03:00,272 [bic.py] => training => Task 2, Epoch 136/200 => Loss 1.302, Train_accy 98.650, Test_accy 49.730
2024-01-11 04:03:28,270 [bic.py] => training => Task 2, Epoch 137/200 => Loss 1.264, Train_accy 98.570, Test_accy 50.520
2024-01-11 04:03:56,518 [bic.py] => training => Task 2, Epoch 138/200 => Loss 1.274, Train_accy 98.520, Test_accy 49.940
2024-01-11 04:04:24,181 [bic.py] => training => Task 2, Epoch 139/200 => Loss 1.263, Train_accy 98.460, Test_accy 49.860
2024-01-11 04:04:53,526 [bic.py] => training => Task 2, Epoch 140/200 => Loss 1.267, Train_accy 98.480, Test_accy 49.970
2024-01-11 04:05:22,345 [bic.py] => training => Task 2, Epoch 141/200 => Loss 1.262, Train_accy 98.040, Test_accy 48.950
2024-01-11 04:05:50,676 [bic.py] => training => Task 2, Epoch 142/200 => Loss 1.300, Train_accy 98.460, Test_accy 49.710
2024-01-11 04:06:19,296 [bic.py] => training => Task 2, Epoch 143/200 => Loss 1.263, Train_accy 98.480, Test_accy 49.620
2024-01-11 04:06:47,506 [bic.py] => training => Task 2, Epoch 144/200 => Loss 1.314, Train_accy 98.290, Test_accy 49.030
2024-01-11 04:07:14,805 [bic.py] => training => Task 2, Epoch 145/200 => Loss 1.257, Train_accy 98.650, Test_accy 49.870
2024-01-11 04:07:43,496 [bic.py] => training => Task 2, Epoch 146/200 => Loss 1.270, Train_accy 98.270, Test_accy 48.110
2024-01-11 04:08:11,706 [bic.py] => training => Task 2, Epoch 147/200 => Loss 1.286, Train_accy 98.570, Test_accy 49.760
2024-01-11 04:08:40,514 [bic.py] => training => Task 2, Epoch 148/200 => Loss 1.289, Train_accy 98.590, Test_accy 49.190
2024-01-11 04:09:09,178 [bic.py] => training => Task 2, Epoch 149/200 => Loss 1.270, Train_accy 98.630, Test_accy 49.560
2024-01-11 04:09:37,334 [bic.py] => training => Task 2, Epoch 150/200 => Loss 1.284, Train_accy 98.380, Test_accy 49.870
2024-01-11 04:10:04,948 [bic.py] => training => Task 2, Epoch 151/200 => Loss 1.285, Train_accy 98.190, Test_accy 48.350
2024-01-11 04:10:32,318 [bic.py] => training => Task 2, Epoch 152/200 => Loss 1.277, Train_accy 98.570, Test_accy 49.920
2024-01-11 04:11:00,833 [bic.py] => training => Task 2, Epoch 153/200 => Loss 1.282, Train_accy 98.480, Test_accy 50.170
2024-01-11 04:11:29,185 [bic.py] => training => Task 2, Epoch 154/200 => Loss 1.294, Train_accy 98.120, Test_accy 49.410
2024-01-11 04:11:57,497 [bic.py] => training => Task 2, Epoch 155/200 => Loss 1.284, Train_accy 98.160, Test_accy 49.100
2024-01-11 04:12:25,834 [bic.py] => training => Task 2, Epoch 156/200 => Loss 1.268, Train_accy 98.520, Test_accy 49.670
2024-01-11 04:12:53,078 [bic.py] => training => Task 2, Epoch 157/200 => Loss 1.273, Train_accy 98.350, Test_accy 49.560
2024-01-11 04:13:19,465 [bic.py] => training => Task 2, Epoch 158/200 => Loss 1.276, Train_accy 98.500, Test_accy 49.600
2024-01-11 04:13:47,702 [bic.py] => training => Task 2, Epoch 159/200 => Loss 1.273, Train_accy 98.350, Test_accy 50.060
2024-01-11 04:14:16,053 [bic.py] => training => Task 2, Epoch 160/200 => Loss 1.296, Train_accy 98.670, Test_accy 49.680
2024-01-11 04:14:44,777 [bic.py] => training => Task 2, Epoch 161/200 => Loss 1.271, Train_accy 98.480, Test_accy 49.950
2024-01-11 04:15:12,779 [bic.py] => training => Task 2, Epoch 162/200 => Loss 1.275, Train_accy 98.420, Test_accy 49.130
2024-01-11 04:15:41,346 [bic.py] => training => Task 2, Epoch 163/200 => Loss 1.280, Train_accy 98.440, Test_accy 49.220
2024-01-11 04:16:10,000 [bic.py] => training => Task 2, Epoch 164/200 => Loss 1.273, Train_accy 97.810, Test_accy 49.440
2024-01-11 04:16:38,431 [bic.py] => training => Task 2, Epoch 165/200 => Loss 1.265, Train_accy 98.460, Test_accy 49.980
2024-01-11 04:17:06,979 [bic.py] => training => Task 2, Epoch 166/200 => Loss 1.260, Train_accy 98.420, Test_accy 49.680
2024-01-11 04:17:35,900 [bic.py] => training => Task 2, Epoch 167/200 => Loss 1.272, Train_accy 98.590, Test_accy 50.130
2024-01-11 04:18:04,037 [bic.py] => training => Task 2, Epoch 168/200 => Loss 1.276, Train_accy 98.420, Test_accy 49.400
2024-01-11 04:18:32,004 [bic.py] => training => Task 2, Epoch 169/200 => Loss 1.269, Train_accy 98.020, Test_accy 48.940
2024-01-11 04:19:00,237 [bic.py] => training => Task 2, Epoch 170/200 => Loss 1.268, Train_accy 98.690, Test_accy 50.160
2024-01-11 04:19:27,645 [bic.py] => training => Task 2, Epoch 171/200 => Loss 1.277, Train_accy 98.480, Test_accy 49.890
2024-01-11 04:19:55,811 [bic.py] => training => Task 2, Epoch 172/200 => Loss 1.278, Train_accy 98.710, Test_accy 50.560
2024-01-11 04:20:23,952 [bic.py] => training => Task 2, Epoch 173/200 => Loss 1.278, Train_accy 98.630, Test_accy 50.130
2024-01-11 04:20:51,721 [bic.py] => training => Task 2, Epoch 174/200 => Loss 1.286, Train_accy 98.480, Test_accy 49.410
2024-01-11 04:21:19,936 [bic.py] => training => Task 2, Epoch 175/200 => Loss 1.272, Train_accy 98.290, Test_accy 49.290
2024-01-11 04:21:48,168 [bic.py] => training => Task 2, Epoch 176/200 => Loss 1.264, Train_accy 98.270, Test_accy 49.840
2024-01-11 04:22:14,461 [bic.py] => training => Task 2, Epoch 177/200 => Loss 1.273, Train_accy 98.760, Test_accy 50.300
2024-01-11 04:22:42,518 [bic.py] => training => Task 2, Epoch 178/200 => Loss 1.302, Train_accy 98.330, Test_accy 49.380
2024-01-11 04:23:10,179 [bic.py] => training => Task 2, Epoch 179/200 => Loss 1.278, Train_accy 98.330, Test_accy 49.160
2024-01-11 04:23:38,309 [bic.py] => training => Task 2, Epoch 180/200 => Loss 1.270, Train_accy 98.610, Test_accy 50.000
2024-01-11 04:24:06,658 [bic.py] => training => Task 2, Epoch 181/200 => Loss 1.257, Train_accy 98.670, Test_accy 50.250
2024-01-11 04:24:34,771 [bic.py] => training => Task 2, Epoch 182/200 => Loss 1.265, Train_accy 98.670, Test_accy 49.750
2024-01-11 04:25:02,411 [bic.py] => training => Task 2, Epoch 183/200 => Loss 1.272, Train_accy 98.310, Test_accy 49.670
2024-01-11 04:25:29,320 [bic.py] => training => Task 2, Epoch 184/200 => Loss 1.273, Train_accy 98.780, Test_accy 49.970
2024-01-11 04:25:57,323 [bic.py] => training => Task 2, Epoch 185/200 => Loss 1.276, Train_accy 98.310, Test_accy 49.410
2024-01-11 04:26:25,731 [bic.py] => training => Task 2, Epoch 186/200 => Loss 1.269, Train_accy 98.460, Test_accy 49.190
2024-01-11 04:26:54,470 [bic.py] => training => Task 2, Epoch 187/200 => Loss 1.266, Train_accy 98.460, Test_accy 49.870
2024-01-11 04:27:23,454 [bic.py] => training => Task 2, Epoch 188/200 => Loss 1.275, Train_accy 98.730, Test_accy 50.110
2024-01-11 04:27:51,536 [bic.py] => training => Task 2, Epoch 189/200 => Loss 1.281, Train_accy 98.540, Test_accy 50.460
2024-01-11 04:28:18,564 [bic.py] => training => Task 2, Epoch 190/200 => Loss 1.274, Train_accy 98.590, Test_accy 49.680
2024-01-11 04:28:46,897 [bic.py] => training => Task 2, Epoch 191/200 => Loss 1.266, Train_accy 98.630, Test_accy 49.700
2024-01-11 04:29:15,751 [bic.py] => training => Task 2, Epoch 192/200 => Loss 1.271, Train_accy 98.760, Test_accy 49.830
2024-01-11 04:29:44,550 [bic.py] => training => Task 2, Epoch 193/200 => Loss 1.293, Train_accy 98.400, Test_accy 49.900
2024-01-11 04:30:13,231 [bic.py] => training => Task 2, Epoch 194/200 => Loss 1.303, Train_accy 98.630, Test_accy 49.730
2024-01-11 04:30:41,145 [bic.py] => training => Task 2, Epoch 195/200 => Loss 1.272, Train_accy 98.710, Test_accy 50.460
2024-01-11 04:31:08,223 [bic.py] => training => Task 2, Epoch 196/200 => Loss 1.308, Train_accy 98.710, Test_accy 49.590
2024-01-11 04:31:37,135 [bic.py] => training => Task 2, Epoch 197/200 => Loss 1.279, Train_accy 98.440, Test_accy 49.870
2024-01-11 04:32:05,779 [bic.py] => training => Task 2, Epoch 198/200 => Loss 1.269, Train_accy 98.670, Test_accy 50.190
2024-01-11 04:32:34,411 [bic.py] => training => Task 2, Epoch 199/200 => Loss 1.267, Train_accy 98.480, Test_accy 49.520
2024-01-11 04:33:02,618 [bic.py] => training => Task 2, Epoch 200/200 => Loss 1.289, Train_accy 98.670, Test_accy 50.320
2024-01-11 04:33:13,030 [bic.py] => bias_correction => Task 2, Epoch 1/200 => Loss 3.226, Train_accy 50.950, Test_accy 51.100
2024-01-11 04:33:23,036 [bic.py] => bias_correction => Task 2, Epoch 2/200 => Loss 3.201, Train_accy 53.330, Test_accy 53.870
2024-01-11 04:33:32,922 [bic.py] => bias_correction => Task 2, Epoch 3/200 => Loss 3.182, Train_accy 54.290, Test_accy 53.630
2024-01-11 04:33:43,057 [bic.py] => bias_correction => Task 2, Epoch 4/200 => Loss 3.183, Train_accy 52.380, Test_accy 51.870
2024-01-11 04:33:53,116 [bic.py] => bias_correction => Task 2, Epoch 5/200 => Loss 3.197, Train_accy 51.430, Test_accy 51.940
2024-01-11 04:34:02,691 [bic.py] => bias_correction => Task 2, Epoch 6/200 => Loss 3.187, Train_accy 53.330, Test_accy 52.870
2024-01-11 04:34:12,629 [bic.py] => bias_correction => Task 2, Epoch 7/200 => Loss 3.177, Train_accy 54.760, Test_accy 52.510
2024-01-11 04:34:22,782 [bic.py] => bias_correction => Task 2, Epoch 8/200 => Loss 3.187, Train_accy 50.950, Test_accy 50.520
2024-01-11 04:34:32,856 [bic.py] => bias_correction => Task 2, Epoch 9/200 => Loss 3.200, Train_accy 50.480, Test_accy 50.160
2024-01-11 04:34:43,022 [bic.py] => bias_correction => Task 2, Epoch 10/200 => Loss 3.196, Train_accy 53.330, Test_accy 51.630
2024-01-11 04:34:53,162 [bic.py] => bias_correction => Task 2, Epoch 11/200 => Loss 3.187, Train_accy 55.240, Test_accy 52.210
2024-01-11 04:35:02,822 [bic.py] => bias_correction => Task 2, Epoch 12/200 => Loss 3.171, Train_accy 53.810, Test_accy 51.670
2024-01-11 04:35:13,464 [bic.py] => bias_correction => Task 2, Epoch 13/200 => Loss 3.181, Train_accy 54.290, Test_accy 51.630
2024-01-11 04:35:23,542 [bic.py] => bias_correction => Task 2, Epoch 14/200 => Loss 3.182, Train_accy 56.190, Test_accy 52.030
2024-01-11 04:35:33,613 [bic.py] => bias_correction => Task 2, Epoch 15/200 => Loss 3.180, Train_accy 53.810, Test_accy 51.670
2024-01-11 04:35:43,506 [bic.py] => bias_correction => Task 2, Epoch 16/200 => Loss 3.189, Train_accy 52.380, Test_accy 51.240
2024-01-11 04:35:53,541 [bic.py] => bias_correction => Task 2, Epoch 17/200 => Loss 3.187, Train_accy 53.810, Test_accy 51.650
2024-01-11 04:36:03,565 [bic.py] => bias_correction => Task 2, Epoch 18/200 => Loss 3.172, Train_accy 55.710, Test_accy 51.950
2024-01-11 04:36:13,442 [bic.py] => bias_correction => Task 2, Epoch 19/200 => Loss 3.167, Train_accy 54.290, Test_accy 51.890
2024-01-11 04:36:23,346 [bic.py] => bias_correction => Task 2, Epoch 20/200 => Loss 3.177, Train_accy 55.240, Test_accy 51.920
2024-01-11 04:36:32,994 [bic.py] => bias_correction => Task 2, Epoch 21/200 => Loss 3.176, Train_accy 55.240, Test_accy 52.110
2024-01-11 04:36:42,958 [bic.py] => bias_correction => Task 2, Epoch 22/200 => Loss 3.168, Train_accy 55.710, Test_accy 52.140
2024-01-11 04:36:53,174 [bic.py] => bias_correction => Task 2, Epoch 23/200 => Loss 3.166, Train_accy 52.860, Test_accy 51.480
2024-01-11 04:37:03,049 [bic.py] => bias_correction => Task 2, Epoch 24/200 => Loss 3.180, Train_accy 52.860, Test_accy 51.140
2024-01-11 04:37:12,873 [bic.py] => bias_correction => Task 2, Epoch 25/200 => Loss 3.182, Train_accy 54.290, Test_accy 51.900
2024-01-11 04:37:23,156 [bic.py] => bias_correction => Task 2, Epoch 26/200 => Loss 3.167, Train_accy 55.710, Test_accy 52.250
2024-01-11 04:37:33,416 [bic.py] => bias_correction => Task 2, Epoch 27/200 => Loss 3.167, Train_accy 54.290, Test_accy 52.110
2024-01-11 04:37:44,003 [bic.py] => bias_correction => Task 2, Epoch 28/200 => Loss 3.177, Train_accy 54.760, Test_accy 52.220
2024-01-11 04:37:54,561 [bic.py] => bias_correction => Task 2, Epoch 29/200 => Loss 3.185, Train_accy 55.240, Test_accy 51.860
2024-01-11 04:38:04,598 [bic.py] => bias_correction => Task 2, Epoch 30/200 => Loss 3.157, Train_accy 53.810, Test_accy 51.870
2024-01-11 04:38:14,706 [bic.py] => bias_correction => Task 2, Epoch 31/200 => Loss 3.174, Train_accy 54.760, Test_accy 52.020
2024-01-11 04:38:24,860 [bic.py] => bias_correction => Task 2, Epoch 32/200 => Loss 3.153, Train_accy 55.240, Test_accy 52.380
2024-01-11 04:38:34,808 [bic.py] => bias_correction => Task 2, Epoch 33/200 => Loss 3.158, Train_accy 55.240, Test_accy 52.290
2024-01-11 04:38:45,192 [bic.py] => bias_correction => Task 2, Epoch 34/200 => Loss 3.157, Train_accy 54.760, Test_accy 52.220
2024-01-11 04:38:55,259 [bic.py] => bias_correction => Task 2, Epoch 35/200 => Loss 3.170, Train_accy 54.760, Test_accy 52.510
2024-01-11 04:39:05,149 [bic.py] => bias_correction => Task 2, Epoch 36/200 => Loss 3.171, Train_accy 54.760, Test_accy 52.300
2024-01-11 04:39:15,135 [bic.py] => bias_correction => Task 2, Epoch 37/200 => Loss 3.179, Train_accy 54.290, Test_accy 52.170
2024-01-11 04:39:24,853 [bic.py] => bias_correction => Task 2, Epoch 38/200 => Loss 3.168, Train_accy 55.710, Test_accy 51.890
2024-01-11 04:39:35,224 [bic.py] => bias_correction => Task 2, Epoch 39/200 => Loss 3.153, Train_accy 55.710, Test_accy 52.250
2024-01-11 04:39:45,312 [bic.py] => bias_correction => Task 2, Epoch 40/200 => Loss 3.168, Train_accy 55.710, Test_accy 52.490
2024-01-11 04:39:55,506 [bic.py] => bias_correction => Task 2, Epoch 41/200 => Loss 3.170, Train_accy 55.710, Test_accy 52.160
2024-01-11 04:40:05,655 [bic.py] => bias_correction => Task 2, Epoch 42/200 => Loss 3.167, Train_accy 55.710, Test_accy 52.560
2024-01-11 04:40:15,840 [bic.py] => bias_correction => Task 2, Epoch 43/200 => Loss 3.159, Train_accy 54.760, Test_accy 52.300
2024-01-11 04:40:25,899 [bic.py] => bias_correction => Task 2, Epoch 44/200 => Loss 3.170, Train_accy 54.290, Test_accy 51.840
2024-01-11 04:40:35,900 [bic.py] => bias_correction => Task 2, Epoch 45/200 => Loss 3.165, Train_accy 55.710, Test_accy 52.210
2024-01-11 04:40:45,979 [bic.py] => bias_correction => Task 2, Epoch 46/200 => Loss 3.156, Train_accy 55.710, Test_accy 52.440
2024-01-11 04:40:56,076 [bic.py] => bias_correction => Task 2, Epoch 47/200 => Loss 3.163, Train_accy 56.190, Test_accy 52.560
2024-01-11 04:41:06,290 [bic.py] => bias_correction => Task 2, Epoch 48/200 => Loss 3.174, Train_accy 56.670, Test_accy 52.710
2024-01-11 04:41:16,559 [bic.py] => bias_correction => Task 2, Epoch 49/200 => Loss 3.154, Train_accy 56.190, Test_accy 52.750
2024-01-11 04:41:26,789 [bic.py] => bias_correction => Task 2, Epoch 50/200 => Loss 3.143, Train_accy 55.240, Test_accy 52.480
2024-01-11 04:41:36,962 [bic.py] => bias_correction => Task 2, Epoch 51/200 => Loss 3.173, Train_accy 52.860, Test_accy 51.400
2024-01-11 04:41:46,296 [bic.py] => bias_correction => Task 2, Epoch 52/200 => Loss 3.170, Train_accy 52.860, Test_accy 51.290
2024-01-11 04:41:56,399 [bic.py] => bias_correction => Task 2, Epoch 53/200 => Loss 3.148, Train_accy 55.240, Test_accy 52.440
2024-01-11 04:42:06,230 [bic.py] => bias_correction => Task 2, Epoch 54/200 => Loss 3.159, Train_accy 55.240, Test_accy 52.830
2024-01-11 04:42:16,211 [bic.py] => bias_correction => Task 2, Epoch 55/200 => Loss 3.173, Train_accy 55.240, Test_accy 52.510
2024-01-11 04:42:26,332 [bic.py] => bias_correction => Task 2, Epoch 56/200 => Loss 3.166, Train_accy 54.760, Test_accy 52.830
2024-01-11 04:42:36,308 [bic.py] => bias_correction => Task 2, Epoch 57/200 => Loss 3.149, Train_accy 55.710, Test_accy 52.810
2024-01-11 04:42:46,266 [bic.py] => bias_correction => Task 2, Epoch 58/200 => Loss 3.159, Train_accy 54.290, Test_accy 52.490
2024-01-11 04:42:56,371 [bic.py] => bias_correction => Task 2, Epoch 59/200 => Loss 3.175, Train_accy 53.330, Test_accy 52.480
2024-01-11 04:43:06,264 [bic.py] => bias_correction => Task 2, Epoch 60/200 => Loss 3.152, Train_accy 54.760, Test_accy 52.680
2024-01-11 04:43:16,332 [bic.py] => bias_correction => Task 2, Epoch 61/200 => Loss 3.152, Train_accy 55.240, Test_accy 52.940
2024-01-11 04:43:26,402 [bic.py] => bias_correction => Task 2, Epoch 62/200 => Loss 3.157, Train_accy 54.760, Test_accy 52.920
2024-01-11 04:43:36,364 [bic.py] => bias_correction => Task 2, Epoch 63/200 => Loss 3.157, Train_accy 53.810, Test_accy 52.970
2024-01-11 04:43:46,495 [bic.py] => bias_correction => Task 2, Epoch 64/200 => Loss 3.155, Train_accy 54.760, Test_accy 52.920
2024-01-11 04:43:56,859 [bic.py] => bias_correction => Task 2, Epoch 65/200 => Loss 3.152, Train_accy 55.240, Test_accy 52.900
2024-01-11 04:44:06,773 [bic.py] => bias_correction => Task 2, Epoch 66/200 => Loss 3.168, Train_accy 55.240, Test_accy 53.000
2024-01-11 04:44:16,665 [bic.py] => bias_correction => Task 2, Epoch 67/200 => Loss 3.164, Train_accy 55.240, Test_accy 53.060
2024-01-11 04:44:26,248 [bic.py] => bias_correction => Task 2, Epoch 68/200 => Loss 3.153, Train_accy 55.240, Test_accy 52.970
2024-01-11 04:44:36,503 [bic.py] => bias_correction => Task 2, Epoch 69/200 => Loss 3.161, Train_accy 54.760, Test_accy 52.860
2024-01-11 04:44:46,117 [bic.py] => bias_correction => Task 2, Epoch 70/200 => Loss 3.165, Train_accy 54.760, Test_accy 52.890
2024-01-11 04:44:56,078 [bic.py] => bias_correction => Task 2, Epoch 71/200 => Loss 3.163, Train_accy 55.240, Test_accy 52.940
2024-01-11 04:45:06,061 [bic.py] => bias_correction => Task 2, Epoch 72/200 => Loss 3.154, Train_accy 55.240, Test_accy 53.110
2024-01-11 04:45:16,037 [bic.py] => bias_correction => Task 2, Epoch 73/200 => Loss 3.162, Train_accy 55.240, Test_accy 52.900
2024-01-11 04:45:26,125 [bic.py] => bias_correction => Task 2, Epoch 74/200 => Loss 3.168, Train_accy 55.240, Test_accy 52.940
2024-01-11 04:45:36,087 [bic.py] => bias_correction => Task 2, Epoch 75/200 => Loss 3.156, Train_accy 55.240, Test_accy 52.700
2024-01-11 04:45:46,244 [bic.py] => bias_correction => Task 2, Epoch 76/200 => Loss 3.160, Train_accy 54.760, Test_accy 52.870
2024-01-11 04:45:56,099 [bic.py] => bias_correction => Task 2, Epoch 77/200 => Loss 3.156, Train_accy 55.240, Test_accy 52.730
2024-01-11 04:46:06,193 [bic.py] => bias_correction => Task 2, Epoch 78/200 => Loss 3.170, Train_accy 55.240, Test_accy 52.830
2024-01-11 04:46:16,094 [bic.py] => bias_correction => Task 2, Epoch 79/200 => Loss 3.160, Train_accy 55.240, Test_accy 52.780
2024-01-11 04:46:26,287 [bic.py] => bias_correction => Task 2, Epoch 80/200 => Loss 3.157, Train_accy 54.760, Test_accy 52.630
2024-01-11 04:46:36,472 [bic.py] => bias_correction => Task 2, Epoch 81/200 => Loss 3.148, Train_accy 55.240, Test_accy 52.730
2024-01-11 04:46:46,565 [bic.py] => bias_correction => Task 2, Epoch 82/200 => Loss 3.157, Train_accy 55.710, Test_accy 52.830
2024-01-11 04:46:56,360 [bic.py] => bias_correction => Task 2, Epoch 83/200 => Loss 3.164, Train_accy 54.760, Test_accy 52.840
2024-01-11 04:47:05,917 [bic.py] => bias_correction => Task 2, Epoch 84/200 => Loss 3.153, Train_accy 54.290, Test_accy 52.830
2024-01-11 04:47:16,032 [bic.py] => bias_correction => Task 2, Epoch 85/200 => Loss 3.157, Train_accy 54.760, Test_accy 52.780
2024-01-11 04:47:25,756 [bic.py] => bias_correction => Task 2, Epoch 86/200 => Loss 3.159, Train_accy 54.760, Test_accy 52.780
2024-01-11 04:47:35,729 [bic.py] => bias_correction => Task 2, Epoch 87/200 => Loss 3.155, Train_accy 54.760, Test_accy 52.890
2024-01-11 04:47:45,751 [bic.py] => bias_correction => Task 2, Epoch 88/200 => Loss 3.167, Train_accy 55.240, Test_accy 52.950
2024-01-11 04:47:55,866 [bic.py] => bias_correction => Task 2, Epoch 89/200 => Loss 3.166, Train_accy 55.240, Test_accy 52.840
2024-01-11 04:48:05,877 [bic.py] => bias_correction => Task 2, Epoch 90/200 => Loss 3.158, Train_accy 55.240, Test_accy 52.870
2024-01-11 04:48:16,014 [bic.py] => bias_correction => Task 2, Epoch 91/200 => Loss 3.148, Train_accy 55.240, Test_accy 52.840
2024-01-11 04:48:26,000 [bic.py] => bias_correction => Task 2, Epoch 92/200 => Loss 3.148, Train_accy 55.240, Test_accy 52.840
2024-01-11 04:48:35,887 [bic.py] => bias_correction => Task 2, Epoch 93/200 => Loss 3.170, Train_accy 55.240, Test_accy 52.730
2024-01-11 04:48:45,990 [bic.py] => bias_correction => Task 2, Epoch 94/200 => Loss 3.150, Train_accy 54.760, Test_accy 52.710
2024-01-11 04:48:55,979 [bic.py] => bias_correction => Task 2, Epoch 95/200 => Loss 3.185, Train_accy 54.290, Test_accy 52.680
2024-01-11 04:49:06,207 [bic.py] => bias_correction => Task 2, Epoch 96/200 => Loss 3.159, Train_accy 55.240, Test_accy 52.670
2024-01-11 04:49:16,086 [bic.py] => bias_correction => Task 2, Epoch 97/200 => Loss 3.177, Train_accy 54.760, Test_accy 52.700
2024-01-11 04:49:26,079 [bic.py] => bias_correction => Task 2, Epoch 98/200 => Loss 3.137, Train_accy 55.240, Test_accy 52.630
2024-01-11 04:49:36,071 [bic.py] => bias_correction => Task 2, Epoch 99/200 => Loss 3.143, Train_accy 55.240, Test_accy 52.670
2024-01-11 04:49:46,056 [bic.py] => bias_correction => Task 2, Epoch 100/200 => Loss 3.149, Train_accy 54.760, Test_accy 52.700
2024-01-11 04:49:55,905 [bic.py] => bias_correction => Task 2, Epoch 101/200 => Loss 3.162, Train_accy 55.240, Test_accy 52.680
2024-01-11 04:50:05,468 [bic.py] => bias_correction => Task 2, Epoch 102/200 => Loss 3.156, Train_accy 54.760, Test_accy 52.700
2024-01-11 04:50:15,606 [bic.py] => bias_correction => Task 2, Epoch 103/200 => Loss 3.146, Train_accy 54.760, Test_accy 52.760
2024-01-11 04:50:25,775 [bic.py] => bias_correction => Task 2, Epoch 104/200 => Loss 3.159, Train_accy 55.710, Test_accy 52.710
2024-01-11 04:50:35,754 [bic.py] => bias_correction => Task 2, Epoch 105/200 => Loss 3.154, Train_accy 55.240, Test_accy 52.730
2024-01-11 04:50:46,400 [bic.py] => bias_correction => Task 2, Epoch 106/200 => Loss 3.168, Train_accy 55.710, Test_accy 52.700
2024-01-11 04:50:56,573 [bic.py] => bias_correction => Task 2, Epoch 107/200 => Loss 3.174, Train_accy 54.760, Test_accy 52.860
2024-01-11 04:51:06,841 [bic.py] => bias_correction => Task 2, Epoch 108/200 => Loss 3.165, Train_accy 55.240, Test_accy 52.920
2024-01-11 04:51:17,010 [bic.py] => bias_correction => Task 2, Epoch 109/200 => Loss 3.166, Train_accy 55.240, Test_accy 52.840
2024-01-11 04:51:27,176 [bic.py] => bias_correction => Task 2, Epoch 110/200 => Loss 3.139, Train_accy 55.240, Test_accy 52.970
2024-01-11 04:51:37,887 [bic.py] => bias_correction => Task 2, Epoch 111/200 => Loss 3.163, Train_accy 54.760, Test_accy 52.940
2024-01-11 04:51:47,859 [bic.py] => bias_correction => Task 2, Epoch 112/200 => Loss 3.176, Train_accy 54.760, Test_accy 52.810
2024-01-11 04:51:57,945 [bic.py] => bias_correction => Task 2, Epoch 113/200 => Loss 3.170, Train_accy 54.760, Test_accy 52.790
2024-01-11 04:52:08,049 [bic.py] => bias_correction => Task 2, Epoch 114/200 => Loss 3.138, Train_accy 54.760, Test_accy 52.950
2024-01-11 04:52:18,141 [bic.py] => bias_correction => Task 2, Epoch 115/200 => Loss 3.152, Train_accy 54.290, Test_accy 52.950
2024-01-11 04:52:27,691 [bic.py] => bias_correction => Task 2, Epoch 116/200 => Loss 3.140, Train_accy 54.760, Test_accy 52.920
2024-01-11 04:52:37,412 [bic.py] => bias_correction => Task 2, Epoch 117/200 => Loss 3.165, Train_accy 55.240, Test_accy 52.940
2024-01-11 04:52:47,391 [bic.py] => bias_correction => Task 2, Epoch 118/200 => Loss 3.158, Train_accy 55.240, Test_accy 52.950
2024-01-11 04:52:57,414 [bic.py] => bias_correction => Task 2, Epoch 119/200 => Loss 3.151, Train_accy 55.240, Test_accy 52.870
2024-01-11 04:53:07,492 [bic.py] => bias_correction => Task 2, Epoch 120/200 => Loss 3.156, Train_accy 55.710, Test_accy 52.920
2024-01-11 04:53:17,888 [bic.py] => bias_correction => Task 2, Epoch 121/200 => Loss 3.151, Train_accy 55.710, Test_accy 52.920
2024-01-11 04:53:28,014 [bic.py] => bias_correction => Task 2, Epoch 122/200 => Loss 3.157, Train_accy 54.760, Test_accy 52.950
2024-01-11 04:53:38,158 [bic.py] => bias_correction => Task 2, Epoch 123/200 => Loss 3.168, Train_accy 55.710, Test_accy 52.920
2024-01-11 04:53:48,351 [bic.py] => bias_correction => Task 2, Epoch 124/200 => Loss 3.161, Train_accy 55.710, Test_accy 52.890
2024-01-11 04:53:58,468 [bic.py] => bias_correction => Task 2, Epoch 125/200 => Loss 3.177, Train_accy 55.240, Test_accy 52.950
2024-01-11 04:54:08,768 [bic.py] => bias_correction => Task 2, Epoch 126/200 => Loss 3.169, Train_accy 55.240, Test_accy 52.970
2024-01-11 04:54:18,897 [bic.py] => bias_correction => Task 2, Epoch 127/200 => Loss 3.147, Train_accy 55.240, Test_accy 52.980
2024-01-11 04:54:28,911 [bic.py] => bias_correction => Task 2, Epoch 128/200 => Loss 3.151, Train_accy 55.240, Test_accy 52.970
2024-01-11 04:54:38,934 [bic.py] => bias_correction => Task 2, Epoch 129/200 => Loss 3.148, Train_accy 55.240, Test_accy 52.890
2024-01-11 04:54:49,118 [bic.py] => bias_correction => Task 2, Epoch 130/200 => Loss 3.149, Train_accy 55.240, Test_accy 52.830
2024-01-11 04:54:59,040 [bic.py] => bias_correction => Task 2, Epoch 131/200 => Loss 3.152, Train_accy 55.710, Test_accy 52.980
2024-01-11 04:55:08,596 [bic.py] => bias_correction => Task 2, Epoch 132/200 => Loss 3.164, Train_accy 55.240, Test_accy 52.900
2024-01-11 04:55:18,591 [bic.py] => bias_correction => Task 2, Epoch 133/200 => Loss 3.158, Train_accy 56.190, Test_accy 52.920
2024-01-11 04:55:28,660 [bic.py] => bias_correction => Task 2, Epoch 134/200 => Loss 3.152, Train_accy 56.190, Test_accy 52.920
2024-01-11 04:55:39,044 [bic.py] => bias_correction => Task 2, Epoch 135/200 => Loss 3.166, Train_accy 55.710, Test_accy 52.760
2024-01-11 04:55:49,387 [bic.py] => bias_correction => Task 2, Epoch 136/200 => Loss 3.151, Train_accy 56.190, Test_accy 52.870
2024-01-11 04:55:59,727 [bic.py] => bias_correction => Task 2, Epoch 137/200 => Loss 3.156, Train_accy 55.710, Test_accy 52.840
2024-01-11 04:56:10,035 [bic.py] => bias_correction => Task 2, Epoch 138/200 => Loss 3.167, Train_accy 55.710, Test_accy 52.940
2024-01-11 04:56:20,391 [bic.py] => bias_correction => Task 2, Epoch 139/200 => Loss 3.173, Train_accy 55.240, Test_accy 52.870
2024-01-11 04:56:30,801 [bic.py] => bias_correction => Task 2, Epoch 140/200 => Loss 3.154, Train_accy 55.710, Test_accy 52.970
2024-01-11 04:56:41,038 [bic.py] => bias_correction => Task 2, Epoch 141/200 => Loss 3.165, Train_accy 55.240, Test_accy 52.790
2024-01-11 04:56:51,077 [bic.py] => bias_correction => Task 2, Epoch 142/200 => Loss 3.155, Train_accy 55.240, Test_accy 52.680
2024-01-11 04:57:01,300 [bic.py] => bias_correction => Task 2, Epoch 143/200 => Loss 3.152, Train_accy 55.240, Test_accy 52.830
2024-01-11 04:57:11,404 [bic.py] => bias_correction => Task 2, Epoch 144/200 => Loss 3.152, Train_accy 55.240, Test_accy 52.700
2024-01-11 04:57:21,959 [bic.py] => bias_correction => Task 2, Epoch 145/200 => Loss 3.168, Train_accy 55.240, Test_accy 52.830
2024-01-11 04:57:32,147 [bic.py] => bias_correction => Task 2, Epoch 146/200 => Loss 3.152, Train_accy 55.240, Test_accy 52.840
2024-01-11 04:57:42,326 [bic.py] => bias_correction => Task 2, Epoch 147/200 => Loss 3.144, Train_accy 55.240, Test_accy 52.680
2024-01-11 04:57:52,351 [bic.py] => bias_correction => Task 2, Epoch 148/200 => Loss 3.174, Train_accy 55.240, Test_accy 52.780
2024-01-11 04:58:02,399 [bic.py] => bias_correction => Task 2, Epoch 149/200 => Loss 3.166, Train_accy 55.240, Test_accy 53.020
2024-01-11 04:58:12,571 [bic.py] => bias_correction => Task 2, Epoch 150/200 => Loss 3.152, Train_accy 54.760, Test_accy 52.860
2024-01-11 04:58:22,687 [bic.py] => bias_correction => Task 2, Epoch 151/200 => Loss 3.159, Train_accy 55.710, Test_accy 53.170
2024-01-11 04:58:32,670 [bic.py] => bias_correction => Task 2, Epoch 152/200 => Loss 3.163, Train_accy 55.240, Test_accy 52.950
2024-01-11 04:58:42,719 [bic.py] => bias_correction => Task 2, Epoch 153/200 => Loss 3.155, Train_accy 54.760, Test_accy 52.950
2024-01-11 04:58:52,648 [bic.py] => bias_correction => Task 2, Epoch 154/200 => Loss 3.151, Train_accy 54.760, Test_accy 53.060
2024-01-11 04:59:02,696 [bic.py] => bias_correction => Task 2, Epoch 155/200 => Loss 3.159, Train_accy 54.760, Test_accy 52.870
2024-01-11 04:59:12,783 [bic.py] => bias_correction => Task 2, Epoch 156/200 => Loss 3.153, Train_accy 54.760, Test_accy 52.950
2024-01-11 04:59:22,865 [bic.py] => bias_correction => Task 2, Epoch 157/200 => Loss 3.166, Train_accy 54.290, Test_accy 52.900
2024-01-11 04:59:32,986 [bic.py] => bias_correction => Task 2, Epoch 158/200 => Loss 3.148, Train_accy 54.760, Test_accy 52.940
2024-01-11 04:59:42,915 [bic.py] => bias_correction => Task 2, Epoch 159/200 => Loss 3.161, Train_accy 54.760, Test_accy 52.870
2024-01-11 04:59:53,488 [bic.py] => bias_correction => Task 2, Epoch 160/200 => Loss 3.163, Train_accy 54.760, Test_accy 52.890
2024-01-11 05:00:03,985 [bic.py] => bias_correction => Task 2, Epoch 161/200 => Loss 3.157, Train_accy 54.760, Test_accy 52.920
2024-01-11 05:00:13,944 [bic.py] => bias_correction => Task 2, Epoch 162/200 => Loss 3.163, Train_accy 54.760, Test_accy 52.900
2024-01-11 05:00:23,637 [bic.py] => bias_correction => Task 2, Epoch 163/200 => Loss 3.161, Train_accy 54.760, Test_accy 52.810
2024-01-11 05:00:33,793 [bic.py] => bias_correction => Task 2, Epoch 164/200 => Loss 3.129, Train_accy 54.760, Test_accy 52.940
2024-01-11 05:00:43,687 [bic.py] => bias_correction => Task 2, Epoch 165/200 => Loss 3.159, Train_accy 54.760, Test_accy 52.920
2024-01-11 05:00:53,656 [bic.py] => bias_correction => Task 2, Epoch 166/200 => Loss 3.181, Train_accy 55.240, Test_accy 52.890
2024-01-11 05:01:03,843 [bic.py] => bias_correction => Task 2, Epoch 167/200 => Loss 3.149, Train_accy 55.240, Test_accy 52.920
2024-01-11 05:01:14,164 [bic.py] => bias_correction => Task 2, Epoch 168/200 => Loss 3.162, Train_accy 55.240, Test_accy 52.900
2024-01-11 05:01:24,322 [bic.py] => bias_correction => Task 2, Epoch 169/200 => Loss 3.154, Train_accy 55.240, Test_accy 52.840
2024-01-11 05:01:34,425 [bic.py] => bias_correction => Task 2, Epoch 170/200 => Loss 3.161, Train_accy 55.710, Test_accy 52.830
2024-01-11 05:01:44,755 [bic.py] => bias_correction => Task 2, Epoch 171/200 => Loss 3.154, Train_accy 56.190, Test_accy 52.860
2024-01-11 05:01:54,885 [bic.py] => bias_correction => Task 2, Epoch 172/200 => Loss 3.162, Train_accy 55.240, Test_accy 52.790
2024-01-11 05:02:05,412 [bic.py] => bias_correction => Task 2, Epoch 173/200 => Loss 3.154, Train_accy 55.240, Test_accy 52.920
2024-01-11 05:02:16,201 [bic.py] => bias_correction => Task 2, Epoch 174/200 => Loss 3.149, Train_accy 55.710, Test_accy 52.760
2024-01-11 05:02:26,566 [bic.py] => bias_correction => Task 2, Epoch 175/200 => Loss 3.159, Train_accy 55.710, Test_accy 52.780
2024-01-11 05:02:36,999 [bic.py] => bias_correction => Task 2, Epoch 176/200 => Loss 3.150, Train_accy 54.760, Test_accy 52.760
2024-01-11 05:02:47,189 [bic.py] => bias_correction => Task 2, Epoch 177/200 => Loss 3.163, Train_accy 55.710, Test_accy 52.730
2024-01-11 05:02:57,905 [bic.py] => bias_correction => Task 2, Epoch 178/200 => Loss 3.160, Train_accy 54.760, Test_accy 52.810
2024-01-11 05:03:07,696 [bic.py] => bias_correction => Task 2, Epoch 179/200 => Loss 3.158, Train_accy 54.760, Test_accy 52.950
2024-01-11 05:03:17,585 [bic.py] => bias_correction => Task 2, Epoch 180/200 => Loss 3.156, Train_accy 55.240, Test_accy 52.950
2024-01-11 05:03:27,634 [bic.py] => bias_correction => Task 2, Epoch 181/200 => Loss 3.149, Train_accy 55.240, Test_accy 52.980
2024-01-11 05:03:37,889 [bic.py] => bias_correction => Task 2, Epoch 182/200 => Loss 3.159, Train_accy 54.760, Test_accy 52.950
2024-01-11 05:03:48,077 [bic.py] => bias_correction => Task 2, Epoch 183/200 => Loss 3.165, Train_accy 54.760, Test_accy 52.870
2024-01-11 05:03:58,166 [bic.py] => bias_correction => Task 2, Epoch 184/200 => Loss 3.169, Train_accy 54.760, Test_accy 52.830
2024-01-11 05:04:08,189 [bic.py] => bias_correction => Task 2, Epoch 185/200 => Loss 3.158, Train_accy 54.760, Test_accy 52.870
2024-01-11 05:04:18,279 [bic.py] => bias_correction => Task 2, Epoch 186/200 => Loss 3.152, Train_accy 54.760, Test_accy 52.970
2024-01-11 05:04:28,557 [bic.py] => bias_correction => Task 2, Epoch 187/200 => Loss 3.147, Train_accy 54.760, Test_accy 52.950
2024-01-11 05:04:39,014 [bic.py] => bias_correction => Task 2, Epoch 188/200 => Loss 3.165, Train_accy 54.760, Test_accy 52.900
2024-01-11 05:04:49,033 [bic.py] => bias_correction => Task 2, Epoch 189/200 => Loss 3.151, Train_accy 55.710, Test_accy 52.980
2024-01-11 05:04:59,409 [bic.py] => bias_correction => Task 2, Epoch 190/200 => Loss 3.146, Train_accy 55.710, Test_accy 52.840
2024-01-11 05:05:09,767 [bic.py] => bias_correction => Task 2, Epoch 191/200 => Loss 3.156, Train_accy 55.240, Test_accy 52.810
2024-01-11 05:05:19,892 [bic.py] => bias_correction => Task 2, Epoch 192/200 => Loss 3.160, Train_accy 55.240, Test_accy 52.860
2024-01-11 05:05:29,924 [bic.py] => bias_correction => Task 2, Epoch 193/200 => Loss 3.146, Train_accy 54.760, Test_accy 52.920
2024-01-11 05:05:40,149 [bic.py] => bias_correction => Task 2, Epoch 194/200 => Loss 3.171, Train_accy 55.240, Test_accy 52.900
2024-01-11 05:05:50,132 [bic.py] => bias_correction => Task 2, Epoch 195/200 => Loss 3.168, Train_accy 55.710, Test_accy 52.760
2024-01-11 05:05:59,934 [bic.py] => bias_correction => Task 2, Epoch 196/200 => Loss 3.159, Train_accy 55.710, Test_accy 52.860
2024-01-11 05:06:09,934 [bic.py] => bias_correction => Task 2, Epoch 197/200 => Loss 3.163, Train_accy 55.710, Test_accy 52.870
2024-01-11 05:06:20,243 [bic.py] => bias_correction => Task 2, Epoch 198/200 => Loss 3.136, Train_accy 55.710, Test_accy 52.810
2024-01-11 05:06:30,502 [bic.py] => bias_correction => Task 2, Epoch 199/200 => Loss 3.154, Train_accy 55.710, Test_accy 52.840
2024-01-11 05:06:40,861 [bic.py] => bias_correction => Task 2, Epoch 200/200 => Loss 3.166, Train_accy 55.710, Test_accy 52.860
2024-01-11 05:06:40,862 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-11 05:07:06,831 [bic.py] => Parameters of bias layer:
2024-01-11 05:07:06,832 [bic.py] => 0 => 1.000, 0.000
2024-01-11 05:07:06,832 [bic.py] => 1 => 0.791, -2.133
2024-01-11 05:07:06,832 [bic.py] => 2 => 0.880, -1.721
2024-01-11 05:07:22,486 [bic.py] => Exemplar size: 1050
2024-01-11 05:07:22,686 [trainer.py] => CNN: {'total': 52.86, '0': 78.89, '1': 48.33, '2': 50.0, '3': 23.33, '4': 31.11, '5': 30.0, '6': 21.11, '7': 29.44, '8': 55.56, '9': 25.56, '10': 39.44, '11': 47.78, '12': 35.0, '13': 37.78, '14': 49.44, '15': 57.78, '16': 71.11, '17': 49.44, '18': 55.0, '19': 41.67, '20': 43.33, '21': 42.22, '22': 38.33, '23': 32.78, '24': 46.11, '25': 68.89, '26': 89.44, '27': 82.22, '28': 56.67, '29': 71.11, '30': 80.56, '31': 78.89, '32': 97.22, '33': 68.89, 'old': 43.22, 'new': 76.94}
2024-01-11 05:07:22,686 [trainer.py] => NME: {'total': 51.03, '0': 76.67, '1': 40.56, '2': 62.78, '3': 27.22, '4': 37.22, '5': 32.78, '6': 30.56, '7': 45.0, '8': 42.22, '9': 27.22, '10': 52.22, '11': 60.56, '12': 39.44, '13': 42.22, '14': 47.78, '15': 55.56, '16': 63.89, '17': 65.0, '18': 60.0, '19': 50.56, '20': 58.89, '21': 51.67, '22': 60.56, '23': 53.33, '24': 45.56, '25': 45.0, '26': 61.67, '27': 57.78, '28': 39.44, '29': 48.89, '30': 61.67, '31': 59.44, '32': 79.44, '33': 50.0, 'old': 49.18, 'new': 55.67}
2024-01-11 05:07:22,686 [trainer.py] => CNN top1 curve: [86.11, 64.91, 52.86]
2024-01-11 05:07:22,686 [trainer.py] => CNN top5 curve: [97.7, 93.13, 84.13]
2024-01-11 05:07:22,686 [trainer.py] => NME top1 curve: [84.37, 68.27, 51.03]
2024-01-11 05:07:22,686 [trainer.py] => NME top5 curve: [98.07, 95.18, 88.78]

2024-01-11 05:07:22,686 [trainer.py] => All params: 21046133
2024-01-11 05:07:22,687 [trainer.py] => Trainable params: 21046133
2024-01-11 05:07:22,688 [bic.py] => Learning on 35-45
2024-01-11 05:07:22,723 [bic.py] => Stage1 dset: 5070, Stage2 dset: 180
2024-01-11 05:07:22,723 [bic.py] => Lambda: 0.778
2024-01-11 05:07:22,777 [bic.py] => Parameters of bias layer:
2024-01-11 05:07:22,778 [bic.py] => 0 => 1.000, 0.000
2024-01-11 05:07:22,778 [bic.py] => 1 => 0.791, -2.133
2024-01-11 05:07:22,778 [bic.py] => 2 => 0.880, -1.721
2024-01-11 05:07:22,778 [bic.py] => 3 => 1.000, 0.000
2024-01-11 05:08:12,130 [bic.py] => training => Task 3, Epoch 1/200 => Loss 2.374, Train_accy 40.670, Test_accy 18.370
2024-01-11 05:08:42,142 [bic.py] => training => Task 3, Epoch 2/200 => Loss 1.969, Train_accy 59.470, Test_accy 31.800
2024-01-11 05:09:13,303 [bic.py] => training => Task 3, Epoch 3/200 => Loss 1.865, Train_accy 68.010, Test_accy 35.430
2024-01-11 05:09:45,060 [bic.py] => training => Task 3, Epoch 4/200 => Loss 1.814, Train_accy 77.320, Test_accy 39.360
2024-01-11 05:10:16,775 [bic.py] => training => Task 3, Epoch 5/200 => Loss 1.779, Train_accy 81.200, Test_accy 41.190
2024-01-11 05:10:48,666 [bic.py] => training => Task 3, Epoch 6/200 => Loss 1.760, Train_accy 84.080, Test_accy 42.090
2024-01-11 05:11:19,684 [bic.py] => training => Task 3, Epoch 7/200 => Loss 1.733, Train_accy 84.160, Test_accy 41.250
2024-01-11 05:11:49,792 [bic.py] => training => Task 3, Epoch 8/200 => Loss 1.718, Train_accy 86.900, Test_accy 43.370
2024-01-11 05:12:21,582 [bic.py] => training => Task 3, Epoch 9/200 => Loss 1.705, Train_accy 87.630, Test_accy 43.640
2024-01-11 05:12:53,314 [bic.py] => training => Task 3, Epoch 10/200 => Loss 1.696, Train_accy 90.790, Test_accy 46.270
2024-01-11 05:13:24,998 [bic.py] => training => Task 3, Epoch 11/200 => Loss 1.682, Train_accy 91.240, Test_accy 45.570
2024-01-11 05:13:56,766 [bic.py] => training => Task 3, Epoch 12/200 => Loss 1.680, Train_accy 90.850, Test_accy 45.480
2024-01-11 05:14:28,065 [bic.py] => training => Task 3, Epoch 13/200 => Loss 1.676, Train_accy 91.700, Test_accy 46.560
2024-01-11 05:14:59,211 [bic.py] => training => Task 3, Epoch 14/200 => Loss 1.663, Train_accy 92.150, Test_accy 46.980
2024-01-11 05:15:30,835 [bic.py] => training => Task 3, Epoch 15/200 => Loss 1.659, Train_accy 92.250, Test_accy 46.120
2024-01-11 05:16:02,569 [bic.py] => training => Task 3, Epoch 16/200 => Loss 1.659, Train_accy 92.820, Test_accy 46.900
2024-01-11 05:16:34,279 [bic.py] => training => Task 3, Epoch 17/200 => Loss 1.661, Train_accy 91.680, Test_accy 45.560
2024-01-11 05:17:06,144 [bic.py] => training => Task 3, Epoch 18/200 => Loss 1.654, Train_accy 92.740, Test_accy 46.480
2024-01-11 05:17:36,296 [bic.py] => training => Task 3, Epoch 19/200 => Loss 1.645, Train_accy 94.420, Test_accy 48.900
2024-01-11 05:18:07,757 [bic.py] => training => Task 3, Epoch 20/200 => Loss 1.651, Train_accy 94.910, Test_accy 48.330
2024-01-11 05:18:38,730 [bic.py] => training => Task 3, Epoch 21/200 => Loss 1.643, Train_accy 94.990, Test_accy 48.260
2024-01-11 05:19:09,802 [bic.py] => training => Task 3, Epoch 22/200 => Loss 1.643, Train_accy 94.810, Test_accy 47.400
2024-01-11 05:19:41,201 [bic.py] => training => Task 3, Epoch 23/200 => Loss 1.637, Train_accy 95.520, Test_accy 48.230
2024-01-11 05:20:13,152 [bic.py] => training => Task 3, Epoch 24/200 => Loss 1.636, Train_accy 94.690, Test_accy 47.090
2024-01-11 05:20:44,562 [bic.py] => training => Task 3, Epoch 25/200 => Loss 1.627, Train_accy 96.230, Test_accy 49.440
2024-01-11 05:21:16,084 [bic.py] => training => Task 3, Epoch 26/200 => Loss 1.627, Train_accy 96.670, Test_accy 48.250
2024-01-11 05:21:47,589 [bic.py] => training => Task 3, Epoch 27/200 => Loss 1.629, Train_accy 95.720, Test_accy 48.320
2024-01-11 05:22:19,610 [bic.py] => training => Task 3, Epoch 28/200 => Loss 1.622, Train_accy 94.830, Test_accy 47.750
2024-01-11 05:22:51,235 [bic.py] => training => Task 3, Epoch 29/200 => Loss 1.623, Train_accy 95.090, Test_accy 47.980
2024-01-11 05:23:22,530 [bic.py] => training => Task 3, Epoch 30/200 => Loss 1.617, Train_accy 96.150, Test_accy 49.350
2024-01-11 05:23:52,926 [bic.py] => training => Task 3, Epoch 31/200 => Loss 1.621, Train_accy 96.690, Test_accy 47.730
2024-01-11 05:24:25,123 [bic.py] => training => Task 3, Epoch 32/200 => Loss 1.619, Train_accy 96.370, Test_accy 49.150
2024-01-11 05:24:57,051 [bic.py] => training => Task 3, Epoch 33/200 => Loss 1.616, Train_accy 97.000, Test_accy 50.570
2024-01-11 05:25:28,433 [bic.py] => training => Task 3, Epoch 34/200 => Loss 1.612, Train_accy 97.160, Test_accy 48.210
2024-01-11 05:26:00,385 [bic.py] => training => Task 3, Epoch 35/200 => Loss 1.613, Train_accy 97.080, Test_accy 49.020
2024-01-11 05:26:31,713 [bic.py] => training => Task 3, Epoch 36/200 => Loss 1.614, Train_accy 96.750, Test_accy 48.790
2024-01-11 05:27:02,018 [bic.py] => training => Task 3, Epoch 37/200 => Loss 1.613, Train_accy 95.720, Test_accy 47.990
2024-01-11 05:27:33,762 [bic.py] => training => Task 3, Epoch 38/200 => Loss 1.608, Train_accy 97.890, Test_accy 50.170
2024-01-11 05:28:04,828 [bic.py] => training => Task 3, Epoch 39/200 => Loss 1.608, Train_accy 96.040, Test_accy 49.700
2024-01-11 05:28:36,835 [bic.py] => training => Task 3, Epoch 40/200 => Loss 1.620, Train_accy 97.710, Test_accy 49.170
2024-01-11 05:29:09,160 [bic.py] => training => Task 3, Epoch 41/200 => Loss 1.620, Train_accy 97.220, Test_accy 48.880
2024-01-11 05:29:40,616 [bic.py] => training => Task 3, Epoch 42/200 => Loss 1.611, Train_accy 96.590, Test_accy 48.360
2024-01-11 05:30:11,616 [bic.py] => training => Task 3, Epoch 43/200 => Loss 1.613, Train_accy 97.200, Test_accy 48.630
2024-01-11 05:30:43,036 [bic.py] => training => Task 3, Epoch 44/200 => Loss 1.613, Train_accy 96.730, Test_accy 50.490
2024-01-11 05:31:13,990 [bic.py] => training => Task 3, Epoch 45/200 => Loss 1.606, Train_accy 97.630, Test_accy 49.880
2024-01-11 05:31:45,154 [bic.py] => training => Task 3, Epoch 46/200 => Loss 1.618, Train_accy 96.840, Test_accy 46.540
2024-01-11 05:32:16,786 [bic.py] => training => Task 3, Epoch 47/200 => Loss 1.612, Train_accy 96.900, Test_accy 48.620
2024-01-11 05:32:47,528 [bic.py] => training => Task 3, Epoch 48/200 => Loss 1.604, Train_accy 97.440, Test_accy 48.480
2024-01-11 05:33:19,140 [bic.py] => training => Task 3, Epoch 49/200 => Loss 1.598, Train_accy 98.260, Test_accy 51.810
2024-01-11 05:33:50,091 [bic.py] => training => Task 3, Epoch 50/200 => Loss 1.601, Train_accy 98.420, Test_accy 50.790
2024-01-11 05:34:21,734 [bic.py] => training => Task 3, Epoch 51/200 => Loss 1.609, Train_accy 97.930, Test_accy 50.520
2024-01-11 05:34:52,769 [bic.py] => training => Task 3, Epoch 52/200 => Loss 1.610, Train_accy 98.360, Test_accy 49.700
2024-01-11 05:35:24,401 [bic.py] => training => Task 3, Epoch 53/200 => Loss 1.605, Train_accy 98.520, Test_accy 50.440
2024-01-11 05:35:53,925 [bic.py] => training => Task 3, Epoch 54/200 => Loss 1.598, Train_accy 98.520, Test_accy 50.350
2024-01-11 05:36:25,063 [bic.py] => training => Task 3, Epoch 55/200 => Loss 1.602, Train_accy 96.170, Test_accy 47.990
2024-01-11 05:36:56,533 [bic.py] => training => Task 3, Epoch 56/200 => Loss 1.612, Train_accy 97.790, Test_accy 50.250
2024-01-11 05:37:28,332 [bic.py] => training => Task 3, Epoch 57/200 => Loss 1.606, Train_accy 96.730, Test_accy 45.700
2024-01-11 05:37:59,716 [bic.py] => training => Task 3, Epoch 58/200 => Loss 1.606, Train_accy 97.750, Test_accy 47.880
2024-01-11 05:38:30,937 [bic.py] => training => Task 3, Epoch 59/200 => Loss 1.603, Train_accy 98.600, Test_accy 50.380
2024-01-11 05:39:01,617 [bic.py] => training => Task 3, Epoch 60/200 => Loss 1.600, Train_accy 98.700, Test_accy 52.120
2024-01-11 05:39:33,601 [bic.py] => training => Task 3, Epoch 61/200 => Loss 1.582, Train_accy 99.740, Test_accy 53.600
2024-01-11 05:40:04,850 [bic.py] => training => Task 3, Epoch 62/200 => Loss 1.571, Train_accy 99.780, Test_accy 53.940
2024-01-11 05:40:36,455 [bic.py] => training => Task 3, Epoch 63/200 => Loss 1.569, Train_accy 99.740, Test_accy 53.790
2024-01-11 05:41:07,332 [bic.py] => training => Task 3, Epoch 64/200 => Loss 1.567, Train_accy 99.780, Test_accy 54.200
2024-01-11 05:41:38,042 [bic.py] => training => Task 3, Epoch 65/200 => Loss 1.565, Train_accy 99.760, Test_accy 54.200
2024-01-11 05:42:08,297 [bic.py] => training => Task 3, Epoch 66/200 => Loss 1.567, Train_accy 99.860, Test_accy 54.110
2024-01-11 05:42:39,886 [bic.py] => training => Task 3, Epoch 67/200 => Loss 1.568, Train_accy 99.840, Test_accy 54.330
2024-01-11 05:43:11,624 [bic.py] => training => Task 3, Epoch 68/200 => Loss 1.565, Train_accy 99.900, Test_accy 54.670
2024-01-11 05:43:42,602 [bic.py] => training => Task 3, Epoch 69/200 => Loss 1.566, Train_accy 99.840, Test_accy 54.260
2024-01-11 05:44:14,080 [bic.py] => training => Task 3, Epoch 70/200 => Loss 1.565, Train_accy 99.840, Test_accy 54.540
2024-01-11 05:44:46,179 [bic.py] => training => Task 3, Epoch 71/200 => Loss 1.565, Train_accy 99.820, Test_accy 54.330
2024-01-11 05:45:17,461 [bic.py] => training => Task 3, Epoch 72/200 => Loss 1.563, Train_accy 99.820, Test_accy 54.310
2024-01-11 05:45:48,921 [bic.py] => training => Task 3, Epoch 73/200 => Loss 1.565, Train_accy 99.820, Test_accy 54.120
2024-01-11 05:46:19,870 [bic.py] => training => Task 3, Epoch 74/200 => Loss 1.565, Train_accy 99.880, Test_accy 54.310
2024-01-11 05:46:51,158 [bic.py] => training => Task 3, Epoch 75/200 => Loss 1.563, Train_accy 99.800, Test_accy 54.790
2024-01-11 05:47:22,251 [bic.py] => training => Task 3, Epoch 76/200 => Loss 1.563, Train_accy 99.880, Test_accy 54.280
2024-01-11 05:47:52,068 [bic.py] => training => Task 3, Epoch 77/200 => Loss 1.564, Train_accy 99.880, Test_accy 54.740
2024-01-11 05:48:23,203 [bic.py] => training => Task 3, Epoch 78/200 => Loss 1.565, Train_accy 99.860, Test_accy 53.860
2024-01-11 05:48:53,910 [bic.py] => training => Task 3, Epoch 79/200 => Loss 1.564, Train_accy 99.840, Test_accy 54.380
2024-01-11 05:49:25,448 [bic.py] => training => Task 3, Epoch 80/200 => Loss 1.564, Train_accy 99.820, Test_accy 54.470
2024-01-11 05:49:57,037 [bic.py] => training => Task 3, Epoch 81/200 => Loss 1.564, Train_accy 99.860, Test_accy 53.880
2024-01-11 05:50:28,639 [bic.py] => training => Task 3, Epoch 82/200 => Loss 1.563, Train_accy 99.860, Test_accy 54.440
2024-01-11 05:50:58,460 [bic.py] => training => Task 3, Epoch 83/200 => Loss 1.562, Train_accy 99.820, Test_accy 54.350
2024-01-11 05:51:29,588 [bic.py] => training => Task 3, Epoch 84/200 => Loss 1.563, Train_accy 99.920, Test_accy 54.670
2024-01-11 05:52:01,592 [bic.py] => training => Task 3, Epoch 85/200 => Loss 1.562, Train_accy 99.900, Test_accy 54.110
2024-01-11 05:52:33,837 [bic.py] => training => Task 3, Epoch 86/200 => Loss 1.563, Train_accy 99.860, Test_accy 54.060
2024-01-11 05:53:05,651 [bic.py] => training => Task 3, Epoch 87/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.220
2024-01-11 05:53:36,221 [bic.py] => training => Task 3, Epoch 88/200 => Loss 1.562, Train_accy 99.840, Test_accy 54.570
2024-01-11 05:54:06,442 [bic.py] => training => Task 3, Epoch 89/200 => Loss 1.563, Train_accy 99.840, Test_accy 54.000
2024-01-11 05:54:37,910 [bic.py] => training => Task 3, Epoch 90/200 => Loss 1.563, Train_accy 99.880, Test_accy 54.370
2024-01-11 05:55:09,667 [bic.py] => training => Task 3, Epoch 91/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.210
2024-01-11 05:55:41,374 [bic.py] => training => Task 3, Epoch 92/200 => Loss 1.563, Train_accy 99.880, Test_accy 54.460
2024-01-11 05:56:12,437 [bic.py] => training => Task 3, Epoch 93/200 => Loss 1.562, Train_accy 99.840, Test_accy 54.750
2024-01-11 05:56:44,338 [bic.py] => training => Task 3, Epoch 94/200 => Loss 1.561, Train_accy 99.860, Test_accy 54.300
2024-01-11 05:57:14,885 [bic.py] => training => Task 3, Epoch 95/200 => Loss 1.562, Train_accy 99.900, Test_accy 54.440
2024-01-11 05:57:46,475 [bic.py] => training => Task 3, Epoch 96/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.220
2024-01-11 05:58:18,290 [bic.py] => training => Task 3, Epoch 97/200 => Loss 1.562, Train_accy 99.880, Test_accy 54.720
2024-01-11 05:58:49,509 [bic.py] => training => Task 3, Epoch 98/200 => Loss 1.562, Train_accy 99.860, Test_accy 54.700
2024-01-11 05:59:21,428 [bic.py] => training => Task 3, Epoch 99/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.470
2024-01-11 05:59:52,523 [bic.py] => training => Task 3, Epoch 100/200 => Loss 1.562, Train_accy 99.880, Test_accy 54.280
2024-01-11 06:00:24,144 [bic.py] => training => Task 3, Epoch 101/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.440
2024-01-11 06:00:55,607 [bic.py] => training => Task 3, Epoch 102/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.560
2024-01-11 06:01:27,488 [bic.py] => training => Task 3, Epoch 103/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.460
2024-01-11 06:01:59,269 [bic.py] => training => Task 3, Epoch 104/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.630
2024-01-11 06:02:31,040 [bic.py] => training => Task 3, Epoch 105/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.410
2024-01-11 06:03:00,825 [bic.py] => training => Task 3, Epoch 106/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.560
2024-01-11 06:03:31,711 [bic.py] => training => Task 3, Epoch 107/200 => Loss 1.562, Train_accy 99.880, Test_accy 54.270
2024-01-11 06:04:03,476 [bic.py] => training => Task 3, Epoch 108/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.430
2024-01-11 06:04:35,368 [bic.py] => training => Task 3, Epoch 109/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.560
2024-01-11 06:05:07,184 [bic.py] => training => Task 3, Epoch 110/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.640
2024-01-11 06:05:38,258 [bic.py] => training => Task 3, Epoch 111/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.470
2024-01-11 06:06:08,106 [bic.py] => training => Task 3, Epoch 112/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.720
2024-01-11 06:06:39,452 [bic.py] => training => Task 3, Epoch 113/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.210
2024-01-11 06:07:11,292 [bic.py] => training => Task 3, Epoch 114/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.740
2024-01-11 06:07:43,082 [bic.py] => training => Task 3, Epoch 115/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.300
2024-01-11 06:08:14,984 [bic.py] => training => Task 3, Epoch 116/200 => Loss 1.562, Train_accy 99.860, Test_accy 54.420
2024-01-11 06:08:45,956 [bic.py] => training => Task 3, Epoch 117/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.900
2024-01-11 06:09:16,519 [bic.py] => training => Task 3, Epoch 118/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.310
2024-01-11 06:09:48,181 [bic.py] => training => Task 3, Epoch 119/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.460
2024-01-11 06:10:19,532 [bic.py] => training => Task 3, Epoch 120/200 => Loss 1.559, Train_accy 99.900, Test_accy 54.350
2024-01-11 06:10:50,867 [bic.py] => training => Task 3, Epoch 121/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.680
2024-01-11 06:11:22,444 [bic.py] => training => Task 3, Epoch 122/200 => Loss 1.557, Train_accy 99.880, Test_accy 54.490
2024-01-11 06:11:52,776 [bic.py] => training => Task 3, Epoch 123/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.330
2024-01-11 06:12:23,569 [bic.py] => training => Task 3, Epoch 124/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.600
2024-01-11 06:12:54,335 [bic.py] => training => Task 3, Epoch 125/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.650
2024-01-11 06:13:25,000 [bic.py] => training => Task 3, Epoch 126/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.740
2024-01-11 06:13:56,080 [bic.py] => training => Task 3, Epoch 127/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.650
2024-01-11 06:14:27,174 [bic.py] => training => Task 3, Epoch 128/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.050
2024-01-11 06:14:56,468 [bic.py] => training => Task 3, Epoch 129/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.380
2024-01-11 06:15:27,366 [bic.py] => training => Task 3, Epoch 130/200 => Loss 1.561, Train_accy 99.860, Test_accy 54.330
2024-01-11 06:15:57,302 [bic.py] => training => Task 3, Epoch 131/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.630
2024-01-11 06:16:28,492 [bic.py] => training => Task 3, Epoch 132/200 => Loss 1.561, Train_accy 99.820, Test_accy 54.440
2024-01-11 06:16:59,252 [bic.py] => training => Task 3, Epoch 133/200 => Loss 1.558, Train_accy 99.860, Test_accy 54.860
2024-01-11 06:17:30,008 [bic.py] => training => Task 3, Epoch 134/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.360
2024-01-11 06:17:58,993 [bic.py] => training => Task 3, Epoch 135/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.020
2024-01-11 06:18:29,357 [bic.py] => training => Task 3, Epoch 136/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.470
2024-01-11 06:19:00,412 [bic.py] => training => Task 3, Epoch 137/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.330
2024-01-11 06:19:31,149 [bic.py] => training => Task 3, Epoch 138/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.580
2024-01-11 06:20:02,020 [bic.py] => training => Task 3, Epoch 139/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.810
2024-01-11 06:20:32,506 [bic.py] => training => Task 3, Epoch 140/200 => Loss 1.561, Train_accy 99.860, Test_accy 54.220
2024-01-11 06:21:01,484 [bic.py] => training => Task 3, Epoch 141/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.880
2024-01-11 06:21:33,158 [bic.py] => training => Task 3, Epoch 142/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.070
2024-01-11 06:22:04,409 [bic.py] => training => Task 3, Epoch 143/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.330
2024-01-11 06:22:35,627 [bic.py] => training => Task 3, Epoch 144/200 => Loss 1.559, Train_accy 99.900, Test_accy 54.380
2024-01-11 06:23:06,368 [bic.py] => training => Task 3, Epoch 145/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.520
2024-01-11 06:23:37,191 [bic.py] => training => Task 3, Epoch 146/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.600
2024-01-11 06:24:08,405 [bic.py] => training => Task 3, Epoch 147/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.410
2024-01-11 06:24:40,403 [bic.py] => training => Task 3, Epoch 148/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.370
2024-01-11 06:25:12,188 [bic.py] => training => Task 3, Epoch 149/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.590
2024-01-11 06:25:42,387 [bic.py] => training => Task 3, Epoch 150/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.280
2024-01-11 06:26:12,900 [bic.py] => training => Task 3, Epoch 151/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.210
2024-01-11 06:26:42,851 [bic.py] => training => Task 3, Epoch 152/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.230
2024-01-11 06:27:12,494 [bic.py] => training => Task 3, Epoch 153/200 => Loss 1.557, Train_accy 99.860, Test_accy 54.460
2024-01-11 06:27:43,535 [bic.py] => training => Task 3, Epoch 154/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.680
2024-01-11 06:28:14,408 [bic.py] => training => Task 3, Epoch 155/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.530
2024-01-11 06:28:45,598 [bic.py] => training => Task 3, Epoch 156/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.960
2024-01-11 06:29:16,636 [bic.py] => training => Task 3, Epoch 157/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.330
2024-01-11 06:29:46,898 [bic.py] => training => Task 3, Epoch 158/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.530
2024-01-11 06:30:16,663 [bic.py] => training => Task 3, Epoch 159/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.480
2024-01-11 06:30:46,566 [bic.py] => training => Task 3, Epoch 160/200 => Loss 1.557, Train_accy 99.880, Test_accy 54.320
2024-01-11 06:31:17,188 [bic.py] => training => Task 3, Epoch 161/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.470
2024-01-11 06:31:47,815 [bic.py] => training => Task 3, Epoch 162/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.310
2024-01-11 06:32:18,751 [bic.py] => training => Task 3, Epoch 163/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.330
2024-01-11 06:32:48,662 [bic.py] => training => Task 3, Epoch 164/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.840
2024-01-11 06:33:17,824 [bic.py] => training => Task 3, Epoch 165/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.570
2024-01-11 06:33:48,861 [bic.py] => training => Task 3, Epoch 166/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.630
2024-01-11 06:34:19,800 [bic.py] => training => Task 3, Epoch 167/200 => Loss 1.560, Train_accy 99.900, Test_accy 54.440
2024-01-11 06:34:50,768 [bic.py] => training => Task 3, Epoch 168/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.620
2024-01-11 06:35:21,288 [bic.py] => training => Task 3, Epoch 169/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.570
2024-01-11 06:35:51,535 [bic.py] => training => Task 3, Epoch 170/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.220
2024-01-11 06:36:21,618 [bic.py] => training => Task 3, Epoch 171/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.260
2024-01-11 06:36:52,578 [bic.py] => training => Task 3, Epoch 172/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.670
2024-01-11 06:37:23,490 [bic.py] => training => Task 3, Epoch 173/200 => Loss 1.560, Train_accy 99.900, Test_accy 54.090
2024-01-11 06:37:53,929 [bic.py] => training => Task 3, Epoch 174/200 => Loss 1.559, Train_accy 99.920, Test_accy 54.480
2024-01-11 06:38:24,799 [bic.py] => training => Task 3, Epoch 175/200 => Loss 1.559, Train_accy 99.860, Test_accy 54.480
2024-01-11 06:38:55,444 [bic.py] => training => Task 3, Epoch 176/200 => Loss 1.559, Train_accy 99.860, Test_accy 53.940
2024-01-11 06:39:25,653 [bic.py] => training => Task 3, Epoch 177/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.460
2024-01-11 06:39:56,405 [bic.py] => training => Task 3, Epoch 178/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.010
2024-01-11 06:40:26,998 [bic.py] => training => Task 3, Epoch 179/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.740
2024-01-11 06:40:57,723 [bic.py] => training => Task 3, Epoch 180/200 => Loss 1.560, Train_accy 99.840, Test_accy 54.490
2024-01-11 06:41:28,171 [bic.py] => training => Task 3, Epoch 181/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.630
2024-01-11 06:41:58,220 [bic.py] => training => Task 3, Epoch 182/200 => Loss 1.559, Train_accy 99.880, Test_accy 54.230
2024-01-11 06:42:28,737 [bic.py] => training => Task 3, Epoch 183/200 => Loss 1.558, Train_accy 99.860, Test_accy 54.790
2024-01-11 06:42:58,539 [bic.py] => training => Task 3, Epoch 184/200 => Loss 1.558, Train_accy 99.880, Test_accy 54.470
2024-01-11 06:43:29,544 [bic.py] => training => Task 3, Epoch 185/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.670
2024-01-11 06:44:00,876 [bic.py] => training => Task 3, Epoch 186/200 => Loss 1.560, Train_accy 99.900, Test_accy 54.230
2024-01-11 06:44:31,713 [bic.py] => training => Task 3, Epoch 187/200 => Loss 1.557, Train_accy 99.880, Test_accy 54.360
2024-01-11 06:45:00,997 [bic.py] => training => Task 3, Epoch 188/200 => Loss 1.561, Train_accy 99.860, Test_accy 54.940
2024-01-11 06:45:31,589 [bic.py] => training => Task 3, Epoch 189/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.420
2024-01-11 06:46:02,376 [bic.py] => training => Task 3, Epoch 190/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.520
2024-01-11 06:46:33,241 [bic.py] => training => Task 3, Epoch 191/200 => Loss 1.558, Train_accy 99.900, Test_accy 54.700
2024-01-11 06:47:04,061 [bic.py] => training => Task 3, Epoch 192/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.270
2024-01-11 06:47:34,819 [bic.py] => training => Task 3, Epoch 193/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.890
2024-01-11 06:48:03,694 [bic.py] => training => Task 3, Epoch 194/200 => Loss 1.558, Train_accy 99.900, Test_accy 54.680
2024-01-11 06:48:34,572 [bic.py] => training => Task 3, Epoch 195/200 => Loss 1.560, Train_accy 99.860, Test_accy 54.740
2024-01-11 06:49:05,405 [bic.py] => training => Task 3, Epoch 196/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.260
2024-01-11 06:49:36,090 [bic.py] => training => Task 3, Epoch 197/200 => Loss 1.557, Train_accy 99.860, Test_accy 54.640
2024-01-11 06:50:06,725 [bic.py] => training => Task 3, Epoch 198/200 => Loss 1.561, Train_accy 99.880, Test_accy 54.730
2024-01-11 06:50:37,610 [bic.py] => training => Task 3, Epoch 199/200 => Loss 1.559, Train_accy 99.840, Test_accy 54.560
2024-01-11 06:51:06,647 [bic.py] => training => Task 3, Epoch 200/200 => Loss 1.560, Train_accy 99.880, Test_accy 54.430
2024-01-11 06:51:18,530 [bic.py] => bias_correction => Task 3, Epoch 1/200 => Loss 3.459, Train_accy 61.670, Test_accy 53.740
2024-01-11 06:51:30,096 [bic.py] => bias_correction => Task 3, Epoch 2/200 => Loss 3.490, Train_accy 61.670, Test_accy 54.440
2024-01-11 06:51:41,314 [bic.py] => bias_correction => Task 3, Epoch 3/200 => Loss 3.421, Train_accy 62.220, Test_accy 55.750
2024-01-11 06:51:52,774 [bic.py] => bias_correction => Task 3, Epoch 4/200 => Loss 3.428, Train_accy 62.780, Test_accy 52.840
2024-01-11 06:52:04,158 [bic.py] => bias_correction => Task 3, Epoch 5/200 => Loss 3.450, Train_accy 62.220, Test_accy 52.070
2024-01-11 06:52:15,209 [bic.py] => bias_correction => Task 3, Epoch 6/200 => Loss 3.421, Train_accy 60.000, Test_accy 53.600
2024-01-11 06:52:26,628 [bic.py] => bias_correction => Task 3, Epoch 7/200 => Loss 3.416, Train_accy 58.330, Test_accy 51.020
2024-01-11 06:52:38,318 [bic.py] => bias_correction => Task 3, Epoch 8/200 => Loss 3.445, Train_accy 53.890, Test_accy 48.720
2024-01-11 06:52:50,093 [bic.py] => bias_correction => Task 3, Epoch 9/200 => Loss 3.457, Train_accy 53.330, Test_accy 48.070
2024-01-11 06:53:01,550 [bic.py] => bias_correction => Task 3, Epoch 10/200 => Loss 3.426, Train_accy 55.000, Test_accy 49.560
2024-01-11 06:53:13,276 [bic.py] => bias_correction => Task 3, Epoch 11/200 => Loss 3.443, Train_accy 56.110, Test_accy 50.700
2024-01-11 06:53:24,769 [bic.py] => bias_correction => Task 3, Epoch 12/200 => Loss 3.399, Train_accy 57.220, Test_accy 50.700
2024-01-11 06:53:36,083 [bic.py] => bias_correction => Task 3, Epoch 13/200 => Loss 3.418, Train_accy 56.110, Test_accy 50.560
2024-01-11 06:53:47,667 [bic.py] => bias_correction => Task 3, Epoch 14/200 => Loss 3.429, Train_accy 54.440, Test_accy 50.120
2024-01-11 06:53:58,994 [bic.py] => bias_correction => Task 3, Epoch 15/200 => Loss 3.406, Train_accy 53.890, Test_accy 49.270
2024-01-11 06:54:10,406 [bic.py] => bias_correction => Task 3, Epoch 16/200 => Loss 3.411, Train_accy 53.890, Test_accy 49.270
2024-01-11 06:54:21,801 [bic.py] => bias_correction => Task 3, Epoch 17/200 => Loss 3.429, Train_accy 55.000, Test_accy 50.070
2024-01-11 06:54:32,913 [bic.py] => bias_correction => Task 3, Epoch 18/200 => Loss 3.427, Train_accy 55.000, Test_accy 49.980
2024-01-11 06:54:44,213 [bic.py] => bias_correction => Task 3, Epoch 19/200 => Loss 3.419, Train_accy 55.000, Test_accy 49.270
2024-01-11 06:54:55,429 [bic.py] => bias_correction => Task 3, Epoch 20/200 => Loss 3.408, Train_accy 54.440, Test_accy 49.700
2024-01-11 06:55:06,760 [bic.py] => bias_correction => Task 3, Epoch 21/200 => Loss 3.418, Train_accy 55.000, Test_accy 49.460
2024-01-11 06:55:18,282 [bic.py] => bias_correction => Task 3, Epoch 22/200 => Loss 3.404, Train_accy 52.220, Test_accy 48.600
2024-01-11 06:55:29,828 [bic.py] => bias_correction => Task 3, Epoch 23/200 => Loss 3.427, Train_accy 52.780, Test_accy 48.260
2024-01-11 06:55:41,147 [bic.py] => bias_correction => Task 3, Epoch 24/200 => Loss 3.409, Train_accy 53.330, Test_accy 48.620
2024-01-11 06:55:52,509 [bic.py] => bias_correction => Task 3, Epoch 25/200 => Loss 3.420, Train_accy 55.000, Test_accy 49.740
2024-01-11 06:56:04,070 [bic.py] => bias_correction => Task 3, Epoch 26/200 => Loss 3.415, Train_accy 55.560, Test_accy 49.980
2024-01-11 06:56:14,633 [bic.py] => bias_correction => Task 3, Epoch 27/200 => Loss 3.411, Train_accy 55.000, Test_accy 49.680
2024-01-11 06:56:25,752 [bic.py] => bias_correction => Task 3, Epoch 28/200 => Loss 3.426, Train_accy 55.000, Test_accy 49.200
2024-01-11 06:56:37,083 [bic.py] => bias_correction => Task 3, Epoch 29/200 => Loss 3.415, Train_accy 55.000, Test_accy 49.050
2024-01-11 06:56:48,318 [bic.py] => bias_correction => Task 3, Epoch 30/200 => Loss 3.408, Train_accy 55.000, Test_accy 49.000
2024-01-11 06:56:59,993 [bic.py] => bias_correction => Task 3, Epoch 31/200 => Loss 3.419, Train_accy 55.560, Test_accy 49.110
2024-01-11 06:57:11,453 [bic.py] => bias_correction => Task 3, Epoch 32/200 => Loss 3.412, Train_accy 55.000, Test_accy 49.630
2024-01-11 06:57:22,976 [bic.py] => bias_correction => Task 3, Epoch 33/200 => Loss 3.422, Train_accy 55.000, Test_accy 49.840
2024-01-11 06:57:34,331 [bic.py] => bias_correction => Task 3, Epoch 34/200 => Loss 3.402, Train_accy 55.000, Test_accy 50.010
2024-01-11 06:57:45,773 [bic.py] => bias_correction => Task 3, Epoch 35/200 => Loss 3.393, Train_accy 55.000, Test_accy 50.150
2024-01-11 06:57:57,302 [bic.py] => bias_correction => Task 3, Epoch 36/200 => Loss 3.385, Train_accy 54.440, Test_accy 49.880
2024-01-11 06:58:09,542 [bic.py] => bias_correction => Task 3, Epoch 37/200 => Loss 3.388, Train_accy 54.440, Test_accy 49.910
2024-01-11 06:58:21,015 [bic.py] => bias_correction => Task 3, Epoch 38/200 => Loss 3.433, Train_accy 55.560, Test_accy 49.750
2024-01-11 06:58:32,276 [bic.py] => bias_correction => Task 3, Epoch 39/200 => Loss 3.402, Train_accy 54.440, Test_accy 49.250
2024-01-11 06:58:43,583 [bic.py] => bias_correction => Task 3, Epoch 40/200 => Loss 3.374, Train_accy 55.000, Test_accy 49.780
2024-01-11 06:58:54,108 [bic.py] => bias_correction => Task 3, Epoch 41/200 => Loss 3.406, Train_accy 53.890, Test_accy 50.140
2024-01-11 06:59:05,308 [bic.py] => bias_correction => Task 3, Epoch 42/200 => Loss 3.393, Train_accy 53.890, Test_accy 50.220
2024-01-11 06:59:16,759 [bic.py] => bias_correction => Task 3, Epoch 43/200 => Loss 3.383, Train_accy 54.440, Test_accy 50.360
2024-01-11 06:59:28,221 [bic.py] => bias_correction => Task 3, Epoch 44/200 => Loss 3.394, Train_accy 54.440, Test_accy 50.630
2024-01-11 06:59:39,787 [bic.py] => bias_correction => Task 3, Epoch 45/200 => Loss 3.431, Train_accy 54.440, Test_accy 49.990
2024-01-11 06:59:51,184 [bic.py] => bias_correction => Task 3, Epoch 46/200 => Loss 3.387, Train_accy 54.440, Test_accy 49.720
2024-01-11 07:00:02,669 [bic.py] => bias_correction => Task 3, Epoch 47/200 => Loss 3.437, Train_accy 55.560, Test_accy 49.890
2024-01-11 07:00:14,147 [bic.py] => bias_correction => Task 3, Epoch 48/200 => Loss 3.378, Train_accy 55.560, Test_accy 49.730
2024-01-11 07:00:25,443 [bic.py] => bias_correction => Task 3, Epoch 49/200 => Loss 3.427, Train_accy 54.440, Test_accy 49.220
2024-01-11 07:00:36,827 [bic.py] => bias_correction => Task 3, Epoch 50/200 => Loss 3.401, Train_accy 55.000, Test_accy 49.800
2024-01-11 07:00:48,278 [bic.py] => bias_correction => Task 3, Epoch 51/200 => Loss 3.416, Train_accy 55.560, Test_accy 50.120
2024-01-11 07:00:59,865 [bic.py] => bias_correction => Task 3, Epoch 52/200 => Loss 3.408, Train_accy 54.440, Test_accy 50.350
2024-01-11 07:01:11,080 [bic.py] => bias_correction => Task 3, Epoch 53/200 => Loss 3.408, Train_accy 54.440, Test_accy 50.570
2024-01-11 07:01:22,389 [bic.py] => bias_correction => Task 3, Epoch 54/200 => Loss 3.388, Train_accy 54.440, Test_accy 50.410
2024-01-11 07:01:33,602 [bic.py] => bias_correction => Task 3, Epoch 55/200 => Loss 3.383, Train_accy 55.560, Test_accy 50.530
2024-01-11 07:01:44,913 [bic.py] => bias_correction => Task 3, Epoch 56/200 => Loss 3.389, Train_accy 55.560, Test_accy 50.330
2024-01-11 07:01:56,285 [bic.py] => bias_correction => Task 3, Epoch 57/200 => Loss 3.417, Train_accy 56.110, Test_accy 50.860
2024-01-11 07:02:07,982 [bic.py] => bias_correction => Task 3, Epoch 58/200 => Loss 3.415, Train_accy 56.110, Test_accy 50.990
2024-01-11 07:02:19,790 [bic.py] => bias_correction => Task 3, Epoch 59/200 => Loss 3.399, Train_accy 55.000, Test_accy 50.600
2024-01-11 07:02:31,410 [bic.py] => bias_correction => Task 3, Epoch 60/200 => Loss 3.412, Train_accy 54.440, Test_accy 50.370
2024-01-11 07:02:42,871 [bic.py] => bias_correction => Task 3, Epoch 61/200 => Loss 3.383, Train_accy 55.560, Test_accy 50.260
2024-01-11 07:02:54,184 [bic.py] => bias_correction => Task 3, Epoch 62/200 => Loss 3.397, Train_accy 55.560, Test_accy 50.280
2024-01-11 07:03:05,564 [bic.py] => bias_correction => Task 3, Epoch 63/200 => Loss 3.396, Train_accy 55.560, Test_accy 50.040
2024-01-11 07:03:17,042 [bic.py] => bias_correction => Task 3, Epoch 64/200 => Loss 3.423, Train_accy 55.000, Test_accy 49.790
2024-01-11 07:03:28,309 [bic.py] => bias_correction => Task 3, Epoch 65/200 => Loss 3.389, Train_accy 56.110, Test_accy 49.650
2024-01-11 07:03:39,554 [bic.py] => bias_correction => Task 3, Epoch 66/200 => Loss 3.389, Train_accy 56.110, Test_accy 49.990
2024-01-11 07:03:50,840 [bic.py] => bias_correction => Task 3, Epoch 67/200 => Loss 3.413, Train_accy 56.110, Test_accy 49.770
2024-01-11 07:04:02,267 [bic.py] => bias_correction => Task 3, Epoch 68/200 => Loss 3.421, Train_accy 56.110, Test_accy 49.720
2024-01-11 07:04:13,548 [bic.py] => bias_correction => Task 3, Epoch 69/200 => Loss 3.387, Train_accy 55.560, Test_accy 49.960
2024-01-11 07:04:24,762 [bic.py] => bias_correction => Task 3, Epoch 70/200 => Loss 3.406, Train_accy 55.560, Test_accy 50.220
2024-01-11 07:04:35,615 [bic.py] => bias_correction => Task 3, Epoch 71/200 => Loss 3.417, Train_accy 56.110, Test_accy 50.280
2024-01-11 07:04:47,246 [bic.py] => bias_correction => Task 3, Epoch 72/200 => Loss 3.379, Train_accy 56.110, Test_accy 50.520
2024-01-11 07:04:58,849 [bic.py] => bias_correction => Task 3, Epoch 73/200 => Loss 3.398, Train_accy 56.110, Test_accy 50.250
2024-01-11 07:05:10,865 [bic.py] => bias_correction => Task 3, Epoch 74/200 => Loss 3.394, Train_accy 55.560, Test_accy 50.190
2024-01-11 07:05:22,490 [bic.py] => bias_correction => Task 3, Epoch 75/200 => Loss 3.384, Train_accy 55.560, Test_accy 50.200
2024-01-11 07:05:33,986 [bic.py] => bias_correction => Task 3, Epoch 76/200 => Loss 3.399, Train_accy 55.560, Test_accy 50.110
2024-01-11 07:05:45,207 [bic.py] => bias_correction => Task 3, Epoch 77/200 => Loss 3.432, Train_accy 56.110, Test_accy 49.960
2024-01-11 07:05:56,574 [bic.py] => bias_correction => Task 3, Epoch 78/200 => Loss 3.413, Train_accy 55.000, Test_accy 49.730
2024-01-11 07:06:07,928 [bic.py] => bias_correction => Task 3, Epoch 79/200 => Loss 3.380, Train_accy 56.670, Test_accy 50.360
2024-01-11 07:06:19,269 [bic.py] => bias_correction => Task 3, Epoch 80/200 => Loss 3.392, Train_accy 55.560, Test_accy 50.110
2024-01-11 07:06:30,499 [bic.py] => bias_correction => Task 3, Epoch 81/200 => Loss 3.370, Train_accy 56.110, Test_accy 50.570
2024-01-11 07:06:42,141 [bic.py] => bias_correction => Task 3, Epoch 82/200 => Loss 3.363, Train_accy 56.670, Test_accy 50.440
2024-01-11 07:06:53,589 [bic.py] => bias_correction => Task 3, Epoch 83/200 => Loss 3.396, Train_accy 56.110, Test_accy 50.440
2024-01-11 07:07:04,827 [bic.py] => bias_correction => Task 3, Epoch 84/200 => Loss 3.408, Train_accy 56.110, Test_accy 50.580
2024-01-11 07:07:16,488 [bic.py] => bias_correction => Task 3, Epoch 85/200 => Loss 3.375, Train_accy 57.220, Test_accy 50.460
2024-01-11 07:07:28,317 [bic.py] => bias_correction => Task 3, Epoch 86/200 => Loss 3.393, Train_accy 56.670, Test_accy 50.380
2024-01-11 07:07:40,083 [bic.py] => bias_correction => Task 3, Epoch 87/200 => Loss 3.409, Train_accy 56.670, Test_accy 50.370
2024-01-11 07:07:51,515 [bic.py] => bias_correction => Task 3, Epoch 88/200 => Loss 3.384, Train_accy 56.670, Test_accy 50.220
2024-01-11 07:08:02,896 [bic.py] => bias_correction => Task 3, Epoch 89/200 => Loss 3.353, Train_accy 56.110, Test_accy 50.410
2024-01-11 07:08:14,320 [bic.py] => bias_correction => Task 3, Epoch 90/200 => Loss 3.418, Train_accy 56.110, Test_accy 50.430
2024-01-11 07:08:25,651 [bic.py] => bias_correction => Task 3, Epoch 91/200 => Loss 3.396, Train_accy 55.560, Test_accy 50.250
2024-01-11 07:08:37,005 [bic.py] => bias_correction => Task 3, Epoch 92/200 => Loss 3.426, Train_accy 55.560, Test_accy 50.010
2024-01-11 07:08:48,391 [bic.py] => bias_correction => Task 3, Epoch 93/200 => Loss 3.386, Train_accy 55.000, Test_accy 50.140
2024-01-11 07:08:59,907 [bic.py] => bias_correction => Task 3, Epoch 94/200 => Loss 3.406, Train_accy 55.560, Test_accy 50.160
2024-01-11 07:09:11,315 [bic.py] => bias_correction => Task 3, Epoch 95/200 => Loss 3.392, Train_accy 55.000, Test_accy 50.380
2024-01-11 07:09:22,861 [bic.py] => bias_correction => Task 3, Epoch 96/200 => Loss 3.396, Train_accy 55.000, Test_accy 50.420
2024-01-11 07:09:34,413 [bic.py] => bias_correction => Task 3, Epoch 97/200 => Loss 3.366, Train_accy 55.000, Test_accy 50.700
2024-01-11 07:09:45,039 [bic.py] => bias_correction => Task 3, Epoch 98/200 => Loss 3.388, Train_accy 55.000, Test_accy 50.770
2024-01-11 07:09:56,152 [bic.py] => bias_correction => Task 3, Epoch 99/200 => Loss 3.398, Train_accy 55.000, Test_accy 50.670
2024-01-11 07:10:07,361 [bic.py] => bias_correction => Task 3, Epoch 100/200 => Loss 3.407, Train_accy 55.560, Test_accy 50.700
2024-01-11 07:10:18,637 [bic.py] => bias_correction => Task 3, Epoch 101/200 => Loss 3.388, Train_accy 55.000, Test_accy 50.570
2024-01-11 07:10:29,973 [bic.py] => bias_correction => Task 3, Epoch 102/200 => Loss 3.395, Train_accy 55.000, Test_accy 50.640
2024-01-11 07:10:41,310 [bic.py] => bias_correction => Task 3, Epoch 103/200 => Loss 3.392, Train_accy 55.000, Test_accy 50.930
2024-01-11 07:10:52,797 [bic.py] => bias_correction => Task 3, Epoch 104/200 => Loss 3.390, Train_accy 54.440, Test_accy 50.960
2024-01-11 07:11:04,239 [bic.py] => bias_correction => Task 3, Epoch 105/200 => Loss 3.415, Train_accy 55.000, Test_accy 50.750
2024-01-11 07:11:15,757 [bic.py] => bias_correction => Task 3, Epoch 106/200 => Loss 3.396, Train_accy 55.000, Test_accy 50.600
2024-01-11 07:11:27,195 [bic.py] => bias_correction => Task 3, Epoch 107/200 => Loss 3.387, Train_accy 56.110, Test_accy 50.740
2024-01-11 07:11:38,522 [bic.py] => bias_correction => Task 3, Epoch 108/200 => Loss 3.393, Train_accy 56.110, Test_accy 50.440
2024-01-11 07:11:50,108 [bic.py] => bias_correction => Task 3, Epoch 109/200 => Loss 3.423, Train_accy 55.560, Test_accy 50.000
2024-01-11 07:12:01,567 [bic.py] => bias_correction => Task 3, Epoch 110/200 => Loss 3.410, Train_accy 57.780, Test_accy 50.110
2024-01-11 07:12:12,875 [bic.py] => bias_correction => Task 3, Epoch 111/200 => Loss 3.393, Train_accy 57.780, Test_accy 49.930
2024-01-11 07:12:23,360 [bic.py] => bias_correction => Task 3, Epoch 112/200 => Loss 3.414, Train_accy 57.220, Test_accy 49.930
2024-01-11 07:12:34,478 [bic.py] => bias_correction => Task 3, Epoch 113/200 => Loss 3.381, Train_accy 56.110, Test_accy 50.020
2024-01-11 07:12:45,651 [bic.py] => bias_correction => Task 3, Epoch 114/200 => Loss 3.378, Train_accy 57.220, Test_accy 50.300
2024-01-11 07:12:56,989 [bic.py] => bias_correction => Task 3, Epoch 115/200 => Loss 3.391, Train_accy 57.220, Test_accy 50.750
2024-01-11 07:13:08,302 [bic.py] => bias_correction => Task 3, Epoch 116/200 => Loss 3.423, Train_accy 56.110, Test_accy 50.800
2024-01-11 07:13:19,843 [bic.py] => bias_correction => Task 3, Epoch 117/200 => Loss 3.396, Train_accy 55.000, Test_accy 50.880
2024-01-11 07:13:31,198 [bic.py] => bias_correction => Task 3, Epoch 118/200 => Loss 3.392, Train_accy 56.110, Test_accy 50.960
2024-01-11 07:13:42,518 [bic.py] => bias_correction => Task 3, Epoch 119/200 => Loss 3.400, Train_accy 56.110, Test_accy 51.000
2024-01-11 07:13:53,841 [bic.py] => bias_correction => Task 3, Epoch 120/200 => Loss 3.406, Train_accy 55.560, Test_accy 50.960
2024-01-11 07:14:05,308 [bic.py] => bias_correction => Task 3, Epoch 121/200 => Loss 3.402, Train_accy 56.110, Test_accy 50.790
2024-01-11 07:14:16,811 [bic.py] => bias_correction => Task 3, Epoch 122/200 => Loss 3.396, Train_accy 56.110, Test_accy 50.620
2024-01-11 07:14:28,135 [bic.py] => bias_correction => Task 3, Epoch 123/200 => Loss 3.394, Train_accy 56.670, Test_accy 50.620
2024-01-11 07:14:39,262 [bic.py] => bias_correction => Task 3, Epoch 124/200 => Loss 3.384, Train_accy 56.670, Test_accy 50.830
2024-01-11 07:14:50,617 [bic.py] => bias_correction => Task 3, Epoch 125/200 => Loss 3.415, Train_accy 56.110, Test_accy 50.520
2024-01-11 07:15:01,901 [bic.py] => bias_correction => Task 3, Epoch 126/200 => Loss 3.387, Train_accy 56.670, Test_accy 50.830
2024-01-11 07:15:12,874 [bic.py] => bias_correction => Task 3, Epoch 127/200 => Loss 3.437, Train_accy 56.110, Test_accy 50.510
2024-01-11 07:15:23,929 [bic.py] => bias_correction => Task 3, Epoch 128/200 => Loss 3.403, Train_accy 56.110, Test_accy 50.380
2024-01-11 07:15:35,459 [bic.py] => bias_correction => Task 3, Epoch 129/200 => Loss 3.406, Train_accy 56.110, Test_accy 50.250
2024-01-11 07:15:46,989 [bic.py] => bias_correction => Task 3, Epoch 130/200 => Loss 3.364, Train_accy 56.110, Test_accy 50.720
2024-01-11 07:15:58,491 [bic.py] => bias_correction => Task 3, Epoch 131/200 => Loss 3.367, Train_accy 56.670, Test_accy 50.730
2024-01-11 07:16:09,946 [bic.py] => bias_correction => Task 3, Epoch 132/200 => Loss 3.381, Train_accy 57.220, Test_accy 51.020
2024-01-11 07:16:21,372 [bic.py] => bias_correction => Task 3, Epoch 133/200 => Loss 3.388, Train_accy 57.220, Test_accy 51.150
2024-01-11 07:16:32,771 [bic.py] => bias_correction => Task 3, Epoch 134/200 => Loss 3.417, Train_accy 57.780, Test_accy 51.010
2024-01-11 07:16:44,165 [bic.py] => bias_correction => Task 3, Epoch 135/200 => Loss 3.403, Train_accy 56.110, Test_accy 50.810
2024-01-11 07:16:55,554 [bic.py] => bias_correction => Task 3, Epoch 136/200 => Loss 3.371, Train_accy 56.110, Test_accy 50.510
2024-01-11 07:17:07,098 [bic.py] => bias_correction => Task 3, Epoch 137/200 => Loss 3.387, Train_accy 56.670, Test_accy 50.470
2024-01-11 07:17:18,446 [bic.py] => bias_correction => Task 3, Epoch 138/200 => Loss 3.386, Train_accy 56.110, Test_accy 50.120
2024-01-11 07:17:29,865 [bic.py] => bias_correction => Task 3, Epoch 139/200 => Loss 3.431, Train_accy 55.560, Test_accy 50.010
2024-01-11 07:17:41,204 [bic.py] => bias_correction => Task 3, Epoch 140/200 => Loss 3.428, Train_accy 55.560, Test_accy 50.210
2024-01-11 07:17:52,209 [bic.py] => bias_correction => Task 3, Epoch 141/200 => Loss 3.398, Train_accy 55.560, Test_accy 50.420
2024-01-11 07:18:03,312 [bic.py] => bias_correction => Task 3, Epoch 142/200 => Loss 3.426, Train_accy 55.560, Test_accy 50.330
2024-01-11 07:18:14,852 [bic.py] => bias_correction => Task 3, Epoch 143/200 => Loss 3.418, Train_accy 55.560, Test_accy 50.440
2024-01-11 07:18:26,255 [bic.py] => bias_correction => Task 3, Epoch 144/200 => Loss 3.378, Train_accy 55.560, Test_accy 50.540
2024-01-11 07:18:37,562 [bic.py] => bias_correction => Task 3, Epoch 145/200 => Loss 3.398, Train_accy 55.560, Test_accy 50.490
2024-01-11 07:18:48,854 [bic.py] => bias_correction => Task 3, Epoch 146/200 => Loss 3.389, Train_accy 55.560, Test_accy 50.380
2024-01-11 07:19:00,181 [bic.py] => bias_correction => Task 3, Epoch 147/200 => Loss 3.410, Train_accy 56.110, Test_accy 50.230
2024-01-11 07:19:11,891 [bic.py] => bias_correction => Task 3, Epoch 148/200 => Loss 3.387, Train_accy 56.110, Test_accy 50.370
2024-01-11 07:19:23,175 [bic.py] => bias_correction => Task 3, Epoch 149/200 => Loss 3.418, Train_accy 55.560, Test_accy 50.530
2024-01-11 07:19:34,493 [bic.py] => bias_correction => Task 3, Epoch 150/200 => Loss 3.399, Train_accy 55.560, Test_accy 50.520
2024-01-11 07:19:45,844 [bic.py] => bias_correction => Task 3, Epoch 151/200 => Loss 3.384, Train_accy 56.110, Test_accy 50.570
2024-01-11 07:19:57,097 [bic.py] => bias_correction => Task 3, Epoch 152/200 => Loss 3.389, Train_accy 56.670, Test_accy 50.490
2024-01-11 07:20:08,554 [bic.py] => bias_correction => Task 3, Epoch 153/200 => Loss 3.406, Train_accy 56.110, Test_accy 50.360
2024-01-11 07:20:19,863 [bic.py] => bias_correction => Task 3, Epoch 154/200 => Loss 3.424, Train_accy 55.560, Test_accy 50.370
2024-01-11 07:20:30,789 [bic.py] => bias_correction => Task 3, Epoch 155/200 => Loss 3.398, Train_accy 55.000, Test_accy 50.330
2024-01-11 07:20:42,080 [bic.py] => bias_correction => Task 3, Epoch 156/200 => Loss 3.430, Train_accy 55.000, Test_accy 50.140
2024-01-11 07:20:53,016 [bic.py] => bias_correction => Task 3, Epoch 157/200 => Loss 3.421, Train_accy 56.110, Test_accy 50.370
2024-01-11 07:21:04,446 [bic.py] => bias_correction => Task 3, Epoch 158/200 => Loss 3.399, Train_accy 55.560, Test_accy 50.210
2024-01-11 07:21:15,471 [bic.py] => bias_correction => Task 3, Epoch 159/200 => Loss 3.387, Train_accy 55.000, Test_accy 50.280
2024-01-11 07:21:26,952 [bic.py] => bias_correction => Task 3, Epoch 160/200 => Loss 3.389, Train_accy 55.560, Test_accy 50.300
2024-01-11 07:21:38,298 [bic.py] => bias_correction => Task 3, Epoch 161/200 => Loss 3.387, Train_accy 55.560, Test_accy 50.440
2024-01-11 07:21:49,628 [bic.py] => bias_correction => Task 3, Epoch 162/200 => Loss 3.391, Train_accy 55.560, Test_accy 50.300
2024-01-11 07:22:00,864 [bic.py] => bias_correction => Task 3, Epoch 163/200 => Loss 3.394, Train_accy 56.110, Test_accy 50.360
2024-01-11 07:22:12,431 [bic.py] => bias_correction => Task 3, Epoch 164/200 => Loss 3.423, Train_accy 55.560, Test_accy 50.170
2024-01-11 07:22:23,861 [bic.py] => bias_correction => Task 3, Epoch 165/200 => Loss 3.376, Train_accy 55.560, Test_accy 50.090
2024-01-11 07:22:35,454 [bic.py] => bias_correction => Task 3, Epoch 166/200 => Loss 3.400, Train_accy 56.110, Test_accy 50.010
2024-01-11 07:22:46,879 [bic.py] => bias_correction => Task 3, Epoch 167/200 => Loss 3.390, Train_accy 55.560, Test_accy 50.070
2024-01-11 07:22:58,363 [bic.py] => bias_correction => Task 3, Epoch 168/200 => Loss 3.421, Train_accy 56.110, Test_accy 49.790
2024-01-11 07:23:09,891 [bic.py] => bias_correction => Task 3, Epoch 169/200 => Loss 3.425, Train_accy 56.110, Test_accy 49.840
2024-01-11 07:23:21,242 [bic.py] => bias_correction => Task 3, Epoch 170/200 => Loss 3.390, Train_accy 56.110, Test_accy 49.640
2024-01-11 07:23:32,038 [bic.py] => bias_correction => Task 3, Epoch 171/200 => Loss 3.391, Train_accy 56.110, Test_accy 49.650
2024-01-11 07:23:43,432 [bic.py] => bias_correction => Task 3, Epoch 172/200 => Loss 3.390, Train_accy 56.670, Test_accy 49.720
2024-01-11 07:23:54,716 [bic.py] => bias_correction => Task 3, Epoch 173/200 => Loss 3.396, Train_accy 56.670, Test_accy 49.670
2024-01-11 07:24:06,069 [bic.py] => bias_correction => Task 3, Epoch 174/200 => Loss 3.392, Train_accy 56.670, Test_accy 50.000
2024-01-11 07:24:17,549 [bic.py] => bias_correction => Task 3, Epoch 175/200 => Loss 3.380, Train_accy 57.220, Test_accy 50.400
2024-01-11 07:24:28,920 [bic.py] => bias_correction => Task 3, Epoch 176/200 => Loss 3.379, Train_accy 56.670, Test_accy 50.430
2024-01-11 07:24:40,304 [bic.py] => bias_correction => Task 3, Epoch 177/200 => Loss 3.361, Train_accy 56.670, Test_accy 50.570
2024-01-11 07:24:51,758 [bic.py] => bias_correction => Task 3, Epoch 178/200 => Loss 3.394, Train_accy 57.220, Test_accy 50.940
2024-01-11 07:25:03,127 [bic.py] => bias_correction => Task 3, Epoch 179/200 => Loss 3.376, Train_accy 57.220, Test_accy 51.010
2024-01-11 07:25:14,476 [bic.py] => bias_correction => Task 3, Epoch 180/200 => Loss 3.399, Train_accy 56.110, Test_accy 50.770
2024-01-11 07:25:25,754 [bic.py] => bias_correction => Task 3, Epoch 181/200 => Loss 3.392, Train_accy 56.670, Test_accy 50.680
2024-01-11 07:25:37,099 [bic.py] => bias_correction => Task 3, Epoch 182/200 => Loss 3.395, Train_accy 56.110, Test_accy 50.720
2024-01-11 07:25:48,011 [bic.py] => bias_correction => Task 3, Epoch 183/200 => Loss 3.401, Train_accy 55.560, Test_accy 50.510
2024-01-11 07:25:58,622 [bic.py] => bias_correction => Task 3, Epoch 184/200 => Loss 3.385, Train_accy 55.560, Test_accy 50.370
2024-01-11 07:26:09,824 [bic.py] => bias_correction => Task 3, Epoch 185/200 => Loss 3.412, Train_accy 55.560, Test_accy 50.630
2024-01-11 07:26:21,196 [bic.py] => bias_correction => Task 3, Epoch 186/200 => Loss 3.379, Train_accy 55.560, Test_accy 50.830
2024-01-11 07:26:32,528 [bic.py] => bias_correction => Task 3, Epoch 187/200 => Loss 3.401, Train_accy 56.110, Test_accy 50.520
2024-01-11 07:26:43,797 [bic.py] => bias_correction => Task 3, Epoch 188/200 => Loss 3.406, Train_accy 55.560, Test_accy 50.470
2024-01-11 07:26:55,091 [bic.py] => bias_correction => Task 3, Epoch 189/200 => Loss 3.391, Train_accy 55.560, Test_accy 50.430
2024-01-11 07:27:06,467 [bic.py] => bias_correction => Task 3, Epoch 190/200 => Loss 3.409, Train_accy 55.560, Test_accy 50.470
2024-01-11 07:27:17,922 [bic.py] => bias_correction => Task 3, Epoch 191/200 => Loss 3.377, Train_accy 55.000, Test_accy 50.440
2024-01-11 07:27:29,341 [bic.py] => bias_correction => Task 3, Epoch 192/200 => Loss 3.398, Train_accy 56.110, Test_accy 50.540
2024-01-11 07:27:40,835 [bic.py] => bias_correction => Task 3, Epoch 193/200 => Loss 3.405, Train_accy 56.670, Test_accy 50.370
2024-01-11 07:27:52,342 [bic.py] => bias_correction => Task 3, Epoch 194/200 => Loss 3.393, Train_accy 55.560, Test_accy 50.430
2024-01-11 07:28:03,399 [bic.py] => bias_correction => Task 3, Epoch 195/200 => Loss 3.388, Train_accy 55.560, Test_accy 50.510
2024-01-11 07:28:14,877 [bic.py] => bias_correction => Task 3, Epoch 196/200 => Loss 3.397, Train_accy 55.560, Test_accy 50.440
2024-01-11 07:28:26,352 [bic.py] => bias_correction => Task 3, Epoch 197/200 => Loss 3.439, Train_accy 56.110, Test_accy 50.470
2024-01-11 07:28:37,219 [bic.py] => bias_correction => Task 3, Epoch 198/200 => Loss 3.442, Train_accy 56.110, Test_accy 50.020
2024-01-11 07:28:49,124 [bic.py] => bias_correction => Task 3, Epoch 199/200 => Loss 3.392, Train_accy 55.560, Test_accy 50.220
2024-01-11 07:29:00,405 [bic.py] => bias_correction => Task 3, Epoch 200/200 => Loss 3.383, Train_accy 55.560, Test_accy 50.100
2024-01-11 07:29:00,406 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-11 07:29:29,003 [bic.py] => Parameters of bias layer:
2024-01-11 07:29:29,004 [bic.py] => 0 => 1.000, 0.000
2024-01-11 07:29:29,004 [bic.py] => 1 => 0.791, -2.133
2024-01-11 07:29:29,004 [bic.py] => 2 => 0.880, -1.721
2024-01-11 07:29:29,004 [bic.py] => 3 => 0.849, -1.720
2024-01-11 07:29:47,152 [bic.py] => Exemplar size: 1350
2024-01-11 07:29:47,334 [trainer.py] => CNN: {'total': 50.1, '0': 47.78, '1': 39.44, '2': 49.44, '3': 17.22, '4': 27.22, '5': 23.89, '6': 12.22, '7': 12.78, '8': 61.67, '9': 22.78, '10': 41.11, '11': 38.89, '12': 32.22, '13': 27.78, '14': 43.89, '15': 40.0, '16': 40.0, '17': 43.89, '18': 44.44, '19': 36.11, '20': 28.89, '21': 33.89, '22': 45.56, '23': 31.11, '24': 46.67, '25': 41.11, '26': 61.67, '27': 68.33, '28': 33.33, '29': 42.22, '30': 53.33, '31': 40.56, '32': 88.33, '33': 36.67, '34': 62.22, '35': 92.78, '36': 87.78, '37': 49.44, '38': 87.78, '39': 91.67, '40': 82.22, '41': 94.44, '42': 91.11, '43': 91.11, 'old': 40.48, 'new': 83.78}
2024-01-11 07:29:47,334 [trainer.py] => NME: {'total': 53.22, '0': 54.44, '1': 41.67, '2': 64.44, '3': 25.56, '4': 42.22, '5': 25.0, '6': 30.0, '7': 34.44, '8': 48.33, '9': 34.44, '10': 48.89, '11': 56.11, '12': 42.22, '13': 46.67, '14': 52.22, '15': 52.78, '16': 68.89, '17': 53.89, '18': 47.78, '19': 53.33, '20': 62.22, '21': 52.22, '22': 57.78, '23': 52.22, '24': 51.11, '25': 46.67, '26': 63.33, '27': 50.56, '28': 30.56, '29': 49.44, '30': 55.56, '31': 45.56, '32': 69.44, '33': 30.56, '34': 42.78, '35': 81.11, '36': 75.56, '37': 48.33, '38': 81.11, '39': 75.56, '40': 64.44, '41': 86.67, '42': 71.67, '43': 73.33, 'old': 48.1, 'new': 71.17}
2024-01-11 07:29:47,335 [trainer.py] => CNN top1 curve: [86.11, 64.91, 52.86, 50.1]
2024-01-11 07:29:47,335 [trainer.py] => CNN top5 curve: [97.7, 93.13, 84.13, 80.38]
2024-01-11 07:29:47,335 [trainer.py] => NME top1 curve: [84.37, 68.27, 51.03, 53.22]
2024-01-11 07:29:47,335 [trainer.py] => NME top5 curve: [98.07, 95.18, 88.78, 87.2]

2024-01-11 07:29:47,335 [trainer.py] => All params: 21047425
2024-01-11 07:29:47,335 [trainer.py] => Trainable params: 21047425
2024-01-11 07:29:47,336 [bic.py] => Learning on 45-55
2024-01-11 07:29:47,371 [bic.py] => Stage1 dset: 5385, Stage2 dset: 165
2024-01-11 07:29:47,371 [bic.py] => Lambda: 0.818
2024-01-11 07:29:47,432 [bic.py] => Parameters of bias layer:
2024-01-11 07:29:47,433 [bic.py] => 0 => 1.000, 0.000
2024-01-11 07:29:47,433 [bic.py] => 1 => 0.791, -2.133
2024-01-11 07:29:47,433 [bic.py] => 2 => 0.880, -1.721
2024-01-11 07:29:47,433 [bic.py] => 3 => 0.849, -1.720
2024-01-11 07:29:47,433 [bic.py] => 4 => 1.000, 0.000
2024-01-11 07:30:43,016 [bic.py] => training => Task 4, Epoch 1/200 => Loss 2.696, Train_accy 25.720, Test_accy 21.670
2024-01-11 07:31:16,435 [bic.py] => training => Task 4, Epoch 2/200 => Loss 2.577, Train_accy 32.440, Test_accy 25.310
2024-01-11 07:31:48,790 [bic.py] => training => Task 4, Epoch 3/200 => Loss 2.504, Train_accy 42.900, Test_accy 25.970
2024-01-11 07:32:22,322 [bic.py] => training => Task 4, Epoch 4/200 => Loss 2.418, Train_accy 51.530, Test_accy 29.730
2024-01-11 07:32:55,647 [bic.py] => training => Task 4, Epoch 5/200 => Loss 2.376, Train_accy 59.310, Test_accy 33.120
2024-01-11 07:33:29,055 [bic.py] => training => Task 4, Epoch 6/200 => Loss 2.321, Train_accy 67.610, Test_accy 33.480
2024-01-11 07:34:02,633 [bic.py] => training => Task 4, Epoch 7/200 => Loss 2.315, Train_accy 67.630, Test_accy 38.080
2024-01-11 07:34:34,823 [bic.py] => training => Task 4, Epoch 8/200 => Loss 2.304, Train_accy 72.810, Test_accy 35.770
2024-01-11 07:35:08,366 [bic.py] => training => Task 4, Epoch 9/200 => Loss 2.269, Train_accy 62.540, Test_accy 32.680
2024-01-11 07:35:42,271 [bic.py] => training => Task 4, Epoch 10/200 => Loss 2.323, Train_accy 69.210, Test_accy 35.670
2024-01-11 07:36:15,944 [bic.py] => training => Task 4, Epoch 11/200 => Loss 2.282, Train_accy 75.520, Test_accy 38.130
2024-01-11 07:36:50,141 [bic.py] => training => Task 4, Epoch 12/200 => Loss 2.257, Train_accy 78.960, Test_accy 37.280
2024-01-11 07:37:23,765 [bic.py] => training => Task 4, Epoch 13/200 => Loss 2.221, Train_accy 75.080, Test_accy 37.930
2024-01-11 07:37:56,432 [bic.py] => training => Task 4, Epoch 14/200 => Loss 2.223, Train_accy 76.250, Test_accy 35.330
2024-01-11 07:38:30,544 [bic.py] => training => Task 4, Epoch 15/200 => Loss 2.251, Train_accy 75.950, Test_accy 37.920
2024-01-11 07:39:04,261 [bic.py] => training => Task 4, Epoch 16/200 => Loss 2.204, Train_accy 75.670, Test_accy 37.700
2024-01-11 07:39:38,325 [bic.py] => training => Task 4, Epoch 17/200 => Loss 2.186, Train_accy 74.040, Test_accy 36.070
2024-01-11 07:40:11,868 [bic.py] => training => Task 4, Epoch 18/200 => Loss 2.192, Train_accy 80.540, Test_accy 40.830
2024-01-11 07:40:40,021 [bic.py] => training => Task 4, Epoch 19/200 => Loss 2.170, Train_accy 75.560, Test_accy 35.820
2024-01-11 07:41:10,399 [bic.py] => training => Task 4, Epoch 20/200 => Loss 2.237, Train_accy 78.090, Test_accy 39.320
2024-01-11 07:41:40,809 [bic.py] => training => Task 4, Epoch 21/200 => Loss 2.178, Train_accy 76.990, Test_accy 36.580
2024-01-11 07:42:11,201 [bic.py] => training => Task 4, Epoch 22/200 => Loss 2.200, Train_accy 82.170, Test_accy 40.470
2024-01-11 07:42:41,359 [bic.py] => training => Task 4, Epoch 23/200 => Loss 2.189, Train_accy 82.230, Test_accy 40.170
2024-01-11 07:43:09,068 [bic.py] => training => Task 4, Epoch 24/200 => Loss 2.169, Train_accy 74.970, Test_accy 35.340
2024-01-11 07:43:39,075 [bic.py] => training => Task 4, Epoch 25/200 => Loss 2.181, Train_accy 84.590, Test_accy 42.260
2024-01-11 07:44:09,007 [bic.py] => training => Task 4, Epoch 26/200 => Loss 2.155, Train_accy 91.250, Test_accy 44.090
2024-01-11 07:44:40,095 [bic.py] => training => Task 4, Epoch 27/200 => Loss 2.135, Train_accy 88.880, Test_accy 43.800
2024-01-11 07:45:11,018 [bic.py] => training => Task 4, Epoch 28/200 => Loss 2.143, Train_accy 85.400, Test_accy 39.990
2024-01-11 07:45:39,427 [bic.py] => training => Task 4, Epoch 29/200 => Loss 2.166, Train_accy 82.120, Test_accy 38.560
2024-01-11 07:46:09,120 [bic.py] => training => Task 4, Epoch 30/200 => Loss 2.192, Train_accy 76.470, Test_accy 37.660
2024-01-11 07:46:39,207 [bic.py] => training => Task 4, Epoch 31/200 => Loss 2.175, Train_accy 85.720, Test_accy 39.890
2024-01-11 07:47:08,947 [bic.py] => training => Task 4, Epoch 32/200 => Loss 2.180, Train_accy 86.650, Test_accy 43.250
2024-01-11 07:47:38,957 [bic.py] => training => Task 4, Epoch 33/200 => Loss 2.171, Train_accy 84.850, Test_accy 41.070
2024-01-11 07:48:07,008 [bic.py] => training => Task 4, Epoch 34/200 => Loss 2.149, Train_accy 81.210, Test_accy 38.850
2024-01-11 07:48:37,037 [bic.py] => training => Task 4, Epoch 35/200 => Loss 2.162, Train_accy 85.460, Test_accy 40.400
2024-01-11 07:49:07,326 [bic.py] => training => Task 4, Epoch 36/200 => Loss 2.125, Train_accy 92.530, Test_accy 44.560
2024-01-11 07:49:37,149 [bic.py] => training => Task 4, Epoch 37/200 => Loss 2.116, Train_accy 92.630, Test_accy 45.270
2024-01-11 07:50:06,831 [bic.py] => training => Task 4, Epoch 38/200 => Loss 2.145, Train_accy 77.550, Test_accy 37.920
2024-01-11 07:50:34,491 [bic.py] => training => Task 4, Epoch 39/200 => Loss 2.191, Train_accy 84.870, Test_accy 40.990
2024-01-11 07:51:04,437 [bic.py] => training => Task 4, Epoch 40/200 => Loss 2.135, Train_accy 90.420, Test_accy 43.630
2024-01-11 07:51:34,117 [bic.py] => training => Task 4, Epoch 41/200 => Loss 2.124, Train_accy 90.970, Test_accy 43.990
2024-01-11 07:52:03,777 [bic.py] => training => Task 4, Epoch 42/200 => Loss 2.151, Train_accy 83.380, Test_accy 39.020
2024-01-11 07:52:33,582 [bic.py] => training => Task 4, Epoch 43/200 => Loss 2.189, Train_accy 83.860, Test_accy 41.570
2024-01-11 07:53:01,793 [bic.py] => training => Task 4, Epoch 44/200 => Loss 2.157, Train_accy 90.160, Test_accy 42.450
2024-01-11 07:53:30,989 [bic.py] => training => Task 4, Epoch 45/200 => Loss 2.147, Train_accy 84.790, Test_accy 40.040
2024-01-11 07:54:00,968 [bic.py] => training => Task 4, Epoch 46/200 => Loss 2.167, Train_accy 87.560, Test_accy 41.490
2024-01-11 07:54:31,090 [bic.py] => training => Task 4, Epoch 47/200 => Loss 2.133, Train_accy 84.620, Test_accy 43.280
2024-01-11 07:55:00,908 [bic.py] => training => Task 4, Epoch 48/200 => Loss 2.121, Train_accy 90.400, Test_accy 42.620
2024-01-11 07:55:30,239 [bic.py] => training => Task 4, Epoch 49/200 => Loss 2.158, Train_accy 89.750, Test_accy 41.850
2024-01-11 07:55:58,630 [bic.py] => training => Task 4, Epoch 50/200 => Loss 2.141, Train_accy 88.250, Test_accy 41.530
2024-01-11 07:56:28,369 [bic.py] => training => Task 4, Epoch 51/200 => Loss 2.187, Train_accy 76.660, Test_accy 38.340
2024-01-11 07:56:58,050 [bic.py] => training => Task 4, Epoch 52/200 => Loss 2.157, Train_accy 89.730, Test_accy 42.630
2024-01-11 07:57:27,660 [bic.py] => training => Task 4, Epoch 53/200 => Loss 2.174, Train_accy 86.740, Test_accy 40.810
2024-01-11 07:57:56,632 [bic.py] => training => Task 4, Epoch 54/200 => Loss 2.129, Train_accy 88.620, Test_accy 42.670
2024-01-11 07:58:24,427 [bic.py] => training => Task 4, Epoch 55/200 => Loss 2.136, Train_accy 90.100, Test_accy 42.350
2024-01-11 07:58:53,922 [bic.py] => training => Task 4, Epoch 56/200 => Loss 2.149, Train_accy 81.760, Test_accy 38.810
2024-01-11 07:59:23,575 [bic.py] => training => Task 4, Epoch 57/200 => Loss 2.199, Train_accy 84.870, Test_accy 41.900
2024-01-11 07:59:53,259 [bic.py] => training => Task 4, Epoch 58/200 => Loss 2.188, Train_accy 86.200, Test_accy 37.820
2024-01-11 08:00:22,992 [bic.py] => training => Task 4, Epoch 59/200 => Loss 2.142, Train_accy 90.440, Test_accy 43.150
2024-01-11 08:00:50,757 [bic.py] => training => Task 4, Epoch 60/200 => Loss 2.160, Train_accy 88.410, Test_accy 41.680
2024-01-11 08:01:20,463 [bic.py] => training => Task 4, Epoch 61/200 => Loss 2.086, Train_accy 98.480, Test_accy 49.610
2024-01-11 08:01:50,119 [bic.py] => training => Task 4, Epoch 62/200 => Loss 2.067, Train_accy 98.810, Test_accy 49.530
2024-01-11 08:02:19,703 [bic.py] => training => Task 4, Epoch 63/200 => Loss 2.059, Train_accy 98.810, Test_accy 50.450
2024-01-11 08:02:49,229 [bic.py] => training => Task 4, Epoch 64/200 => Loss 2.068, Train_accy 99.070, Test_accy 50.540
2024-01-11 08:03:16,479 [bic.py] => training => Task 4, Epoch 65/200 => Loss 2.047, Train_accy 99.110, Test_accy 50.400
2024-01-11 08:03:45,868 [bic.py] => training => Task 4, Epoch 66/200 => Loss 2.054, Train_accy 99.240, Test_accy 51.100
2024-01-11 08:04:15,580 [bic.py] => training => Task 4, Epoch 67/200 => Loss 2.041, Train_accy 99.130, Test_accy 50.150
2024-01-11 08:04:45,144 [bic.py] => training => Task 4, Epoch 68/200 => Loss 2.048, Train_accy 99.310, Test_accy 50.220
2024-01-11 08:05:15,017 [bic.py] => training => Task 4, Epoch 69/200 => Loss 2.052, Train_accy 99.350, Test_accy 51.950
2024-01-11 08:05:43,205 [bic.py] => training => Task 4, Epoch 70/200 => Loss 2.057, Train_accy 99.240, Test_accy 50.190
2024-01-11 08:06:12,626 [bic.py] => training => Task 4, Epoch 71/200 => Loss 2.049, Train_accy 99.310, Test_accy 50.390
2024-01-11 08:06:42,384 [bic.py] => training => Task 4, Epoch 72/200 => Loss 2.046, Train_accy 99.290, Test_accy 50.410
2024-01-11 08:07:12,390 [bic.py] => training => Task 4, Epoch 73/200 => Loss 2.043, Train_accy 99.260, Test_accy 50.940
2024-01-11 08:07:41,852 [bic.py] => training => Task 4, Epoch 74/200 => Loss 2.039, Train_accy 99.420, Test_accy 50.980
2024-01-11 08:08:10,748 [bic.py] => training => Task 4, Epoch 75/200 => Loss 2.069, Train_accy 99.280, Test_accy 50.910
2024-01-11 08:08:38,643 [bic.py] => training => Task 4, Epoch 76/200 => Loss 2.059, Train_accy 99.310, Test_accy 51.580
2024-01-11 08:09:08,043 [bic.py] => training => Task 4, Epoch 77/200 => Loss 2.053, Train_accy 99.290, Test_accy 50.920
2024-01-11 08:09:38,318 [bic.py] => training => Task 4, Epoch 78/200 => Loss 2.046, Train_accy 99.390, Test_accy 51.100
2024-01-11 08:10:07,659 [bic.py] => training => Task 4, Epoch 79/200 => Loss 2.049, Train_accy 99.460, Test_accy 51.360
2024-01-11 08:10:36,240 [bic.py] => training => Task 4, Epoch 80/200 => Loss 2.041, Train_accy 99.390, Test_accy 51.090
2024-01-11 08:11:03,985 [bic.py] => training => Task 4, Epoch 81/200 => Loss 2.048, Train_accy 99.570, Test_accy 51.150
2024-01-11 08:11:33,500 [bic.py] => training => Task 4, Epoch 82/200 => Loss 2.034, Train_accy 99.480, Test_accy 51.220
2024-01-11 08:12:02,777 [bic.py] => training => Task 4, Epoch 83/200 => Loss 2.040, Train_accy 99.550, Test_accy 51.940
2024-01-11 08:12:32,282 [bic.py] => training => Task 4, Epoch 84/200 => Loss 2.034, Train_accy 99.500, Test_accy 51.530
2024-01-11 08:13:01,740 [bic.py] => training => Task 4, Epoch 85/200 => Loss 2.043, Train_accy 99.480, Test_accy 51.350
2024-01-11 08:13:28,905 [bic.py] => training => Task 4, Epoch 86/200 => Loss 2.042, Train_accy 99.420, Test_accy 51.260
2024-01-11 08:13:58,335 [bic.py] => training => Task 4, Epoch 87/200 => Loss 2.039, Train_accy 99.610, Test_accy 51.610
2024-01-11 08:14:28,227 [bic.py] => training => Task 4, Epoch 88/200 => Loss 2.038, Train_accy 99.650, Test_accy 51.600
2024-01-11 08:14:58,002 [bic.py] => training => Task 4, Epoch 89/200 => Loss 2.037, Train_accy 99.520, Test_accy 51.610
2024-01-11 08:15:27,612 [bic.py] => training => Task 4, Epoch 90/200 => Loss 2.054, Train_accy 99.630, Test_accy 50.410
2024-01-11 08:15:55,516 [bic.py] => training => Task 4, Epoch 91/200 => Loss 2.029, Train_accy 99.550, Test_accy 51.770
2024-01-11 08:16:24,970 [bic.py] => training => Task 4, Epoch 92/200 => Loss 2.042, Train_accy 99.540, Test_accy 51.120
2024-01-11 08:16:55,217 [bic.py] => training => Task 4, Epoch 93/200 => Loss 2.031, Train_accy 99.680, Test_accy 51.530
2024-01-11 08:17:25,037 [bic.py] => training => Task 4, Epoch 94/200 => Loss 2.039, Train_accy 99.610, Test_accy 51.760
2024-01-11 08:17:54,803 [bic.py] => training => Task 4, Epoch 95/200 => Loss 2.034, Train_accy 99.680, Test_accy 51.930
2024-01-11 08:18:23,622 [bic.py] => training => Task 4, Epoch 96/200 => Loss 2.032, Train_accy 99.680, Test_accy 51.560
2024-01-11 08:18:52,157 [bic.py] => training => Task 4, Epoch 97/200 => Loss 2.037, Train_accy 99.650, Test_accy 51.420
2024-01-11 08:19:21,807 [bic.py] => training => Task 4, Epoch 98/200 => Loss 2.027, Train_accy 99.680, Test_accy 52.080
2024-01-11 08:19:51,648 [bic.py] => training => Task 4, Epoch 99/200 => Loss 2.028, Train_accy 99.680, Test_accy 51.740
2024-01-11 08:20:21,761 [bic.py] => training => Task 4, Epoch 100/200 => Loss 2.030, Train_accy 99.540, Test_accy 51.480
2024-01-11 08:20:51,274 [bic.py] => training => Task 4, Epoch 101/200 => Loss 2.041, Train_accy 99.610, Test_accy 51.900
2024-01-11 08:21:19,669 [bic.py] => training => Task 4, Epoch 102/200 => Loss 2.027, Train_accy 99.670, Test_accy 52.390
2024-01-11 08:21:49,285 [bic.py] => training => Task 4, Epoch 103/200 => Loss 2.031, Train_accy 99.650, Test_accy 52.400
2024-01-11 08:22:19,215 [bic.py] => training => Task 4, Epoch 104/200 => Loss 2.026, Train_accy 99.590, Test_accy 51.930
2024-01-11 08:22:48,945 [bic.py] => training => Task 4, Epoch 105/200 => Loss 2.025, Train_accy 99.570, Test_accy 50.990
2024-01-11 08:23:17,831 [bic.py] => training => Task 4, Epoch 106/200 => Loss 2.029, Train_accy 99.590, Test_accy 51.170
2024-01-11 08:23:45,720 [bic.py] => training => Task 4, Epoch 107/200 => Loss 2.041, Train_accy 99.650, Test_accy 51.770
2024-01-11 08:24:15,337 [bic.py] => training => Task 4, Epoch 108/200 => Loss 2.028, Train_accy 99.720, Test_accy 52.210
2024-01-11 08:24:45,669 [bic.py] => training => Task 4, Epoch 109/200 => Loss 2.024, Train_accy 99.650, Test_accy 51.910
2024-01-11 08:25:15,166 [bic.py] => training => Task 4, Epoch 110/200 => Loss 2.025, Train_accy 99.720, Test_accy 52.350
2024-01-11 08:25:45,251 [bic.py] => training => Task 4, Epoch 111/200 => Loss 2.035, Train_accy 99.700, Test_accy 51.630
2024-01-11 08:26:13,062 [bic.py] => training => Task 4, Epoch 112/200 => Loss 2.025, Train_accy 99.590, Test_accy 51.350
2024-01-11 08:26:42,726 [bic.py] => training => Task 4, Epoch 113/200 => Loss 2.035, Train_accy 99.630, Test_accy 52.090
2024-01-11 08:27:12,633 [bic.py] => training => Task 4, Epoch 114/200 => Loss 2.016, Train_accy 99.650, Test_accy 51.210
2024-01-11 08:27:42,365 [bic.py] => training => Task 4, Epoch 115/200 => Loss 2.026, Train_accy 99.680, Test_accy 52.270
2024-01-11 08:28:12,679 [bic.py] => training => Task 4, Epoch 116/200 => Loss 2.026, Train_accy 99.680, Test_accy 52.530
2024-01-11 08:28:40,719 [bic.py] => training => Task 4, Epoch 117/200 => Loss 2.033, Train_accy 99.700, Test_accy 52.430
2024-01-11 08:29:10,346 [bic.py] => training => Task 4, Epoch 118/200 => Loss 2.024, Train_accy 99.670, Test_accy 51.350
2024-01-11 08:29:40,178 [bic.py] => training => Task 4, Epoch 119/200 => Loss 2.023, Train_accy 99.670, Test_accy 52.130
2024-01-11 08:30:10,073 [bic.py] => training => Task 4, Epoch 120/200 => Loss 2.028, Train_accy 99.760, Test_accy 52.520
2024-01-11 08:30:40,154 [bic.py] => training => Task 4, Epoch 121/200 => Loss 2.029, Train_accy 99.670, Test_accy 52.530
2024-01-11 08:31:07,942 [bic.py] => training => Task 4, Epoch 122/200 => Loss 2.024, Train_accy 99.700, Test_accy 51.740
2024-01-11 08:31:37,575 [bic.py] => training => Task 4, Epoch 123/200 => Loss 2.037, Train_accy 99.610, Test_accy 51.840
2024-01-11 08:32:07,032 [bic.py] => training => Task 4, Epoch 124/200 => Loss 2.021, Train_accy 99.650, Test_accy 52.190
2024-01-11 08:32:36,757 [bic.py] => training => Task 4, Epoch 125/200 => Loss 2.030, Train_accy 99.650, Test_accy 51.370
2024-01-11 08:33:06,441 [bic.py] => training => Task 4, Epoch 126/200 => Loss 2.022, Train_accy 99.590, Test_accy 52.420
2024-01-11 08:33:35,036 [bic.py] => training => Task 4, Epoch 127/200 => Loss 2.027, Train_accy 99.720, Test_accy 53.130
2024-01-11 08:34:03,271 [bic.py] => training => Task 4, Epoch 128/200 => Loss 2.023, Train_accy 99.670, Test_accy 52.490
2024-01-11 08:34:33,734 [bic.py] => training => Task 4, Epoch 129/200 => Loss 2.029, Train_accy 99.700, Test_accy 51.990
2024-01-11 08:35:03,370 [bic.py] => training => Task 4, Epoch 130/200 => Loss 2.029, Train_accy 99.650, Test_accy 50.580
2024-01-11 08:35:33,417 [bic.py] => training => Task 4, Epoch 131/200 => Loss 2.024, Train_accy 99.670, Test_accy 51.190
2024-01-11 08:36:02,145 [bic.py] => training => Task 4, Epoch 132/200 => Loss 2.028, Train_accy 99.680, Test_accy 51.560
2024-01-11 08:36:30,520 [bic.py] => training => Task 4, Epoch 133/200 => Loss 2.026, Train_accy 99.700, Test_accy 51.870
2024-01-11 08:37:00,393 [bic.py] => training => Task 4, Epoch 134/200 => Loss 2.032, Train_accy 99.650, Test_accy 51.030
2024-01-11 08:37:30,311 [bic.py] => training => Task 4, Epoch 135/200 => Loss 2.028, Train_accy 99.590, Test_accy 51.390
2024-01-11 08:38:00,002 [bic.py] => training => Task 4, Epoch 136/200 => Loss 2.039, Train_accy 99.630, Test_accy 51.640
2024-01-11 08:38:29,176 [bic.py] => training => Task 4, Epoch 137/200 => Loss 2.028, Train_accy 99.700, Test_accy 52.320
2024-01-11 08:38:57,746 [bic.py] => training => Task 4, Epoch 138/200 => Loss 2.027, Train_accy 99.610, Test_accy 51.450
2024-01-11 08:39:27,334 [bic.py] => training => Task 4, Epoch 139/200 => Loss 2.030, Train_accy 99.680, Test_accy 52.390
2024-01-11 08:39:57,704 [bic.py] => training => Task 4, Epoch 140/200 => Loss 2.031, Train_accy 99.650, Test_accy 52.030
2024-01-11 08:40:27,734 [bic.py] => training => Task 4, Epoch 141/200 => Loss 2.032, Train_accy 99.720, Test_accy 52.560
2024-01-11 08:40:57,733 [bic.py] => training => Task 4, Epoch 142/200 => Loss 2.029, Train_accy 99.680, Test_accy 52.200
2024-01-11 08:41:27,018 [bic.py] => training => Task 4, Epoch 143/200 => Loss 2.033, Train_accy 99.680, Test_accy 51.540
2024-01-11 08:41:57,151 [bic.py] => training => Task 4, Epoch 144/200 => Loss 2.037, Train_accy 99.650, Test_accy 51.850
2024-01-11 08:42:27,390 [bic.py] => training => Task 4, Epoch 145/200 => Loss 2.022, Train_accy 99.760, Test_accy 51.630
2024-01-11 08:42:58,122 [bic.py] => training => Task 4, Epoch 146/200 => Loss 2.028, Train_accy 99.670, Test_accy 51.630
2024-01-11 08:43:27,583 [bic.py] => training => Task 4, Epoch 147/200 => Loss 2.025, Train_accy 99.780, Test_accy 52.440
2024-01-11 08:43:54,984 [bic.py] => training => Task 4, Epoch 148/200 => Loss 2.031, Train_accy 99.680, Test_accy 51.910
2024-01-11 08:44:24,434 [bic.py] => training => Task 4, Epoch 149/200 => Loss 2.026, Train_accy 99.500, Test_accy 51.560
2024-01-11 08:44:54,177 [bic.py] => training => Task 4, Epoch 150/200 => Loss 2.031, Train_accy 99.720, Test_accy 52.240
2024-01-11 08:45:24,093 [bic.py] => training => Task 4, Epoch 151/200 => Loss 2.033, Train_accy 99.740, Test_accy 52.400
2024-01-11 08:45:53,469 [bic.py] => training => Task 4, Epoch 152/200 => Loss 2.029, Train_accy 99.680, Test_accy 51.710
2024-01-11 08:46:20,679 [bic.py] => training => Task 4, Epoch 153/200 => Loss 2.029, Train_accy 99.780, Test_accy 51.600
2024-01-11 08:46:51,419 [bic.py] => training => Task 4, Epoch 154/200 => Loss 2.020, Train_accy 99.760, Test_accy 52.330
2024-01-11 08:47:20,967 [bic.py] => training => Task 4, Epoch 155/200 => Loss 2.025, Train_accy 99.680, Test_accy 51.180
2024-01-11 08:47:50,771 [bic.py] => training => Task 4, Epoch 156/200 => Loss 2.024, Train_accy 99.700, Test_accy 52.030
2024-01-11 08:48:20,387 [bic.py] => training => Task 4, Epoch 157/200 => Loss 2.024, Train_accy 99.720, Test_accy 52.770
2024-01-11 08:48:48,354 [bic.py] => training => Task 4, Epoch 158/200 => Loss 2.024, Train_accy 99.680, Test_accy 52.560
2024-01-11 08:49:08,185 [bic.py] => training => Task 4, Epoch 159/200 => Loss 2.022, Train_accy 99.720, Test_accy 52.670
2024-01-11 08:49:28,382 [bic.py] => training => Task 4, Epoch 160/200 => Loss 2.039, Train_accy 99.680, Test_accy 51.760
2024-01-11 08:49:49,146 [bic.py] => training => Task 4, Epoch 161/200 => Loss 2.031, Train_accy 99.700, Test_accy 52.270
2024-01-11 08:50:09,184 [bic.py] => training => Task 4, Epoch 162/200 => Loss 2.024, Train_accy 99.700, Test_accy 52.410
2024-01-11 08:50:29,221 [bic.py] => training => Task 4, Epoch 163/200 => Loss 2.040, Train_accy 99.680, Test_accy 51.530
2024-01-11 08:50:49,296 [bic.py] => training => Task 4, Epoch 164/200 => Loss 2.030, Train_accy 99.740, Test_accy 52.100
2024-01-11 08:51:09,488 [bic.py] => training => Task 4, Epoch 165/200 => Loss 2.025, Train_accy 99.720, Test_accy 52.160
2024-01-11 08:51:29,396 [bic.py] => training => Task 4, Epoch 166/200 => Loss 2.039, Train_accy 99.680, Test_accy 52.310
2024-01-11 08:51:49,648 [bic.py] => training => Task 4, Epoch 167/200 => Loss 2.027, Train_accy 99.720, Test_accy 52.220
2024-01-11 08:52:10,644 [bic.py] => training => Task 4, Epoch 168/200 => Loss 2.020, Train_accy 99.700, Test_accy 52.950
2024-01-11 08:52:30,710 [bic.py] => training => Task 4, Epoch 169/200 => Loss 2.032, Train_accy 99.720, Test_accy 53.090
2024-01-11 08:52:50,674 [bic.py] => training => Task 4, Epoch 170/200 => Loss 2.034, Train_accy 99.650, Test_accy 51.650
2024-01-11 08:53:10,732 [bic.py] => training => Task 4, Epoch 171/200 => Loss 2.023, Train_accy 99.760, Test_accy 52.170
2024-01-11 08:53:30,709 [bic.py] => training => Task 4, Epoch 172/200 => Loss 2.033, Train_accy 99.720, Test_accy 52.670
2024-01-11 08:53:50,556 [bic.py] => training => Task 4, Epoch 173/200 => Loss 2.023, Train_accy 99.700, Test_accy 52.370
2024-01-11 08:54:10,476 [bic.py] => training => Task 4, Epoch 174/200 => Loss 2.026, Train_accy 99.720, Test_accy 52.100
2024-01-11 08:54:30,345 [bic.py] => training => Task 4, Epoch 175/200 => Loss 2.029, Train_accy 99.630, Test_accy 51.890
2024-01-11 08:54:50,342 [bic.py] => training => Task 4, Epoch 176/200 => Loss 2.027, Train_accy 99.720, Test_accy 51.920
2024-01-11 08:55:10,359 [bic.py] => training => Task 4, Epoch 177/200 => Loss 2.023, Train_accy 99.680, Test_accy 51.660
2024-01-11 08:55:30,391 [bic.py] => training => Task 4, Epoch 178/200 => Loss 2.025, Train_accy 99.720, Test_accy 51.950
2024-01-11 08:55:50,284 [bic.py] => training => Task 4, Epoch 179/200 => Loss 2.035, Train_accy 99.630, Test_accy 52.140
2024-01-11 08:56:10,381 [bic.py] => training => Task 4, Epoch 180/200 => Loss 2.024, Train_accy 99.780, Test_accy 52.380
2024-01-11 08:56:30,200 [bic.py] => training => Task 4, Epoch 181/200 => Loss 2.039, Train_accy 99.610, Test_accy 51.030
2024-01-11 08:56:50,054 [bic.py] => training => Task 4, Epoch 182/200 => Loss 2.032, Train_accy 99.680, Test_accy 51.660
2024-01-11 08:57:10,178 [bic.py] => training => Task 4, Epoch 183/200 => Loss 2.027, Train_accy 99.780, Test_accy 52.750
2024-01-11 08:57:30,550 [bic.py] => training => Task 4, Epoch 184/200 => Loss 2.029, Train_accy 99.720, Test_accy 52.070
2024-01-11 08:57:50,653 [bic.py] => training => Task 4, Epoch 185/200 => Loss 2.023, Train_accy 99.740, Test_accy 52.050
2024-01-11 08:58:10,645 [bic.py] => training => Task 4, Epoch 186/200 => Loss 2.031, Train_accy 99.720, Test_accy 51.680
2024-01-11 08:58:30,577 [bic.py] => training => Task 4, Epoch 187/200 => Loss 2.026, Train_accy 99.700, Test_accy 52.540
2024-01-11 08:58:50,839 [bic.py] => training => Task 4, Epoch 188/200 => Loss 2.028, Train_accy 99.670, Test_accy 52.720
2024-01-11 08:59:11,487 [bic.py] => training => Task 4, Epoch 189/200 => Loss 2.031, Train_accy 99.700, Test_accy 51.770
2024-01-11 08:59:31,561 [bic.py] => training => Task 4, Epoch 190/200 => Loss 2.019, Train_accy 99.720, Test_accy 52.200
2024-01-11 08:59:51,657 [bic.py] => training => Task 4, Epoch 191/200 => Loss 2.033, Train_accy 99.720, Test_accy 51.640
2024-01-11 09:00:12,120 [bic.py] => training => Task 4, Epoch 192/200 => Loss 2.021, Train_accy 99.680, Test_accy 51.940
2024-01-11 09:00:32,376 [bic.py] => training => Task 4, Epoch 193/200 => Loss 2.015, Train_accy 99.720, Test_accy 52.400
2024-01-11 09:00:52,317 [bic.py] => training => Task 4, Epoch 194/200 => Loss 2.027, Train_accy 99.670, Test_accy 52.000
2024-01-11 09:01:12,310 [bic.py] => training => Task 4, Epoch 195/200 => Loss 2.034, Train_accy 99.650, Test_accy 51.270
2024-01-11 09:01:32,097 [bic.py] => training => Task 4, Epoch 196/200 => Loss 2.030, Train_accy 99.680, Test_accy 52.250
2024-01-11 09:01:51,857 [bic.py] => training => Task 4, Epoch 197/200 => Loss 2.017, Train_accy 99.800, Test_accy 52.700
2024-01-11 09:02:11,765 [bic.py] => training => Task 4, Epoch 198/200 => Loss 2.023, Train_accy 99.650, Test_accy 51.610
2024-01-11 09:02:31,870 [bic.py] => training => Task 4, Epoch 199/200 => Loss 2.027, Train_accy 99.760, Test_accy 52.790
2024-01-11 09:02:53,027 [bic.py] => training => Task 4, Epoch 200/200 => Loss 2.033, Train_accy 99.680, Test_accy 51.780
2024-01-11 09:03:01,892 [bic.py] => bias_correction => Task 4, Epoch 1/200 => Loss 3.777, Train_accy 44.850, Test_accy 50.610
2024-01-11 09:03:10,572 [bic.py] => bias_correction => Task 4, Epoch 2/200 => Loss 3.809, Train_accy 44.240, Test_accy 49.720
2024-01-11 09:03:19,469 [bic.py] => bias_correction => Task 4, Epoch 3/200 => Loss 3.813, Train_accy 42.420, Test_accy 49.210
2024-01-11 09:03:28,180 [bic.py] => bias_correction => Task 4, Epoch 4/200 => Loss 3.775, Train_accy 44.240, Test_accy 49.520
2024-01-11 09:03:36,883 [bic.py] => bias_correction => Task 4, Epoch 5/200 => Loss 3.737, Train_accy 43.030, Test_accy 49.240
2024-01-11 09:03:45,617 [bic.py] => bias_correction => Task 4, Epoch 6/200 => Loss 3.738, Train_accy 42.420, Test_accy 47.950
2024-01-11 09:03:54,208 [bic.py] => bias_correction => Task 4, Epoch 7/200 => Loss 3.788, Train_accy 43.640, Test_accy 47.150
2024-01-11 09:04:03,305 [bic.py] => bias_correction => Task 4, Epoch 8/200 => Loss 3.797, Train_accy 44.850, Test_accy 47.030
2024-01-11 09:04:12,286 [bic.py] => bias_correction => Task 4, Epoch 9/200 => Loss 3.769, Train_accy 44.240, Test_accy 46.020
2024-01-11 09:04:20,863 [bic.py] => bias_correction => Task 4, Epoch 10/200 => Loss 3.780, Train_accy 40.610, Test_accy 44.170
2024-01-11 09:04:29,760 [bic.py] => bias_correction => Task 4, Epoch 11/200 => Loss 3.758, Train_accy 38.180, Test_accy 43.080
2024-01-11 09:04:38,534 [bic.py] => bias_correction => Task 4, Epoch 12/200 => Loss 3.756, Train_accy 38.790, Test_accy 43.090
2024-01-11 09:04:47,201 [bic.py] => bias_correction => Task 4, Epoch 13/200 => Loss 3.789, Train_accy 38.790, Test_accy 42.890
2024-01-11 09:04:55,751 [bic.py] => bias_correction => Task 4, Epoch 14/200 => Loss 3.750, Train_accy 39.390, Test_accy 44.100
2024-01-11 09:05:04,419 [bic.py] => bias_correction => Task 4, Epoch 15/200 => Loss 3.734, Train_accy 41.210, Test_accy 44.750
2024-01-11 09:05:13,110 [bic.py] => bias_correction => Task 4, Epoch 16/200 => Loss 3.767, Train_accy 40.610, Test_accy 44.800
2024-01-11 09:05:21,759 [bic.py] => bias_correction => Task 4, Epoch 17/200 => Loss 3.774, Train_accy 41.210, Test_accy 44.460
2024-01-11 09:05:30,344 [bic.py] => bias_correction => Task 4, Epoch 18/200 => Loss 3.768, Train_accy 41.210, Test_accy 44.060
2024-01-11 09:05:39,203 [bic.py] => bias_correction => Task 4, Epoch 19/200 => Loss 3.764, Train_accy 40.610, Test_accy 44.100
2024-01-11 09:05:48,000 [bic.py] => bias_correction => Task 4, Epoch 20/200 => Loss 3.781, Train_accy 39.390, Test_accy 44.150
2024-01-11 09:05:56,665 [bic.py] => bias_correction => Task 4, Epoch 21/200 => Loss 3.790, Train_accy 40.610, Test_accy 43.630
2024-01-11 09:06:05,227 [bic.py] => bias_correction => Task 4, Epoch 22/200 => Loss 3.756, Train_accy 39.390, Test_accy 44.320
2024-01-11 09:06:13,905 [bic.py] => bias_correction => Task 4, Epoch 23/200 => Loss 3.753, Train_accy 38.180, Test_accy 44.090
2024-01-11 09:06:22,621 [bic.py] => bias_correction => Task 4, Epoch 24/200 => Loss 3.748, Train_accy 40.000, Test_accy 44.080
2024-01-11 09:06:31,154 [bic.py] => bias_correction => Task 4, Epoch 25/200 => Loss 3.753, Train_accy 38.790, Test_accy 43.550
2024-01-11 09:06:39,843 [bic.py] => bias_correction => Task 4, Epoch 26/200 => Loss 3.739, Train_accy 40.000, Test_accy 43.640
2024-01-11 09:06:48,471 [bic.py] => bias_correction => Task 4, Epoch 27/200 => Loss 3.764, Train_accy 38.180, Test_accy 43.410
2024-01-11 09:06:57,103 [bic.py] => bias_correction => Task 4, Epoch 28/200 => Loss 3.779, Train_accy 39.390, Test_accy 43.990
2024-01-11 09:07:05,804 [bic.py] => bias_correction => Task 4, Epoch 29/200 => Loss 3.781, Train_accy 40.000, Test_accy 43.790
2024-01-11 09:07:14,296 [bic.py] => bias_correction => Task 4, Epoch 30/200 => Loss 3.756, Train_accy 40.000, Test_accy 44.100
2024-01-11 09:07:22,924 [bic.py] => bias_correction => Task 4, Epoch 31/200 => Loss 3.756, Train_accy 40.610, Test_accy 43.760
2024-01-11 09:07:31,602 [bic.py] => bias_correction => Task 4, Epoch 32/200 => Loss 3.756, Train_accy 40.000, Test_accy 43.800
2024-01-11 09:07:40,274 [bic.py] => bias_correction => Task 4, Epoch 33/200 => Loss 3.756, Train_accy 38.790, Test_accy 43.460
2024-01-11 09:07:49,044 [bic.py] => bias_correction => Task 4, Epoch 34/200 => Loss 3.762, Train_accy 39.390, Test_accy 43.430
2024-01-11 09:07:57,650 [bic.py] => bias_correction => Task 4, Epoch 35/200 => Loss 3.778, Train_accy 38.790, Test_accy 43.450
2024-01-11 09:08:06,305 [bic.py] => bias_correction => Task 4, Epoch 36/200 => Loss 3.742, Train_accy 38.180, Test_accy 43.450
2024-01-11 09:08:14,887 [bic.py] => bias_correction => Task 4, Epoch 37/200 => Loss 3.772, Train_accy 37.580, Test_accy 43.580
2024-01-11 09:08:23,521 [bic.py] => bias_correction => Task 4, Epoch 38/200 => Loss 3.754, Train_accy 40.000, Test_accy 44.140
2024-01-11 09:08:32,203 [bic.py] => bias_correction => Task 4, Epoch 39/200 => Loss 3.741, Train_accy 40.610, Test_accy 43.950
2024-01-11 09:08:40,783 [bic.py] => bias_correction => Task 4, Epoch 40/200 => Loss 3.758, Train_accy 41.210, Test_accy 44.400
2024-01-11 09:08:49,468 [bic.py] => bias_correction => Task 4, Epoch 41/200 => Loss 3.772, Train_accy 40.000, Test_accy 44.160
2024-01-11 09:08:58,136 [bic.py] => bias_correction => Task 4, Epoch 42/200 => Loss 3.758, Train_accy 40.000, Test_accy 43.870
2024-01-11 09:09:07,088 [bic.py] => bias_correction => Task 4, Epoch 43/200 => Loss 3.768, Train_accy 40.000, Test_accy 44.110
2024-01-11 09:09:15,914 [bic.py] => bias_correction => Task 4, Epoch 44/200 => Loss 3.746, Train_accy 40.000, Test_accy 44.550
2024-01-11 09:09:24,602 [bic.py] => bias_correction => Task 4, Epoch 45/200 => Loss 3.731, Train_accy 39.390, Test_accy 44.360
2024-01-11 09:09:33,238 [bic.py] => bias_correction => Task 4, Epoch 46/200 => Loss 3.731, Train_accy 40.610, Test_accy 44.750
2024-01-11 09:09:41,765 [bic.py] => bias_correction => Task 4, Epoch 47/200 => Loss 3.754, Train_accy 40.000, Test_accy 44.530
2024-01-11 09:09:50,480 [bic.py] => bias_correction => Task 4, Epoch 48/200 => Loss 3.785, Train_accy 40.000, Test_accy 44.020
2024-01-11 09:09:59,105 [bic.py] => bias_correction => Task 4, Epoch 49/200 => Loss 3.728, Train_accy 37.580, Test_accy 43.610
2024-01-11 09:10:07,685 [bic.py] => bias_correction => Task 4, Epoch 50/200 => Loss 3.722, Train_accy 38.180, Test_accy 42.820
2024-01-11 09:10:16,255 [bic.py] => bias_correction => Task 4, Epoch 51/200 => Loss 3.749, Train_accy 38.180, Test_accy 42.110
2024-01-11 09:10:24,860 [bic.py] => bias_correction => Task 4, Epoch 52/200 => Loss 3.753, Train_accy 38.180, Test_accy 42.560
2024-01-11 09:10:33,519 [bic.py] => bias_correction => Task 4, Epoch 53/200 => Loss 3.751, Train_accy 37.580, Test_accy 42.940
2024-01-11 09:10:42,070 [bic.py] => bias_correction => Task 4, Epoch 54/200 => Loss 3.737, Train_accy 38.790, Test_accy 44.220
2024-01-11 09:10:50,652 [bic.py] => bias_correction => Task 4, Epoch 55/200 => Loss 3.777, Train_accy 38.790, Test_accy 44.800
2024-01-11 09:10:59,213 [bic.py] => bias_correction => Task 4, Epoch 56/200 => Loss 3.773, Train_accy 39.390, Test_accy 44.580
2024-01-11 09:11:07,802 [bic.py] => bias_correction => Task 4, Epoch 57/200 => Loss 3.755, Train_accy 40.000, Test_accy 44.650
2024-01-11 09:11:16,406 [bic.py] => bias_correction => Task 4, Epoch 58/200 => Loss 3.740, Train_accy 39.390, Test_accy 44.680
2024-01-11 09:11:25,083 [bic.py] => bias_correction => Task 4, Epoch 59/200 => Loss 3.749, Train_accy 39.390, Test_accy 44.210
2024-01-11 09:11:33,640 [bic.py] => bias_correction => Task 4, Epoch 60/200 => Loss 3.750, Train_accy 38.790, Test_accy 43.940
2024-01-11 09:11:42,783 [bic.py] => bias_correction => Task 4, Epoch 61/200 => Loss 3.726, Train_accy 38.790, Test_accy 44.210
2024-01-11 09:11:52,382 [bic.py] => bias_correction => Task 4, Epoch 62/200 => Loss 3.778, Train_accy 38.790, Test_accy 44.150
2024-01-11 09:12:01,164 [bic.py] => bias_correction => Task 4, Epoch 63/200 => Loss 3.749, Train_accy 37.580, Test_accy 43.950
2024-01-11 09:12:09,779 [bic.py] => bias_correction => Task 4, Epoch 64/200 => Loss 3.743, Train_accy 39.390, Test_accy 43.710
2024-01-11 09:12:18,753 [bic.py] => bias_correction => Task 4, Epoch 65/200 => Loss 3.729, Train_accy 38.180, Test_accy 44.020
2024-01-11 09:12:27,599 [bic.py] => bias_correction => Task 4, Epoch 66/200 => Loss 3.800, Train_accy 39.390, Test_accy 43.810
2024-01-11 09:12:36,189 [bic.py] => bias_correction => Task 4, Epoch 67/200 => Loss 3.733, Train_accy 38.790, Test_accy 43.930
2024-01-11 09:12:44,865 [bic.py] => bias_correction => Task 4, Epoch 68/200 => Loss 3.769, Train_accy 38.180, Test_accy 43.820
2024-01-11 09:12:53,407 [bic.py] => bias_correction => Task 4, Epoch 69/200 => Loss 3.733, Train_accy 38.790, Test_accy 44.270
2024-01-11 09:13:02,060 [bic.py] => bias_correction => Task 4, Epoch 70/200 => Loss 3.745, Train_accy 39.390, Test_accy 44.430
2024-01-11 09:13:10,669 [bic.py] => bias_correction => Task 4, Epoch 71/200 => Loss 3.730, Train_accy 39.390, Test_accy 44.650
2024-01-11 09:13:19,366 [bic.py] => bias_correction => Task 4, Epoch 72/200 => Loss 3.765, Train_accy 41.210, Test_accy 44.560
2024-01-11 09:13:27,950 [bic.py] => bias_correction => Task 4, Epoch 73/200 => Loss 3.772, Train_accy 41.210, Test_accy 44.440
2024-01-11 09:13:36,605 [bic.py] => bias_correction => Task 4, Epoch 74/200 => Loss 3.757, Train_accy 40.610, Test_accy 44.410
2024-01-11 09:13:45,237 [bic.py] => bias_correction => Task 4, Epoch 75/200 => Loss 3.781, Train_accy 41.820, Test_accy 44.250
2024-01-11 09:13:54,729 [bic.py] => bias_correction => Task 4, Epoch 76/200 => Loss 3.751, Train_accy 40.610, Test_accy 43.860
2024-01-11 09:14:03,724 [bic.py] => bias_correction => Task 4, Epoch 77/200 => Loss 3.755, Train_accy 40.610, Test_accy 43.860
2024-01-11 09:14:12,433 [bic.py] => bias_correction => Task 4, Epoch 78/200 => Loss 3.773, Train_accy 41.820, Test_accy 44.010
2024-01-11 09:14:21,048 [bic.py] => bias_correction => Task 4, Epoch 79/200 => Loss 3.767, Train_accy 40.610, Test_accy 44.090
2024-01-11 09:14:29,574 [bic.py] => bias_correction => Task 4, Epoch 80/200 => Loss 3.736, Train_accy 40.610, Test_accy 44.200
2024-01-11 09:14:38,160 [bic.py] => bias_correction => Task 4, Epoch 81/200 => Loss 3.731, Train_accy 40.000, Test_accy 44.180
2024-01-11 09:14:46,747 [bic.py] => bias_correction => Task 4, Epoch 82/200 => Loss 3.749, Train_accy 40.000, Test_accy 44.530
2024-01-11 09:14:55,450 [bic.py] => bias_correction => Task 4, Epoch 83/200 => Loss 3.771, Train_accy 40.610, Test_accy 44.100
2024-01-11 09:15:04,357 [bic.py] => bias_correction => Task 4, Epoch 84/200 => Loss 3.732, Train_accy 41.210, Test_accy 44.150
2024-01-11 09:15:13,551 [bic.py] => bias_correction => Task 4, Epoch 85/200 => Loss 3.743, Train_accy 40.610, Test_accy 44.340
2024-01-11 09:15:22,111 [bic.py] => bias_correction => Task 4, Epoch 86/200 => Loss 3.756, Train_accy 38.790, Test_accy 44.420
2024-01-11 09:15:31,046 [bic.py] => bias_correction => Task 4, Epoch 87/200 => Loss 3.754, Train_accy 38.790, Test_accy 44.350
2024-01-11 09:15:39,963 [bic.py] => bias_correction => Task 4, Epoch 88/200 => Loss 3.780, Train_accy 40.000, Test_accy 43.820
2024-01-11 09:15:48,619 [bic.py] => bias_correction => Task 4, Epoch 89/200 => Loss 3.775, Train_accy 40.610, Test_accy 43.890
2024-01-11 09:15:57,368 [bic.py] => bias_correction => Task 4, Epoch 90/200 => Loss 3.792, Train_accy 40.000, Test_accy 43.630
2024-01-11 09:16:06,011 [bic.py] => bias_correction => Task 4, Epoch 91/200 => Loss 3.718, Train_accy 40.000, Test_accy 43.860
2024-01-11 09:16:14,520 [bic.py] => bias_correction => Task 4, Epoch 92/200 => Loss 3.737, Train_accy 39.390, Test_accy 43.740
2024-01-11 09:16:23,093 [bic.py] => bias_correction => Task 4, Epoch 93/200 => Loss 3.721, Train_accy 39.390, Test_accy 43.840
2024-01-11 09:16:31,765 [bic.py] => bias_correction => Task 4, Epoch 94/200 => Loss 3.760, Train_accy 38.790, Test_accy 43.770
2024-01-11 09:16:40,440 [bic.py] => bias_correction => Task 4, Epoch 95/200 => Loss 3.773, Train_accy 39.390, Test_accy 43.650
2024-01-11 09:16:48,983 [bic.py] => bias_correction => Task 4, Epoch 96/200 => Loss 3.728, Train_accy 39.390, Test_accy 43.960
2024-01-11 09:16:57,598 [bic.py] => bias_correction => Task 4, Epoch 97/200 => Loss 3.783, Train_accy 40.000, Test_accy 43.930
2024-01-11 09:17:06,211 [bic.py] => bias_correction => Task 4, Epoch 98/200 => Loss 3.741, Train_accy 39.390, Test_accy 43.940
2024-01-11 09:17:14,965 [bic.py] => bias_correction => Task 4, Epoch 99/200 => Loss 3.738, Train_accy 38.180, Test_accy 44.180
2024-01-11 09:17:23,666 [bic.py] => bias_correction => Task 4, Epoch 100/200 => Loss 3.737, Train_accy 39.390, Test_accy 44.230
2024-01-11 09:17:32,310 [bic.py] => bias_correction => Task 4, Epoch 101/200 => Loss 3.757, Train_accy 40.000, Test_accy 43.900
2024-01-11 09:17:40,929 [bic.py] => bias_correction => Task 4, Epoch 102/200 => Loss 3.766, Train_accy 40.610, Test_accy 43.990
2024-01-11 09:17:49,532 [bic.py] => bias_correction => Task 4, Epoch 103/200 => Loss 3.744, Train_accy 40.000, Test_accy 44.470
2024-01-11 09:17:58,185 [bic.py] => bias_correction => Task 4, Epoch 104/200 => Loss 3.761, Train_accy 40.000, Test_accy 44.580
2024-01-11 09:18:06,807 [bic.py] => bias_correction => Task 4, Epoch 105/200 => Loss 3.738, Train_accy 40.000, Test_accy 44.930
2024-01-11 09:18:15,445 [bic.py] => bias_correction => Task 4, Epoch 106/200 => Loss 3.754, Train_accy 39.390, Test_accy 44.630
2024-01-11 09:18:24,171 [bic.py] => bias_correction => Task 4, Epoch 107/200 => Loss 3.736, Train_accy 40.610, Test_accy 44.430
2024-01-11 09:18:32,769 [bic.py] => bias_correction => Task 4, Epoch 108/200 => Loss 3.720, Train_accy 40.000, Test_accy 44.390
2024-01-11 09:18:41,471 [bic.py] => bias_correction => Task 4, Epoch 109/200 => Loss 3.769, Train_accy 40.000, Test_accy 44.340
2024-01-11 09:18:50,323 [bic.py] => bias_correction => Task 4, Epoch 110/200 => Loss 3.764, Train_accy 41.210, Test_accy 44.150
2024-01-11 09:18:59,176 [bic.py] => bias_correction => Task 4, Epoch 111/200 => Loss 3.712, Train_accy 39.390, Test_accy 44.250
2024-01-11 09:19:07,777 [bic.py] => bias_correction => Task 4, Epoch 112/200 => Loss 3.777, Train_accy 38.180, Test_accy 43.630
2024-01-11 09:19:16,301 [bic.py] => bias_correction => Task 4, Epoch 113/200 => Loss 3.729, Train_accy 39.390, Test_accy 43.770
2024-01-11 09:19:25,216 [bic.py] => bias_correction => Task 4, Epoch 114/200 => Loss 3.739, Train_accy 39.390, Test_accy 43.640
2024-01-11 09:19:33,942 [bic.py] => bias_correction => Task 4, Epoch 115/200 => Loss 3.780, Train_accy 40.000, Test_accy 43.590
2024-01-11 09:19:42,539 [bic.py] => bias_correction => Task 4, Epoch 116/200 => Loss 3.788, Train_accy 38.180, Test_accy 43.490
2024-01-11 09:19:51,161 [bic.py] => bias_correction => Task 4, Epoch 117/200 => Loss 3.739, Train_accy 39.390, Test_accy 43.520
2024-01-11 09:20:00,442 [bic.py] => bias_correction => Task 4, Epoch 118/200 => Loss 3.728, Train_accy 40.000, Test_accy 43.850
2024-01-11 09:20:10,233 [bic.py] => bias_correction => Task 4, Epoch 119/200 => Loss 3.758, Train_accy 38.790, Test_accy 43.770
2024-01-11 09:20:18,774 [bic.py] => bias_correction => Task 4, Epoch 120/200 => Loss 3.756, Train_accy 39.390, Test_accy 43.930
2024-01-11 09:20:27,368 [bic.py] => bias_correction => Task 4, Epoch 121/200 => Loss 3.749, Train_accy 38.790, Test_accy 44.020
2024-01-11 09:20:35,960 [bic.py] => bias_correction => Task 4, Epoch 122/200 => Loss 3.742, Train_accy 39.390, Test_accy 44.040
2024-01-11 09:20:44,587 [bic.py] => bias_correction => Task 4, Epoch 123/200 => Loss 3.748, Train_accy 39.390, Test_accy 44.250
2024-01-11 09:20:53,384 [bic.py] => bias_correction => Task 4, Epoch 124/200 => Loss 3.741, Train_accy 39.390, Test_accy 44.260
2024-01-11 09:21:01,921 [bic.py] => bias_correction => Task 4, Epoch 125/200 => Loss 3.744, Train_accy 40.000, Test_accy 44.110
2024-01-11 09:21:10,606 [bic.py] => bias_correction => Task 4, Epoch 126/200 => Loss 3.756, Train_accy 39.390, Test_accy 44.160
2024-01-11 09:21:19,150 [bic.py] => bias_correction => Task 4, Epoch 127/200 => Loss 3.731, Train_accy 40.610, Test_accy 44.550
2024-01-11 09:21:27,729 [bic.py] => bias_correction => Task 4, Epoch 128/200 => Loss 3.717, Train_accy 38.790, Test_accy 44.800
2024-01-11 09:21:36,322 [bic.py] => bias_correction => Task 4, Epoch 129/200 => Loss 3.727, Train_accy 40.610, Test_accy 44.920
2024-01-11 09:21:44,886 [bic.py] => bias_correction => Task 4, Epoch 130/200 => Loss 3.740, Train_accy 40.000, Test_accy 44.890
2024-01-11 09:21:53,514 [bic.py] => bias_correction => Task 4, Epoch 131/200 => Loss 3.756, Train_accy 38.790, Test_accy 44.950
2024-01-11 09:22:02,008 [bic.py] => bias_correction => Task 4, Epoch 132/200 => Loss 3.734, Train_accy 39.390, Test_accy 44.770
2024-01-11 09:22:10,854 [bic.py] => bias_correction => Task 4, Epoch 133/200 => Loss 3.749, Train_accy 40.000, Test_accy 44.610
2024-01-11 09:22:19,577 [bic.py] => bias_correction => Task 4, Epoch 134/200 => Loss 3.727, Train_accy 39.390, Test_accy 44.920
2024-01-11 09:22:28,146 [bic.py] => bias_correction => Task 4, Epoch 135/200 => Loss 3.762, Train_accy 40.610, Test_accy 44.770
2024-01-11 09:22:36,816 [bic.py] => bias_correction => Task 4, Epoch 136/200 => Loss 3.780, Train_accy 40.000, Test_accy 44.960
2024-01-11 09:22:45,401 [bic.py] => bias_correction => Task 4, Epoch 137/200 => Loss 3.761, Train_accy 40.000, Test_accy 45.140
2024-01-11 09:22:53,917 [bic.py] => bias_correction => Task 4, Epoch 138/200 => Loss 3.766, Train_accy 38.790, Test_accy 44.890
2024-01-11 09:23:02,569 [bic.py] => bias_correction => Task 4, Epoch 139/200 => Loss 3.749, Train_accy 38.180, Test_accy 44.580
2024-01-11 09:23:11,099 [bic.py] => bias_correction => Task 4, Epoch 140/200 => Loss 3.742, Train_accy 39.390, Test_accy 44.610
2024-01-11 09:23:19,748 [bic.py] => bias_correction => Task 4, Epoch 141/200 => Loss 3.766, Train_accy 39.390, Test_accy 44.220
2024-01-11 09:23:28,254 [bic.py] => bias_correction => Task 4, Epoch 142/200 => Loss 3.759, Train_accy 38.790, Test_accy 44.300
2024-01-11 09:23:36,914 [bic.py] => bias_correction => Task 4, Epoch 143/200 => Loss 3.771, Train_accy 38.790, Test_accy 43.790
2024-01-11 09:23:45,519 [bic.py] => bias_correction => Task 4, Epoch 144/200 => Loss 3.752, Train_accy 38.790, Test_accy 44.050
2024-01-11 09:23:54,006 [bic.py] => bias_correction => Task 4, Epoch 145/200 => Loss 3.740, Train_accy 38.790, Test_accy 44.080
2024-01-11 09:24:02,731 [bic.py] => bias_correction => Task 4, Epoch 146/200 => Loss 3.779, Train_accy 39.390, Test_accy 43.730
2024-01-11 09:24:11,370 [bic.py] => bias_correction => Task 4, Epoch 147/200 => Loss 3.766, Train_accy 39.390, Test_accy 43.840
2024-01-11 09:24:20,037 [bic.py] => bias_correction => Task 4, Epoch 148/200 => Loss 3.752, Train_accy 38.790, Test_accy 44.240
2024-01-11 09:24:28,576 [bic.py] => bias_correction => Task 4, Epoch 149/200 => Loss 3.751, Train_accy 40.000, Test_accy 44.440
2024-01-11 09:24:37,143 [bic.py] => bias_correction => Task 4, Epoch 150/200 => Loss 3.766, Train_accy 41.820, Test_accy 44.230
2024-01-11 09:24:45,673 [bic.py] => bias_correction => Task 4, Epoch 151/200 => Loss 3.757, Train_accy 41.210, Test_accy 43.790
2024-01-11 09:24:54,290 [bic.py] => bias_correction => Task 4, Epoch 152/200 => Loss 3.765, Train_accy 40.610, Test_accy 43.540
2024-01-11 09:25:02,952 [bic.py] => bias_correction => Task 4, Epoch 153/200 => Loss 3.719, Train_accy 41.210, Test_accy 44.070
2024-01-11 09:25:11,614 [bic.py] => bias_correction => Task 4, Epoch 154/200 => Loss 3.767, Train_accy 40.000, Test_accy 43.790
2024-01-11 09:25:20,288 [bic.py] => bias_correction => Task 4, Epoch 155/200 => Loss 3.771, Train_accy 39.390, Test_accy 43.520
2024-01-11 09:25:28,840 [bic.py] => bias_correction => Task 4, Epoch 156/200 => Loss 3.730, Train_accy 40.000, Test_accy 43.980
2024-01-11 09:25:37,348 [bic.py] => bias_correction => Task 4, Epoch 157/200 => Loss 3.767, Train_accy 40.000, Test_accy 43.810
2024-01-11 09:25:45,936 [bic.py] => bias_correction => Task 4, Epoch 158/200 => Loss 3.726, Train_accy 41.210, Test_accy 44.130
2024-01-11 09:25:54,547 [bic.py] => bias_correction => Task 4, Epoch 159/200 => Loss 3.746, Train_accy 41.820, Test_accy 44.380
2024-01-11 09:26:03,151 [bic.py] => bias_correction => Task 4, Epoch 160/200 => Loss 3.739, Train_accy 42.420, Test_accy 44.590
2024-01-11 09:26:11,690 [bic.py] => bias_correction => Task 4, Epoch 161/200 => Loss 3.738, Train_accy 40.610, Test_accy 44.460
2024-01-11 09:26:20,261 [bic.py] => bias_correction => Task 4, Epoch 162/200 => Loss 3.770, Train_accy 41.210, Test_accy 44.540
2024-01-11 09:26:28,854 [bic.py] => bias_correction => Task 4, Epoch 163/200 => Loss 3.766, Train_accy 39.390, Test_accy 44.460
2024-01-11 09:26:37,565 [bic.py] => bias_correction => Task 4, Epoch 164/200 => Loss 3.772, Train_accy 41.820, Test_accy 44.520
2024-01-11 09:26:46,473 [bic.py] => bias_correction => Task 4, Epoch 165/200 => Loss 3.764, Train_accy 38.790, Test_accy 44.290
2024-01-11 09:26:55,111 [bic.py] => bias_correction => Task 4, Epoch 166/200 => Loss 3.764, Train_accy 39.390, Test_accy 44.390
2024-01-11 09:27:03,638 [bic.py] => bias_correction => Task 4, Epoch 167/200 => Loss 3.744, Train_accy 38.180, Test_accy 44.120
2024-01-11 09:27:12,218 [bic.py] => bias_correction => Task 4, Epoch 168/200 => Loss 3.757, Train_accy 38.790, Test_accy 43.930
2024-01-11 09:27:20,849 [bic.py] => bias_correction => Task 4, Epoch 169/200 => Loss 3.764, Train_accy 39.390, Test_accy 43.860
2024-01-11 09:27:29,427 [bic.py] => bias_correction => Task 4, Epoch 170/200 => Loss 3.755, Train_accy 40.000, Test_accy 44.220
2024-01-11 09:27:38,034 [bic.py] => bias_correction => Task 4, Epoch 171/200 => Loss 3.756, Train_accy 38.790, Test_accy 43.970
2024-01-11 09:27:46,743 [bic.py] => bias_correction => Task 4, Epoch 172/200 => Loss 3.747, Train_accy 38.790, Test_accy 44.120
2024-01-11 09:27:55,439 [bic.py] => bias_correction => Task 4, Epoch 173/200 => Loss 3.736, Train_accy 40.610, Test_accy 44.260
2024-01-11 09:28:04,103 [bic.py] => bias_correction => Task 4, Epoch 174/200 => Loss 3.789, Train_accy 40.000, Test_accy 44.170
2024-01-11 09:28:12,914 [bic.py] => bias_correction => Task 4, Epoch 175/200 => Loss 3.756, Train_accy 40.610, Test_accy 44.420
2024-01-11 09:28:21,412 [bic.py] => bias_correction => Task 4, Epoch 176/200 => Loss 3.752, Train_accy 40.000, Test_accy 44.440
2024-01-11 09:28:30,309 [bic.py] => bias_correction => Task 4, Epoch 177/200 => Loss 3.772, Train_accy 41.210, Test_accy 44.470
2024-01-11 09:28:39,068 [bic.py] => bias_correction => Task 4, Epoch 178/200 => Loss 3.763, Train_accy 41.820, Test_accy 44.520
2024-01-11 09:28:47,853 [bic.py] => bias_correction => Task 4, Epoch 179/200 => Loss 3.772, Train_accy 40.000, Test_accy 44.350
2024-01-11 09:28:56,524 [bic.py] => bias_correction => Task 4, Epoch 180/200 => Loss 3.730, Train_accy 40.610, Test_accy 44.270
2024-01-11 09:29:05,183 [bic.py] => bias_correction => Task 4, Epoch 181/200 => Loss 3.757, Train_accy 40.000, Test_accy 43.980
2024-01-11 09:29:13,685 [bic.py] => bias_correction => Task 4, Epoch 182/200 => Loss 3.736, Train_accy 39.390, Test_accy 44.240
2024-01-11 09:29:22,254 [bic.py] => bias_correction => Task 4, Epoch 183/200 => Loss 3.728, Train_accy 40.000, Test_accy 44.050
2024-01-11 09:29:30,844 [bic.py] => bias_correction => Task 4, Epoch 184/200 => Loss 3.763, Train_accy 37.580, Test_accy 43.670
2024-01-11 09:29:39,558 [bic.py] => bias_correction => Task 4, Epoch 185/200 => Loss 3.767, Train_accy 37.580, Test_accy 43.810
2024-01-11 09:29:48,242 [bic.py] => bias_correction => Task 4, Epoch 186/200 => Loss 3.753, Train_accy 37.580, Test_accy 43.710
2024-01-11 09:29:57,058 [bic.py] => bias_correction => Task 4, Epoch 187/200 => Loss 3.757, Train_accy 40.000, Test_accy 43.940
2024-01-11 09:30:05,412 [bic.py] => bias_correction => Task 4, Epoch 188/200 => Loss 3.750, Train_accy 38.790, Test_accy 43.880
2024-01-11 09:30:14,300 [bic.py] => bias_correction => Task 4, Epoch 189/200 => Loss 3.756, Train_accy 39.390, Test_accy 43.850
2024-01-11 09:30:23,164 [bic.py] => bias_correction => Task 4, Epoch 190/200 => Loss 3.751, Train_accy 37.580, Test_accy 44.220
2024-01-11 09:30:31,839 [bic.py] => bias_correction => Task 4, Epoch 191/200 => Loss 3.741, Train_accy 40.610, Test_accy 44.740
2024-01-11 09:30:40,622 [bic.py] => bias_correction => Task 4, Epoch 192/200 => Loss 3.759, Train_accy 38.180, Test_accy 44.660
2024-01-11 09:30:49,338 [bic.py] => bias_correction => Task 4, Epoch 193/200 => Loss 3.727, Train_accy 40.000, Test_accy 44.650
2024-01-11 09:30:57,782 [bic.py] => bias_correction => Task 4, Epoch 194/200 => Loss 3.740, Train_accy 40.000, Test_accy 44.420
2024-01-11 09:31:06,395 [bic.py] => bias_correction => Task 4, Epoch 195/200 => Loss 3.753, Train_accy 38.180, Test_accy 44.470
2024-01-11 09:31:14,982 [bic.py] => bias_correction => Task 4, Epoch 196/200 => Loss 3.730, Train_accy 39.390, Test_accy 44.430
2024-01-11 09:31:23,760 [bic.py] => bias_correction => Task 4, Epoch 197/200 => Loss 3.758, Train_accy 40.000, Test_accy 44.550
2024-01-11 09:31:32,336 [bic.py] => bias_correction => Task 4, Epoch 198/200 => Loss 3.748, Train_accy 40.610, Test_accy 44.350
2024-01-11 09:31:40,947 [bic.py] => bias_correction => Task 4, Epoch 199/200 => Loss 3.750, Train_accy 39.390, Test_accy 44.250
2024-01-11 09:31:49,580 [bic.py] => bias_correction => Task 4, Epoch 200/200 => Loss 3.762, Train_accy 39.390, Test_accy 44.350
2024-01-11 09:31:49,581 [base.py] => Constructing exemplars for new classes...(30 per classes)
2024-01-11 09:32:16,932 [bic.py] => Parameters of bias layer:
2024-01-11 09:32:16,933 [bic.py] => 0 => 1.000, 0.000
2024-01-11 09:32:16,933 [bic.py] => 1 => 0.791, -2.133
2024-01-11 09:32:16,933 [bic.py] => 2 => 0.880, -1.721
2024-01-11 09:32:16,933 [bic.py] => 3 => 0.849, -1.720
2024-01-11 09:32:16,933 [bic.py] => 4 => 0.834, -1.586
2024-01-11 09:32:31,671 [bic.py] => Exemplar size: 1650
2024-01-11 09:32:31,832 [trainer.py] => CNN: {'total': 44.35, '0': 47.78, '1': 31.11, '2': 36.11, '3': 16.67, '4': 17.22, '5': 21.11, '6': 23.89, '7': 11.11, '8': 36.11, '9': 15.0, '10': 31.67, '11': 47.78, '12': 30.0, '13': 28.33, '14': 40.56, '15': 40.56, '16': 35.0, '17': 45.0, '18': 32.22, '19': 30.56, '20': 25.56, '21': 33.89, '22': 37.78, '23': 26.11, '24': 37.22, '25': 28.89, '26': 47.22, '27': 36.67, '28': 29.44, '29': 30.0, '30': 37.22, '31': 32.22, '32': 66.67, '33': 27.22, '34': 48.89, '35': 61.11, '36': 42.22, '37': 13.33, '38': 42.78, '39': 58.33, '40': 50.56, '41': 60.56, '42': 70.0, '43': 65.0, '44': 37.78, '45': 71.11, '46': 82.78, '47': 75.0, '48': 75.0, '49': 68.33, '50': 75.56, '51': 77.22, '52': 86.67, '53': 82.78, 'old': 36.99, 'new': 77.5}
2024-01-11 09:32:31,832 [trainer.py] => NME: {'total': 48.48, '0': 69.44, '1': 39.44, '2': 53.89, '3': 20.0, '4': 43.33, '5': 26.67, '6': 29.44, '7': 33.89, '8': 32.78, '9': 31.67, '10': 41.11, '11': 60.0, '12': 36.67, '13': 47.22, '14': 47.78, '15': 52.78, '16': 66.67, '17': 60.0, '18': 50.0, '19': 46.11, '20': 62.22, '21': 46.11, '22': 55.56, '23': 52.22, '24': 40.56, '25': 39.44, '26': 45.56, '27': 45.56, '28': 21.11, '29': 46.11, '30': 52.78, '31': 47.78, '32': 60.56, '33': 30.0, '34': 36.67, '35': 60.56, '36': 45.56, '37': 32.78, '38': 61.11, '39': 59.44, '40': 48.89, '41': 66.11, '42': 66.67, '43': 67.22, '44': 32.78, '45': 46.11, '46': 63.89, '47': 50.0, '48': 58.33, '49': 51.67, '50': 56.67, '51': 51.67, '52': 64.44, '53': 58.89, 'old': 46.94, 'new': 55.44}
2024-01-11 09:32:31,832 [trainer.py] => CNN top1 curve: [86.11, 64.91, 52.86, 50.1, 44.35]
2024-01-11 09:32:31,832 [trainer.py] => CNN top5 curve: [97.7, 93.13, 84.13, 80.38, 75.08]
2024-01-11 09:32:31,832 [trainer.py] => NME top1 curve: [84.37, 68.27, 51.03, 53.22, 48.48]
2024-01-11 09:32:31,832 [trainer.py] => NME top5 curve: [98.07, 95.18, 88.78, 87.2, 83.67]

2025-04-22 01:10:42,627 [trainer.py] => 实验名称:CIL实验
2025-04-22 01:10:42,680 [trainer.py] => config: ./exps/bic.json
2025-04-22 01:10:42,681 [trainer.py] => experiment_name: 实验名称:CIL实验
2025-04-22 01:10:42,681 [trainer.py] => prefix: reproduce
2025-04-22 01:10:42,681 [trainer.py] => dataset: xrfdataset
2025-04-22 01:10:42,681 [trainer.py] => memory_size: 1650
2025-04-22 01:10:42,681 [trainer.py] => memory_per_class: 30
2025-04-22 01:10:42,681 [trainer.py] => fixed_memory: True
2025-04-22 01:10:42,681 [trainer.py] => shuffle: True
2025-04-22 01:10:42,681 [trainer.py] => init_cls: 15
2025-04-22 01:10:42,681 [trainer.py] => increment: 10
2025-04-22 01:10:42,681 [trainer.py] => model_name: bic
2025-04-22 01:10:42,681 [trainer.py] => convnet_type: unet
2025-04-22 01:10:42,681 [trainer.py] => device: [device(type='cuda', index=2)]
2025-04-22 01:10:42,681 [trainer.py] => seed: 1993
2025-04-22 01:10:42,696 [data.py] => 加载完毕XRF原始数据集
2025-04-22 01:10:42,703 [data.py] => 加载完毕XRF原始数据集
2025-04-22 01:10:42,903 [trainer.py] => All params: 21041612
2025-04-22 01:10:42,903 [trainer.py] => Trainable params: 21041612
2025-04-22 01:10:42,904 [bic.py] => Learning on 0-15
2025-04-22 01:10:42,983 [bic.py] => Parameters of bias layer:
2025-04-22 01:10:42,983 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:11:03,764 [bic.py] => training => Task 0, Epoch 1/1 => Loss 2.472, Train_accy 14.330, Test_accy 13.560
2025-04-22 01:11:03,765 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:11:22,156 [bic.py] => Parameters of bias layer:
2025-04-22 01:11:22,157 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:11:28,555 [bic.py] => Exemplar size: 450
2025-04-22 01:11:28,784 [trainer.py] => CNN: {'total': 13.56, '0': 6.11, '1': 43.89, '2': 36.67, '3': 0.0, '4': 1.11, '5': 0.0, '6': 7.22, '7': 0.0, '8': 40.0, '9': 0.0, '10': 27.22, '11': 17.22, '12': 6.67, '13': 0.56, 'old': 0, 'new': 13.56}
2025-04-22 01:11:28,784 [trainer.py] => NME: {'total': 13.93, '0': 7.22, '1': 4.44, '2': 33.33, '3': 0.0, '4': 4.44, '5': 17.78, '6': 4.44, '7': 23.89, '8': 5.56, '9': 2.22, '10': 9.44, '11': 53.89, '12': 4.44, '13': 5.0, 'old': 0, 'new': 13.93}
2025-04-22 01:11:28,784 [trainer.py] => CNN top1 curve: [13.56]
2025-04-22 01:11:28,784 [trainer.py] => CNN top5 curve: [53.78]
2025-04-22 01:11:28,784 [trainer.py] => NME top1 curve: [13.93]
2025-04-22 01:11:28,784 [trainer.py] => NME top5 curve: [50.81]

2025-04-22 01:11:28,785 [trainer.py] => All params: 21043549
2025-04-22 01:11:28,785 [trainer.py] => Trainable params: 21043549
2025-04-22 01:11:28,787 [bic.py] => Learning on 15-25
2025-04-22 01:11:28,853 [bic.py] => Stage1 dset: 4105, Stage2 dset: 125
2025-04-22 01:11:28,853 [bic.py] => Lambda: 0.600
2025-04-22 01:11:28,895 [bic.py] => Parameters of bias layer:
2025-04-22 01:11:28,895 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:11:28,895 [bic.py] => 1 => 1.000, 0.000
2025-04-22 01:11:46,298 [bic.py] => training => Task 1, Epoch 1/1 => Loss 2.293, Train_accy 26.990, Test_accy 11.000
2025-04-22 01:11:53,443 [bic.py] => bias_correction => Task 1, Epoch 1/1 => Loss 3.117, Train_accy 26.400, Test_accy 11.070
2025-04-22 01:11:53,444 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:12:12,584 [bic.py] => Parameters of bias layer:
2025-04-22 01:12:12,584 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:12:12,584 [bic.py] => 1 => 1.005, 0.000
2025-04-22 01:12:22,263 [bic.py] => Exemplar size: 750
2025-04-22 01:12:22,475 [trainer.py] => CNN: {'total': 11.07, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 37.22, '16': 0.0, '17': 21.67, '18': 18.89, '19': 18.89, '20': 2.78, '21': 22.78, '22': 13.89, '23': 72.22, 'old': 0.0, 'new': 27.67}
2025-04-22 01:12:22,476 [trainer.py] => NME: {'total': 8.44, '0': 36.11, '1': 2.22, '2': 18.33, '3': 2.78, '4': 3.89, '5': 9.44, '6': 2.78, '7': 27.78, '8': 2.22, '9': 6.67, '10': 2.78, '11': 8.33, '12': 7.78, '13': 4.44, '14': 4.44, '15': 3.89, '16': 0.56, '17': 11.67, '18': 11.67, '19': 5.56, '20': 10.0, '21': 0.56, '22': 1.11, '23': 9.44, 'old': 9.33, 'new': 7.11}
2025-04-22 01:12:22,476 [trainer.py] => CNN top1 curve: [13.56, 11.07]
2025-04-22 01:12:22,476 [trainer.py] => CNN top5 curve: [53.78, 31.04]
2025-04-22 01:12:22,476 [trainer.py] => NME top1 curve: [13.93, 8.44]
2025-04-22 01:12:22,476 [trainer.py] => NME top5 curve: [50.81, 34.96]

2025-04-22 01:12:22,477 [trainer.py] => All params: 21044841
2025-04-22 01:12:22,477 [trainer.py] => Trainable params: 21044841
2025-04-22 01:12:22,478 [bic.py] => Learning on 25-35
2025-04-22 01:12:22,524 [bic.py] => Stage1 dset: 4165, Stage2 dset: 85
2025-04-22 01:12:22,524 [bic.py] => Lambda: 0.714
2025-04-22 01:12:22,577 [bic.py] => Parameters of bias layer:
2025-04-22 01:12:22,577 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:12:22,577 [bic.py] => 1 => 1.005, 0.000
2025-04-22 01:12:22,577 [bic.py] => 2 => 1.000, 0.000
2025-04-22 01:12:44,605 [bic.py] => training => Task 2, Epoch 1/1 => Loss 2.681, Train_accy 28.670, Test_accy 7.970
2025-04-22 01:12:53,180 [bic.py] => bias_correction => Task 2, Epoch 1/1 => Loss 3.439, Train_accy 21.180, Test_accy 8.080
2025-04-22 01:12:53,181 [base.py] => Constructing exemplars for new classes...(30 per classes)
2025-04-22 01:13:16,302 [bic.py] => Parameters of bias layer:
2025-04-22 01:13:16,303 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:13:16,303 [bic.py] => 1 => 1.005, 0.000
2025-04-22 01:13:16,303 [bic.py] => 2 => 1.006, 0.000
2025-04-22 01:13:28,804 [bic.py] => Exemplar size: 1050
2025-04-22 01:13:29,009 [trainer.py] => CNN: {'total': 8.08, '0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0, '10': 0.0, '11': 0.0, '12': 0.0, '13': 0.0, '14': 0.0, '15': 0.0, '16': 0.0, '17': 0.0, '18': 0.0, '19': 0.0, '20': 0.0, '21': 0.0, '22': 0.0, '23': 0.0, '24': 0.0, '25': 41.67, '26': 42.22, '27': 41.11, '28': 3.89, '29': 6.67, '30': 9.44, '31': 11.67, '32': 83.33, '33': 26.67, 'old': 0.0, 'new': 28.28}
2025-04-22 01:13:29,010 [trainer.py] => NME: {'total': 6.33, '0': 30.56, '1': 3.33, '2': 13.89, '3': 2.78, '4': 6.11, '5': 17.22, '6': 5.0, '7': 19.44, '8': 2.22, '9': 2.22, '10': 2.22, '11': 10.0, '12': 3.89, '13': 7.22, '14': 1.67, '15': 9.44, '16': 4.44, '17': 10.0, '18': 1.11, '19': 2.22, '20': 4.44, '21': 0.0, '22': 0.0, '23': 2.78, '24': 2.22, '25': 0.56, '26': 16.11, '27': 4.44, '28': 1.67, '29': 1.11, '30': 0.56, '31': 2.22, '32': 20.56, '33': 5.0, 'old': 6.58, 'new': 5.72}
2025-04-22 01:13:29,010 [trainer.py] => CNN top1 curve: [13.56, 11.07, 8.08]
2025-04-22 01:13:29,010 [trainer.py] => CNN top5 curve: [53.78, 31.04, 23.11]
2025-04-22 01:13:29,010 [trainer.py] => NME top1 curve: [13.93, 8.44, 6.33]
2025-04-22 01:13:29,010 [trainer.py] => NME top5 curve: [50.81, 34.96, 27.27]

2025-04-22 01:13:29,010 [trainer.py] => All params: 21046133
2025-04-22 01:13:29,011 [trainer.py] => Trainable params: 21046133
2025-04-22 01:13:29,011 [bic.py] => Learning on 35-45
2025-04-22 01:13:29,063 [bic.py] => Stage1 dset: 4195, Stage2 dset: 75
2025-04-22 01:13:29,063 [bic.py] => Lambda: 0.778
2025-04-22 01:13:29,136 [bic.py] => Parameters of bias layer:
2025-04-22 01:13:29,136 [bic.py] => 0 => 1.000, 0.000
2025-04-22 01:13:29,136 [bic.py] => 1 => 1.005, 0.000
2025-04-22 01:13:29,136 [bic.py] => 2 => 1.006, 0.000
2025-04-22 01:13:29,137 [bic.py] => 3 => 1.000, 0.000
